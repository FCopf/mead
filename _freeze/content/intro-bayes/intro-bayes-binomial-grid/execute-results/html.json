{
  "hash": "6c3490c1206710ec103b3ac553bbfa36",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Inferência Bayesiana Binomial\"  \nsubtitle: \"Estimando $p$ via aproximação por Grid\"  \ndescription: \"Introdução ao conceito de aproximação por grid na abordagem bayesiana.\"\nCategories: [\n          \"Inferência bayesiana\",\n          \"Distribuição a priori\",\n          \"Distribuição posterior\",\n          \"Aproximação por grid\",\n          \"Modelo binomial\"\n        ]\n\nimage: \"images/intro-bayes-binomial-grid.png\"  \nexecute:  \n  echo: true  \n  warning: false  \n  include: true  \n  message: false  \n\n---\n\n\n\n\nA estratégia de **inferência via grid** consiste em discretizar o parâmetro $p$ em pequenos intervalos, avaliando a distribuição *a priori* e a verossimilhança em cada ponto da grade. Em seguida, multiplica-se esses valores e normaliza-se o resultado para obter a distribuição *a posteriori*.\n\n## Aproximação Bayesiana via Grid\n\n1. **Definir os dados**  \n   - $N$: número total de observações (ensaios Bernoulli).  \n   - $k$: número de sucessos observados.\n\n2. **Criar a malha (grid) de valores para $p$**  \n   - Divida o intervalo $[0, 1]$ em muitos pontos (ex. 1000 pontos).  \n   - Cada ponto será uma hipótese para o valor de $p$.\n\n3. **Avaliar a priori**  \n   - Escolha uma forma para a distribuição a priori de $p$.  \n   - Exemplos: uma Beta($\\alpha, \\beta$) ou mesmo uma priori uniforme.  \n   - Calcule a densidade da priori em cada ponto do grid.\n\n4. **Calcular a verossimilhança**  \n   - Para cada valor de $p$ no grid, calcule $P(Y = k \\mid p, N)$ usando a distribuição Binomial:  \n     $$\\mathcal{L}(p) = \\binom{N}{k}\\, p^k (1-p)^{N-k}.$$\n\n   - Use por exempo o método **`binom.pmf(k, N, p)`** do módulo [SciPy](https://scipy.org/) ou escreva a fórmula manualmente.\n\n5. **Combinar *priori* e verossimilhança**  \n   - A posteriori não normalizada em cada ponto do grid é:  \n     $$\\text{posterior}_{\\text{unnorm}}(p) = \\text{prior}(p) \\times \\mathcal{L}(p).$$\n\n6. **Normalizar a *posteriori***  \n   - Some os valores de $\\text{posterior}_{\\text{unnorm}}(p)$ sobre todos os pontos $p$.  \n   - Divida cada valor pela soma total (use integração, como `scipy.integrate.simpson` para maior precisão).  \n   - O resultado é a distribuição a *posteriori* discreta (aproximada).\n\n7. **Calcular probabilidades de intervalo**  \n   - Para calcular $P(x_1 \\leq p \\leq x_2)$, some (ou integre) os valores da posteriori nos pontos entre $x_1$ e $x_2$.\n\n8. **Visualizar os resultados**  \n   - Faça gráficos do perfil da *priori*, da verossimilhança e da *posteriori* ao longo do grid de $p$.  \n   - Destaque intervalos de interesse ($x_1, x_2$) e use os valores de probabilidade para estimar o valor de $p$.\n\n---\n\n## Exemplo em Python\n\nA seguir, um **exemplo completo** usando `numpy` e `matplotlib` para ilustrar cada etapa. Ajuste os valores de $N$, $k$, $\\alpha$ e $\\beta$ conforme necessário.\n\n::: {#e6d72e80 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, beta\nfrom scipy.integrate import simpson\n\n# Parâmetros do experimento\nN = 10   # número total de ensaios\nk = 6    # número de sucessos observados\n\n# Parâmetros da priori Beta\nalpha_param = 1\nbeta_param = 1\n\n# Grid de p (1000 pontos entre 0 e 1)\np_grid = np.linspace(0, 1, 1000)\n\n# 1) Prior: densidade Beta em cada ponto do grid\nprior = beta.pdf(p_grid, a=alpha_param, b=beta_param)\n\n# 2) Verossimilhança: Binomial(k | N, p)\nlikelihood = binom.pmf(k, N, p_grid)\n\n# 3) Posterior não normalizada\nposterior_unnorm = prior * likelihood\n\n# 4) Normaliza para obter a posteriori propriamente dita\narea = simpson(y=posterior_unnorm, x=p_grid)  # integra usando Simpson\nposterior = posterior_unnorm / area\n\n# 5) (Opcional) Calcular probabilidade de um intervalo [x1, x2]\nx1, x2 = 0.4, 0.7\nmask_interval = (p_grid >= x1) & (p_grid <= x2)\nprob_interval = simpson(y=posterior[mask_interval], x=p_grid[mask_interval])\n\n# Visualizar\nfig, axs = plt.subplots(3, 1, figsize=(6, 8))\n\n# Plot da Prior\naxs[0].plot(p_grid, prior, color='red')\naxs[0].set_title(\"Priori Beta\")\naxs[0].set_ylabel(\"Densidade\")\n\n# Plot da Verossimilhança\naxs[1].plot(p_grid, likelihood, color='green')\naxs[1].set_title(f\"Verossimilhança Binomial (k={k}, N={N})\")\naxs[1].set_ylabel(\"PMF\")\n\n# Plot da Posterior\naxs[2].plot(p_grid, posterior, color='blue')\naxs[2].set_title(f\"Posteriori - Prob({x1:.2f} ≤ p ≤ {x2:.2f}) = {prob_interval:.3f}\")\naxs[2].set_xlabel(\"p\")\naxs[2].set_ylabel(\"Densidade\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](intro-bayes-binomial-grid_files/figure-html/cell-2-output-1.png){width=566 height=758}\n:::\n:::\n\n\n## Interpretação\n\n- Observe como a forma da *posteriori* (curva azul) é proporcional ao produto da *priori* (vermelho) pela verossimilhança (verde).\n- Se a *priori* for $Beta(1,1)$ (uniforme), a *posteriori* fica essencialmente guiada pelos dados.\n- Alterar $\\alpha$ e $\\beta$ faz a *priori* pesar mais (ou menos) no resultado final, dependendo de quão informativa ela é e do tamanho amostral $N$.\n\n",
    "supporting": [
      "intro-bayes-binomial-grid_files"
    ],
    "filters": [],
    "includes": {}
  }
}