{
  "hash": "778a805b8b0a92914bcd2f1fe10c64a7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"De contagens a probabilidades\"  \nsubtitle: \"A distribuiÃ§Ã£o *a posteriori*\"  \ndescription: \"TransiÃ§Ã£o de contagens para probabilidades sob uma perspectiva bayesiana. Baseado em *Statistical Rethinking* [@mcelreath2018statistical].\"  \nCategories: [\n          \"InferÃªncia bayesiana\",\n          \"DistribuiÃ§Ã£o de probabilidade\",\n          \"DistribuiÃ§Ã£o a priori\",\n          \"DistribuiÃ§Ã£o posterior\"\n        ]\n\nimage: \"images/intro-bayes-distr-prob.png\"  \nexecute:  \n  echo: false  \n  warning: false  \n  include: true  \n  message: false  \n\n---\n\n\n\n\n---\n\nVoltemos ao problema das bolinhas de gude. Temos uma caixa contendo quatro bolinhas, que podem ser azuis ou brancas. Sabemos que hÃ¡ exatamente quatro bolinhas, mas nÃ£o conhecemos a distribuiÃ§Ã£o entre as cores, pois podemos ver apenas uma bolinha por vez atravÃ©s de um orifÃ­cio. Para estimar quantas bolas de cada cor hÃ¡ na caixa, fazemos uma observaÃ§Ã£o, misturamos as bolinhas, fazemos outra observaÃ§Ã£o e assim por diante. Antes de realizarmos qualquer observaÃ§Ã£o, podemos listar cinco configuraÃ§Ãµes possÃ­veis para o conteÃºdo da caixa:\n\n1. [âšªâšªâšªâšª]  \n2. [ğŸ”µâšªâšªâšª]  \n3. [ğŸ”µğŸ”µâšªâšª]  \n4. [ğŸ”µğŸ”µğŸ”µâšª]  \n5. [ğŸ”µğŸ”µğŸ”µğŸ”µ]\n\nNosso objetivo Ã© *estimar o nÃºmero $N$ de bolas azuis*, o qual pode variar, neste exemplo, de 0 a 4. Como nÃ£o dispomos de conhecimento prÃ©vio sobre a composiÃ§Ã£o da caixa antes da primeira observaÃ§Ã£o, adotamos uma distribuiÃ§Ã£o *a priori* uniforme entre as hipÃ³teses. Assim, cada hipÃ³tese recebe uma probabilidade de $p = \\frac{1}{5}$.\n\n| **HipÃ³tese** | **N** | **Priori** |\n|:------------:|:-----:|:----------:|\n| [âšªâšªâšªâšª]   |  0    | $1/5$    |\n| [ğŸ”µâšªâšªâšª]   |  1    | $1/5$    |\n| [ğŸ”µğŸ”µâšªâšª]   |  2    | $1/5$    |\n| [ğŸ”µğŸ”µğŸ”µâšª]   |  3    | $1/5$    |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   |  4    | $1/5$    |\n\n: **DistribuiÃ§Ã£o de probabilidade *a priori* sobre o conteÃºdo da caixa** {#tbl-priori} \n\n---\n\n## DistribuiÃ§Ãµes *a priori*, *a posteriori* e *verossimilhanÃ§a*\n\nSuponha que realizamos trÃªs observaÃ§Ãµes da caixa e a sequÃªncia registrada seja [ğŸ”µ, âšª, ğŸ”µ] â€“ ou seja, duas bolas azuis. Para atualizar nosso conhecimento sobre a composiÃ§Ã£o da caixa, combinamos nossa distribuiÃ§Ã£o *a priori* com a verossimilhanÃ§a de cada hipÃ³tese. A verossimilhanÃ§a Ã© calculada a partir da contagem do nÃºmero de maneiras em que cada hipÃ³tese pode gerar a sequÃªncia observada. Em seguida, aplicamos a regra de Bayes, que nos fornece a distribuiÃ§Ã£o *a posteriori* por meio da fÃ³rmula:\n\n$$\\text{Posterior}_i = \\frac{\\text{Priori}_i \\times P_i}{\\sum_{j} \\left(\\text{Priori}_j \\times P_j\\right)},$$ {#eq-bayes}\n\nonde $P_i$ representa, de forma proporcional, o nÃºmero de caminhos possÃ­veis para que a hipÃ³tese $i$ gere a sequÃªncia [ğŸ”µ, âšª, ğŸ”µ].\n\nA equaÃ§Ã£o @eq-bayes indica que, para cada valor que $N$ pode assumir, julgamos sua plausibilidade como proporcional ao nÃºmero de maneiras pelas quais esse valor pode ter gerado os dados, multiplicado pela sua evidÃªncia anterior (a distribuiÃ§Ã£o *a priori*). Esse produto â€“ representado na @tbl-posteriori por $\\text{Priori}_i \\times P_i$ â€“ Ã© entÃ£o *normalizado*, dividindo cada um deles pelo somatÃ³rio $\\sum (1/5 \\times \\text{NÂº de caminhos})$. Essa normalizaÃ§Ã£o gera a distribuiÃ§Ã£o **a posteriori**, que reflete nosso conhecimento atualizado apÃ³s a incorporaÃ§Ã£o das evidÃªncias observadas.\n\n\nNa @tbl-posteriori, a coluna *â€œManeiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]â€* indica o nÃºmero de caminhos possÃ­veis para que cada hipÃ³tese gere a sequÃªncia observada. Note que as hipÃ³teses [âšªâšªâšªâšª] e [ğŸ”µğŸ”µğŸ”µğŸ”µ] nÃ£o conseguem gerar a sequÃªncia (ou seja, possuem verossimilhanÃ§a zero). \n\n| **HipÃ³tese** | **N** | **Priori** | **Maneiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]** | **Posterior** |\n|:------------:|:-----:|:----------:|:---------------------------------------:|:-------------:|\n| [âšªâšªâšªâšª]   |  0    | $1/5$    | $0 \\times 4 \\times 0 = 0$             | $\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0$  |\n| [ğŸ”µâšªâšªâšª]   |  1    | $1/5$    | $1 \\times 3 \\times 1 = 3$             | $\\dfrac{(1/5 \\times 3)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.15$  |\n| [ğŸ”µğŸ”µâšªâšª]   |  2    | $1/5$    | $2 \\times 2 \\times 2 = 8$             | $\\dfrac{(1/5 \\times 8)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.40$  |\n| [ğŸ”µğŸ”µğŸ”µâšª]   |  3    | $1/5$    | $3 \\times 1 \\times 3 = 9$             | $\\dfrac{(1/5 \\times 9)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.45$  |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   |  4    | $1/5$    | $4 \\times 0 \\times 4 = 0$             | $\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0$  |\n\n: **AtualizaÃ§Ã£o da distribuiÃ§Ã£o de probabilidade combinando a priori e verossimilhanÃ§a** {#tbl-posteriori} \n\nDessa forma, a plausibilidade de cada hipÃ³tese Ã© convertida em **probabilidades** â€“ valores nÃ£o negativos cuja soma Ã© igual a 1 â€“ para cada uma das hipÃ³teses sobre o conteÃºdo da caixa. O resultado final da inferÃªncia bayesiana Ã© fornecer uma base probabilÃ­stica para a tomada de decisÃ£o sobre um fenÃ´meno parcialmente desconhecido, expressando o quÃ£o plausÃ­vel Ã© cada hipÃ³tese Ã  luz dos dados disponÃ­veis (@fig-priori-posteriori).\n\n::: {#cell-fig-priori-posteriori .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![DistribuiÃ§Ã£o a priori (esquerda) e a posteriori (direita) para o nÃºmero de bolas azuis. A priori, as hipÃ³teses tÃªm probabilidade uniforme; a posteriori, a observaÃ§Ã£o [ğŸ”µ, âšª, ğŸ”µ] atualiza a plausibilidade, favorecendo hipÃ³teses intermediÃ¡rias](intro-bayes-distr-prob_files/figure-html/fig-priori-posteriori-output-1.png){#fig-priori-posteriori width=710 height=279}\n:::\n:::\n\n\nEsses conceitos possuem nomenclaturas especÃ­ficas, e vale a pena aprendÃª-los, pois vocÃª os encontrarÃ¡ repetidamente:\n\n- A conjectura sobre o nÃºmero de bolinhas azuis $N$ Ã© chamada de **valor do parÃ¢metro** â€“ uma maneira de indexar as possÃ­veis explicaÃ§Ãµes para os dados.\n- O nÃºmero relativo de maneiras pelo qual esse parÃ¢metro pode produzir os dados Ã© chamado de **verossimilhanÃ§a** (*likelihood*). Essa medida Ã© obtida ao enumerar todas as sequÃªncias de dados possÃ­veis e, em seguida, descartar aquelas que nÃ£o sÃ£o compatÃ­veis com os dados observados.\n- A plausibilidade anterior de um valor especÃ­fico Ã© denominada **distribuiÃ§Ã£o de probabilidade a priori**.\n- A plausibilidade atualizada de um valor especÃ­fico, apÃ³s a incorporaÃ§Ã£o dos dados, Ã© denominada **distribuiÃ§Ã£o de probabilidade a posteriori**, utilizada para inferir a probabilidade de cada hipÃ³tese ou conjunto de hipÃ³teses sobre o parÃ¢metro.\n\n",
    "supporting": [
      "intro-bayes-distr-prob_files"
    ],
    "filters": [],
    "includes": {}
  }
}