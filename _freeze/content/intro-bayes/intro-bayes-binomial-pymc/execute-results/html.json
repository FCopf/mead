{
  "hash": "4e52ab577da521924bad38c01579549b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Inferência Bayesiana Binomial com PyMC\"  \nsubtitle: \"Estimando $p$ usando modelagem probabilística\"  \ndescription: \"Introdução à modelagem probabilística na abordagem bayesiana.\"\nCategories: [\n          \"Inferência bayesiana\",\n          \"Distribuição a priori\",\n          \"Distribuição posterior\",\n          \"Modelagem probabilística\",\n          \"Modelo binomial\"\n        ]\n\nimage: \"images/intro-bayes-binomial-pymc.png\"  \nexecute:  \n  echo: true  \n  warning: false  \n  include: true  \n  message: false  \n\n---\n\n\n\n\nO [PyMC](https://www.pymc.io/projects/docs/en/stable/learn.html) é uma biblioteca de programação probabilística em Python que facilita a construção de modelos bayesianos, utilizando métodos como a **amostragem MCMC** (Markov Chain Monte Carlo) para estimar distribuições *a posteriori* de forma eficiente. \n\nPara modelar uma variável aleatória com distribuição Binomial, podemos especificar uma distribuição **a priori** do tipo Beta para o parâmetro $p$, observar os dados (número de sucessos em $N$ ensaios) e, então, obter a distribuição *a posteriori* utilizando técnicas de amostragem fornecidas pelo PyMC.\n\n## Estimativa Bayesiana com PyMC\n\n1. **Definir os dados**  \n\n   - $N$: número total de observações (ensaios Bernoulli).  \n   - $k$: número de sucessos observados.\n\n2. **Definir o modelo probabilístico**  \n\n   - Especifique uma distribuição *a priori* para o parâmetro $p$, como uma Beta($\\alpha$, $\\beta$).  \n   - Modele os dados observados usando uma distribuição Binomial($N$, $p$):  \n\n     ```python\n     with pm.Model() as modelo:\n         p = pm.Beta(\"p\", alpha=α_prior, beta=β_prior)\n         y = pm.Binomial(\"y\", n=N, p=p, observed=k)\n     ```\n\n3. **Executar a amostragem MCMC**  \n\n   - Use o método `pm.sample()` para gerar amostras da distribuição *a posteriori*.  \n   - O PyMC utiliza, por padrão, o algoritmo **NUTS** (No-U-Turn Sampler), baseado em Hamiltonian Monte Carlo.  \n   \n     ```python\n     trace = pm.sample()\n     ```\n\n4. **Inspecionar os resultados da amostragem**  \n\n   - Use `az.summary(trace)` para obter estatísticas descritivas: média, desvio padrão, intervalos de credibilidade, $\\hat{R}$ (diagnóstico de convergência), entre outros.  \n   - Visualize as cadeias com `az.plot_trace(trace)`, que mostra as séries temporais e histogramas das amostras.  \n   - Visualize a distribuição *a posteriori* com `az.plot_posterior(trace, var_names=[\"p\"])`.\n\n5. **Calcular probabilidades e intervalos de credibilidade**  \n\n   - Use as amostras da posteriori para calcular quantidades como $P(x_1 \\leq p \\leq x_2)$, filtrando os valores de `p` entre esses limites e estimando a proporção.  \n   - Exemplo: \n\n     ```python\n     amostras_p = trace.posterior[\"p\"].values.flatten()\n     prob = ((amostras_p >= x1) & (amostras_p <= x2)).mean()\n     ```\n\n6. **Visualizar os resultados**  \n\n   - Faça gráficos para comparar a *priori* e a *posteriori*, ou destacar regiões de interesse com os intervalos de credibilidade.  \n   - Combine visualizações com `matplotlib`, `arviz` e outras bibliotecas para tornar as conclusões mais claras.\n\n\n## Exemplo em Python\n\n::: {#4a39159d .cell execution_count=1}\n``` {.python .cell-code}\nimport pymc as pm\nimport arviz as az  # Pacote auxiliar para análise e visualização dos resultados\n\n# 1. Definir os dados observados\nN = 10    # Número total de ensaios (Bernoulli)\nk = 6     # Número de sucessos observados\n\n# 2. Parâmetros da distribuição a priori (Beta)\nalpha_param = 2\nbeta_param = 2\n\n# 3. Definir o modelo probabilístico no PyMC\nwith pm.Model() as model:\n    # 3.1. Definição da distribuição a priori para p\n    p = pm.Beta(\"p\", alpha=alpha_param, beta=beta_param)\n    \n    # 3.2. Observações via distribuição Binomial\n    obs = pm.Binomial(\"obs\", n=N, p=p, observed=k)\n    \n    # 4. Amostragem MCMC (posteriori)\n    trace = pm.sample()\n\n# 5. Inspeção dos resultados\nprint(az.summary(trace, var_names=[\"p\"], kind=\"stats\"))\n\n# 6. Visualizações da amostragem e da posteriori\naz.plot_trace(trace, var_names=[\"p\"])  # Trajetória e histograma das amostras\naz.plot_posterior(trace, var_names=[\"p\"], rope=[0.3, 0.7]);  # Posteriori com intervalo de relevância\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"f137bd49ba8645a7a54664a71088364e\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n    mean     sd  hdi_3%  hdi_97%\np  0.566  0.129   0.326    0.806\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](intro-bayes-binomial-pymc_files/figure-html/cell-2-output-4.png){width=912 height=209}\n:::\n\n::: {.cell-output .cell-output-display}\n![](intro-bayes-binomial-pymc_files/figure-html/cell-2-output-5.png){width=540 height=440}\n:::\n:::\n\n\n## Interpretação\n\n- A **forma** e a **localização** da posteriori dependerão tanto dos dados observados ($k$, $N$) quanto dos parâmetros da distribuição *a priori* ($\\alpha$, $\\beta$).  \n- Conforme $N$ aumenta, a verossimilhança passa a dominar o resultado, reduzindo o impacto de uma *a priori* moderada.  \n- Se você alterar $\\alpha_{\\mathrm{prior}}$ e $\\beta_{\\mathrm{prior}}$, verá como suposições prévias mudam a forma inicial da posteriori, sobretudo em situações com poucos dados.\n\n---\n\n## Exercício\n\n- **Varie** $N$ e $k$ para simular cenários distintos (poucos sucessos, muitos sucessos) e veja como a posteriori se adapta.  \n- **Altere** $\\alpha_{\\mathrm{prior}}$ e $\\beta_{\\mathrm{prior}}$ (por exemplo, prior fortemente concentrada em 0.8) e observe se, com poucos dados, a posteriori permanece próxima da distribuição *a priori*.\n\n",
    "supporting": [
      "intro-bayes-binomial-pymc_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"31d0610845d1408896083d4e3b810bc4\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"f137bd49ba8645a7a54664a71088364e\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_31d0610845d1408896083d4e3b810bc4\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">                                                                                                                   \\n <span style=\\\"font-weight: bold\\\"> Progress                 </span> <span style=\\\"font-weight: bold\\\"> Draws </span> <span style=\\\"font-weight: bold\\\"> Divergences </span> <span style=\\\"font-weight: bold\\\"> Step size </span> <span style=\\\"font-weight: bold\\\"> Grad evals </span> <span style=\\\"font-weight: bold\\\"> Sampling Speed  </span> <span style=\\\"font-weight: bold\\\"> Elapsed </span> <span style=\\\"font-weight: bold\\\"> Remaining </span> \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.31        1            3709.38 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.54        1            3550.29 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.71        3            3202.54 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             1.55        1            2420.72 draws/s   0:00:00   0:00:00    \\n                                                                                                                   \\n</pre>\\n\",\"text/plain\":\"                                                                                                                   \\n \\u001b[1m \\u001b[0m\\u001b[1mProgress                \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDraws\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDivergences\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mStep size\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mGrad evals\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mSampling Speed \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mElapsed\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mRemaining\\u001b[0m\\u001b[1m \\u001b[0m \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             1.31        1            3709.38 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             1.54        1            3550.29 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.71        3            3202.54 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             1.55        1            2420.72 draws/s   0:00:00   0:00:00    \\n                                                                                                                   \\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}