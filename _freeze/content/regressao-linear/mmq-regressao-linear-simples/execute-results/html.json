{
  "hash": "37bb48ef070d9a7f253506fa037d4d38",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples\"\nsubtitle: \"Implementa√ß√£o em Python usando √Ålgebra Matricial\"\ndescription: \"Tutorial pr√°tico para implementar o m√©todo dos m√≠nimos quadrados em Python, aplicando os conceitos de √°lgebra linear e estat√≠stica b√°sica.\"\nCategories: [\n          \"Regress√£o linear\",\n          \"M√©todo dos M√≠nimos Quadrados\",\n          \"√Ålgebra Matricial\",\n          \"Python\"\n        ]\n\nimage: \"images/mmq-regressao-linear-simples.png\"\nexecute:\n  echo: true\n  warning: false\n  include: true\n  message: false\n---\n\n\n\n\n## üìö Introdu√ß√£o\n\n::: {.callout-tip title=\"Objetivos\"}\n\nNeste tutorial, vamos implementar o **M√©todo dos M√≠nimos Quadrados (MMQ)** em Python para ajustar um modelo de **regress√£o linear simples**.\n\n**Objetivo**: Encontrar os coeficientes $\\beta_0$ e $\\beta_1$ da equa√ß√£o $\\hat{y} = \\beta_0 + \\beta_1 x$ que melhor se ajustam aos nossos dados.\n\n:::\n\n## üõ†Ô∏è Importando as Bibliotecas\n\nPrimeiro, vamos importar as bibliotecas que usaremos:\n\n::: {#a0184b8f .cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt  # Para cria√ß√£o e manipula√ß√£o gr√°fica\nimport numpy as np           # Para opera√ß√µes matem√°ticas e matriciais\n```\n:::\n\n\n**üí° Dica**: No Google Colab, essas bibliotecas j√° v√™m instaladas!\n\n## üìä Inserindo os Dados\n\nVamos trabalhar um exemplo simples em que $x$ e $y$ s√£o inseridos como listas em Python:\n\n::: {#4546c8dc .cell execution_count=2}\n``` {.python .cell-code}\n# Nossos dados de exemplo\nx = [0, 1, 2, 3, 4]  # Vari√°vel independente (preditora)\ny = [0, 1, 1, 4, 4]  # Vari√°vel dependente (resposta)\n```\n:::\n\n\nCaso deseje visualizar se os objetos `x` e `y` foram criados corretamente podemos utilizar a fun√ß√£o `print()`.\n\n::: {#1ac8497d .cell execution_count=3}\n``` {.python .cell-code}\nprint(\"Valores de x:\", x)\nprint(\"Valores de y:\", y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nValores de x: [0, 1, 2, 3, 4]\nValores de y: [0, 1, 1, 4, 4]\n```\n:::\n:::\n\n\n## üìà Visualizando os Dados\n\nAntes de ajustar o modelo, vamos visualizar nossos dados em um gr√°figo de dispers√£o utilizando a fun√ß√£o `scatter()` da biblioteca [Matplotlib](https://matplotlib.org/):\n\n::: {#1ef1ff8f .cell execution_count=4}\n``` {.python .cell-code}\n# Criando o gr√°fico de dispers√£o\nplt.figure(figsize=(8, 6))\nplt.scatter(x, y, color = '#0072B2', s=120, label='Dados observados')\n\n# Configurando o layout gr√°fico\nplt.title('Gr√°fico de Dispers√£o dos Dados', fontsize=14, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](mmq-regressao-linear-simples_files/figure-html/cell-5-output-1.png){width=666 height=529}\n:::\n:::\n\n\n**üìù Observa√ß√£o**: O gr√°fico sugere uma rela√ß√£o linear entre as vari√°veis, o que justifica o uso da regress√£o linear simples, que iremos ajustra por meio do MMQ.\n\n## üßÆ Implementando o MMQ - Passo a Passo\n\n### Criando os Vetores Base\n\nLembre-se da teoria: inicialmente precisamos caracterizar os vetores $\\vec{f}_0$, $\\vec{f}_1$ e $\\vec{y}$:\n\n$$\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}$$\n\n::: {#020dde8e .cell execution_count=5}\n``` {.python .cell-code}\n# N√∫mero de observa√ß√µes\nn = len(x)\n\n# Vetor f0: vetor de 1's (para o intercepto Œ≤‚ÇÄ)\nf0 = [1] * n  # Cria uma lista com n elementos iguais a 1\n\n# Vetor f1: nossos valores de x (para o coeficiente Œ≤‚ÇÅ)\nf1 = x.copy()  # Copia os valores de x para um novo objeto denominado f1\n```\n:::\n\n\nVisualizando os vetores $\\vec{f}_0$ e $\\vec{f}_1$.\n\n::: {#1bede7f2 .cell execution_count=6}\n``` {.python .cell-code}\nprint(\"Vetor f0 (intercepto):\", f0)\nprint(\"Vetor f1 (coeficiente):\", f1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVetor f0 (intercepto): [1, 1, 1, 1, 1]\nVetor f1 (coeficiente): [0, 1, 2, 3, 4]\n```\n:::\n:::\n\n\n### Construindo as Matrizes X e Y\n\nAgora vamos montar as matrizes do sistema:\n\n$$X = \\begin{bmatrix} \\vec{f}_0 & \\vec{f}_1 \\end{bmatrix} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\quad \\text{e} \\quad Y = \\begin{bmatrix} \\vec{y} \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}$$\n\n::: {#681b054e .cell execution_count=7}\n``` {.python .cell-code}\n# Matriz X: combinando f0 e f1 em colunas\nX = np.column_stack((f0, f1))\n\n# Matriz Y: transformando y em matriz com n linhas e 1 coluna \nY = np.array(y).reshape(n, 1)\n```\n:::\n\n\nVisualizando as matrizes $X$ e $Y$.\n\n::: {#a9758d8a .cell execution_count=8}\n``` {.python .cell-code}\nprint(\"Matriz X:\")\nprint(X)\nprint(\"\\nMatriz Y:\")\nprint(Y)\nprint(f\"\\nDimens√µes - X: {X.shape}, Y: {Y.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMatriz X:\n[[1 0]\n [1 1]\n [1 2]\n [1 3]\n [1 4]]\n\nMatriz Y:\n[[0]\n [1]\n [1]\n [4]\n [4]]\n\nDimens√µes - X: (5, 2), Y: (5, 1)\n```\n:::\n:::\n\n\nNote agora que a matriz $X$ tem 5 linhas e 2 colunas, enquanto a matriz $Y$ tem 5 linhas e 1 colunas.\n\n### Resolvendo o Sistema Normal\n\nAgora vamos calcular os coeficientes usando as opera√ß√µes matriciais: \n$$B = (X^T X)^{-1} X^T Y$$\n\n::: {#9ca7759f .cell execution_count=9}\n``` {.python .cell-code}\n# Calculando X transposta vezes X\nXTX = np.dot(X.T, X)  # X.T √© a transposta de X\n# Calculando X transposta vezes Y\nXTY = np.dot(X.T, Y)\n# Calculando a matriz inversa (X^T X)^(-1)\nXTX_inv = np.linalg.inv(XTX)  # Inversa de X^T X\n# Coeficientes de regress√£o\nB = np.dot(XTX_inv, XTY)\n```\n:::\n\n\nVisualizando os objetos\n\n::: {#80f026f2 .cell execution_count=10}\n``` {.python .cell-code}\n# Calculando X transposta vezes X\nprint(\"X^T X:\")\nprint(XTX)\n\nprint(\"\\nX^T Y:\")\nprint(XTY)\n\nprint(\"\\nB:\")\nprint(B)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nX^T X:\n[[ 5 10]\n [10 30]]\n\nX^T Y:\n[[10]\n [31]]\n\nB:\n[[-0.2]\n [ 1.1]]\n```\n:::\n:::\n\n\n::: {.callout-note}\n\n1. A fun√ß√£o ¬¥np.dot()¬¥ em Python pode ser substitu√≠da pelo s√≠mbolo `@`. Teste os c√≥digos abaixo e verifique que os resultados coincidem:\n\n::: {#e8934be0 .cell execution_count=11}\n``` {.python .cell-code}\nprint(\"Usando np.dot()\")\nprint(np.dot(X.T, X))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsando np.dot()\n[[ 5 10]\n [10 30]]\n```\n:::\n:::\n\n\n::: {#46c01d44 .cell execution_count=12}\n``` {.python .cell-code}\nprint(\"Usando '@'\")\nprint(X.T @ X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsando '@'\n[[ 5 10]\n [10 30]]\n```\n:::\n:::\n\n\n2. Os elementos internos de uma matriz podem ser acessados destacando suas posi√ß√µes na linha e coluna. Considere a matrtiz `B`. O coeficiente $\\beta_0$ pode ser acessado na linha 1 e coluna 1, enquanto $\\beta_1$ pode ser acessado na linha 2 e coluna 1.\n\n::: {#86fde2d9 .cell execution_count=13}\n``` {.python .cell-code}\nprint(B[0,0]) # Beta 0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-0.1999999999999993\n```\n:::\n:::\n\n\n::: {#884fb963 .cell execution_count=14}\n``` {.python .cell-code}\nprint(B[1,0]) # Beta 1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.1\n```\n:::\n:::\n\n\n:::\n\n### Obtendo os Valores Ajustados de y\n\nTendo obtido os coeficientes de regress√£o, os valores ajustados de y ($\\hat{y}$) podem ser obtido pela multiplica√ß√£o matricial:\n\n$$F = X B = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\begin{bmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{bmatrix}$$\n\n**Obs.**: denominamos $F$ a matriz de valores ajustados de $y$.\n\n::: {#9f381604 .cell execution_count=15}\n``` {.python .cell-code}\n# Valores ajustados (preditos)\nF = np.dot(X, B)\n```\n:::\n\n\n::: {#7e1fa225 .cell execution_count=16}\n``` {.python .cell-code}\n# Valores ajustados (preditos)\nprint(F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[-0.2]\n [ 0.9]\n [ 2. ]\n [ 3.1]\n [ 4.2]]\n```\n:::\n:::\n\n\n### Avaliando a Qualidade do Ajuste\n\n#### Calculando a Soma dos Quadrados dos Res√≠duos ($SQ_{res}$)\n\n$SQ_{res}$ pode ser obtida pela multiplica√ß√£o matricial:\n\n$$SQ_{res} = \\boldsymbol{e}^T \\boldsymbol{e}$$\n\nEm que $\\boldsymbol{e}$ √© a matriz coluna dos **res√≠duos** obtida pela diferen√ßa entre os valores observados e ajustados de $y$:\n\n$$\\boldsymbol{e} = Y - F = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}$$\n\n::: {#25e3d12b .cell execution_count=17}\n``` {.python .cell-code}\n# Res√≠duos: diferen√ßa entre valores observados e ajustados\ne = Y - F\n\n# Soma dos Quadrados dos Res√≠duos\nSQres = np.dot(e.T, e)[0, 0]\n```\n:::\n\n\n#### Calculando a Soma dos Quadrados Totais ($SQ_{tot}$)\n\n$SQ_{tot}$ pode ser obtida pela multiplica√ß√£o matricial:\n\n$$SQ_{tot} = \\boldsymbol{D}^T \\boldsymbol{D}$$\n\nEm que $\\boldsymbol{D}$ √© a matriz coluna dos **desvios da m√©dis** obtida pela diferen√ßa entre os valores observados de $y$ e a m√©dia de $\\overline{y}$:\n\n$$\\boldsymbol{D} = Y - \\overline{Y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\overline{y} \\\\ \\overline{y} \\\\ \\vdots \\\\ \\overline{y} \\end{bmatrix} = \\begin{bmatrix} d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_n \\end{bmatrix}$$\n\n::: {#308fc4c7 .cell execution_count=18}\n``` {.python .cell-code}\n# Soma dos Quadrados Total\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = np.dot(D.T, D)[0, 0]\n```\n:::\n\n\n#### Calculando o coeficiente de determina√ß√£o $R^2$:\n\nO $R^2$ √© dado pela express√£o:\n\n$$R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}$$\n\n::: {#cdd83328 .cell execution_count=19}\n``` {.python .cell-code}\n# Coeficiente de Determina√ß√£o R¬≤\nR2 = 1 - (SQres / SQtot)\n```\n:::\n\n\n---\n\nVisualizando os resultados:\n\n::: {#eab3780f .cell execution_count=20}\n``` {.python .cell-code}\nprint(\"üìä Medidas de Qualidade do Ajuste:\")\nprint(f\"Soma dos Quadrados dos Res√≠duos (SQres): {SQres:.4f}\")\nprint(f\"Soma dos Quadrados Total (SQtot): {SQtot:.4f}\")\nprint(f\"Coeficiente de Determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nüìä Medidas de Qualidade do Ajuste:\nSoma dos Quadrados dos Res√≠duos (SQres): 1.9000\nSoma dos Quadrados Total (SQtot): 14.0000\nCoeficiente de Determina√ß√£o (R¬≤): 0.8643\nPorcentagem da varia√ß√£o explicada: 86.43%\n```\n:::\n:::\n\n\n**üìù Interpreta√ß√£o do $R^2$**:\n\n- Varia de 0 a 1\n- Quanto mais pr√≥ximo de 1, melhor o ajuste\n- Representa a propor√ß√£o da varia√ß√£o em $y$ explicada pelo modelo\n\n---\n\n## üìä Visualizando o Resultado Final\n\nVamos plotar os dados originais junto com a reta ajustada:\n\n::: {#c8d77836 .cell execution_count=21}\n``` {.python .cell-code}\n# Criando o gr√°fico final\nplt.figure(figsize=(8, 6))\n\n# Pontos observados\nplt.scatter(x, y, \n            color = '#0072B2', s=120,\n            label=f'Dados observados (n={n})')\n\n# Valores ajustados\nplt.scatter(x, F[:,0],\n            color='#000000', marker='*', s=120, \n            label='Valores ajustados')\n\n# Reta ajustada\nplt.plot(x, F[:,0], color='#D55E00', \n         label=fr'Reta de regress√£o: $\\hat{{y}} = {B[0,0]:.3f} + {B[1,0]:.3f}x$')\n\n# Configura√ß√µes do gr√°fico\nplt.title(f'Regress√£o Linear Simples - MMQ\\nR¬≤ = {R2:.4f}', \n          fontsize=14, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](mmq-regressao-linear-simples_files/figure-html/cell-22-output-1.png){width=759 height=566}\n:::\n:::\n\n\n## üéØ Resumo dos Resultados\n\n::: {#2f0a5c8f .cell execution_count=22}\n``` {.python .cell-code}\nprint(\"=\"*50)\nprint(\"         RESUMO DA REGRESS√ÉO LINEAR\")\nprint(\"=\"*50)\nprint(f\"Equa√ß√£o ajustada: y = {B[0,0]:.4f} + {B[1,0]:.4f}x\")\nprint(f\"Coeficiente de determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\nprint(\"=\"*50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n         RESUMO DA REGRESS√ÉO LINEAR\n==================================================\nEqua√ß√£o ajustada: y = -0.2000 + 1.1000x\nCoeficiente de determina√ß√£o (R¬≤): 0.8643\nPorcentagem da varia√ß√£o explicada: 86.43%\n==================================================\n```\n:::\n:::\n\n\n## üßæ Resumo do C√≥digo\n\n1. Inser√ß√£o dos Dados\n\n::: {#8e0db4e0 .cell execution_count=23}\n``` {.python .cell-code}\nx = [0, 1, 2, 3, 4]\ny = [0, 1, 1, 4, 4]\n```\n:::\n\n\n2. Defini√ß√£o das matrizes do sistema\n\n::: {#52f0a768 .cell execution_count=24}\n``` {.python .cell-code}\nn = len(x)\nf0 = [1] * n\nf1 = x.copy()\n\nX = np.column_stack((f0, f1))\nY = np.array(y).reshape(n, 1)\n```\n:::\n\n\n3. C√°lculo dos coeficientes\n\n::: {#194c1a56 .cell execution_count=25}\n``` {.python .cell-code}\nXTX = X.T @ X\nXTY = X.T @ Y\nXTX_inv = np.linalg.inv(XTX)\nB = XTX_inv @ XTY\n```\n:::\n\n\n4. Qualidade do ajuste\n\n::: {#13d14cb6 .cell execution_count=26}\n``` {.python .cell-code}\nF = X @ B\ne = Y - F\nSQres = (e.T @ e)[0, 0]\n\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\nR2 = 1 - (SQres / SQtot)\n```\n:::\n\n\n## üöÄ Exerc√≠cio Pr√°tico\n\nImplemente o MMQ com novos dados:\n\n::: {#0c82839d .cell execution_count=27}\n``` {.python .cell-code}\n# Experimente com estes dados:\nx_novo = [1, 2, 3, 4, 5, 6]\ny_novo = [2, 4, 5, 4, 5, 7]\n\n# Dica: voc√™ pode copiar e adaptar o c√≥digo acima!\n```\n:::\n\n\n",
    "supporting": [
      "mmq-regressao-linear-simples_files"
    ],
    "filters": [],
    "includes": {}
  }
}