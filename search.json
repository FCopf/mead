[
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html",
    "title": "InferÃªncia Bayesiana Binomial com PyMC",
    "section": "",
    "text": "O PyMC Ã© uma biblioteca de programaÃ§Ã£o probabilÃ­stica em Python que facilita a construÃ§Ã£o de modelos bayesianos, utilizando mÃ©todos como a amostragem MCMC (Markov Chain Monte Carlo) para estimar distribuiÃ§Ãµes a posteriori de forma eficiente.\nPara modelar uma variÃ¡vel aleatÃ³ria com distribuiÃ§Ã£o Binomial, podemos especificar uma distribuiÃ§Ã£o a priori do tipo Beta para o parÃ¢metro \\(p\\), observar os dados (nÃºmero de sucessos em \\(N\\) ensaios) e, entÃ£o, obter a distribuiÃ§Ã£o a posteriori utilizando tÃ©cnicas de amostragem fornecidas pelo PyMC."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#estimativa-bayesiana-com-pymc",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#estimativa-bayesiana-com-pymc",
    "title": "InferÃªncia Bayesiana Binomial com PyMC",
    "section": "1 Estimativa Bayesiana com PyMC",
    "text": "1 Estimativa Bayesiana com PyMC\n\nDefinir os dados\n\n\\(N\\): nÃºmero total de observaÃ§Ãµes (ensaios Bernoulli).\n\n\\(k\\): nÃºmero de sucessos observados.\n\nDefinir o modelo probabilÃ­stico\n\nEspecifique uma distribuiÃ§Ã£o a priori para o parÃ¢metro \\(p\\), como uma Beta(\\(\\alpha\\), \\(\\beta\\)).\n\nModele os dados observados usando uma distribuiÃ§Ã£o Binomial(\\(N\\), \\(p\\)):\nwith pm.Model() as modelo:\n    p = pm.Beta(\"p\", alpha=Î±_prior, beta=Î²_prior)\n    y = pm.Binomial(\"y\", n=N, p=p, observed=k)\n\nExecutar a amostragem MCMC\n\nUse o mÃ©todo pm.sample() para gerar amostras da distribuiÃ§Ã£o a posteriori.\n\nO PyMC utiliza, por padrÃ£o, o algoritmo NUTS (No-U-Turn Sampler), baseado em Hamiltonian Monte Carlo.\ntrace = pm.sample()\n\nInspecionar os resultados da amostragem\n\nUse az.summary(trace) para obter estatÃ­sticas descritivas: mÃ©dia, desvio padrÃ£o, intervalos de credibilidade, \\(\\hat{R}\\) (diagnÃ³stico de convergÃªncia), entre outros.\n\nVisualize as cadeias com az.plot_trace(trace), que mostra as sÃ©ries temporais e histogramas das amostras.\n\nVisualize a distribuiÃ§Ã£o a posteriori com az.plot_posterior(trace, var_names=[\"p\"]).\n\nCalcular probabilidades e intervalos de credibilidade\n\nUse as amostras da posteriori para calcular quantidades como \\(P(x_1 \\leq p \\leq x_2)\\), filtrando os valores de p entre esses limites e estimando a proporÃ§Ã£o.\n\nExemplo:\namostras_p = trace.posterior[\"p\"].values.flatten()\nprob = ((amostras_p &gt;= x1) & (amostras_p &lt;= x2)).mean()\n\nVisualizar os resultados\n\nFaÃ§a grÃ¡ficos para comparar a priori e a posteriori, ou destacar regiÃµes de interesse com os intervalos de credibilidade.\n\nCombine visualizaÃ§Ãµes com matplotlib, arviz e outras bibliotecas para tornar as conclusÃµes mais claras."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#exemplo-em-python",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#exemplo-em-python",
    "title": "InferÃªncia Bayesiana Binomial com PyMC",
    "section": "2 Exemplo em Python",
    "text": "2 Exemplo em Python\n\nimport pymc as pm\nimport arviz as az  # Pacote auxiliar para anÃ¡lise e visualizaÃ§Ã£o dos resultados\n\n# 1. Definir os dados observados\nN = 10    # NÃºmero total de ensaios (Bernoulli)\nk = 6     # NÃºmero de sucessos observados\n\n# 2. ParÃ¢metros da distribuiÃ§Ã£o a priori (Beta)\nalpha_param = 2\nbeta_param = 2\n\n# 3. Definir o modelo probabilÃ­stico no PyMC\nwith pm.Model() as model:\n    # 3.1. DefiniÃ§Ã£o da distribuiÃ§Ã£o a priori para p\n    p = pm.Beta(\"p\", alpha=alpha_param, beta=beta_param)\n    \n    # 3.2. ObservaÃ§Ãµes via distribuiÃ§Ã£o Binomial\n    obs = pm.Binomial(\"obs\", n=N, p=p, observed=k)\n    \n    # 4. Amostragem MCMC (posteriori)\n    trace = pm.sample()\n\n# 5. InspeÃ§Ã£o dos resultados\nprint(az.summary(trace, var_names=[\"p\"], kind=\"stats\"))\n\n# 6. VisualizaÃ§Ãµes da amostragem e da posteriori\naz.plot_trace(trace, var_names=[\"p\"])  # TrajetÃ³ria e histograma das amostras\naz.plot_posterior(trace, var_names=[\"p\"], rope=[0.3, 0.7]);  # Posteriori com intervalo de relevÃ¢ncia\n\n\n\n\n\n\n\n    mean     sd  hdi_3%  hdi_97%\np  0.566  0.129   0.326    0.806"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#interpretaÃ§Ã£o",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#interpretaÃ§Ã£o",
    "title": "InferÃªncia Bayesiana Binomial com PyMC",
    "section": "3 InterpretaÃ§Ã£o",
    "text": "3 InterpretaÃ§Ã£o\n\nA forma e a localizaÃ§Ã£o da posteriori dependerÃ£o tanto dos dados observados (\\(k\\), \\(N\\)) quanto dos parÃ¢metros da distribuiÃ§Ã£o a priori (\\(\\alpha\\), \\(\\beta\\)).\n\nConforme \\(N\\) aumenta, a verossimilhanÃ§a passa a dominar o resultado, reduzindo o impacto de uma a priori moderada.\n\nSe vocÃª alterar \\(\\alpha_{\\mathrm{prior}}\\) e \\(\\beta_{\\mathrm{prior}}\\), verÃ¡ como suposiÃ§Ãµes prÃ©vias mudam a forma inicial da posteriori, sobretudo em situaÃ§Ãµes com poucos dados."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#exercÃ­cio",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#exercÃ­cio",
    "title": "InferÃªncia Bayesiana Binomial com PyMC",
    "section": "4 ExercÃ­cio",
    "text": "4 ExercÃ­cio\n\nVarie \\(N\\) e \\(k\\) para simular cenÃ¡rios distintos (poucos sucessos, muitos sucessos) e veja como a posteriori se adapta.\n\nAltere \\(\\alpha_{\\mathrm{prior}}\\) e \\(\\beta_{\\mathrm{prior}}\\) (por exemplo, prior fortemente concentrada em 0.8) e observe se, com poucos dados, a posteriori permanece prÃ³xima da distribuiÃ§Ã£o a priori."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html",
    "href": "content/intro-bayes/intro-bayes-counting.html",
    "title": "Contando possibilidades",
    "section": "",
    "text": "A inferÃªncia bayesiana, em essÃªncia, Ã© uma forma de contar e comparar as diferentes maneiras pelas quais algo pode acontecer. A seguir, vamos desenvolver os princÃ­pios da inferÃªncia bayesiana de forma simples e intuitiva utilizando o princÃ­pio da contagem.\nImagine que temos uma caixa contendo quatro bolinhas de gude, que podem ser azuis ou brancas. Sabemos que hÃ¡ exatamente quatro bolinhas, mas nÃ£o conhecemos a distribuiÃ§Ã£o entre as cores. Com base nessa informaÃ§Ã£o, podemos listar cinco configuraÃ§Ãµes possÃ­veis:\nEssas sÃ£o todas as possibilidades compatÃ­veis com o que sabemos sobre o conteÃºdo da caixa â€” o conhecimento a priori. Chamamos essas cinco configuraÃ§Ãµes de hipÃ³teses.\nNosso objetivo serÃ¡ descobrir qual dessas hipÃ³teses Ã© mais plausÃ­vel Ã  medida que obtivermos evidÃªncias sobre o conteÃºdo da caixa."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#um-leque-de-possibilidades",
    "href": "content/intro-bayes/intro-bayes-counting.html#um-leque-de-possibilidades",
    "title": "Contando possibilidades",
    "section": "1 Um leque de possibilidades",
    "text": "1 Um leque de possibilidades\nA caixa possui um orifÃ­cio pelo qual podemos ver apenas uma bolinha por vez. Assim, a Ãºnica forma de obter evidÃªncias sobre o conteÃºdo da caixa serÃ¡ fazer uma observaÃ§Ã£o, misturar as bolinhas, fazer outra observaÃ§Ã£o e assim por diante. Antes de iniciar esse processo, vamos entender como cada observaÃ§Ã£o nos ajuda a alcanÃ§ar nosso objetivo, avaliando-as Ã  luz das hipÃ³teses sobre o conteÃºdo da caixa.\nVamos comeÃ§ar assumindo que seja verdadeira a situaÃ§Ã£o (2) [ğŸ”µâšªâšªâšª]. Nesse caso, terÃ­amos 1 possibilidade de observar a bolinha azul e 3 possibilidades de observar uma bolinha branca (FiguraÂ 1).\n\n\n\n\n\n\nFiguraÂ 1: As quatro possibilidades, assumindo que existam trÃªs bolinhas brancas e uma azul. ExtraÃ­do de McElreath (2018).\n\n\n\n\n\n\n\n\n\nDicaDica Ãºtil\n\n\n\nObserve que, embora as trÃªs bolinhas brancas pareÃ§am iguais do ponto de vista dos dados (pois apenas registramos suas cores), elas sÃ£o eventos diferentes. Isso Ã© importante, pois significa que hÃ¡ trÃªs maneiras a mais de observar âšª do que ğŸ”µ.\n\n\nObservamos agora uma segunda bolinha. Isso expande nosso leque de possibilidades em mais uma camada (FiguraÂ 2). Agora existem 16 caminhos possÃ­veis (um para cada par de observaÃ§Ãµes), pois, na segunda observaÃ§Ã£o, cada um dos caminhos anteriores se ramifica em outros quatro caminhos possÃ­veis.\n\n\n\n\n\n\nFiguraÂ 2: Os 16 caminhos possÃ­veis, assumindo que existam trÃªs bolinhas brancas e uma azul. ExtraÃ­do de McElreath (2018).\n\n\n\nAo observar uma terceira bolinha da caixa, a terceira camada Ã© construÃ­da da mesma forma, e agora temos \\(4^3 = 64\\) caminhos possÃ­veis para uma sequÃªncia de observaÃ§Ãµes de cores em uma caixa com 4 bolinhas (FiguraÂ 3).\n\n\n\n\n\n\nFiguraÂ 3: Os 64 caminhos possÃ­veis, assumindo que existam trÃªs bolinhas brancas e uma azul. ExtraÃ­do de McElreath (2018).\n\n\n\n\n\n\n\n\n\nAvisoPressuposto Importante\n\n\n\nAcreditamos que, ao sacudir a caixa, cada bolinha tem a mesma chance de ser observada pelo orifÃ­cio, independentemente de qual tenha saÃ­do anteriormente. Por isso, cada caminho do leque Ã© igualmente provÃ¡vel de ser observado."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-evidÃªncias",
    "href": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-evidÃªncias",
    "title": "Contando possibilidades",
    "section": "2 Avaliando as evidÃªncias",
    "text": "2 Avaliando as evidÃªncias\nÃ€ medida que observamos a cor de uma nova bolinha da caixa, alguns desses caminhos sÃ£o logicamente eliminados.\nSuponha que a sequÃªncia de cores observada tenha sido:\n1Âª bolinha: ğŸ”µ\n2Âª bolinha: âšª\n3Âª bolinha: ğŸ”µ\nApÃ³s a primeira retirada resultar em ğŸ”µ, os trÃªs caminhos que levariam Ã  observaÃ§Ã£o de uma bolinha branca na primeira camada sÃ£o imediatamente eliminados. Na segunda retirada, obtivemos âšª, de modo que um dos caminhos possÃ­veis na segunda camada foi eliminado, restando os trÃªs caminhos que se ramificam a partir do primeiro caminho azul. ApÃ³s a terceira observaÃ§Ã£o, cada um dos trÃªs caminhos restantes na segunda camada segue somente para a bolinha azul na terceira camada. Assim, assumindo que a caixa contenha [ğŸ”µâšªâšªâšª], existe um total de trÃªs maneiras para a sequÃªncia [ğŸ”µ â†’ âšª â†’ ğŸ”µ] aparecer. Todas as outras possibilidades foram descartadas Ã  medida que as evidÃªncias surgiam.\nDos caminhos restantes na FiguraÂ 4, nÃ£o podemos ter certeza de qual dos trÃªs caminhos os dados reais seguiram, pois nÃ£o podemos identificar as bolinhas individualmente, apenas por sua cor. Entretanto, considerando a hipÃ³tese de que a caixa contenha [ğŸ”µâšªâšªâšª], podemos afirmar que os dados seguiram um desses trÃªs caminhos, pois sÃ£o os Ãºnicos compatÃ­veis tanto com nosso conhecimento prÃ©vio (4 bolinhas, azuis ou brancas) quanto com a sequÃªncia de dados observada ([ğŸ”µ â†’ âšª â†’ ğŸ”µ]).\n\n\n\n\n\n\nFiguraÂ 4: ApÃ³s eliminar caminhos inconsistentes com a sequÃªncia observada, apenas 3 dos 64 caminhos permanecem. ExtraÃ­do de McElreath (2018)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-demais-hipÃ³teses",
    "href": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-demais-hipÃ³teses",
    "title": "Contando possibilidades",
    "section": "3 Avaliando as demais hipÃ³teses",
    "text": "3 Avaliando as demais hipÃ³teses\nConsiderando que a caixa contenha [ğŸ”µâšªâšªâšª], verificamos que apenas trÃªs dos 64 caminhos possÃ­veis poderiam gerar a sequÃªncia [ğŸ”µ â†’ âšª â†’ ğŸ”µ]. Falta agora aplicar a mesma lÃ³gica Ã s demais hipÃ³teses. Por exemplo, considere [âšªâšªâšªâšª]. HÃ¡ zero maneiras de essa hipÃ³tese produzir os dados observados, pois uma Ãºnica ğŸ”µ jÃ¡ Ã© logicamente incompatÃ­vel com ela. A hipÃ³tese [ğŸ”µğŸ”µğŸ”µğŸ”µ] tambÃ©m nÃ£o pode produzir a sequÃªncia, pois hÃ¡ ao menos uma âšª observada. Assim, podemos eliminar essas duas hipÃ³teses, pois nenhuma delas fornece sequer um Ãºnico caminho consistente com os dados.\nPara as hipÃ³teses restantes, isto Ã©, [ğŸ”µğŸ”µâšªâšª] e [ğŸ”µğŸ”µğŸ”µâšª], o leque de possibilidades se abre novamente.\nA FiguraÂ 5 mostra o leque completo para as trÃªs hipÃ³teses compatÃ­veis com os dados observados: [ğŸ”µâšªâšªâšª], [ğŸ”µğŸ”µâšªâšª] e [ğŸ”µğŸ”µğŸ”µâšª].\n\n\n\n\n\n\nFiguraÂ 5: Caminhos de composiÃ§Ã£o possÃ­vel para cada hipÃ³tese logicamente compatÃ­vel com a sequÃªncia observada. ExtraÃ­do de McElreath (2018).\n\n\n\nAgora, contamos todas as maneiras pelas quais cada hipÃ³tese poderia produzir os dados observados. Para uma bolinha azul e trÃªs brancas, existem trÃªs maneiras (como jÃ¡ contamos). Para duas bolinhas azuis e duas brancas, hÃ¡ oito caminhos consistentes com a sequÃªncia. Para trÃªs bolinhas azuis e uma branca, hÃ¡ nove caminhos que sobrevivem Ã s observaÃ§Ãµes.\nConsideramos, assim, as cinco hipÃ³teses diferentes sobre o conteÃºdo da caixa, variando de zero bolinhas ğŸ”µ a quatro bolinhas ğŸ”µ e, para cada uma dessas hipÃ³teses, contamos quantas possibilidades (ou â€œcaminhosâ€) poderiam potencialmente produzir a sequÃªncia observada.\n\n\n\nTabelaÂ 1: Total de maneiras pelas quais cada hipÃ³tese pode gerar a sequÃªncia [ğŸ”µ â†’ âšª â†’ ğŸ”µ].\n\n\n\n\n\nHipÃ³tese\nManeiras de produzir [ğŸ”µ â†’ âšª â†’ ğŸ”µ]\n\n\n\n\n1. [âšªâšªâšªâšª]\n\\(0 \\times 4 \\times 0 = 0\\)\n\n\n2. [ğŸ”µâšªâšªâšª]\n\\(1 \\times 3 \\times 1 = 3\\)\n\n\n3. [ğŸ”µğŸ”µâšªâšª]\n\\(2 \\times 2 \\times 2 = 8\\)\n\n\n4. [ğŸ”µğŸ”µğŸ”µâšª]\n\\(3 \\times 1 \\times 3 = 9\\)\n\n\n5. [ğŸ”µğŸ”µğŸ”µğŸ”µ]\n\\(4 \\times 0 \\times 4 = 0\\)\n\n\n\n\n\n\nObserve que o nÃºmero de maneiras de produzir os dados, para cada hipÃ³tese, pode ser obtido contando as ramificaÃ§Ãµes em cada camada do leque de possibilidades e, em seguida, multiplicando esses valores (TabelaÂ 1). Isso Ã© apenas um recurso computacional. Ele nos diz a mesma coisa que a FiguraÂ 5, mas sem precisar desenhar todo o diagrama. O fato de multiplicarmos os nÃºmeros nÃ£o altera o sentido de estarmos apenas contando caminhos logicamente possÃ­veis."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#atualizando-o-conhecimento",
    "href": "content/intro-bayes/intro-bayes-counting.html#atualizando-o-conhecimento",
    "title": "Contando possibilidades",
    "section": "4 Atualizando o conhecimento",
    "text": "4 Atualizando o conhecimento\nSuponha que o experimento anterior, sumarizado na TabelaÂ 1, tenha sido finalizado. Isso nos diz que, por ora, temos evidÃªncias melhores para as hipÃ³teses 3 e 4, isto Ã©, de que a caixa contenha 2 ou 3 bolinhas azuis. Para ajudar a diferenciar essas duas possibilidades ainda mais, resolvemos continuar o experimento e amostrar outra bolinha, o que resultou na observaÃ§Ã£o de uma bolinha azul. Como se trata de um novo experimento, poderÃ­amos recomeÃ§ar todo o processo. No entanto, hÃ¡ uma forma melhor de aproveitar o conhecimento adquirido a priori â€” para cada hipÃ³tese, listamos as maneiras anteriores de produzir as observaÃ§Ãµes (o prior) e multiplicamos pelo nÃºmero de maneiras de produzir a nova evidÃªncia ğŸ”µ:\n\n\n\nTabelaÂ 2: Total de maneiras pelas quais cada hipÃ³tese pode gerar a sequÃªncia completa [ğŸ”µ â†’ âšª â†’ ğŸ”µ â†’ ğŸ”µ], combinando a contagem anterior com a nova evidÃªncia.\n\n\n\n\n\n\n\n\n\n\n\nHipÃ³tese\nContagem anterior (prior)\nManeiras de produzir a nova observaÃ§Ã£o ğŸ”µ\nContagem posterior\n\n\n\n\n1. [âšªâšªâšªâšª]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n2. [ğŸ”µâšªâšªâšª]\n3\n1\n\\(3 \\times 1 = 3\\)\n\n\n3. [ğŸ”µğŸ”µâšªâšª]\n8\n2\n\\(8 \\times 2 = 16\\)\n\n\n4. [ğŸ”µğŸ”µğŸ”µâšª]\n9\n3\n\\(9 \\times 3 = 27\\)\n\n\n5. [ğŸ”µğŸ”µğŸ”µğŸ”µ]\n0\n4\n\\(0 \\times 4 = 0\\)\n\n\n\n\n\n\nA nova contagem na coluna da direita da TabelaÂ 2 resume as evidÃªncias a favor de cada hipÃ³tese, de modo que sejam compatÃ­veis tanto com as observaÃ§Ãµes anteriores quanto com a nova observaÃ§Ã£o. Portanto, Ã  medida que novos dados chegam e, desde que sejam independentes dos anteriores, o total de caminhos logicamente possÃ­veis para explicar tanto as observaÃ§Ãµes antigas quanto as novas pode ser calculado pela multiplicaÃ§Ã£o das contagens anteriores pelas novas.\nEm outras palavras, sempre que temos \\(W_\\text{prior}\\) maneiras de uma hipÃ³tese produzir observaÃ§Ãµes anteriores (\\(D_\\text{prior}\\)) e, em seguida, obtemos novas observaÃ§Ãµes (\\(D_\\text{novo}\\)) que essa mesma hipÃ³tese pode produzir de \\(W_\\text{novo}\\) maneiras, a quantidade total de formas possÃ­veis para essa hipÃ³tese explicar tanto os dados antigos quanto os novos Ã© dada simplesmente por \\(W_\\text{prior} \\times W_\\text{novo}\\). Por exemplo, na TabelaÂ 2, a hipÃ³tese [ğŸ”µğŸ”µâšªâšª] apresenta \\(W_\\text{prior} = 8\\) maneiras de gerar as observaÃ§Ãµes anteriores [ğŸ”µ â†’ âšª â†’ ğŸ”µ] e \\(W_\\text{novo} = 2\\) maneiras de gerar a nova observaÃ§Ã£o [ğŸ”µ]. Logo, \\(8 \\times 2 = 16\\) caminhos possÃ­veis para explicar tanto os dados antigos quanto os novos.\n\n\n\n\n\n\nAvisoCombinando evidÃªncias\n\n\n\nNo exemplo acima, os dados antigos e os novos sÃ£o do mesmo tipo (bolinhas observadas na caixa). Entretanto, nÃ£o hÃ¡ motivo para excluir a situaÃ§Ã£o em que os dados antigos e os novos tenham sido obtidos de forma diferente. Suponha, por exemplo, que alguÃ©m da fÃ¡brica de bolinhas informe que as azuis sÃ£o raras. Para cada caixa contendo [ğŸ”µğŸ”µğŸ”µâšª], a fÃ¡brica produz duas caixas contendo [ğŸ”µğŸ”µâšªâšª] e trÃªs caixas contendo [ğŸ”µâšªâšªâšª]. TambÃ©m garante que cada caixa contenha pelo menos uma bolinha azul e uma bolinha branca. Com essa nova informaÃ§Ã£o, podemos atualizar nossas contagens novamente (TabelaÂ 3).\n\n\n\nTabelaÂ 3: Contagens atualizadas apÃ³s incorporar a nova observaÃ§Ã£o ğŸ”µ e as informaÃ§Ãµes externas sobre a frequÃªncia das hipÃ³teses.\n\n\n\n\n\n\n\n\n\n\n\nHipÃ³tese\nContagem anterior (prior)\nManeiras de produzir ğŸ”µ informadas pela fÃ¡brica\nNova contagem\n\n\n\n\n1. [âšªâšªâšªâšª]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n2. [ğŸ”µâšªâšªâšª]\n3\n3\n\\(3 \\times 3 = 9\\)\n\n\n3. [ğŸ”µğŸ”µâšªâšª]\n16\n2\n\\(16 \\times 2 = 32\\)\n\n\n4. [ğŸ”µğŸ”µğŸ”µâšª]\n27\n1\n\\(27 \\times 1 = 27\\)\n\n\n5. [ğŸ”µğŸ”µğŸ”µğŸ”µ]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n\n\n\n\nAgora, Ã  luz dessa informaÃ§Ã£o adicional, a hipÃ³tese [ğŸ”µğŸ”µâšªâšª] torna-se ligeiramente mais plausÃ­vel do que [ğŸ”µğŸ”µğŸ”µâšª]."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-distr-prob.html",
    "href": "content/intro-bayes/intro-bayes-distr-prob.html",
    "title": "De contagens a probabilidades",
    "section": "",
    "text": "Voltemos ao problema das bolinhas de gude. Temos uma caixa contendo quatro bolinhas, que podem ser azuis ou brancas. Sabemos que hÃ¡ exatamente quatro bolinhas, mas nÃ£o conhecemos a distribuiÃ§Ã£o entre as cores, pois podemos ver apenas uma bolinha por vez atravÃ©s de um orifÃ­cio. Para estimar quantas bolas de cada cor hÃ¡ na caixa, fazemos uma observaÃ§Ã£o, misturamos as bolinhas, fazemos outra observaÃ§Ã£o e assim por diante. Antes de realizarmos qualquer observaÃ§Ã£o, podemos listar cinco configuraÃ§Ãµes possÃ­veis para o conteÃºdo da caixa:\nNosso objetivo Ã© estimar o nÃºmero \\(N\\) de bolas azuis, o qual pode variar, neste exemplo, de 0 a 4. Como nÃ£o dispomos de conhecimento prÃ©vio sobre a composiÃ§Ã£o da caixa antes da primeira observaÃ§Ã£o, adotamos uma distribuiÃ§Ã£o a priori uniforme entre as hipÃ³teses. Assim, cada hipÃ³tese recebe uma probabilidade de \\(p = \\frac{1}{5}\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-distr-prob.html#distribuiÃ§Ãµes-a-priori-a-posteriori-e-verossimilhanÃ§a",
    "href": "content/intro-bayes/intro-bayes-distr-prob.html#distribuiÃ§Ãµes-a-priori-a-posteriori-e-verossimilhanÃ§a",
    "title": "De contagens a probabilidades",
    "section": "1 DistribuiÃ§Ãµes a priori, a posteriori e verossimilhanÃ§a",
    "text": "1 DistribuiÃ§Ãµes a priori, a posteriori e verossimilhanÃ§a\nSuponha que realizamos trÃªs observaÃ§Ãµes da caixa e a sequÃªncia registrada seja [ğŸ”µ, âšª, ğŸ”µ] â€“ ou seja, duas bolas azuis. Para atualizar nosso conhecimento sobre a composiÃ§Ã£o da caixa, combinamos nossa distribuiÃ§Ã£o a priori com a verossimilhanÃ§a de cada hipÃ³tese. A verossimilhanÃ§a Ã© calculada a partir da contagem do nÃºmero de maneiras em que cada hipÃ³tese pode gerar a sequÃªncia observada. Em seguida, aplicamos a regra de Bayes, que nos fornece a distribuiÃ§Ã£o a posteriori por meio da fÃ³rmula:\n\\[\\text{Posterior}_i = \\frac{\\text{Priori}_i \\times P_i}{\\sum_{j} \\left(\\text{Priori}_j \\times P_j\\right)}, \\tag{1}\\]\nonde \\(P_i\\) representa, de forma proporcional, o nÃºmero de caminhos possÃ­veis para que a hipÃ³tese \\(i\\) gere a sequÃªncia [ğŸ”µ, âšª, ğŸ”µ].\nA equaÃ§Ã£o EquaÃ§Ã£oÂ 1 indica que, para cada valor que \\(N\\) pode assumir, julgamos sua plausibilidade como proporcional ao nÃºmero de maneiras pelas quais esse valor pode ter gerado os dados, multiplicado pela sua evidÃªncia anterior (a distribuiÃ§Ã£o a priori). Esse produto â€“ representado na TabelaÂ 2 por \\(\\text{Priori}_i \\times P_i\\) â€“ Ã© entÃ£o normalizado, dividindo cada um deles pelo somatÃ³rio \\(\\sum (1/5 \\times \\text{NÂº de caminhos})\\). Essa normalizaÃ§Ã£o gera a distribuiÃ§Ã£o a posteriori, que reflete nosso conhecimento atualizado apÃ³s a incorporaÃ§Ã£o das evidÃªncias observadas.\nNa TabelaÂ 2, a coluna â€œManeiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]â€ indica o nÃºmero de caminhos possÃ­veis para que cada hipÃ³tese gere a sequÃªncia observada. Note que as hipÃ³teses [âšªâšªâšªâšª] e [ğŸ”µğŸ”µğŸ”µğŸ”µ] nÃ£o conseguem gerar a sequÃªncia (ou seja, possuem verossimilhanÃ§a zero).\n\n\n\nTabelaÂ 2: AtualizaÃ§Ã£o da distribuiÃ§Ã£o de probabilidade combinando a priori e verossimilhanÃ§a\n\n\n\n\n\n\n\n\n\n\n\n\nHipÃ³tese\nN\nPriori\nManeiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]\nPosterior\n\n\n\n\n[âšªâšªâšªâšª]\n0\n\\(1/5\\)\n\\(0 \\times 4 \\times 0 = 0\\)\n\\(\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0\\)\n\n\n[ğŸ”µâšªâšªâšª]\n1\n\\(1/5\\)\n\\(1 \\times 3 \\times 1 = 3\\)\n\\(\\dfrac{(1/5 \\times 3)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.15\\)\n\n\n[ğŸ”µğŸ”µâšªâšª]\n2\n\\(1/5\\)\n\\(2 \\times 2 \\times 2 = 8\\)\n\\(\\dfrac{(1/5 \\times 8)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.40\\)\n\n\n[ğŸ”µğŸ”µğŸ”µâšª]\n3\n\\(1/5\\)\n\\(3 \\times 1 \\times 3 = 9\\)\n\\(\\dfrac{(1/5 \\times 9)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.45\\)\n\n\n[ğŸ”µğŸ”µğŸ”µğŸ”µ]\n4\n\\(1/5\\)\n\\(4 \\times 0 \\times 4 = 0\\)\n\\(\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0\\)\n\n\n\n\n\n\nDessa forma, a plausibilidade de cada hipÃ³tese Ã© convertida em probabilidades â€“ valores nÃ£o negativos cuja soma Ã© igual a 1 â€“ para cada uma das hipÃ³teses sobre o conteÃºdo da caixa. O resultado final da inferÃªncia bayesiana Ã© fornecer uma base probabilÃ­stica para a tomada de decisÃ£o sobre um fenÃ´meno parcialmente desconhecido, expressando o quÃ£o plausÃ­vel Ã© cada hipÃ³tese Ã  luz dos dados disponÃ­veis (FiguraÂ 1).\n\n\n\n\n\n\n\n\nFiguraÂ 1: DistribuiÃ§Ã£o a priori (esquerda) e a posteriori (direita) para o nÃºmero de bolas azuis. A priori, as hipÃ³teses tÃªm probabilidade uniforme; a posteriori, a observaÃ§Ã£o [ğŸ”µ, âšª, ğŸ”µ] atualiza a plausibilidade, favorecendo hipÃ³teses intermediÃ¡rias\n\n\n\n\n\nEsses conceitos possuem nomenclaturas especÃ­ficas, e vale a pena aprendÃª-los, pois vocÃª os encontrarÃ¡ repetidamente:\n\nA conjectura sobre o nÃºmero de bolinhas azuis \\(N\\) Ã© chamada de valor do parÃ¢metro â€“ uma maneira de indexar as possÃ­veis explicaÃ§Ãµes para os dados.\nO nÃºmero relativo de maneiras pelo qual esse parÃ¢metro pode produzir os dados Ã© chamado de verossimilhanÃ§a (likelihood). Essa medida Ã© obtida ao enumerar todas as sequÃªncias de dados possÃ­veis e, em seguida, descartar aquelas que nÃ£o sÃ£o compatÃ­veis com os dados observados.\nA plausibilidade anterior de um valor especÃ­fico Ã© denominada distribuiÃ§Ã£o de probabilidade a priori.\nA plausibilidade atualizada de um valor especÃ­fico, apÃ³s a incorporaÃ§Ã£o dos dados, Ã© denominada distribuiÃ§Ã£o de probabilidade a posteriori, utilizada para inferir a probabilidade de cada hipÃ³tese ou conjunto de hipÃ³teses sobre o parÃ¢metro."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html",
    "href": "content/teste-hipoteses/teste-t.html",
    "title": "Comparando mÃ©dias: teste t de Student",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas no capÃ­tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nO modelo normal de probabilidades nÃ£o Ã© a melhor aproximaÃ§Ã£o para a distribuiÃ§Ã£o das mÃ©dias amostrais quando nÃ£o conhecemos \\(\\mu\\) e \\(\\sigma\\) e/ou quando o tamanho amostral \\(n\\) Ã© pequeno. Nesta situaÃ§Ã£o, a distribuiÃ§Ã£o t de Student Ã© mais apropriada para o cÃ¡lculo do intervalo de confianÃ§a. Da mesma forma, o teste \\(Z\\) assume que a distribuiÃ§Ã£o das mÃ©dias amostrais Ã© normalmente distribuÃ­da e que a variÃ¢ncia populacional \\(\\sigma\\) seja conhecida, uma informaÃ§Ã£o que nÃ£o temos na prÃ¡tica cientÃ­fica.\nO teste t de Student Ã© utilizado em substituiÃ§Ã£o ao teste \\(Z\\) quando \\(\\sigma\\) Ã© desconhecido e/ou o tamanho amostral Ã© pequeno. A lÃ³gica do teste Ã© a mesma apresentada discutida no teste \\(Z\\), porÃ©m estabelece que a distribuiÃ§Ã£o das mÃ©dias amostrais Ã© melhor descrita pela distribuiÃ§Ã£o \\(t\\) e nÃ£o pela distribuiÃ§Ã£o normal."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#teste-t-para-uma-mÃ©dia-populacional",
    "href": "content/teste-hipoteses/teste-t.html#teste-t-para-uma-mÃ©dia-populacional",
    "title": "Comparando mÃ©dias: teste t de Student",
    "section": "1 Teste t para uma mÃ©dia populacional",
    "text": "1 Teste t para uma mÃ©dia populacional\nConsidere um exemplo simples. Dados do Banco Central do Brasil dizem que moedas de \\(R\\$ 0,10\\) da segunda geraÃ§Ã£o pesam 4.8 gramas. VocÃª tem \\(8\\) moedas no bolso e resolve testar essa afirmaÃ§Ã£o pesando cada moeda. Os pesos obtidos sÃ£o: \\(X = 5.1, 5, 4.8, 5, 5, 4.9, 4.9, 4.7\\).\nInicialmente, devemos estabelecer nossa hipÃ³tese nula (\\(H_0\\)), nossa hipÃ³tese alternativa (\\(H_a\\)) e o nÃ­vel se significÃ¢ncia \\(\\alpha\\). Iremos estabelecer \\(\\alpha = 0,05\\) e as hipÃ³teses como:\n\\(H_0: \\mu = 4.8\\) gramas\n\\(H_a: \\mu \\ne 4.8\\) gramas\nComo nÃ£o conhecemos \\(\\sigma\\) e temos uma amostra pequena, a posiÃ§Ã£o das mÃ©dias amostrais seguirÃ¡ uma distribuiÃ§Ã£o \\(t\\) de Student e a estatÃ­stica do teste serÃ¡:\n\\[t = \\frac{\\overline{X} - \\mu}{s_{\\overline{X}}}\\]\nsendo o erro padrÃ£o amostral obtido por:\n\\[s_{\\overline{X}} = \\frac{s}{\\sqrt{n}}\\]\nO cÃ¡lculo de \\(t\\) Ã© muito similar ao escore \\(Z\\). No entanto, substituÃ­mos \\(\\sigma\\) por \\(s\\). As distribuiÃ§Ãµes de \\(t\\) e de \\(Z\\) sÃ£o muito similares. Entretanto, para amostras pequenas e quando \\(\\sigma\\) Ã© desconhecido, a curva de \\(t\\) nos fornece uma melhor estimativa das probabilidades associadas a distribuiÃ§Ã£o das mÃ©dias amostrais.\nPara este exemplo, temos uma amostra de tamanho \\(n = 8\\) com mÃ©dia \\(\\overline{X} = 4.925\\)g e desvio padrÃ£o \\(s = 0.13\\)g. O valor de \\(t\\) pode ser calculado por:\n\\[t_{c} = \\frac{\\overline{X} - \\mu}{s_{\\overline{X}}} = \\frac{\\overline{X} - \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{4.925  - 4.8}{\\frac{0.13}{\\sqrt{8}}} = 2.76\\]\nAssim como fizemos para a distribuiÃ§Ã£o \\(Z\\), devemos encontrar a probabilidade de obtermos um valor tÃ£o ou maior que o mÃ³dulo de \\(t_c\\). Na figura abaixo, nosso resultado fica:\n\n\n\n\n\n\n\n\nFiguraÂ 2: Valor de p associado ao resultado do teste t.\n\n\n\n\n\nA probabilidade de encontrarmos um valor de \\(t_c\\) tÃ£o ou mais extremo segundo a hipÃ³tese nula foi de \\(p = 0.028\\). Uma vez que este valor Ã© menor que o nÃ­vel crÃ­tico \\(\\alpha = 0,05\\), concluÃ­mos que existe evidÃªncia suficiente para rejeitar \\(H_0\\) e aceitar a hipÃ³tese alternativa de que as moedas de \\(10\\) centavos nÃ£o provÃ©m de uma populaÃ§Ã£o estatÃ­stica com \\(\\mu = 4,8\\) gramas. Nossa conclusÃ£o Ã© portanto, que as moedas de \\(R\\$ 0,10\\) sÃ£o mais pesadas que \\(4,8\\) gramas.\n\n\n\n\n\n\nNotaTerste t no R\n\n\n\n\nt.test(X, mu = 4.8)\n\n\n    One Sample t-test\n\ndata:  X\nt = 2.7584, df = 7, p-value = 0.02816\nalternative hypothesis: true mean is not equal to 4.8\n95 percent confidence interval:\n 4.817844 5.032156\nsample estimates:\nmean of x \n    4.925 \n\n\n\nNos comandos acima, \\(X\\) Ã© a amostra e o argumento mu representa a expectativa sobre a mÃ©dia populacional segundo \\(H_0\\). Como resultados temos:\n\na indicaÃ§Ã£o de que fizemos um teste \\(t\\) para uma amostra: One Sample t-test;\no valor de \\(t\\) calculado: t = 2.7584;\nos graus de liberdade: df = 8 - 1 = 7; e\no valor de p = 0.028.\n\nA saÃ­da da funÃ§Ã£o apresenta ainda o valor da mÃ©dia amostral (\\(\\overline{X} = 4.925\\)) e o intervalo de confianÃ§a a \\(95\\%\\) (4.817844 - 5.032156)."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#graus-de-liberdade",
    "href": "content/teste-hipoteses/teste-t.html#graus-de-liberdade",
    "title": "Comparando mÃ©dias: teste t de Student",
    "section": "2 Graus de liberdade",
    "text": "2 Graus de liberdade\nA distribuiÃ§Ã£o \\(t\\) como vÃ¡rias outras distribuiÃ§Ãµes amostrais utilizadas em inferÃªncia estatÃ­stica, muda seu formato em funÃ§Ã£o do que chamamos de graus de liberdade (\\(gl\\)). Os graus de liberdade tÃªm relaÃ§Ã£o com o tamanho amostral. No caso do teste \\(t\\) para \\(1\\) amostra, esta relaÃ§Ã£o Ã© simplesmente: \\(gl = n-1\\).\nÃ€ medida que os graus de liberdade aumentam, o formato da distribuiÃ§Ã£o \\(t\\) se assemelha ao formato da distribuiÃ§Ã£o Normal padronizada. De fato, para graus de liberdades altos (ex. \\(n \\ge 30\\)), os formatos das distribuiÃ§Ãµes \\(Z\\) e \\(t\\) sÃ£o praticamente indistinguÃ­veis. Na prÃ¡tica, isto faz que as distribuiÃ§Ã£o \\(Z\\) raramente seja utilizada.\n\n\n\n\n\n\n\n\nFiguraÂ 3: FunÃ§Ã£o de densidade de t para diferentes graus de liberdade."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#probabilidades-no-teste-t-de-student-a-tabela-t",
    "href": "content/teste-hipoteses/teste-t.html#probabilidades-no-teste-t-de-student-a-tabela-t",
    "title": "Comparando mÃ©dias: teste t de Student",
    "section": "3 Probabilidades no teste \\(t\\) de Student: a tabela \\(t\\)",
    "text": "3 Probabilidades no teste \\(t\\) de Student: a tabela \\(t\\)\nA rejeiÃ§Ã£o uo aceitaÃ§Ã£o da hipÃ³tese nula em um teste \\(t\\) pode ser feita por meio da obtenÃ§Ã£o do valor de p ou pela comparaÃ§Ã£o do \\(t\\) calculado com valores crÃ­ticos de referÃªncia para determinado nÃ­vel de significÃ¢ncia. O primeiro caso foi o que apresentamos acima e depende de um software estatÃ­stico para obtermos valores exatos de \\(p\\). O segundo caso, pode ser feito com auxÃ­lio da Tabela \\(t\\), em que limites crÃ­ticos de \\(t\\) sÃ£o disponibilizados para diferentes nÃ­veis de significÃ¢ncia e graus de liberdade.\nAtualmente, o uso da tabela \\(t\\) tÃªm finalidade em grande parte didÃ¡tica e, por este motivo, vamos apresentÃ¡-lo aqui rapidamente. No entanto, fora da sala de aula, o teste \\(t\\) serÃ¡ invariavelmente conduzido por meio de um software estatÃ­stico este mÃ©todo que permitirÃ¡ a obtenÃ§Ã£o do valor exato de \\(p\\).\nNa Tabela t, a primeira coluna mostra os graus de liberdade de \\(1\\) a \\(120\\). O cabeÃ§alho da tabela de \\(90\\%\\) a \\(0,1\\%\\) mostra a Ã¡rea na distribuiÃ§Ã£o de \\(t\\) nas caldas inferior e superior.\nVamos retornar ao exemplo da moedas de \\(R\\$0,10\\) para exemplificar sua utilizaÃ§Ã£o. Neste exemplo a tinhamos \\(8\\) (\\(gl = 7\\) graus de liberdade) e o teste foi feito com \\(\\alpha =0,05\\). Se buscarmos na linha \\(gl = 7\\) e a coluna \\(5\\%\\) (\\(\\alpha = 0,05\\)), encontraremos o valor \\(t = 2,3646\\). Este Ã© o chamado \\(t\\) crÃ­tico (\\(t_{crÃ­tico}\\)). Acima deste valor e abaixo de sua contraparte negativa temos exatamente \\(5\\%\\) da Ã¡rea na disribuiÃ§Ã£o \\(t\\). Deste modo, qualquer valor calulado maior que \\(t_{crÃ­tico}\\) estarÃ¡ mais para a extremidade da distribuiÃ§Ã£o e consequentemente estarÃ¡ associado a menores valores de probabilidade. Neste sentido:\n\n\\(t_{calculado} \\ge t_{crÃ­tico}\\) leva a rejeiÃ§Ã£o de \\(H_0\\)\n\n\n\\(t_{calculado} &lt; t_{crÃ­tico}\\) leva a aceitaÃ§Ã£o de \\(H_0\\)\n\nO resultado do teste estatÃ­stico em nosso exemplo foi \\(t_c = 2.76\\) que Ã© maior que \\(2,3646\\). Isto nos leva Ã  mesma decisÃ£o anterior (rejeitar \\(H_0\\)), ainda que por meio da tabela \\(t\\) nÃ£o tenhamos o valor exato de probabilidade."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#teste-t-para-comparaÃ§Ã£o-de-duas-mÃ©dias-independentes",
    "href": "content/teste-hipoteses/teste-t.html#teste-t-para-comparaÃ§Ã£o-de-duas-mÃ©dias-independentes",
    "title": "Comparando mÃ©dias: teste t de Student",
    "section": "4 Teste t para comparaÃ§Ã£o de duas mÃ©dias independentes",
    "text": "4 Teste t para comparaÃ§Ã£o de duas mÃ©dias independentes\nO que vimos no teste \\(t\\) para uma amostra pode ser facilmente extendido para testarmos a diferenÃ§as entre duas amostras.\nOs dados abaixo mostram o tempo de coagulaÃ§Ã£o sanguÃ­nea (em minutos) em ratos machos adultos tratados com dois tipos de drogas, retirado do livro Biostatistical Analysis (Zar 2010), pp.Â 130-134.\n\n\nCÃ³digo\nra &lt;- data.frame(Droga = factor(c(rep(\"Droga A\", 6), rep(\"Droga B\",7))),\n                Tempo = c(8.8, 8.4, 7.9, 8.7, 9.1, 9.6, \n                          9.9, 9.0, 11.1, 9.6, 8.7, 10.4, 9.5))\n\n\n\n\n\n\nTabelaÂ 1: Tempo de coagulaÃ§Ã£o sanguÃ­nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\n\n\n\n\nDroga\nTempo\n\n\n\n\nDroga A\n8.80\n\n\nDroga A\n8.40\n\n\nDroga A\n7.90\n\n\nDroga A\n8.70\n\n\nDroga A\n9.10\n\n\nDroga A\n9.60\n\n\nDroga B\n9.90\n\n\nDroga B\n9.00\n\n\nDroga B\n11.10\n\n\nDroga B\n9.60\n\n\nDroga B\n8.70\n\n\nDroga B\n10.40\n\n\nDroga B\n9.50\n\n\n\n\n\n\n\n\n\n\nNosso objetivo Ã© testar se as duas drogas resultam, em mÃ©dia, no mesmo tempo de coagulaÃ§Ã£o. Inicialmente, vamos fazer um grÃ¡fico de dispersÃ£o para verificar a distribuiÃ§Ã£o do tempo de coagulaÃ§Ã£o para cada droga.\n\n\nCÃ³digo\nggplot(ra, aes(y = Tempo, x = Droga)) +\n  geom_boxplot() +\n  geom_point(col = 2, size = 3) +\n  labs(y = 'Tempo de coalgulaÃ§Ã£o (min)', x = '') +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nFiguraÂ 4: DistribuiÃ§Ã£o do tempo de coagulaÃ§Ã£o sanguÃ­nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\nAs mÃ©dias, desvios padrÃµes e tamanhos amostrais de cada grupo sÃ£o:\n\n\nCÃ³digo\nra_m = ra |&gt; \n    group_by(Droga) |&gt; \n    summarize('Tempo mÃ©dio' = round(mean(Tempo),2), \n              Desvio = round(sd(Tempo),2), n = n() )\n\nra_m |&gt; \n  gt()\n\n\n\n\nTabelaÂ 2: Tempo de coagulaÃ§Ã£o sanguÃ­nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\n\n\n\n\nDroga\nTempo mÃ©dio\nDesvio\nn\n\n\n\n\nDroga A\n8.75\n0.58\n6\n\n\nDroga B\n9.74\n0.82\n7\n\n\n\n\n\n\n\n\n\n\nPara testarmos se as mÃ©dias dos grupos provÃ©m de populaÃ§Ãµes estatÃ­sticas com diferentes \\(\\mu's\\) devemos estabelecer nosso nÃ­vel de significÃ¢ncia (por exemplo \\(\\alpha = 0.05\\)) as hipoteses estatÃ­sticas:\n\\(H_0: \\mu_A = \\mu_B\\) gramas\n\\(H_a: \\mu_A \\ne \\mu_B\\) gramas\n\n\n\n\n\n\nNotaTeste de homogeneidade de variÃ¢ncias\n\n\n\nUm dos pressupostos do teste t que apresentaremos a frente Ã© de que as populaÃ§Ãµes que serÃ£o comparadas tÃªm a mesma variÃ¢ncia \\(\\sigma^2\\). Devemos portanto testar o pressuposto de homogeneidade de variÃ¢ncias que pode ser realizado com o teste de razÃ£o de variÃ¢ncias.\nNo R fazemos o teste de homogeneidade de variÃ¢ncias com o comando abaixo.\n\nvar.test(ra$Tempo ~ ra$Droga)\n\n\n    F test to compare two variances\n\ndata:  ra$Tempo by ra$Droga\nF = 0.50633, num df = 5, denom df = 6, p-value = 0.4722\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.08456359 3.53301988\nsample estimates:\nratio of variances \n           0.50633 \n\n\nNo teste acima, \\(F_{calculado} = 0.51\\) e \\(p = 0.472\\). Assumindo um \\(\\alpha = 0,05\\), concluÃ­mos que nÃ£o hÃ¡ evidÃªncias para rejeitar a hipÃ³tese de homogeneidade e que assumimos que as duas populaÃ§Ãµes tÃªm a mesma variÃ¢ncia. Deste modo podemos continuar com o teste t.\n\n\nO teste t para duas amostras Ã© calculado por:\n\\[t = \\frac{(\\overline{X_A} - \\mu_A) - (\\overline{X_B} - \\mu_B)}{s_{\\overline{X_A}-\\overline{X_B}}}\\]\nAssumindo a hipotese nula em que \\(\\mu_A = \\mu_B\\) a expressÃ£o fica\n\\[t = \\frac{\\overline{X_A} - \\overline{X_B}}{s_{\\overline{X_A}-\\overline{X_B}}}\\]\nem que a quantia \\(s_{\\overline{X_A}-\\overline{X_B}}\\) Ã© calculada por:\n\\[s_{\\overline{X_A}-\\overline{X_B}} = \\sqrt{\\frac{s^2_{p}}{n_1} + \\frac{s^2_{p}}{n_2}}\\]\n\\(s_p\\) Ã© denominada de variÃ¢ncia conjunta calculada por\n\\[s^2_p = \\frac{(n_1 - 1) \\times s^2_1 + (n_2 - 1) \\times s^2_2}{(n_1 - 1) + (n_2 - 1)}\\]\nPara este exemplo,\n\\(s_p = 0.52\\)\ne\n\\(s_{\\overline{X_A}-\\overline{X_B}} =  0.4\\)\nO valor de t calculado Ã©:\n\\(t_c =  -2.476\\)\nNa distribuiÃ§Ã£o t, a probabilidade de encontrar valores tÃ£o ou mais extremos que 2.476 Ã© de \\(p = 0.031\\).\nPortanto:\n\\(P(|t| \\ge 2.476) \\le 0.05\\)\nUma vez que a probabilidade associada ao valor de \\(t\\) Ã© menor que o nÃ­vel de significÃ¢ncia, rejeitamos \\(H_0\\) e assumimos que os tempos mÃ©dios de coagulaÃ§Ã£o sÃ£o diferentes. Ao avaliar as mÃ©dia amostrais \\(\\overline{X}_A\\) e \\(\\overline{X}_B\\), concluÃ­mos que a droga \\(A\\) resulta, em mÃ©dia, em tempos menores de coagulaÃ§Ã£o.\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html",
    "href": "content/teste-hipoteses/intro-testehipot.html",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nUm dos objetivos centrais em estatÃ­stica Ã© fazer inferÃªncias vÃ¡lidas para a populaÃ§Ã£o examinando as caracterÃ­sticas de uma amostra. Considere as afirmaÃ§Ãµes abaixo:\nTodas estas afirmaÃ§Ãµes sÃ£o na realidade hipÃ³teses, sobre um ou mais parÃ¢metros de uma populaÃ§Ã£o estatÃ­stica que podem ser testadas por meio de experimentos adequados. A experimentaÃ§Ã£o nos permite tirar conclusÃµes sobre determitada hipÃ³tese com base na amostra. Mais especificamente, queremos saber se os dados em mÃ£os nos permitem ou nÃ£o refutar uma hipÃ³tese inicial. Portanto, se desejamos fazer uma inferÃªncia sobre um parÃ¢metro da populaÃ§Ã£o estatÃ­stica (ex.: sua mÃ©dia \\(\\mu\\)), devemos iniciar com uma afirmaÃ§Ã£o sobre a posiÃ§Ã£o deste parÃ¢metro, que denominamos de hipÃ³tese nula (\\(H_0\\))."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#probabilidade-e-teste-de-hipÃ³teses",
    "href": "content/teste-hipoteses/intro-testehipot.html#probabilidade-e-teste-de-hipÃ³teses",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "1 Probabilidade e teste de hipÃ³teses",
    "text": "1 Probabilidade e teste de hipÃ³teses\nA mÃ©dia \\(\\overline{X}\\) de uma amostra serÃ¡ nossa melhor evidÃªncia a respeito de \\(\\mu\\). Tendo este valor, podemos nos perguntar:\n\nO valor obtido de \\(\\overline{X}\\) Ã© condizente com o esperado segundo \\(H_0\\)?\n\nCaso \\(\\overline{X}\\) esteja muito prÃ³ximo a \\(\\mu\\), nÃ£o hÃ¡ evidÃªncias para rejeitar \\(H_0\\). Por outro lado, um valor de \\(\\overline{X}\\) muito distante de \\(\\mu\\) irÃ¡ colocar em dÃºvida a afirmaÃ§Ã£o estabelecida em \\(H_0\\). O ponto relevante aqui Ã© decidirmos quÃ£o distante de \\(\\mu\\) deve estar \\(\\overline{X}\\) para que rejeitemos \\(H_0\\)? Esta resposta poderÃ¡ ser respondida somente com o auxÃ­lio de um modelo probabilÃ­stico aplicado ao experimento em questÃ£o.\nSeja \\(H_0\\) verdadeira, Ã© esperado que a probabilidade de \\(\\overline{X}\\) estar prÃ³ximo a \\(\\mu\\) Ã© alta. Portanto, uma pergunta melhor formulada seria:\n\nSendo \\(H_0\\) verdadeira, qual Ã© a probabilidade de que uma determinada mÃ©dia amostral \\(\\overline{X}\\) esteja tÃ£o ou mais distante de \\(\\mu\\) quanto o observado em nossa amostra particular?\n\n\n1.1 Um modelo de distribuiÃ§Ã£o das mÃ©dias amostrais para testar \\(H_0\\)\nA pergunta feita acima Ã© de natureza probabilÃ­stica, de modo que para respondÃª-la iremos precisar estabelecer um modelo probabilÃ­stico para a distribuiÃ§Ã£o das mÃ©dias amostrais. De acordo com o que temos discutido atÃ© este ponto, Teorema Central do Limite (TCL) estabelece que a distribuiÃ§Ã£o normal Ã© um bom modelo neste situaÃ§Ã£o.\nDesta forma, para um \\(H_0\\) verdadeiro, seria esperado que a distribuiÃ§Ã£o das mÃ©dias amostrais resultantes de um procedimento experimental tivesse o formato de um distribuiÃ§Ã£o normal, centrada em \\(110\\) mm. Segundo o TCL, a distribuiÃ§Ã£o seria centrada em \\(\\mu\\) e o desvio padrÃ£o seria definido pelo erro padrÃ£o da mÃ©dia, isto Ã©, \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\nDigamos ainda que o modelo climÃ¡tico estabeleÃ§a que desvio padrÃ£o para a quantidade de chuva seja \\(\\sigma = 30\\). Neste caso, o erro padrÃ£o seria de \\(\\sigma_{\\mu} = \\frac{30}{\\sqrt{n}}\\).\nFeito isto, temos em mÃ£os o modelo probabilÃ­stico que, aliado a uma amostra particular, nos permitirÃ¡ concluir se hÃ¡ evidÃªncias para rejeitar \\(H_0\\) em favor de \\(H_a\\).\n\n\n1.2 Definindo o limite de rejeiÃ§Ã£o para \\(H_0\\): nivel de significÃ¢ncia \\(\\alpha\\)\nSegundo a distribuiÃ§Ã£o normal, a probabilidade do valor observado \\(\\overline{X}\\) estar tÃ£o ou mais distante de \\(\\mu\\) na distribuiÃ§Ã£o \\(Z\\) Ã© calculando por:\n\\[z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\overline{X}}}\\]\nO valor de \\(z\\) calculado Ã© chamado de estatitica do teste. Com o uso da Tabela \\(Z\\), esta estatÃ­stica serÃ¡ utilizada para encontrar:\n\\[P(Z \\ge z) = P(\\overline{X} \\ge \\mu)\\] A probabilidade \\(P(Z \\ge z)\\) Ã© encontrada na distribuiÃ§Ã£o normal padronizada em que \\(Z \\sim \\mathcal{N}(0,\\,\\frac{\\sigma}{\\sqrt{n}})\\) e como nossa pergunta se refere Ã  distÃ¢ncia entre \\(\\overline{X}\\) e \\(\\mu\\), devemos encontar tambÃ©m \\(P(Z \\le -z)\\), de modo que a probabilidade que nos interessa Ã© denominada de valor de p de um teste de hipÃ³teses:\n\\[p = P(Z \\ge |z|)\\]\nO valor de \\(p\\) Ã© a Ã¡rea destacada em vermelho da distribuiÃ§Ã£o normal padronizada:\n\n\n\n\n\n\n\n\nFiguraÂ 1: RepresentaÃ§Ã£o da Ã¡rea de rejeiÃ§Ã£o na distribuiÃ§Ã£o Z.\n\n\n\n\n\nA Ã¡rea destacada em vermelho diminui conforme \\(\\overline{X}\\) se distancia de \\(\\mu\\) e aumenta se \\(\\overline{X}\\) estÃ¡ prÃ³ximo a \\(\\mu\\).\n\n\n\n\n\n\nNotaO valor de p e nÃ­vel de significÃ¢ncia\n\n\n\nMede a probabilidade de encontrarmos \\(\\overline{X}\\) tÃ£o ou mais distante de \\(\\mu\\), assumindo que \\(H_0\\) seja verdadeira. Se \\(p\\) for muito pequeno, a probabilidade de que \\(\\overline{X}\\) seja condizente com \\(H_0\\) diminui. Neste caso dizemos que Ã© improvÃ¡vel que \\(\\overline{X}\\) seja proviniente de \\(H_0\\), o que nos leva levando a rejeitar a hipÃ³tese nula em favor de \\(H_a\\).\nA decisÃ£o de rejeitar \\(H_0\\) depende do limite de rejeiÃ§Ã£o \\(\\alpha\\), tambÃ©m chamado de nivel crÃ­tico ou nÃ­vel de significÃ¢ncia. A definir o valor de \\(\\alpha\\), a conclusÃ£o de um teste estatÃ­stico se dÃ¡ por (FiguraÂ 2):\n\nSe \\(p &gt; \\alpha\\) â€“&gt; ACEITAMOS \\(H_0\\), \\(\\overline{X}\\) estÃ¡ prÃ³ximo de \\(\\mu\\)\nSe \\(p \\le \\alpha\\) â€“&gt; REJEITAMOS \\(H_0\\), \\(\\overline{X}\\) estÃ¡ distante de \\(\\mu\\). A assumimos \\(H_a\\) como verdadeira.\n\n\n\n\n\n\n\n\n\nFiguraÂ 2: Efeito do nÃ­vel de significancia sobre a Ã¡rea de rejeiÃ§Ã£o em um teste de hipÃ³tese."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#exemplificando-um-teste-de-hipÃ³teses-o-teste-z",
    "href": "content/teste-hipoteses/intro-testehipot.html#exemplificando-um-teste-de-hipÃ³teses-o-teste-z",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "2 Exemplificando um teste de hipÃ³teses: o teste \\(Z\\)",
    "text": "2 Exemplificando um teste de hipÃ³teses: o teste \\(Z\\)\n\n\n\n\n\n\nNotaDescriÃ§Ã£o do problema\n\n\n\nDigamos que o nÃºmero de batimentos cardÃ­acos por minuto de um adulto em repouso tenha mÃ©dia \\(\\mu = 65\\) e desvio padrÃ£o \\(\\sigma = 9\\). VocÃª imagina que o sedentarismo altera o batimento mÃ©dio de um adulto.\n\n\n\nHipÃ³teses estatÃ­ticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\ne 65\\) batimentos por minuto\n\nLimite de rejeiÃ§Ã£o: determinamos o nÃ­vel de significÃ¢ncia (\\(\\alpha\\)) do teste como \\(\\alpha = 0,05\\).\n\n\nIMPORTANTE: O nÃ­vel de significÃ¢ncia \\(\\alpha\\) deve ser determinado antes da tomada de dados.\n\n\nExperimento: selecionamos uma amostra aleatÃ³ria selecionando ao acaso \\(n = 15\\) pessoas de hÃ¡bito sedentÃ¡rio e medimos seus batimentos cardÃ­acos. Os resultados sÃ£o:\n\nAmostra: 65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66\nque nos dÃ¡ uma mÃ©dia amostral de:\n\\(\\overline{X} = \\frac{\\sum{X_i}}{n} = \\frac{65+73+56+71+69+69+68+59+73+68+69+64+67+64+66}{15} = 66.73\\) batimentos por minuto;\ne um erro padrÃ£o de:\n\\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{9}{3.87} = 2.32\\)\n\nTeste de hipÃ³teses: com estes resultados encontramos o valor correspondente de Z.\n\n\\(z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\mu}} = \\frac{66.73 - 65}{2.32} = 0.75\\)\ne utilizando a Tabela Z , encontramos a probabilidade de obtermos valores tÃ£o ou mais extremos que \\(-0.75\\) e \\(+0.75\\).\n\n\n\n\n\n\n\n\nFiguraÂ 3: Ãrea de rejeiÃ§Ã£o para z = 0,75.\n\n\n\n\n\nCom isto, a probabilidade de encontarmos valores tÃ£o ou mais extermos que \\(\\overline{X} = 66.73\\) foi calculada em \\(0.227 + 0.227 =\\) 0.453.\nNeste exemplo, a estatÃ­stica do teste foi \\(z = 0.75\\) o a probabilidade associada \\(p = 0.453\\).\n\n\n\n\n\n\nNotaTeste Z no R\n\n\n\n\nX &lt;- c(65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66)\nXm &lt;- mean(X)\npnorm(q = Xm, mean = 65, sd = 9/sqrt(15), lower.tail = FALSE) * 2\n\n[1] 0.4557231"
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#tomada-de-decisÃ£o-sobre-h_0-nÃ­vel-de-significÃ¢ncia",
    "href": "content/teste-hipoteses/intro-testehipot.html#tomada-de-decisÃ£o-sobre-h_0-nÃ­vel-de-significÃ¢ncia",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "3 Tomada de decisÃ£o sobre \\(H_0\\): nÃ­vel de significÃ¢ncia",
    "text": "3 Tomada de decisÃ£o sobre \\(H_0\\): nÃ­vel de significÃ¢ncia\nNo exemplo anterior, obtivemos \\(p =\\) 0.453. Isto significa que:\n\nsendo \\(H_0\\) verdadeira, existe uma probabilidade igual a \\(0.453\\) de que a mÃ©dia de uma amostra com \\(n = 15\\) esteja tÃ£o ou mais distante de \\(\\mu = 65\\) como observado neste experimento.\n\nSe aceitarmos que esta probabilidade Ã© alta, entÃ£o nÃ£o hÃ¡ motivo para buscar por outras explicaÃ§Ãµes. Por outro lado, se concluirmos que esta probabilidade Ã© baixa, estamos dizendo que resultado obtido Ã© improvÃ¡vel segundo a hipÃ³tese nula. Neste caso, devemos recorrer Ã  hipÃ³tese alternativa para explicar o fenÃ´meno.\nPara decidir se a probabilidade obtida Ã© alta ou baixa, devemos comparÃ¡-la ao nÃ­vel de significÃ¢ncia \\(\\alpha\\) prÃ©-estabelecido. \\(H_0\\) serÃ¡ aceita somente se a probabilidade encontrada for maior que \\(\\alpha\\). Por outro lado, se nossa probabilidade for menor ou igual a \\(\\alpha\\), considerarmos os resultados improvÃ¡veis segundo a hipÃ³tese nula e rejeitamos \\(H_0\\) em favor de \\(H_a\\).\nUm nÃ­vel crÃ­tico comumente utilizado Ã© \\(\\alpha = 0.05\\). No exemplo acima a probabilidade foi de 0.453, um valor muito acima de \\(0.05\\). Dizemos portanto, que a mÃ©dia amostral \\(\\overline{X}\\) nÃ£o estÃ¡ tÃ£o distante do \\(\\mu\\) a ponto de rejeitarmos \\(H_0\\).\n\nConcluimos que, neste exemplo, \\(\\overline{X} = 66.73\\) nÃ£o nos fornece evidÃªncia suficiente para rejeitar \\(H_0\\)."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#erros-de-decisÃ£o-em-um-teste-de-hipÃ³teses",
    "href": "content/teste-hipoteses/intro-testehipot.html#erros-de-decisÃ£o-em-um-teste-de-hipÃ³teses",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "4 Erros de decisÃ£o em um teste de hipÃ³teses",
    "text": "4 Erros de decisÃ£o em um teste de hipÃ³teses\nA interpretaÃ§Ã£o da probabilidade final esta associada Ã  situaÃ§Ã£o em que \\(H_0\\) seja verdadeira.\nIsto nos leva perguntar: o que esperar caso \\(H_0\\) seja falsa?\nComo nÃ£o sabemos de fato, de \\(H_0\\) Ã© verdadeira ou nÃ£o, a tomada de decisÃ£o sobre um resultado de um teste estatÃ­stico pode nos levar Ã s seguintes situaÃ§Ãµes:\n\n\n\nTabelaÂ 1: Erros de decisÃ£o em um teste de hipÃ³testes\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\) Verdadeira\n\\(H_0\\) Falsa\n\n\n\n\n\\(H_0\\) Ã© rejeitada\n\\(\\alpha\\) (\\(\\textbf{Erro Tipo I}\\))\nDecisÃ£o correta (\\(1-\\beta\\))\n\n\n\\(H_0\\) Ã© aceita\nDecisÃ£o correta (\\(1-\\alpha\\))\n\\(\\beta\\) (\\(\\textbf{Erro Tipo II}\\))\n\n\n\n\n\n\nA TabelaÂ 1 nos mostra os tipos de erros aos quais estamos sujeitos ao realizar um teste de hipÃ³tese. Podemos rejeitar \\(H_0\\), ainda que ela seja verdadeira. O nivel de significÃ¢ncia adotado, estabele que a probabilidade disto acontecer Ã© \\(\\alpha\\). Se rejeitarmos \\(H_0\\) quando ela Ã© verdadeira, estaremos incorrendo em um erro de decisÃ£o que denominamos de Erro Tipo I. Consequentemente, temos uma probabilidade de \\(1 - \\alpha\\) de aceitar corretamente \\(H_0\\) quando ela Ã© verdadeira. Estabelecer um \\(\\alpha = 0,05\\) nos garante que iremos incorrer no erro do tipo I em somente \\(5\\%\\) das vezes que o experimento for realizado.\nUm outra situaÃ§Ã£o ocorre quando aceitamos erroneamente a hipÃ³tese nula que Ã© falsa, incorrendo no Erro Tipo II. O erro do tipo II tem probabilidade \\(\\beta\\) de acontecer. O complementar desta probabilidade (\\(1-\\beta\\)) Ã© denominado de Poder do Teste. Um teste poderoso Ã© portanto, aquele que tem elevada probabilidade de rejeitar \\(H_0\\) quando ela Ã© falsa.\nAs figuras abaixo representam as distribuiÃ§Ãµes das mÃ©dias amostrais e os erros do tipos I e II quando o \\(H_0\\) Ã© verdadeira (\\(\\mu_a = \\mu\\)) e quando \\(H_0\\) Ã© falsa (\\(\\mu_a &gt; \\mu\\)).\n\n\n\n\n\n\n\n\nFiguraÂ 4: RelaÃ§Ã£o entre o erro tipo I (\\(\\alpha\\)) e o erro tipos II (\\(\\beta\\)), ao aceitar ou rejeitar \\(H_0\\).\n\n\n\n\n\nIdealmente em um teste estatÃ­stico, seria interessante reduzir ao mÃ¡ximo os erros do tipo I e II. Ao reduzirmos o erro do tipo I, diminuindo \\(\\alpha\\) teremos um teste mais rigoroso que raramente iria errar ao rejeitar um \\(H_0\\) verdadeiro (Figura A). Entretanto, este teste tambÃ©m raramente iria rejeitar \\(H_0\\) ainda que ele seja falso (Figura B). Consequentemente, ao diminuir o valor de \\(\\alpha\\) ficamos menos propensos a cometer o erro do tipo I, porÃ©m mais propensos a incorrer no erro tipo II, isto Ã©, nÃ£o rejeitar uma \\(H_0\\) falsa.\nDadas estas caracterÃ­sticas, o Ãºnico modo que reduzir os dois tipos de erros simultaneamente Ã© aumentando o tamanho amostral \\(n\\) pois, neste caso, reduzimos o erro padrÃ£o (\\(\\sigma_{\\overline{X}}\\)) e consequentemente a sobreposiÃ§Ã£o entre as duas curvas acima."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#estabelecendo-a-hipÃ³tese-alternativa-testes-bilaterais-vs-unilaterais",
    "href": "content/teste-hipoteses/intro-testehipot.html#estabelecendo-a-hipÃ³tese-alternativa-testes-bilaterais-vs-unilaterais",
    "title": "IntroduÃ§Ã£o ao teste de hipÃ³teses",
    "section": "5 Estabelecendo a hipÃ³tese alternativa: testes bilaterais vs unilaterais",
    "text": "5 Estabelecendo a hipÃ³tese alternativa: testes bilaterais vs unilaterais\nA hipÃ³tese alternativa estabelece nossa expectativa para a explicaÃ§Ã£o dos resultados de um experimento no caso de \\(H_0\\) ser falsa. Os testes que descrevemos acima sÃ£o chamados testes bilaterais ou bicaudais. Isto significa que sendo \\(H_0\\) falsa, podemos esperar que a mÃ©dia populacional esteja tanto acima quanto abaixo de \\(\\mu\\). Existem situaÃ§Ãµes, no entanto, para as quais jÃ¡ temos uma expectativa a priori com base no conhecimento prÃ©vio sobre o fenÃªmeno estudado.\nVoltemos ao exemplo sobre a frequÃªncia cardÃ­aca. Sabemos que o sedentarismo, tende a elevar a frequÃªncia cardÃ­aca em repouso. Deste modo, o problema poderia ser estabelecido da seguinte forma.\n\n\n\n\n\n\nNotaDescriÃ§Ã£o do problema\n\n\n\nDigamos que o nÃºmero de batimentos cardÃ­acos por minuto de um adulto em repouso tenha mÃ©dia \\(\\mu = 65\\) e desvio padrÃ£o \\(\\sigma = 9\\). A literatura sugere que o sedentarismo aumenta o batimento mÃ©dio de um adulto.\n\n\nO problema agora estabelece que no caso de rejeiÃ§Ã£o de \\(H_0\\), a frequÃªncia cardÃ­aca deveia ser maior que 65 batimentos por minuto. Deste modo teremos como hipÃ³teses estatÃ­sticas:\n\nHipÃ³teses estatÃ­ticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\gt 65\\) batimentos por minuto\nA mudanÃ§a aqui estÃ¡ em \\(H_a\\) que estabelece que na hipÃ³tese de rejeiÃ§Ã£o de \\(H_0\\), esperamos somente que a frequencia cardÃ­aca aumente.\nEsta modificaÃ§Ã£o na construÃ§Ã£o das hipÃ³teses estatÃ­sticas tem implicaÃ§Ã£o na definiÃ§Ã£o do limite de rejeiÃ§Ã£o.\n\nLimite de rejeiÃ§Ã£o: se definimos \\(\\alpha = 0,05\\), e \\(H_a: \\mu \\gt 65\\), temos que a Ã¡rea de rejeiÃ§Ã£o serÃ¡ expressa acima de 65 batimentos por minuto.\n\n\n\n\n\n\n\n\n\nFiguraÂ 5: Ãrea de rejeiÃ§Ã£o em um teste unilateral com \\(\\alpha = 0,05\\).\n\n\n\n\n\nNote portanto, que a diferenÃ§a entre um teste bilateral e um teste unilateral estÃ¡ na definiÃ§Ã£o dÃ¡ Ã¡rea que expressa a zona de rejeiÃ§Ã£o, \\(\\alpha\\) para \\(H_0\\). Nos teste bilaterais, a Ã¡rea de rejeiÃ§Ã£o Ã© distribuÃ­da acima e abaixo de \\(\\mu\\) (FiguraÂ 2), enquanto nos teste unilaterais, a Ã¡rea estarÃ¡ toda acima ou abaixo de \\(\\mu\\), a depender do que foi estabelecido em \\(H_a\\) (FiguraÂ 5).\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-prioris-e-posterioris",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-prioris-e-posterioris",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "O que aprendemos atÃ© aqui: prioris e posterioris",
    "text": "O que aprendemos atÃ© aqui: prioris e posterioris"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-distribuiÃ§Ã£o-normal-de-probabilidade",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-distribuiÃ§Ã£o-normal-de-probabilidade",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "O que aprendemos atÃ© aqui: distribuiÃ§Ã£o Normal de Probabilidade",
    "text": "O que aprendemos atÃ© aqui: distribuiÃ§Ã£o Normal de Probabilidade\n\\[\nf(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2} \\left(\\frac{y - \\mu}{\\sigma} \\right)^2} \\longrightarrow \\quad y \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-o-modelo-de-regressÃ£o-linear",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-o-modelo-de-regressÃ£o-linear",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "O que aprendemos atÃ© aqui: o modelo de RegressÃ£o linear",
    "text": "O que aprendemos atÃ© aqui: o modelo de RegressÃ£o linear\n\n\n\nVariÃ¡vel aleatÃ³ria resposta\n\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\n\\[\n\\mu = \\beta_0 + \\beta_1 x\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-programaÃ§Ã£o-probabilÃ­stica",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-programaÃ§Ã£o-probabilÃ­stica",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "O que aprendemos atÃ© aqui: ProgramaÃ§Ã£o ProbabilÃ­stica",
    "text": "O que aprendemos atÃ© aqui: ProgramaÃ§Ã£o ProbabilÃ­stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # DefiniÃ§Ã£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=60, sigma=5)\n    calcado = pm.Normal(\"calcado\", mu=2.8, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n    \n    # DefiniÃ§Ã£o do modelo\n    mu = beta_0 + beta_1 * X\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, \n                        observed=Y)\n    \n    # Amostra a distribuiÃ§Ã£o posterior\n    resultados = pm.sample()\n\n\nBambi\n\n# DefiniÃ§Ã£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=60, sigma=5),\n    \"calcado\": bmb.Prior(\"Normal\", mu=2.8, sigma=0.1),\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\n\n# DefiniÃ§Ã£o do modelo\nmodelo = bmb.Model(\"altura ~ calcado\", df, \n                    priors=custom_priors)\n\n# Amostra a distribuiÃ§Ã£o posterior\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-ajuste-da-posteriori",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-atÃ©-aqui-ajuste-da-posteriori",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "O que aprendemos atÃ© aqui: ajuste da posteriori",
    "text": "O que aprendemos atÃ© aqui: ajuste da posteriori"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#daqui-para-frente-uma-variedade-de-modelos-e-estruturas",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#daqui-para-frente-uma-variedade-de-modelos-e-estruturas",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "Daqui para frente: uma variedade de modelos e estruturas",
    "text": "Daqui para frente: uma variedade de modelos e estruturas\n\nExtenÃ§Ã£o da RegressÃ£o Linear para:\n\nMÃºltiplos preditores.\nDiferentes tipos de variÃ¡veis resposta (GLMs).\nDados com estrutura de agrupamento (Modelos HierÃ¡rquicos)."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-linear-mÃºltipla",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-linear-mÃºltipla",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "RegressÃ£o linear mÃºltipla",
    "text": "RegressÃ£o linear mÃºltipla\n\n\n\nVariÃ¡vel aleatÃ³ria resposta\n\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\n\\[\n\\mu = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_j \\sim \\mathcal{N}(\\mu_{\\beta_j}, \\sigma_{\\beta_j}) \\quad \\text{para } j = 1, \\dots, k\n\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "ProgramaÃ§Ã£o ProbabilÃ­stica",
    "text": "ProgramaÃ§Ã£o ProbabilÃ­stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # DefiniÃ§Ã£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=60, sigma=5)\n    beta_1 = pm.Normal(\"beta_1\", mu=2.8, sigma=0.1)\n    beta_2 = pm.Normal(\"beta_2\", mu=1.5, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n\n    # DefiniÃ§Ã£o do modelo\n    mu = Intercept + beta_1 * X1 + beta_2 * X2\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, \n                       observed=Y)\n\n    # Amostra a distribuiÃ§Ã£o posterior\n    resultados = pm.sample()\n\n\nBambi\n\n# DefiniÃ§Ã£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=60, sigma=5),\n    \"X1\": bmb.Prior(\"Normal\", mu=2.8, sigma=0.1),\n    \"X2\": bmb.Prior(\"Normal\", mu=1.5, sigma=0.1),\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\n\n# DefiniÃ§Ã£o do modelo\nmodelo = bmb.Model(\"altura ~ X1 + X2\", df, \n                   priors=custom_priors)\n\n# Amostra a distribuiÃ§Ã£o posterior\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-de-poisson-dados-de-contagem",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-de-poisson-dados-de-contagem",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "RegressÃ£o de Poisson: dados de contagem",
    "text": "RegressÃ£o de Poisson: dados de contagem\n\n\n\\[\ny \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu = \\beta_0 + \\beta_1 x\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-de-poisson-dados-de-contagem-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-de-poisson-dados-de-contagem-1",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "RegressÃ£o de Poisson: dados de contagem",
    "text": "RegressÃ£o de Poisson: dados de contagem\n\n\n\\[\nf(y) = \\frac{e^{-\\lambda} \\lambda^y}{y!} \\longrightarrow \\quad y \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu\n\\]\n\n\nVariÃ¡vel aleatÃ³ria resposta\n\n\\[\ny \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica-1",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "ProgramaÃ§Ã£o ProbabilÃ­stica",
    "text": "ProgramaÃ§Ã£o ProbabilÃ­stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # DefiniÃ§Ã£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=0, sigma=5)\n    beta = pm.Normal(\"beta\", mu=0, sigma=2)\n    \n    # FunÃ§Ã£o de ligaÃ§Ã£o log: log(Î») = Î¼ = Intercept + beta * X\n    mu = Intercept + beta * X\n    lambda_ = pm.math.exp(mu)\n    \n    # Modelo de verossimilhanÃ§a\n    contagem = pm.Poisson(\"contagem\", mu=lambda_, \n                          observed=Y)\n    \n    # Amostragem\n    resultados = pm.sample()\n\n\nBambi\n\n# DefiniÃ§Ã£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n    \"x\": bmb.Prior(\"Normal\", mu=0, sigma=2),\n}\n\n# Modelo com funÃ§Ã£o de ligaÃ§Ã£o log (default da famÃ­lia Poisson)\nmodelo = bmb.Model(\"contagem ~ x\", df, \n                   family=\"poisson\", priors=custom_priors)\n\n# Amostragem\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-logÃ­stica-dados-dicotÃ´micos",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-logÃ­stica-dados-dicotÃ´micos",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "RegressÃ£o LogÃ­stica: dados dicotÃ´micos",
    "text": "RegressÃ£o LogÃ­stica: dados dicotÃ´micos\n\n\n\\[\ny \\sim \\text{Bernoulli}(p)\n\\]\n\\[\n\\log\\left(\\frac{p}{1-p}\\right) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\\[\np = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}}\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-logÃ­stica-dados-dicotÃ´micos-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regressÃ£o-logÃ­stica-dados-dicotÃ´micos-1",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "RegressÃ£o LogÃ­stica: dados dicotÃ´micos",
    "text": "RegressÃ£o LogÃ­stica: dados dicotÃ´micos\n\n\n\nDistribuiÃ§Ã£o da variÃ¡vel resposta\n\n\\[\nf(y) = p^y (1 - p)^{1 - y}\n\\]\n\\[\ny \\sim \\text{Bernoulli}(p)\n\\]\n\nFunÃ§Ã£o de ligaÃ§Ã£o\n\n\\[\n\\text{logit}(p) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\\[\n\\text{logit}(p) = \\log\\left(\\frac{p}{1 - p}\\right)\n\\]\n\\[\n\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 x\n\\]\n\n\\[\n\\frac{p}{1 - p} = e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = (1 - p) \\cdot e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = e^{\\beta_0 + \\beta_1 x} - p \\cdot e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np \\left(1 + e^{\\beta_0 + \\beta_1 x}\\right) = e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica-2",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programaÃ§Ã£o-probabilÃ­stica-2",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "ProgramaÃ§Ã£o ProbabilÃ­stica",
    "text": "ProgramaÃ§Ã£o ProbabilÃ­stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # DefiniÃ§Ã£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=0, sigma=5)\n    beta = pm.Normal(\"beta\", mu=0, sigma=2)\n    \n    # Preditor linear e funÃ§Ã£o de ligaÃ§Ã£o logit\n    mu = Intercept + beta * X\n    p = pm.math.sigmoid(mu)\n    \n    # VerossimilhanÃ§a\n    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=Y)\n    \n    # Amostragem\n    resultados = pm.sample()\n\n\nBambi\n\n# DefiniÃ§Ã£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n    \"x\": bmb.Prior(\"Normal\", mu=0, sigma=2),\n}\n\n# Modelo logÃ­stico (ligaÃ§Ã£o logit Ã© padrÃ£o para bernoulli)\nmodelo = bmb.Model(\"y ~ x\", df, \n                   family=\"bernoulli\", priors=custom_priors)\n\n# Amostragem\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#modelo-hierÃ¡rquico-normal-com-intercepto-e-inclinaÃ§Ã£o-variaveis",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#modelo-hierÃ¡rquico-normal-com-intercepto-e-inclinaÃ§Ã£o-variaveis",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "Modelo HierÃ¡rquico Normal com Intercepto e InclinaÃ§Ã£o VariaÌveis",
    "text": "Modelo HierÃ¡rquico Normal com Intercepto e InclinaÃ§Ã£o VariaÌveis\n\n\n\\[\ny_{ij} \\sim \\mathcal{N}(\\mu_{ij}, \\sigma^2)\n\\]\n\\[\n\\mu_{ij} = \\beta_{0j} + \\beta_{1j} x_{ij}\n\\]\n\\[\n\\beta_{0j} \\sim \\mathcal{N}(\\gamma_0, \\tau_0^2) \\\\\n\\beta_{1j} \\sim \\mathcal{N}(\\gamma_1, \\tau_1^2)\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#variaÃ§Ã£o-entre-grupos-coeficientes-do-modelo-hierÃ¡rquico",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#variaÃ§Ã£o-entre-grupos-coeficientes-do-modelo-hierÃ¡rquico",
    "title": "Explorando Modelos de RegressÃ£o Bayesiana",
    "section": "VariaÃ§Ã£o entre grupos: coeficientes do modelo hierÃ¡rquico",
    "text": "VariaÃ§Ã£o entre grupos: coeficientes do modelo hierÃ¡rquico\n\n\nCoeficientes especÃ­ficos por grupo:\n\\[\n\\beta_{0j} \\sim \\mathcal{N}(\\gamma_0, \\tau_0^2) \\\\\n\\beta_{1j} \\sim \\mathcal{N}(\\gamma_1, \\tau_1^2)\n\\]\nVisualizando a dispersÃ£o dos parÃ¢metros em relaÃ§Ã£o Ã s mÃ©dias populacionais \\(\\gamma_0, \\gamma_1\\)."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html",
    "title": "RegressÃ£o Linear Bayesiana",
    "section": "",
    "text": "Na inferÃªncia bayesiana, atualizamos nossas crenÃ§as sobre os parÃ¢metros de um modelo combinando o conhecimento prÃ©vio (expresso pela distribuiÃ§Ã£o a priori) com a informaÃ§Ã£o contida nos dados observados (expressa pela verossimilhanÃ§a) para obter a distribuiÃ§Ã£o a posteriori. A inferÃªncia bayesiana fornece uma distribuiÃ§Ã£o completa de probabilidade para os parÃ¢metros, refletindo explicitamente a incerteza sobre seus valores.\nNo modelo de regressÃ£o linear bayesiano, assumimos que a variÃ¡vel resposta \\(y\\) Ã© uma variÃ¡vel aleatÃ³ria com distribuiÃ§Ã£o Normal, cuja mÃ©dia depende linearmente de uma variÃ¡vel preditora \\(x\\), ou seja, \\(\\mu = \\beta_0 + \\beta_1 x\\), e com desvio padrÃ£o \\(\\sigma\\).\n\\[\ny \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x, \\sigma)\n\\tag{1}\\]\nOnde:\nA especificaÃ§Ã£o completa do modelo bayesiano requer a definiÃ§Ã£o das distribuiÃ§Ãµes a priori para os parÃ¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\). Podemos assumir, por exemplo, distribuiÃ§Ãµes normais para os coeficientes da regressÃ£o e uma distribuiÃ§Ã£o Lognormal para o desvio padrÃ£o, garantindo que \\(\\sigma\\) assuma apenas valores positivos. As distribuiÃ§Ãµes a priori sÃ£o entÃ£o:\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\tag{2}\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\tag{3}\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\tag{4}\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html#atividate-prÃ¡tica",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html#atividate-prÃ¡tica",
    "title": "RegressÃ£o Linear Bayesiana",
    "section": "1 Atividate prÃ¡tica",
    "text": "1 Atividate prÃ¡tica\n\n\n\n\n\n\nImportanteObjetivos de Aprendizagem\n\n\n\n\nCompreender os fundamentos da regressÃ£o linear sob a abordagem bayesiana.\nSimular dados utilizando a biblioteca SciPy.\nAplicar conhecimento prÃ©vio para especificar distribuiÃ§Ãµes a priori informativas para os parÃ¢metros do modelo.\nImplementar um modelo de regressÃ£o linear bayesiana com PyMC, realizar a checagem preditiva a priori e ajustÃ¡-lo a dados reais para obter as distribuiÃ§Ãµes a posteriori dos parÃ¢metros.\nInterpretar e validar os resultados da inferÃªncia bayesiana.\n\n\n\nNesta atividade, aplicaremos a inferÃªncia bayesiana para modelar a relaÃ§Ã£o entre duas variÃ¡veis contÃ­nuas: a altura de indivÃ­duos e o nÃºmero do calÃ§ado que utilizam. O conjunto de dados de altura (cm) e nÃºmero do calÃ§ado estÃ¡ disponÃ­vel no link: altura_adultos.csv.\nIntuitivamente, esperamos que haja uma relaÃ§Ã£o positiva: pessoas com pÃ©s maiores tendem a ser mais altas. Para quantificar essa relaÃ§Ã£o, utilizaremos um modelo de regressÃ£o linear. O co\n\n# ConfiguraÃ§Ã£o inicial e importaÃ§Ã£o de bibliotecas\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, lognorm\nimport pandas as pd\nimport seaborn as sns\nimport arviz as az\n\n\n\n1.1 Escolhendo as prioris\nDesenvolver uma boa intuiÃ§Ã£o sobre os parÃ¢metros Ã© essencial para construir modelos coerentes com o conhecimento prÃ©vio. Esta atividade tem como finalidade apoiar a definiÃ§Ã£o informada das distribuiÃ§Ãµes a priori no modelo bayesiano, de modo que reflitam o que sabemos (ou assumimos saber) sobre os parÃ¢metros antes de observar os dados. O objetivo Ã© explorar diferentes valores para os parÃ¢metros da regressÃ£o linear e identificar combinaÃ§Ãµes que representem, de forma realista, a relaÃ§Ã£o esperada entre essas duas variÃ¡veis, e que possam ser utilizadas como prioris no modelo.\n1. Escolha valores para os parÃ¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) (EquaÃ§Ã£oÂ 1).\n\n\\(\\beta_0\\) (intercepto): representa altura esperada quando o nÃºmero do calÃ§ado Ã© 0. Embora esse valor nÃ£o tenha significado fÃ­sico direto, ele influencia a posiÃ§Ã£o da reta ajustada.\n\\(\\beta_1\\) (inclinaÃ§Ã£o da reta): representa a variaÃ§Ã£o mÃ©dia na altura para cada nÃºmero a mais de calÃ§ado.\n\\(\\sigma\\) (desvio padrÃ£o): representa a variaÃ§Ã£o natural nas alturas entre pessoas com o mesmo nÃºmero de calÃ§ado.\n\n\n# ParÃ¢metros para simulaÃ§Ã£o\nbeta_0 =       # ESCOLHA a altura base (quando o nÃºmero do calÃ§ado Ã© zero)\nbeta_1 =      # ESCOLHA a taxa mÃ©dia de aumento na altura para cada nÃºmero a mais de calÃ§ado\nsigma =         # ESCOLHA a variaÃ§Ã£o individual na altura (desvio padrÃ£o dos erros)\n\n2. Crie uma sequÃªncia de valores para \\(x\\) abrangendo limites coerentes com nÃºmero do calÃ§ado para indivÃ­duos adultos e utilize a funÃ§Ã£o norm.rvs da biblioteca SciPy para gerar dados simulados de altura com base no nÃºmero do calÃ§ado.\n\n# Simule o nÃºmero do calÃ§ado (ex.: valores inteiros de 33 a 48, com 100 repetiÃ§Ãµes por nÃºmero)\nx_sim = np.repeat(np.arange(33, 49), 100)\n\n# Gere as alturas simuladas com erro normal\nmu = beta_0 + beta_1 * x_sim\ny_sim = norm.rvs(loc=mu, scale=sigma, size=len(x_sim))\n\n3. Utilize o matplotlib para visualizar os dados simulados. O grÃ¡fico de dispersÃ£o mostrarÃ¡ a altura em funÃ§Ã£o do nÃºmero do calÃ§ado. Isso ajudarÃ¡ a avaliar se a simulaÃ§Ã£o Ã© coerente com sua expectativa sobre essa relaÃ§Ã£o.\n\n# Use o matplotlib para plotar o resultado da simulaÃ§Ã£o, isto Ã©, altura_sim em funÃ§Ã£o de x_sim\nplt.figure(figsize=(9, 6))\nplt.scatter(x_sim, y_sim, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\nplt.xlabel(\"NÃºmero do calÃ§ado\")\nplt.ylabel(\"Altura (cm)\")\nplt.title(\"RelaÃ§Ã£o simulada entre nÃºmero do calÃ§ado e altura\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n4. Ajuste os valores de \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) e repita a simulaÃ§Ã£o atÃ© obter uma distribuiÃ§Ã£o de pontos que represente adequadamente sua espectativa sobre a relaÃ§Ã£o entre as variÃ¡veis.\n\n\n\n1.2 Implementando distribuiÃ§Ãµes a priori no PyMC\nAgora que vocÃª jÃ¡ explorou os efeitos dos parÃ¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\), o prÃ³ximo passo Ã© formalizar esse conhecimento na distribuiÃ§Ãµes a priori (EquaÃ§Ãµes 2, 3 e 4). Para isso, vamos utilizar a biblioteca de programaÃ§Ã£o probabilÃ­stica PyMC.\n1. Defina as distribuiÃ§Ãµes a priori\nUtilize os valores escolhidos anteriormente como os centros das distribuiÃ§Ãµes a priori, isto Ã©, utilize beta_0, beta_1 e sigma respectivamente para representar \\(\\mu_{\\beta_0}\\) (EquaÃ§Ã£oÂ 2), \\(\\mu_{\\beta_1}\\) (EquaÃ§Ã£oÂ 3) e \\(\\mu_{\\log \\sigma}\\) (EquaÃ§Ã£oÂ 4). A implementaÃ§Ã£o em PyMC tem por objetivo facilitar a escolha de valores razoÃ¡veis para \\(\\sigma_{\\beta_0}\\) (EquaÃ§Ã£oÂ 2), \\(\\sigma_{\\beta_1}\\) (EquaÃ§Ã£oÂ 3) e \\(\\sigma_{\\log \\sigma}\\) (EquaÃ§Ã£oÂ 4) compatÃ­veis com seu grau de incerteza sobre estes parÃ¢metros.\n\n# GeraÃ§Ã£o de valores simulados para a variÃ¡vel preditora (calcado)\ncalcado_sim = np.arange(33, 49)\n\n# ESCOLHA altura base (quando o nÃºmero do calÃ§ado Ã© zero)\nmu_beta_0 =  # MÃ©dia\nsd_beta_0 =  # Desvio padrÃ£o\n\n# ESCOLHA a taxa mÃ©dia de aumento na altura para cada nÃºmero a mais de calÃ§ad\nmu_beta_1 =   # MÃ©dia\nsd_beta_1 =   # Desvio padrÃ£o\n\n# ESCOLHA a variaÃ§Ã£o individual na altura (desvio padrÃ£o dos erros)\nmu_lsigma =   # MÃ©dia\nsd_lsigma =   # Desvio padrÃ£o\n\n\nn_samples = 1000\nwith pm.Model() as modelo_regressao-linear:\n\n    # Prioris\n    beta_0 = pm.Normal(\"beta_0\", mu=mu_beta_0, sigma=sd_beta_0) \n    beta_1 = pm.Normal(\"beta_1\", mu=mu_beta_1, sigma=sd_beta_1)\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(mu_lsigma), sigma=sd_lsigma)\n\n    # VerossimilhanÃ§a\n    mu = beta_0 + beta_1 * calcado_sim\n    altura_sim = pm.Normal(\"altura_sim\", mu=mu, sigma=sigma, shape=len(calcado_sim))\n\n    # Amostragem da distribuiÃ§Ã£o preditiva a priori\n    prior_predictive_samples = pm.sample_prior_predictive(samples=n_samples)\n\n2. Checagem preditiva a priori: Extraia as distribuiÃ§Ãµes a priori dos parÃ¢metros\n\n# ExtraÃ§Ã£o das distribuiÃ§Ãµes a priori dos parÃ¢metros\nbeta_0_prior = prior_predictive_samples.prior[\"beta_0\"].values.flatten()\nbeta_1_prior = prior_predictive_samples.prior[\"beta_1\"].values.flatten()\nsigma_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\n\n# ExtraÃ§Ã£o da distribuiÃ§Ã£o preditiva de y\naltura_sim_prior = prior_predictive_samples.prior[\"altura_sim\"].values.flatten()\n\n# Repita calcado_sim para alinhar com os n_samples valores de altura_sim_prior\ncalcado_sim_rep = np.tile(calcado_sim, n_samples)\n\n3. Verifique os histogramas das distribuiÃ§Ãµes a priori e a distribuiÃ§Ã£o preditiva com os dados simulados\n\n\n\n# Plot dos histogramas e do grÃ¡fico de dispersÃ£o\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\n\n# Histograma do beta_0\naxes[0, 0].hist(beta_0_prior, bins=30, color='lightcoral', edgecolor='black')\naxes[0, 0].set_title(\"Intercepto: Î²â‚€\")\naxes[0, 0].set_xlabel(\"Î²â‚€\")\naxes[0, 0].set_ylabel(\"FrequÃªncia\")\n\n# Histograma do beta_1\naxes[0, 1].hist(beta_1_prior, bins=30, color='cornflowerblue', edgecolor='black')\naxes[0, 1].set_title(\"InclinaÃ§Ã£o: Î²â‚\")\naxes[0, 1].set_xlabel(\"Î²â‚\")\naxes[0, 1].set_ylabel(\"FrequÃªncia\")\n\n# Histograma de sigma\naxes[1, 0].hist(sigma_prior, bins=30, color='mediumseagreen', edgecolor='black')\naxes[1, 0].set_title(\"Desvio padrÃ£o: Ïƒ\")\naxes[1, 0].set_xlabel(\"Ïƒ\")\naxes[1, 0].set_ylabel(\"FrequÃªncia\")\n\n# GrÃ¡fico de dispersÃ£o dos dados simulados anteriormente\naxes[1, 1].scatter(calcado_sim_rep, altura_sim_prior, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\naxes[1, 1].set_title(\"RelaÃ§Ã£o a priori predita\")\naxes[1, 1].set_xlabel(\"NÃºmero do calÃ§ado\")\naxes[1, 1].set_ylabel(\"Altura (cm)\")\naxes[1, 1].legend()\naxes[1, 1].grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\nFiguraÂ 1\n\n\n\n4. Ajuste os valores dos parÃ¢metros e repita a implementaÃ§Ã£o do modelo atÃ© obter uma distribuiÃ§Ã£o de pontos que represente adequadamente sua espectativa sobre a relaÃ§Ã£o entre as variÃ¡veis.\n\n\n1.3 Ajustando o modelo a dados reais\n1. Importe os dados altura_adultos.csv\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura_adultos.csv')\ndf\n\nOs dados contÃ©m informaÃ§Ãµes sobre altura (cm), nÃºmero do calcado e ano de adultos.\n2. FaÃ§a um grÃ¡fico de dispersÃ£o entre altura (\\(y\\)) e calcado (\\(x\\)).\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=df, x='calcado', y='altura', \n                alpha=0.7,           # transparÃªncia dos pontos\n                s=60,                # tamanho dos pontos\n                color='firebrick')   # cor dos pontos\n\nplt.title('RelaÃ§Ã£o entre NÃºmero do CalÃ§ado e Altura', fontsize=14, fontweight='bold')\nplt.xlabel('NÃºmero do CalÃ§ado', fontsize=12)\nplt.ylabel('Altura (cm)', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n3. Implemente os dados no PyMC para estimar as distribuiÃ§Ãµes posteriores\nDADOS DE ENTRADA\n\n# ENTRE com os parÃ¢metros das prioris\nmu_beta_0 = \nsd_beta_0 = \n\nmu_beta_1 = \nsd_beta_1 = \n\nmu_lsigma = \nsd_lsigma = \n\n# Dados observados\nX = df['calcado']\nY = df['altura']\n\nIMPLEMENTAÃ‡ÃƒO EM PYMC\n\nwith pm.Model() as modelo_regressao-linear:\n    \n    # Priori\n    beta_0 = pm.Normal(\"beta_0\", mu=mu_beta_0, sigma=sd_beta_0)\n    beta_1 = pm.Normal(\"beta_1\", mu=mu_beta_1, sigma=sd_beta_1)\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(mu_lsigma), sigma=sd_lsigma)\n\n    # VerossimilhanÃ§a\n    mu = beta_0 + beta_1 * calcado_sim # EquaÃ§Ã£o da reta (modelo preditivo)\n    altura_obs = pm.Normal(\"altura_obs\", mu=beta_0 + beta_1 * X, \n                           sigma=sigma, observed = Y)\n    \n    # Amostragem MCMC para estimar a posterior e da distribuiÃ§Ã£o preditiva posterior\n    trace = pm.sample(draws=1000, tune=1000, chains=4, target_accept=0.95)\n    posterior_predictive_samples = pm.sample_posterior_predictive(trace)\n\n4. Resultados do ajuste\n4.1. Resumo dos parÃ¢metros posteriores\n\naz.summary(trace)\n\n\n4.2. GrÃ¡ficos de diagnÃ³stico\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 6))\n\n# Trace plots\naz.plot_trace(trace, var_names=['beta_0', 'beta_1', 'sigma'], axes=axes)\nplt.suptitle('Trace Plots - ConvergÃªncia das Cadeias MCMC')\nplt.tight_layout()\nplt.show()\n\n\n4.3. DistribuiÃ§Ãµes posteriores\n\naz.plot_posterior(trace, var_names=['beta_0', 'beta_1', 'sigma'], \n                 hdi_prob=0.95, figsize=(8, 4))\nplt.suptitle('DistribuiÃ§Ãµes Posteriores dos ParÃ¢metros')\nplt.show()\n\n\n4.4. Ajuste do modelo (dados observados vs prediÃ§Ãµes)\nPrediÃ§Ãµes\n\n# Intervalo de credibilidade das prediÃ§Ãµes\ncalcado_range = np.linspace(X.min(), X.max(), 100)\nposterior_beta_0 = trace.posterior['beta_0'].values.flatten()\nposterior_beta_1 = trace.posterior['beta_1'].values.flatten()\n\n# Calculando intervalos de credibilidade para a linha de regressÃ£o\npredictions = []\nfor x in calcado_range:\n    pred = posterior_beta_0 + posterior_beta_1 * x\n    predictions.append(pred)\n\npredictions = np.array(predictions)\npred_mean = np.mean(predictions, axis=1)\npred_lower = np.percentile(predictions, 2.5, axis=1)\npred_upper = np.percentile(predictions, 97.5, axis=1)\n\n GrÃ¡fico de valores preditos\n\nplt.figure(figsize=(8, 6))\n\nplt.scatter(X, Y, alpha=0.6, label='Dados Observados', color = 'firebrick')\nplt.plot(calcado_range, pred_mean, color = 'darkgreen', label='RegressÃ£o (MÃ©dia Posterior)', \n        linewidth=2, linestyle=\"--\")\nplt.fill_between(calcado_range, pred_lower, pred_upper, \n                alpha=0.2, color='darkgreen', label='IC 95% (Posterior)')\nplt.xlabel('NÃºmero do CalÃ§ado')\nplt.ylabel('Altura (cm)')\nplt.title('Ajuste do Modelo de RegressÃ£o Linear Bayesiana')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "",
    "text": "Neste tutorial, vamos explorar como trabalhar com estruturas de dados tabulares em Python usando a biblioteca Pandas. Utilizaremos o dataset de [pinguins de Palmer](https://allisonhorst.github.io/palmerpenguins/index.html}{target=â€œ_blankâ€} como exemplo prÃ¡tico."
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#pacotes-necessÃ¡rios",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#pacotes-necessÃ¡rios",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "1 Pacotes necessÃ¡rios",
    "text": "1 Pacotes necessÃ¡rios\n\nimport pandas as pd\n# pip install palmerpenguins\nfrom palmerpenguins import load_penguins\n\n\n\n\n\n\n\nNotaInstalaÃ§Ã£o de palmerpenguins\n\n\n\nO dataset palmerpenguins pode ser instalado com: pip install palmerpenguins"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#carregando-os-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#carregando-os-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "2 Carregando os dados",
    "text": "2 Carregando os dados\n\npenguins = load_penguins()"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#explorando-a-estrutura-dos-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#explorando-a-estrutura-dos-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "3 Explorando a estrutura dos dados",
    "text": "3 Explorando a estrutura dos dados\n\n3.1 DimensÃµes do DataFrame\n\npenguins.shape  # (nÃºmero de linhas, nÃºmero de colunas)\n\n(344, 8)\n\n\n\n\n3.2 Primeiras observaÃ§Ãµes\n\npenguins.head()  # Mostra as primeiras 5 linhas\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n3.3 Tipos de dados\n\npenguins.dtypes  # Mostra o tipo de cada coluna\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-colunas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-colunas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "4 Selecionando colunas",
    "text": "4 Selecionando colunas\n\n4.1 SeleÃ§Ã£o de uma coluna\n\npenguins['species']  # Retorna uma Series\n\n0         Adelie\n1         Adelie\n2         Adelie\n3         Adelie\n4         Adelie\n         ...    \n339    Chinstrap\n340    Chinstrap\n341    Chinstrap\n342    Chinstrap\n343    Chinstrap\nName: species, Length: 344, dtype: object\n\n\n\n\n4.2 SeleÃ§Ã£o de mÃºltiplas colunas\n\npenguins[['species', 'island', 'body_mass_g']]  # Retorna um DataFrame\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\n\n\n1\nAdelie\nTorgersen\n3800.0\n\n\n2\nAdelie\nTorgersen\n3250.0\n\n\n3\nAdelie\nTorgersen\nNaN\n\n\n4\nAdelie\nTorgersen\n3450.0\n\n\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n4000.0\n\n\n340\nChinstrap\nDream\n3400.0\n\n\n341\nChinstrap\nDream\n3775.0\n\n\n342\nChinstrap\nDream\n4100.0\n\n\n343\nChinstrap\nDream\n3775.0\n\n\n\n\n344 rows Ã— 3 columns\n\n\n\n\n\n\n\n\n\nDica\n\n\n\nDiferenÃ§a importante:\n- df['coluna'] retorna uma Series (uma dimensÃ£o)\n- df[['coluna']] retorna um DataFrame (duas dimensÃµes)"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-linhas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-linhas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "5 Selecionando linhas",
    "text": "5 Selecionando linhas\n\n5.1 SeleÃ§Ã£o por Ã­ndice numÃ©rico\n\npenguins.iloc[0]     # Primeira linha (Ã­ndice 0)\npenguins.iloc[10]    # 11Âª linha (Ã­ndice 10)\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            37.8\nbill_depth_mm             17.1\nflipper_length_mm        186.0\nbody_mass_g             3300.0\nsex                        NaN\nyear                      2007\nName: 10, dtype: object\n\n\n\n\n5.2 SeleÃ§Ã£o de mÃºltiplas linhas\n\npenguins.iloc[0:5]   # Linhas 0 a 4 (5 nÃ£o incluÃ­do)\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#seleÃ§Ã£o-combinada-linhas-e-colunas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#seleÃ§Ã£o-combinada-linhas-e-colunas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "6 SeleÃ§Ã£o combinada: linhas e colunas",
    "text": "6 SeleÃ§Ã£o combinada: linhas e colunas\n\npenguins.iloc[0:5, 0:3]  # Linhas 0-4, colunas 0-2\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n\n\n1\nAdelie\nTorgersen\n39.5\n\n\n2\nAdelie\nTorgersen\n40.3\n\n\n3\nAdelie\nTorgersen\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nIndexaÃ§Ã£o em Python:\n- Ãndices comeÃ§am em 0\n- Intervalos [inicio:fim] nÃ£o incluem o valor fim\n- 0:5 significa Ã­ndices 0, 1, 2, 3, 4"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#filtragem-de-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#filtragem-de-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "7 Filtragem de dados",
    "text": "7 Filtragem de dados\n\n7.1 Filtro simples\n\nfiltro = penguins['species'] == 'Adelie'\nfiltro  # Retorna uma Series de True/False\n\n0       True\n1       True\n2       True\n3       True\n4       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: species, Length: 344, dtype: bool\n\n\n\npenguins[filtro]  # Retorna apenas as linhas onde filtro Ã© True\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n147\nAdelie\nDream\n36.6\n18.4\n184.0\n3475.0\nfemale\n2009\n\n\n148\nAdelie\nDream\n36.0\n17.8\n195.0\n3450.0\nfemale\n2009\n\n\n149\nAdelie\nDream\n37.8\n18.1\n193.0\n3750.0\nmale\n2009\n\n\n150\nAdelie\nDream\n36.0\n17.1\n187.0\n3700.0\nfemale\n2009\n\n\n151\nAdelie\nDream\n41.5\n18.5\n201.0\n4000.0\nmale\n2009\n\n\n\n\n152 rows Ã— 8 columns\n\n\n\n\n\n7.2 MÃºltiplas condiÃ§Ãµes\nPara combinar condiÃ§Ãµes, usamos operadores lÃ³gicos:\n\n& para E (AND)\n| para OU (OR)\n~ para NÃƒO (NOT)\n\n\nfiltro2 = (penguins['species'] == 'Adelie') & (penguins['island'] == 'Torgersen')\nfiltro2\n\n0       True\n1       True\n2       True\n3       True\n4       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nLength: 344, dtype: bool\n\n\n\npenguins[filtro2]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007\n\n\n10\nAdelie\nTorgersen\n37.8\n17.1\n186.0\n3300.0\nNaN\n2007\n\n\n11\nAdelie\nTorgersen\n37.8\n17.3\n180.0\n3700.0\nNaN\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n13\nAdelie\nTorgersen\n38.6\n21.2\n191.0\n3800.0\nmale\n2007\n\n\n14\nAdelie\nTorgersen\n34.6\n21.1\n198.0\n4400.0\nmale\n2007\n\n\n15\nAdelie\nTorgersen\n36.6\n17.8\n185.0\n3700.0\nfemale\n2007\n\n\n16\nAdelie\nTorgersen\n38.7\n19.0\n195.0\n3450.0\nfemale\n2007\n\n\n17\nAdelie\nTorgersen\n42.5\n20.7\n197.0\n4500.0\nmale\n2007\n\n\n18\nAdelie\nTorgersen\n34.4\n18.4\n184.0\n3325.0\nfemale\n2007\n\n\n19\nAdelie\nTorgersen\n46.0\n21.5\n194.0\n4200.0\nmale\n2007\n\n\n68\nAdelie\nTorgersen\n35.9\n16.6\n190.0\n3050.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n70\nAdelie\nTorgersen\n33.5\n19.0\n190.0\n3600.0\nfemale\n2008\n\n\n71\nAdelie\nTorgersen\n39.7\n18.4\n190.0\n3900.0\nmale\n2008\n\n\n72\nAdelie\nTorgersen\n39.6\n17.2\n196.0\n3550.0\nfemale\n2008\n\n\n73\nAdelie\nTorgersen\n45.8\n18.9\n197.0\n4150.0\nmale\n2008\n\n\n74\nAdelie\nTorgersen\n35.5\n17.5\n190.0\n3700.0\nfemale\n2008\n\n\n75\nAdelie\nTorgersen\n42.8\n18.5\n195.0\n4250.0\nmale\n2008\n\n\n76\nAdelie\nTorgersen\n40.9\n16.8\n191.0\n3700.0\nfemale\n2008\n\n\n77\nAdelie\nTorgersen\n37.2\n19.4\n184.0\n3900.0\nmale\n2008\n\n\n78\nAdelie\nTorgersen\n36.2\n16.1\n187.0\n3550.0\nfemale\n2008\n\n\n79\nAdelie\nTorgersen\n42.1\n19.1\n195.0\n4000.0\nmale\n2008\n\n\n80\nAdelie\nTorgersen\n34.6\n17.2\n189.0\n3200.0\nfemale\n2008\n\n\n81\nAdelie\nTorgersen\n42.9\n17.6\n196.0\n4700.0\nmale\n2008\n\n\n82\nAdelie\nTorgersen\n36.7\n18.8\n187.0\n3800.0\nfemale\n2008\n\n\n83\nAdelie\nTorgersen\n35.1\n19.4\n193.0\n4200.0\nmale\n2008\n\n\n116\nAdelie\nTorgersen\n38.6\n17.0\n188.0\n2900.0\nfemale\n2009\n\n\n117\nAdelie\nTorgersen\n37.3\n20.5\n199.0\n3775.0\nmale\n2009\n\n\n118\nAdelie\nTorgersen\n35.7\n17.0\n189.0\n3350.0\nfemale\n2009\n\n\n119\nAdelie\nTorgersen\n41.1\n18.6\n189.0\n3325.0\nmale\n2009\n\n\n120\nAdelie\nTorgersen\n36.2\n17.2\n187.0\n3150.0\nfemale\n2009\n\n\n121\nAdelie\nTorgersen\n37.7\n19.8\n198.0\n3500.0\nmale\n2009\n\n\n122\nAdelie\nTorgersen\n40.2\n17.0\n176.0\n3450.0\nfemale\n2009\n\n\n123\nAdelie\nTorgersen\n41.4\n18.5\n202.0\n3875.0\nmale\n2009\n\n\n124\nAdelie\nTorgersen\n35.2\n15.9\n186.0\n3050.0\nfemale\n2009\n\n\n125\nAdelie\nTorgersen\n40.6\n19.0\n199.0\n4000.0\nmale\n2009\n\n\n126\nAdelie\nTorgersen\n38.8\n17.6\n191.0\n3275.0\nfemale\n2009\n\n\n127\nAdelie\nTorgersen\n41.5\n18.3\n195.0\n4300.0\nmale\n2009\n\n\n128\nAdelie\nTorgersen\n39.0\n17.1\n191.0\n3050.0\nfemale\n2009\n\n\n129\nAdelie\nTorgersen\n44.1\n18.0\n210.0\n4000.0\nmale\n2009\n\n\n130\nAdelie\nTorgersen\n38.5\n17.9\n190.0\n3325.0\nfemale\n2009\n\n\n131\nAdelie\nTorgersen\n43.1\n19.2\n197.0\n3500.0\nmale\n2009\n\n\n\n\n\n\n\n\npenguins[filtro2].shape  # Quantas linhas atendem aos critÃ©rios\n\n(52, 8)\n\n\n\n\n\n\n\n\nAviso\n\n\n\nParÃªnteses sÃ£o obrigatÃ³rios ao combinar condiÃ§Ãµes:\n- âœ… (condiÃ§Ã£o1) & (condiÃ§Ã£o2)\n- âŒ condiÃ§Ã£o1 & condiÃ§Ã£o2"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#tratando-dados-ausentes",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#tratando-dados-ausentes",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "8 Tratando dados ausentes",
    "text": "8 Tratando dados ausentes\n\n8.1 Identificando valores ausentes\n\npenguins.isnull().sum(axis=1)  # Valores ausentes por linha\n\n0      0\n1      0\n2      0\n3      5\n4      0\n      ..\n339    0\n340    0\n341    0\n342    0\n343    0\nLength: 344, dtype: int64\n\n\n\npenguins.isnull().sum(axis=0)  # Valores ausentes por coluna\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\n\n\n8.2 Removendo valores ausentes\n\npenguins2 = penguins.dropna()  # Remove todas as linhas com valores ausentes\npenguins2.isnull().sum(axis=0)  # Verifica se ainda hÃ¡ valores ausentes\n\nspecies              0\nisland               0\nbill_length_mm       0\nbill_depth_mm        0\nflipper_length_mm    0\nbody_mass_g          0\nsex                  0\nyear                 0\ndtype: int64"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#mÃ©todos-Ãºteis-para-exploraÃ§Ã£o",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#mÃ©todos-Ãºteis-para-exploraÃ§Ã£o",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "9 MÃ©todos Ãºteis para exploraÃ§Ã£o",
    "text": "9 MÃ©todos Ãºteis para exploraÃ§Ã£o\n\n9.1 InformaÃ§Ãµes gerais\n\npenguins.info()          # InformaÃ§Ãµes gerais sobre o DataFrame\npenguins.describe()      # EstatÃ­sticas descritivas para colunas numÃ©ricas\npenguins['species'].unique()        # Valores Ãºnicos em uma coluna\npenguins['species'].value_counts()  # Contagem de cada valor Ãºnico\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nspecies\nAdelie       152\nGentoo       124\nChinstrap     68\nName: count, dtype: int64\n\n\n\n\n9.2 VerificaÃ§Ã£o de dados\n\npenguins.shape           # DimensÃµes\npenguins.columns         # Nomes das colunas\npenguins.index           # Ãndices das linhas\n\nRangeIndex(start=0, stop=344, step=1)"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#exemplos-prÃ¡ticos",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#exemplos-prÃ¡ticos",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "10 Exemplos prÃ¡ticos",
    "text": "10 Exemplos prÃ¡ticos\n\n10.1 Filtros complexos\n\n# Pinguins Adelie com massa corporal &gt; 4000g\nfiltro_complexo = (penguins['species'] == 'Adelie') & (penguins['body_mass_g'] &gt; 4000)\npenguins_grandes = penguins[filtro_complexo]\nprint(f\"Encontrados {len(penguins_grandes)} pinguins Adelie com massa &gt; 4000g\")\n\nEncontrados 35 pinguins Adelie com massa &gt; 4000g\n\n\n\n\n10.2 SeleÃ§Ã£o especÃ­fica\n\n# Primeiros 10 pinguins, apenas espÃ©cie e massa corporal\npenguins.iloc[0:10][['species', 'body_mass_g']]\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\n\n\n\n\n0\nAdelie\n3750.0\n\n\n1\nAdelie\n3800.0\n\n\n2\nAdelie\n3250.0\n\n\n3\nAdelie\nNaN\n\n\n4\nAdelie\n3450.0\n\n\n5\nAdelie\n3650.0\n\n\n6\nAdelie\n3625.0\n\n\n7\nAdelie\n4675.0\n\n\n8\nAdelie\n3475.0\n\n\n9\nAdelie\n4250.0\n\n\n\n\n\n\n\n\n\n10.3 Combinando operaÃ§Ãµes\n\n# Pinguins da ilha Biscoe, removendo valores ausentes, apenas colunas numÃ©ricas\nresultado = (penguins[penguins['island'] == 'Biscoe']\n            .dropna()\n            [['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']])\nresultado.shape\n\n(163, 4)"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "",
    "text": "Utilize este roteiro de atividades para consolidar os conceitos apresentados na primeira aula sobre descriÃ§Ã£o e visualizaÃ§Ã£o de dados com Python.\nCrie um novo arquivo no Google Colab e execute cada exercÃ­cio em uma ou mais cÃ©lular. Teste e observe os resultados antes de prosseguir para o prÃ³ximo.\nAproveite para experimentar variaÃ§Ãµes dos cÃ³digos apresentados para garantir que tenha entendido a atividade.\nCaso encontre dificuldades, revise o material da aula correspondente ao tÃ³pico em questÃ£o.\nMantenha o notebook organizado com comentÃ¡rios explicativos sobre o que cada cÃ³digo faz e suas principais descobertas."
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#orientaÃ§Ãµes-gerais",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#orientaÃ§Ãµes-gerais",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "",
    "text": "Utilize este roteiro de atividades para consolidar os conceitos apresentados na primeira aula sobre descriÃ§Ã£o e visualizaÃ§Ã£o de dados com Python.\nCrie um novo arquivo no Google Colab e execute cada exercÃ­cio em uma ou mais cÃ©lular. Teste e observe os resultados antes de prosseguir para o prÃ³ximo.\nAproveite para experimentar variaÃ§Ãµes dos cÃ³digos apresentados para garantir que tenha entendido a atividade.\nCaso encontre dificuldades, revise o material da aula correspondente ao tÃ³pico em questÃ£o.\nMantenha o notebook organizado com comentÃ¡rios explicativos sobre o que cada cÃ³digo faz e suas principais descobertas."
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#preparaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#preparaÃ§Ã£o",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "2 PreparaÃ§Ã£o",
    "text": "2 PreparaÃ§Ã£o\nAntes de comeÃ§ar, importe os pacotes necessÃ¡rios e carregue os dados que serÃ£o utilizados:\n\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom seaborn import load_dataset\n\n# Carregando iris\niris = sns.load_dataset('iris')\ntips = sns.load_dataset('tips')"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-1-operaÃ§Ãµes-bÃ¡sicas-e-estruturas-de-dados",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-1-operaÃ§Ãµes-bÃ¡sicas-e-estruturas-de-dados",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "3 Parte 1: OperaÃ§Ãµes BÃ¡sicas e Estruturas de Dados",
    "text": "3 Parte 1: OperaÃ§Ãµes BÃ¡sicas e Estruturas de Dados\n\n3.1 ExercÃ­cio 1.1 - OperaÃ§Ãµes AritmÃ©ticas\n\nCalcule as seguintes operaÃ§Ãµes:\n\n15 + 8\n25 * 3\n100 / 7 (divisÃ£o comum)\n100 // 7 (divisÃ£o inteira)\n100 % 7 (resto da divisÃ£o)\n2**8 (potenciaÃ§Ã£o)\n\nUse as funÃ§Ãµes matemÃ¡ticas para calcular:\n\nLogaritmo natural de 50\nLogaritmo base 10 de 1000\nRaiz quadrada de 64\nSeno de Ï€/4 (use math.pi)\n\n\n\n\n3.2 ExercÃ­cio 1.2 - VariÃ¡veis e AtribuiÃ§Ãµes\n\nCrie uma variÃ¡vel altura com valor 1.75\nCrie uma variÃ¡vel peso com valor 70\nCalcule o IMC (peso / alturaÂ²) e armazene em uma variÃ¡vel imc\nVerifique o resultado\n\n\n\n3.3 ExercÃ­cio 1.3 - Listas e Arrays\n\nCrie uma lista com as idades: [23, 34, 45, 28, 31, 29]\nConverta essa lista em um array NumPy\nMultiplique todos os valores por 2 usando a lista e depois usando o array\nCompare os resultados obtidos\n\n\n\n3.4 ExercÃ­cio 1.4 - SequÃªncias\n\nCrie uma sequÃªncia de nÃºmeros de 1 a 20 usando range()\nCrie um array com 7 valores igualmente espaÃ§ados entre 0 e 100 usando np.linspace()\nRepita o nÃºmero 5 dez vezes usando np.repeat()"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-2-explorando-os-dados---dataset-iris",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-2-explorando-os-dados---dataset-iris",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "4 Parte 2: Explorando os Dados - Dataset Iris",
    "text": "4 Parte 2: Explorando os Dados - Dataset Iris\n\n4.1 ExercÃ­cio 2.1 - Primeiras ExploraÃ§Ãµes\n\nVisualize as primeiras 10 linhas do dataset iris\nVerifique as dimensÃµes do dataset (shape)\nExamine os tipos de dados de cada coluna\nVerifique se hÃ¡ valores ausentes no dataset. Se houver, exclua este valores.\n\n\n\n4.2 ExercÃ­cio 2.2 - SeleÃ§Ã£o e Filtragem\n\nSelecione apenas a coluna â€˜sepal length (cm)â€™\nSelecione as colunas â€˜petal length (cm)â€™ e â€˜petal width (cm)â€™ simultaneamente\nSelecione as linhas de 20 a 30\nFiltre apenas as observaÃ§Ãµes da espÃ©cie â€˜setosaâ€™\nFiltre as observaÃ§Ãµes onde â€˜petal length (cm)â€™ &gt; 4.0"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-3-estatÃ­stica-descritiva---dataset-tips",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-3-estatÃ­stica-descritiva---dataset-tips",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "5 Parte 3: EstatÃ­stica Descritiva - Dataset Tips",
    "text": "5 Parte 3: EstatÃ­stica Descritiva - Dataset Tips\n\n5.1 ExercÃ­cio 3.1 - VariÃ¡veis Qualitativas\n\nCalcule a frequÃªncia absoluta da variÃ¡vel â€˜dayâ€™ (dia da semana)\nCalcule a frequÃªncia relativa da variÃ¡vel â€˜timeâ€™ (almoÃ§o/jantar)\nCrie um grÃ¡fico de barras para a variÃ¡vel â€˜smokerâ€™\n\n\n\n5.2 ExercÃ­cio 3.2 - VariÃ¡veis Quantitativas\n\nGere um resumo descritivo completo da variÃ¡vel â€˜total_billâ€™\nCalcule separadamente a mÃ©dia, mediana e desvio padrÃ£o de â€˜tipâ€™\nCrie um histograma da variÃ¡vel â€˜total_billâ€™ com 8 intervalos\nCrie um boxplot da variÃ¡vel â€˜tipâ€™\n\n\n\n5.3 ExercÃ­cio 3.3 - Quartis e Medidas de PosiÃ§Ã£o\n\nCalcule os quartis (25%, 50%, 75%) da variÃ¡vel â€˜total_billâ€™\nIdentifique qual Ã© o valor do percentil 90 da variÃ¡vel â€˜tipâ€™\n\n\n\n5.4 ExercÃ­cio 3.4 - PadronizaÃ§Ã£o (Z-score)\n\nCalcule o Z-score da variÃ¡vel â€˜total_billâ€™\nAdicione esta nova variÃ¡vel ao dataset como â€˜zscore_billâ€™\nVerifique que a mÃ©dia do Z-score Ã© aproximadamente 0 e o desvio padrÃ£o Ã© 1\nCrie dois histogramas lado a lado: um da variÃ¡vel original e outro do Z-score"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-4-medidas-de-associaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-4-medidas-de-associaÃ§Ã£o",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "6 Parte 4: Medidas de AssociaÃ§Ã£o",
    "text": "6 Parte 4: Medidas de AssociaÃ§Ã£o\n\n6.1 ExercÃ­cio 4.1 - AssociaÃ§Ã£o entre VariÃ¡veis Qualitativas (Dataset Tips)\n\nCrie uma tabela de contingÃªncia entre â€˜dayâ€™ e â€˜timeâ€™\nCalcule as frequÃªncias relativas por linha (marginal por linha)\nCalcule as frequÃªncias relativas por coluna (marginal por coluna)\nCrie um grÃ¡fico de barras agrupadas mostrando a relaÃ§Ã£o entre â€˜dayâ€™ e â€˜smokerâ€™\n\n\n\n6.2 ExercÃ­cio 4.2 - AssociaÃ§Ã£o entre VariÃ¡veis Quantitativas (Dataset Iris)\n\nCrie um grÃ¡fico de dispersÃ£o entre â€˜sepal length (cm)â€™ e â€˜petal length (cm)â€™\nCalcule a covariÃ¢ncia entre essas duas variÃ¡veis\nCalcule a correlaÃ§Ã£o entre essas duas variÃ¡veis\n\n\n\n6.3 ExercÃ­cio 4.3 - AssociaÃ§Ã£o entre VariÃ¡vel Quantitativa e Qualitativa\nCom dataset Tips:\n\nCalcule a mÃ©dia de â€˜tipâ€™ por categoria de â€˜timeâ€™ (almoÃ§o/jantar)\nCrie um boxplot de â€˜total_billâ€™ por â€˜dayâ€™\nFaÃ§a um grÃ¡fico de pontos (pointplot) mostrando a mÃ©dia de â€˜tipâ€™ por â€˜smokerâ€™ com barras de erro Com dataset Iris:\nCalcule um resumo descritivo de â€˜petal width (cm)â€™ por espÃ©cie\nCrie boxplots de â€˜sepal width (cm)â€™ por espÃ©cie\n\n\n\n6.4 ExercÃ­cio 4.4 - AnÃ¡lises Multivariadas\n\nDataset Tips: Crie um grÃ¡fico de dispersÃ£o de â€˜total_billâ€™ vs â€˜tipâ€™, colorindo os pontos por â€˜smokerâ€™\nDataset Iris: FaÃ§a um pairplot das variÃ¡veis quantitativas, colorindo por espÃ©cie"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#desafios-extras",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#desafios-extras",
    "title": "Roteiro de Atividades - CiÃªncias de Dados",
    "section": "7 Desafios Extras",
    "text": "7 Desafios Extras\n\n7.1 Desafio 1\nUsando o dataset Tips, investigue se existe diferenÃ§a no comportamento de gorjeta entre fumantes e nÃ£o fumantes em diferentes dias da semana. Use tabelas de contingÃªncia e grÃ¡ficos apropriados.\n\n\n7.2 Desafio 2\nNo dataset Iris, identifique qual espÃ©cie possui a maior variabilidade nas medidas. Compare os coeficientes de variaÃ§Ã£o (desvio padrÃ£o / mÃ©dia) de cada medida para cada espÃ©cie.\n\n\n7.3 Desafio 3\nCrie uma nova variÃ¡vel no dataset Tips chamada â€˜tip_rateâ€™ que represente a porcentagem de gorjeta em relaÃ§Ã£o Ã  conta total. Analise essa nova variÃ¡vel descritivamente e investigue sua relaÃ§Ã£o com outras variÃ¡veis do dataset."
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "",
    "text": "Neste tutorial, exploraremos como realizar anÃ¡lise estatÃ­stica descritiva em Python, utilizando o dataset de [pinguins de Palmer](https://allisonhorst.github.io/palmerpenguins/index.html}{target=â€œ_blankâ€} para exemplificar conceitos fundamentais de estatÃ­stica."
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#pacotes-necessÃ¡rios",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#pacotes-necessÃ¡rios",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "1 Pacotes necessÃ¡rios",
    "text": "1 Pacotes necessÃ¡rios\n\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#carregando-e-preparando-os-dados",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#carregando-e-preparando-os-dados",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "2 Carregando e preparando os dados",
    "text": "2 Carregando e preparando os dados\n\npenguins = load_penguins().dropna()  # Remove valores ausentes\npenguins.shape  # Verificar dimensÃµes\n\n(333, 8)"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#variÃ¡veis-qualitativas-categÃ³ricas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#variÃ¡veis-qualitativas-categÃ³ricas",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "3 VariÃ¡veis Qualitativas (CategÃ³ricas)",
    "text": "3 VariÃ¡veis Qualitativas (CategÃ³ricas)\n\n3.1 Identificando tipos de dados\n\npenguins.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\n\n\n3.2 FrequÃªncia absoluta\n\npenguins['species'].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\n\n\n3.3 FrequÃªncia relativa\n\npenguins['species'].value_counts(normalize=True)\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\n\n\n3.4 VisualizaÃ§Ã£o: GrÃ¡fico de barras\n\npenguins['species'].value_counts().plot(kind='bar')\nplt.title(\"NÃºmero de Pinguins por EspÃ©cie\")\nplt.xlabel(\"EspÃ©cie\")\nplt.ylabel(\"FrequÃªncia\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n# Para outra variÃ¡vel categÃ³rica\npenguins['island'].value_counts().plot(kind='bar')\nplt.title(\"DistribuiÃ§Ã£o de Pinguins por Ilha\")\nplt.xlabel(\"Ilha\")\nplt.ylabel(\"FrequÃªncia\")\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#variÃ¡veis-quantitativas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#variÃ¡veis-quantitativas",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "4 VariÃ¡veis Quantitativas",
    "text": "4 VariÃ¡veis Quantitativas\n\n4.1 Resumo descritivo bÃ¡sico\n\npenguins['body_mass_g'].describe()\n\ncount     333.000000\nmean     4207.057057\nstd       805.215802\nmin      2700.000000\n25%      3550.000000\n50%      4050.000000\n75%      4775.000000\nmax      6300.000000\nName: body_mass_g, dtype: float64\n\n\n\n# Para todas as variÃ¡veis numÃ©ricas\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n333.000000\n333.000000\n333.000000\n333.000000\n333.000000\n\n\nmean\n43.992793\n17.164865\n200.966967\n4207.057057\n2008.042042\n\n\nstd\n5.468668\n1.969235\n14.015765\n805.215802\n0.812944\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.500000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.500000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.600000\n18.700000\n213.000000\n4775.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\n\n4.2 VisualizaÃ§Ã£o: Histograma\n\npenguins['body_mass_g'].plot(kind='hist', \n                            bins=5, \n                            edgecolor=\"white\")\nplt.title(\"Histograma da Massa Corporal\")\nplt.xlabel(\"Massa (g)\")\nplt.ylabel(\"FrequÃªncia\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDica\n\n\n\nInterpretando histogramas:\n- Forma: simÃ©trica, assimÃ©trica Ã  esquerda/direita\n- TendÃªncia central: onde se concentram os dados\n- DispersÃ£o: quÃ£o espalhados estÃ£o os valores"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#quartis-e-medidas-de-posiÃ§Ã£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#quartis-e-medidas-de-posiÃ§Ã£o",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "5 Quartis e Medidas de PosiÃ§Ã£o",
    "text": "5 Quartis e Medidas de PosiÃ§Ã£o\n\n5.1 Quartis individuais\n\npenguins['body_mass_g'].quantile(0.25)  # Q1\npenguins['body_mass_g'].quantile(0.50)  # Q2 (mediana)\npenguins['body_mass_g'].quantile(0.75)  # Q3\n\nnp.float64(4775.0)\n\n\n\n\n5.2 MÃºltiplos quantis\n\npenguins['body_mass_g'].quantile([0.25, 0.5, 0.75])\n\n0.25    3550.0\n0.50    4050.0\n0.75    4775.0\nName: body_mass_g, dtype: float64\n\n\n\n\n5.3 VisualizaÃ§Ã£o: Boxplot\n\npenguins['body_mass_g'].plot(kind='box')\nplt.title(\"Boxplot da Massa Corporal\")\nplt.ylabel(\"Massa (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando boxplots:\n- Linha central: mediana (Q2)\n- Caixa: do Q1 ao Q3 (50% dos dados centrais)\n- Whiskers: extensÃ£o atÃ© ~1.5 Ã— IQR\n- Pontos isolados: possÃ­veis outliers"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-tendÃªncia-central",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-tendÃªncia-central",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "6 Medidas de TendÃªncia Central",
    "text": "6 Medidas de TendÃªncia Central\n\npenguins['body_mass_g'].mean()    # MÃ©dia aritmÃ©tica\npenguins['body_mass_g'].median()  # Mediana\n\nnp.float64(4050.0)\n\n\n\n\n\n\n\n\nDica\n\n\n\nQuando usar cada medida:\n- MÃ©dia: dados simÃ©tricos, sem outliers extremos\n- Mediana: dados assimÃ©tricos ou com outliers"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-variaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-variaÃ§Ã£o",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "7 Medidas de VariaÃ§Ã£o",
    "text": "7 Medidas de VariaÃ§Ã£o\n\npenguins['body_mass_g'].std()   # Desvio padrÃ£o\npenguins['body_mass_g'].var()   # VariÃ¢ncia\n\nnp.float64(648372.4876985418)\n\n\n\n7.1 CÃ¡lculo manual da variÃ¢ncia\n\nx = penguins['body_mass_g']\n# FÃ³rmula: Î£(xi - xÌ„)Â² / (n-1)\nvariancia_manual = np.sum((x - x.mean())**2) / (len(x) - 1)\nprint(f\"VariÃ¢ncia manual: {variancia_manual}\")\nprint(f\"VariÃ¢ncia pandas: {x.var()}\")\n\nVariÃ¢ncia manual: 648372.4876985418\nVariÃ¢ncia pandas: 648372.4876985418"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#escore-z-padronizaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#escore-z-padronizaÃ§Ã£o",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "8 Escore-Z (PadronizaÃ§Ã£o)",
    "text": "8 Escore-Z (PadronizaÃ§Ã£o)\nA padronizaÃ§Ã£o transforma os dados para mÃ©dia = 0 e desvio padrÃ£o = 1:\n\\[Z = \\frac{(X - \\mu)}{\\sigma}\\]\n\nmedia = penguins['body_mass_g'].mean()\ndesvio_padrao = penguins['body_mass_g'].std()\n\npenguins['zscore_massa'] = (penguins['body_mass_g'] - media) / desvio_padrao\n\n\n8.1 Verificando a padronizaÃ§Ã£o\n\npenguins[['body_mass_g', 'zscore_massa']].head()\n\n\n\n\n\n\n\n\nbody_mass_g\nzscore_massa\n\n\n\n\n0\n3750.0\n-0.567621\n\n\n1\n3800.0\n-0.505525\n\n\n2\n3250.0\n-1.188572\n\n\n4\n3450.0\n-0.940192\n\n\n5\n3650.0\n-0.691811\n\n\n\n\n\n\n\n\npenguins[['body_mass_g', 'zscore_massa']].describe()\n\n\n\n\n\n\n\n\nbody_mass_g\nzscore_massa\n\n\n\n\ncount\n333.000000\n3.330000e+02\n\n\nmean\n4207.057057\n-8.535048e-17\n\n\nstd\n805.215802\n1.000000e+00\n\n\nmin\n2700.000000\n-1.871619e+00\n\n\n25%\n3550.000000\n-8.160012e-01\n\n\n50%\n4050.000000\n-1.950496e-01\n\n\n75%\n4775.000000\n7.053301e-01\n\n\nmax\n6300.000000\n2.599232e+00\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretaÃ§Ã£o do Z-score:\n- Z = 0: valor igual Ã  mÃ©dia\n- Z = 1: um desvio padrÃ£o acima da mÃ©dia\n- Z = -1: um desvio padrÃ£o abaixo da mÃ©dia\n- |Z| &gt; 2: valor considerado incomum"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#comparaÃ§Ã£o-visual-original-vs-padronizado",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#comparaÃ§Ã£o-visual-original-vs-padronizado",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "9 ComparaÃ§Ã£o Visual: Original vs Padronizado",
    "text": "9 ComparaÃ§Ã£o Visual: Original vs Padronizado\n\nfig, axes = plt.subplots(2, 1, figsize=(8, 6))\n\n# Histograma da variÃ¡vel original\naxes[0].hist(penguins['body_mass_g'], bins=20, color='skyblue', edgecolor='black')\naxes[0].set_title(\"Massa Corporal (g) - Original\")\naxes[0].set_xlabel(\"Massa (g)\")\naxes[0].set_ylabel(\"FrequÃªncia\")\n\n# Histograma da variÃ¡vel padronizada\naxes[1].hist(penguins['zscore_massa'], bins=20, color='lightgreen', edgecolor='black')\naxes[1].set_title(\"Massa Corporal - Z-Score\")\naxes[1].set_xlabel(\"Escore-Z\")\naxes[1].set_ylabel(\"FrequÃªncia\")\n\nplt.tight_layout()\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#resumo-das-medidas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#resumo-das-medidas",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "10 Resumo das Medidas",
    "text": "10 Resumo das Medidas\n\n\n\nMedida\nFunÃ§Ã£o Python\nInterpretaÃ§Ã£o\n\n\n\n\nMÃ©dia\n.mean()\nValor central (sensÃ­vel a outliers)\n\n\nMediana\n.median()\nValor central (robusta a outliers)\n\n\nDesvio PadrÃ£o\n.std()\nDispersÃ£o dos dados\n\n\nVariÃ¢ncia\n.var()\nDispersÃ£o ao quadrado\n\n\nQ1, Q3\n.quantile(0.25), .quantile(0.75)\nQuartis\n\n\nMÃ­nimo/MÃ¡ximo\n.min(), .max()\nValores extremos"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#aplicaÃ§Ãµes-prÃ¡ticas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#aplicaÃ§Ãµes-prÃ¡ticas",
    "title": "EstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python",
    "section": "11 AplicaÃ§Ãµes PrÃ¡ticas",
    "text": "11 AplicaÃ§Ãµes PrÃ¡ticas\n\n11.1 Identificando outliers com Z-score\n\n# Valores com |Z| &gt; 2 sÃ£o considerados incomuns\noutliers = penguins[np.abs(penguins['zscore_massa']) &gt; 2]\nprint(f\"Encontrados {len(outliers)} possÃ­veis outliers\")\noutliers[['species', 'body_mass_g', 'zscore_massa']]\n\nEncontrados 9 possÃ­veis outliers\n\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\nzscore_massa\n\n\n\n\n165\nGentoo\n5850.0\n2.040376\n\n\n167\nGentoo\n5850.0\n2.040376\n\n\n169\nGentoo\n6300.0\n2.599232\n\n\n185\nGentoo\n6050.0\n2.288757\n\n\n229\nGentoo\n6000.0\n2.226661\n\n\n231\nGentoo\n5950.0\n2.164566\n\n\n263\nGentoo\n5950.0\n2.164566\n\n\n267\nGentoo\n5850.0\n2.040376\n\n\n269\nGentoo\n6000.0\n2.226661\n\n\n\n\n\n\n\n\n\n11.2 ComparaÃ§Ã£o rÃ¡pida entre variÃ¡veis\n\n# EstatÃ­sticas descritivas para mÃºltiplas variÃ¡veis\ncolunas_numericas = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\npenguins[colunas_numericas].describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\ncount\n333.000000\n333.000000\n333.000000\n333.000000\n\n\nmean\n43.992793\n17.164865\n200.966967\n4207.057057\n\n\nstd\n5.468668\n1.969235\n14.015765\n805.215802\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n\n\n25%\n39.500000\n15.600000\n190.000000\n3550.000000\n\n\n50%\n44.500000\n17.300000\n197.000000\n4050.000000\n\n\n75%\n48.600000\n18.700000\n213.000000\n4775.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000"
  },
  {
    "objectID": "content/anova/anova-simples.html",
    "href": "content/anova/anova-simples.html",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nsource('scripts/anova-sim.r')\nA AnÃ¡lise de VariÃ¢ncia (ANOVA) desenvolvida por R. A. Fisher aplica-se Ã  uma classe de desenho experimental em que a variÃ¡vel resposta \\(Y\\) Ã© contÃ­nua e a variÃ¡vel explanatÃ³ria \\(X\\) Ã© categÃ³rica com \\(2\\) ou mais nÃ­veis. A ANOVA nos permite testar a hipÃ³tese de que duas ou mais mÃ©dias amostrais (\\(\\overline{Y}_i\\)) tenham sido obtidas de uma mesma populaÃ§Ã£o estatÃ­stica com mÃ©dia \\(\\mu\\). Alternativamente, podemos concluir que as mÃ©dias amostrais diferem umas das outras, de tal forma que devemos assumir que foram amostradas a partir de diferentes populaÃ§Ãµes estatÃ­sticas, nas quais ao menos um \\(\\mu_i\\) seja diferente dos demais. Iremos denominar estas duas possibilidades de hipÃ³tese estatÃ­sticas sobre a relaÃ§Ã£o entre as mÃ©dias populacionais."
  },
  {
    "objectID": "content/anova/anova-simples.html#o-modelo-da-anova-e-as-hipÃ³teses-estatÃ­sticas",
    "href": "content/anova/anova-simples.html#o-modelo-da-anova-e-as-hipÃ³teses-estatÃ­sticas",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "1 O modelo da ANOVA e as hipÃ³teses estatÃ­sticas",
    "text": "1 O modelo da ANOVA e as hipÃ³teses estatÃ­sticas\nO modelo pode ser representado por:\n\\[Y_{ij} = \\mu + A_i + \\epsilon_{ij}\\]\nonde \\(Y_{ij}\\) Ã© a variÃ¡vel resposta associada Ã  observaÃ§Ã£o \\(i\\) do tratamento \\(j\\), \\(\\mu\\) representa a mÃ©dia geral e \\(A_i\\) o efeito do tratamento \\(i\\). O termo \\(\\epsilon_{ij}\\) Ã© denominado de resÃ­duo (ou erro) associado a cada observaÃ§Ã£o, que assumimos ter distribuiÃ§Ã£o normal com mÃ©dia zero e variÃ¢ncia constante.\n\\[\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\n\n\n\n\nNotaHipÃ³teses estatÃ­sticas no modelo de ANOVA\n\n\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 =.... = \\mu_k\\) (HIPÃ“TESE NULA)\n\\(H_a\\): ao menos um par de mÃ©dias Ã© diferente (HIPÃ“TESE ALTERNATIVA)\n\n\nA hipÃ³tese nula (\\(H_0\\)) define a ausÃªncia de diferenÃ§as entre as mÃ©dias populacionais enquanto a hipÃ³tese alternativa (\\(H_a\\)) refere-se a qualquer possibilidade diferente de \\(H_0\\). Se temos exatamente dois nÃ­veis em \\(X\\), a comparaÃ§Ã£o de mÃ©dias pode ser feita por meio de um teste \\(t\\). Por outro lado, quando temos mais de dois nÃ­veis em \\(X\\), devemos utilizar o modelo de ANOVA."
  },
  {
    "objectID": "content/anova/anova-simples.html#partiÃ§Ã£o-das-soma-dos-quadrados",
    "href": "content/anova/anova-simples.html#partiÃ§Ã£o-das-soma-dos-quadrados",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "2 PartiÃ§Ã£o das Soma dos Quadrados",
    "text": "2 PartiÃ§Ã£o das Soma dos Quadrados\nAo representarmos a distribuiÃ§Ã£o de uma variÃ¡vel \\(Y\\) contÃ­nua em funÃ§Ã£o de uma variÃ¡vel \\(X\\) categÃ³rica, geralmente estamos interessados em determinar se os diferentes nÃ­veis de \\(X\\) (diferentes grupos) tÃªm mÃ©dias similares ou se ao menos um dos nÃ­veis tÃªm mÃ©dia diferente dos demais. Queremos uma medida que nos permita diferenciar situaÃ§Ãµes como as apresentadas abaixo.\n\n\n\n\n\n\n\n\n\nNa figura \\(A\\) todos os grupos sÃ£o provenientes da mesma distribuiÃ§Ã£o e tÃªm mÃ©dias aproximadamente iguais (\\(\\overline{Y}_A \\approx  \\overline{Y}_B \\approx \\overline{Y}_C \\approx \\overline{Y}_D\\)) e as diferenÃ§as sÃ£o provinientes unicamente da variabilidade amostral. Na figura \\(B\\) o segundo grupo tem mÃ©dia mais elevada que os demais, enquanto na figura \\(C\\), todas as mÃ©dias parecem ser diferentes entre si (\\(\\overline{Y}_A \\ne  \\overline{Y}_B \\ne \\overline{Y}_C \\ne \\overline{Y}_D\\)).\nPara mensurar o grau de associaÃ§Ã£o entre \\(Y\\) e \\(X\\) de modo a diferenciar as situaÃ§Ãµes acima, vamos introduzir o processo de PartiÃ§Ã£o da Soma dos Quadrados.\nSuponha a situÃ§Ã£o abaixo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotaNotaÃ§Ãµes\n\n\n\n\nTemos \\(k = 3\\) grupos (A, B ou C) e para cada grupo \\(n =  5\\) observaÃ§Ãµes. Denotamos por \\(n_{ij}\\) o nÃºmero de observaÃ§Ãµes dentro de cada grupo, em que \\(i\\) Ã© a i-Ã©sima observaÃ§Ã£o (\\(i = 1\\) a \\(5\\)) do j-Ã©simo grupo (\\(j = 1\\) a \\(3\\) - grupos A ao C). Neste exemplo, o nÃºmero de observaÃ§Ãµes em cada grupo Ã© o mesmo (\\(n_1 = n_2 = n_3 = n\\)), de modo que o total de observaÃ§Ãµes Ã© dado por:\n\n\\(N = k \\times n = n_1 + n_2 + n_3 = 15\\)\n\nA mÃ©dia de cada grupo serÃ¡ denotada por \\(\\overline{Y}_j\\), que neste exemplo sÃ£o: \\(Y_1 = 20.64\\) (grupo A), \\(Y_2 = 28.68\\) (grupo B) e \\(Y_3 = 12.18\\) (grupo C).\nVamos denotar por \\(\\overline{\\overline{Y}}\\) a Grande MÃ©dia, isto Ã©, a mÃ©dia geral de todas as observaÃ§Ãµes independente do grupo de origem.\n\n\\[\\overline{\\overline{Y}} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}\\frac{Y_{ij}}{N} = \\frac{\\overline{Y_1} + \\overline{Y_2} + \\overline{Y_3}}{3} = 20.5\\]\n\n\nPodemos agora observar estes elementos no grÃ¡fico de dispersÃ£o.\n\n\n\n\n\n\n\n\n\nEm seguida, precisamos calcular \\(3\\) quantias, a Soma dos Quadrados Totais (\\(SQ_{Total}\\)), a Soma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\) e a Soma dos Quadrados dos ResÃ­duos \\(SQ_{Res}\\).\n\nSoma dos Quadrados Totais \\(SQ_{Total}\\): mede as diferenÃ§as entre \\(Y_{ij}\\) e \\(\\overline{\\overline{Y}}\\). Temos nesta expressÃ£o o somatÃ³rio dos desvios ao quadrado de todas as observaÃ§Ãµes com relaÃ§Ã£o Ã  grande mÃ©dia independente do grupo de origem de cada observaÃ§Ã£o.\n\n\\[SQ_{Total} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\): mede as diferenÃ§as entre as mÃ©dias dos tratamentos \\(\\overline{Y}_j\\) e \\(\\overline{\\overline{Y}}\\), sendo portanto os desvios ao quadrado da mÃ©dia de cada tratamento subtraÃ­da da grande mÃ©dia. \\(SQ_{Trat}\\) tambÃ©m Ã© chamada de soma dos quadrados entre grupos ou entre tratamentos\n\n\\[SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos ResÃ­duos \\(SQ_{Res}\\): mede as diferenÃ§as entre cada observaÃ§Ã£o \\(Y_{ij}\\) e a mÃ©dia de seu prÃ³prio grupo \\(\\overline{Y}_{j}\\). \\(SQ_{Res}\\) tambÃ©m Ã© chamada de soma dos quadrados dentro dos grupos ou dentro dos tratamentos\n\n\\[SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2\\]\n\n\n\n\n\n\nNotaA caracterÃ­stica aditiva das somas dos quadrados\n\n\n\nA partiÃ§Ã£o da soma dos quadrados consiste em decompor a variaÃ§Ã£o total do experimento em uma parcela atribuÃ­da Ã  variaÃ§Ã£o entre tratamentos e outra parcela da variaÃ§Ã£o dentro dos tratamentos. Isto Ã© possÃ­vel pois as somas dos quadrados definidas acima podem ser expressas de forma aditiva como:\n\\[SQ_{Total} = SQ_{Trat} + SQ_{Res}\\]\nDeste modo, Ã© possÃ­vel demostrar que:\n\\(\\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(Y_{j} - \\overline{\\overline{Y}})^2 + \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{Y}_{j})^2\\)"
  },
  {
    "objectID": "content/anova/anova-simples.html#medindo-a-associaÃ§Ã£o-entre-y-e-x",
    "href": "content/anova/anova-simples.html#medindo-a-associaÃ§Ã£o-entre-y-e-x",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "3 Medindo a associaÃ§Ã£o entre \\(Y\\) e \\(X\\)",
    "text": "3 Medindo a associaÃ§Ã£o entre \\(Y\\) e \\(X\\)\nA caracterÃ­stica aditiva das somas dos quadrados pode ser utilizada para mensurar o grau de dependÃªncia de \\(Y_{ij}\\) com respeito aos diferentes tratamentos. Compare as duas figuras abaixo:\n\n\n\n\n\n\n\n\n\nA soma dos quadrados dentro dos grupos Ã© a mesma nas duas figuras (\\(SQ_{Res} = 362.6\\)). No entanto, na figura da esquerda, em que as mÃ©dias dos tratamentos sÃ£o similares (e consequentemente prÃ³ximas Ã  grande mÃ©dia), a soma dos quadrados entre os tratamentos Ã© muito menor (\\(SQ_{Trat}^{esquerda} = 15.8\\)) que na figura da direita, em que as mÃ©dias dos tratamentos estÃ£o distantes entre si (\\(SQ_{Trat}^{direita} = 680.8\\)). Ã‰ desta forma que a partiÃ§Ã£o das somas dos quadrados nos permite diferenciar situaÃ§Ãµes em que: i - a mÃ©dia dos grupos depende dos nÃ­veis do tratamento (figura da direita); de situaÃ§Ãµes em que ii - a mÃ©dia nÃ£o depende dos nÃ­veis do tratamento (figura da esquerda)."
  },
  {
    "objectID": "content/anova/anova-simples.html#quadrados-mÃ©dios-e-graus-de-liberdade",
    "href": "content/anova/anova-simples.html#quadrados-mÃ©dios-e-graus-de-liberdade",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "4 Quadrados mÃ©dios e graus de liberdade",
    "text": "4 Quadrados mÃ©dios e graus de liberdade\nPara que os somatÃ³rios dos quadrados expressem uma medida de variaÃ§Ã£o Ã© necessÃ¡rio corrigi-los em funÃ§Ã£o dos graus de liberdade (\\(gl\\)), obtendo assim os Quadrados mÃ©dios conforme abaixo:\n\nQuadrado MÃ©dio Total (\\(QM_{Total}\\))\n\n\\[QM_{Total} = \\frac{SQ_{Total}}{gl_{Total}}\\]\nem que \\(gl_{Total} = N - 1\\)\n\nQuadrado MÃ©dio dos Tratamentos (\\(QM_{Trat}\\))\n\n\\[QM_{Trat} = \\frac{SQ_{Trat}}{gl_{Trat}}\\]\nem que \\(gl_{Trat} = k - 1\\)\n\nQuadrado MÃ©dio dos ResÃ­duos (\\(QM_{Res}\\))\n\n\\[QM_{Res} = \\frac{SQ_{Res}}{gl_{Res}}\\]\nem que \\(gl_{Res} = N-k\\)\nAssim como a soma dos quadrados, os graus de liberdade tambÃ©m tÃªm caracterÃ­stica aditiva.\n\\[gl_{Total} = gl_{Trat} + gl_{Res} = (k - 1) + (N - K) = N - 1\\]\nOs quadrados mÃ©dios que sÃ£o estimativas de variÃ¢ncias. Compare por exemplo a expressÃ£o do \\(QM_{Total}\\) com a fÃ³rmula da variÃ¢ncia amostral (\\(s^2\\)) e verÃ¡ que excetuando mudanÃ§as de notaÃ§Ã£o, as expressÃµes sÃ£o essencialmente as mesmas."
  },
  {
    "objectID": "content/anova/anova-simples.html#estatÃ­stica-f-e-teste-de-hipÃ³teses",
    "href": "content/anova/anova-simples.html#estatÃ­stica-f-e-teste-de-hipÃ³teses",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "5 EstatÃ­stica \\(F\\) e teste de hipÃ³teses",
    "text": "5 EstatÃ­stica \\(F\\) e teste de hipÃ³teses\nUma vez que os quadrados mÃ©dios sÃ£o estimativas de variÃ¢ncia, uma estatÃ­stica de teste apropriada Ã©:\n\\[F_{calculado} = \\frac{QM_{Trat}}{QM_{Res}}\\]\nA estatÃ­stica \\(F\\) (ou razÃ£o-\\(F\\)) estÃ¡ associada Ã  distribuiÃ§Ã£o de probabilidades \\(F\\) e nos permite comparar a variÃ¢ncia associada ao tratamento com a variÃ¢ncia associada aos resÃ­duos. Com o valor de \\(F_{calculado}\\), o teste de hipÃ³teses Ã© possÃ­vel apÃ³s a definiÃ§Ã£o do nÃ­vel de significÃ¢ncia \\(\\alpha\\).\n\n5.1 NÃ­vel de significÃ¢ncia\nAssim como discutimos nos testes \\(Z\\) e \\(t\\), o valor de \\(\\alpha\\) estabelece um limite de aceitaÃ§Ã£o para \\(H_0\\), isto Ã©, um limite a partir do qual a estatÃ­stica do teste se torna tÃ£o extrema que nos leva a assumir que \\(H_0\\) Ã© improvÃ¡vel, devendo portanto ser rejeitada em favor de \\(H_a\\). Este passo Ã© possÃ­vel pois o valor de \\(F_{calculado}\\) pode ser associado Ã  distribuiÃ§Ã£o \\(F\\) de probabilidades, o que nos permite calcular a probabilidade:\n\\[P(F_{calculado}) \\le \\alpha\\]\nPara facilitar a notaÃ§Ã£o denominaremos \\(P(F_{calculado})\\) simplesmente de valor de \\(p\\) expresso em vermelho na figura abaixo:\n\n\n\n\n\n\nNotaTomada de decisÃ£o na ANOVA\n\n\n\nSe \\(p &gt; \\alpha\\) â€“&gt; ACEITAMOS \\(H_0\\)\nSe \\(p \\le \\alpha\\) â€“&gt; REJEITAMOS \\(H_0\\) (e assumimos \\(H_a\\) como verdadeira)\n\n\n\n\n\n\n\n\n\n\n\nTradicionalmente utiliza-se \\(\\alpha = 0.05\\). Neste caso, \\(H_0\\) seria rejeitada somente de \\(p \\le 0.05\\). Em algumas situaÃ§Ãµes podemos utilizar \\(\\alpha = 0.01\\), o que torna o experimento mais rigoroso, isto Ã©, menos propenso ao erro do tipo I."
  },
  {
    "objectID": "content/anova/anova-simples.html#um-exemplo-de-anova-os-nÃ­veis-de-metais-pesados-afetam-a-diversidade-de-espÃ©cies",
    "href": "content/anova/anova-simples.html#um-exemplo-de-anova-os-nÃ­veis-de-metais-pesados-afetam-a-diversidade-de-espÃ©cies",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "6 Um exemplo de ANOVA: os nÃ­veis de metais pesados afetam a diversidade de espÃ©cies?",
    "text": "6 Um exemplo de ANOVA: os nÃ­veis de metais pesados afetam a diversidade de espÃ©cies?\nImporte a base de dados medley.csv (disponÃ­vel tambÃ©m em Chapter 10 - Single factor classification (ANOVA)) que avalia o impacto da presenÃ§a de metais pesados na diversidade de espÃ©cies de diatomÃ¡cias em riachos (Medley e Clements (1998); Queen, Quinn, e Keough (2002); Logan (2011)).\n\nmedley = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/medley.csv\") |&gt; \n  mutate(STREAM = factor(STREAM),\n         ZINC = factor(ZINC, ordered = TRUE,\n                       levels = c(\"BACK\", \"LOW\", \"MED\", \"HIGH\")))\nvar_medley = colnames(medley)\nstream_levels = levels(medley$STREAM)\nn_stream = nlevels(medley$STREAM)\nzinc_levels = levels(medley$ZINC)\nn_zinc = nlevels(medley$ZINC)\n\n\nmedley |&gt; gt()\n\n\n\n\n\n\n\nSTREAM\nZINC\nDIVERSITY\n\n\n\n\nEagle\nBACK\n2.27\n\n\nEagle\nHIGH\n1.25\n\n\nEagle\nHIGH\n1.15\n\n\nEagle\nMED\n1.62\n\n\nBlue\nBACK\n1.70\n\n\nBlue\nHIGH\n0.63\n\n\nBlue\nBACK\n2.05\n\n\nBlue\nBACK\n1.98\n\n\nBlue\nHIGH\n1.04\n\n\nBlue\nMED\n2.19\n\n\nBlue\nMED\n2.10\n\n\nSnake\nBACK\n2.20\n\n\nSnake\nMED\n2.06\n\n\nSnake\nHIGH\n1.90\n\n\nSnake\nHIGH\n1.88\n\n\nSnake\nHIGH\n0.85\n\n\nArkan\nLOW\n1.40\n\n\nArkan\nLOW\n2.18\n\n\nArkan\nLOW\n1.83\n\n\nArkan\nLOW\n1.88\n\n\nArkan\nMED\n2.02\n\n\nArkan\nMED\n1.94\n\n\nArkan\nLOW\n2.10\n\n\nChalk\nLOW\n2.38\n\n\nChalk\nHIGH\n1.43\n\n\nChalk\nHIGH\n1.37\n\n\nChalk\nMED\n1.75\n\n\nChalk\nLOW\n2.83\n\n\nSplat\nBACK\n1.53\n\n\nSplat\nBACK\n0.76\n\n\nSplat\nMED\n0.80\n\n\nSplat\nLOW\n1.66\n\n\nSplat\nMED\n0.98\n\n\nSplat\nBACK\n1.89\n\n\n\n\n\n\n\nA coluna STREAM Ã© uma variÃ¡vel categÃ³rica contendo o nome dos \\(6\\) riachos amostrados (Arkan, Blue, Chalk, Eagle, Snake, Splat). A coluna ZINC Ã© uma variÃ¡vel categÃ³rica ordinal com \\(4\\) nÃ­veis de concentraÃ§Ã£o de zinco na Ã¡gua (BACK &lt; LOW &lt; MED &lt; HIGH). O primeiro nÃ­vel (BACK) Ã© o nÃ­vel de referÃªncia. Finalmente, a coluna DIVERSITY Ã© uma variÃ¡vel contÃ­nua que contÃ©m a diversidade de diatomÃ¡cieas medida pelo Ã­ndice de Shannon em cada uma das 34 amostras.\nVamos nos concentrar nas variÃ¡veis DIVERSITY e ZINC. DIVERSITY serÃ¡ a variÃ¡vel resposta. Dizemos que ZINC Ã© um tratamento, isto Ã©, uma condiÃ§Ã£o experimental (ou observacional) sob a qual a variÃ¡vel dependente \\(Y\\) foi medida.\nPara verificarmos a distribuiÃ§Ã£o de diversidade para cada concentraÃ§Ã£o de zinco vamos fazer um boxplot da variÃ¡vel DIVERSITY em funÃ§Ã£o de ZINC.\n\n\nCÃ³digo\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\nVemos que a concentraÃ§Ã£o HIGH aparenta ter menor diversidade que as demais concentralÃ§Ãµes. A ANOVA nos permitirÃ¡ testar esta suposiÃ§Ã£o.\n\n\n\n\n\n\nNotaHipÃ³pteses estatÃ­sticas\n\n\n\n\\(H_0: \\mu_{BACK} = \\mu_{LOW} = \\mu_{MED}  = \\mu_{HIGH}\\)\n\\(H_a\\): ao menos um \\(\\mu\\) Ã© diferente\n\\(\\alpha = 0.05\\)\n\n\n\n6.1 Calculando a ANOVA\ni. SomatÃ³rios dos quadrados\n\\(SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = 2.5666124\\)\n\\(SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2 = 6.5164111\\)\nii. Graus de liberdade\n\\(gl_{Trat} = k - 1 = 3\\)\n\\(gl_{Res} = N-k = 30\\)\niii. Quadrados mÃ©dios\n\\(QM_{Trat} = \\frac{SQ_{Trat}}{gl_{Trat}} = 0.8555375\\)\n\\(QM_{Res} = \\frac{SQ_{Res}}{gl_{Res}} = 0.2172137\\)\niv. EstatÃ­stica \\(F\\)\n\\(F_{calculado} = \\frac{QM_{Trat}}{QM_{Res}} = 3.939\\)\n\n\n\n\n\n\nNotaTabela da ANOVA**\n\n\n\nAs quantias acima sÃ£o tradicionalmente expressas em uma Tabela de ANOVA.\n\n\nCÃ³digo\naov_ex = aov(DIVERSITY ~ ZINC, data = medley)\nanova_ex = anova(aov_ex)\n\n\n\n\n\n\nTabelaÂ 1: Tabela da ANOVA para a base de dados medley.\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\n3\n2.566612\n0.8555375\n3.93869\n0.01755956\n\n\n30\n6.516411\n0.2172137\nNA\nNA\n\n\n\n\n\n\n\n\n\n\nem que:\nDf: graus de liberdade\nSum Sq: soma dos quadrados\nMean Sq: quadrados mÃ©dios\nF value: valor de \\(F_{calculado}\\)\nPr(&gt;F): valor de p\nA primeira linha refere-se aos valores associados aos tratamentos e a segunda linha aos resÃ­duos. Note que o cÃ´mputo de \\(SQ_{Total}\\), \\(gl_{Total}\\) e \\(QM_{Total}\\) nÃ£o Ã© realmente necessÃ¡rio.\n\n\nO valor de \\(p = 0.0175596\\) mostrado na TabelaÂ 1 refere-se Ã  Ã¡rea na distribuiÃ§Ã£o \\(F\\) que fica acima de \\(F_{calculado}\\) e que estÃ¡ representado em vermelho na FiguraÂ 1.\n\n\n\n\n\n\n\n\nFiguraÂ 1: DistribuiÃ§Ã£o F com indicaÃ§Ã£o do valor de p.\n\n\n\n\n\nAo verificar que \\(p \\le \\alpha\\), nossa conclusÃ£o deve ser de REJEITAR \\(H_0\\), pois \\(F_{calculado}\\) Ã© muito extremo para ser resultante da hipÃ³tese nula. Neste caso, assumimos que a \\(H_a\\) Ã© mais condizente com a estrutura dos dados, de modo que os tratamentos devem ser provenientes de populaÃ§Ãµes estatÃ­sticas com diferentes mÃ©dias \\(\\mu\\)."
  },
  {
    "objectID": "content/anova/anova-simples.html#testes-a-posteriori-de-comparaÃ§Ã£o-de-mÃ©dias-o-teste-de-tukey",
    "href": "content/anova/anova-simples.html#testes-a-posteriori-de-comparaÃ§Ã£o-de-mÃ©dias-o-teste-de-tukey",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "7 Testes a posteriori de comparaÃ§Ã£o de mÃ©dias: o teste de Tukey",
    "text": "7 Testes a posteriori de comparaÃ§Ã£o de mÃ©dias: o teste de Tukey\nTendo rejeitado \\(H_0\\) concluÃ­mos que ao menos 1 par mÃ©dias Ã© diferente entre si. Nos resta saber quais pares sÃ£o estatisticamente diferentes, o que nos leva a buscar por um teste que permita fazer comparaÃ§Ãµes par-a-par. Os testes a posteriori sÃ£o uma alternativa.\nEntre os diferentes testes a posteriori na literatura discutiremos o teste de Tukey, em que o objetivo Ã© estabelecer uma DiferenÃ§a Honesta Significativa (DHS) entre um dado par de mÃ©dias. Considerando a diferenÃ§a entre um par de mÃ©dias e o erro padrÃ£o das diferenÃ§as de mÃ©dias, a estatÃ­stica do teste de Tukey Ã©:\n\\[q = \\frac{\\overline{Y}_1 - \\overline{Y}_2}{SE}\\]\nem que:\n\\[SE = \\sqrt{\\frac{QM_{Res}}{2}(\\frac{1}{n_1} + \\frac{1}{n_2})}\\]\nonde:\n\\(q\\): Ã© e estatÃ­stica do teste\n\\(\\overline{Y}_1\\): Ã© a maior das mÃ©dias do par consideraddo;\n\\(\\overline{Y}_2\\): Ã© a menor das mÃ©dias do par consideraddo\n\\(QM_{Res}\\): Ã© quadrado mÃ©dio do resÃ­duo obtido na ANOVA, e;\n\\(n_1\\), \\(n_2\\): os tamanhos amostrais de cada grupo envolvido na comparaÃ§Ã£o.\nO valor crÃ­tico de \\(q\\) pode ser obtido de uma tabela estatÃ­stica da distribuiÃ§Ã£o de amplitude normalizada (studentized range q table). Para um dado \\(\\alpha\\), o valor desejado de \\(q\\) Ã© encontrado cruzando a linha contento o nÃºmero \\(k\\) de tratamentos do experimento com a linha contendo os graus de liberdade do resÃ­duo (\\(gl_{Res}\\)). Veja um exemplo desta tabela no link: Studentized Range q Table.\nEm nosso exemplo, os valores de \\(q\\) entre os pares de mÃ©dias serÃ£o:\n\nTukey_tab |&gt; \n  gt() |&gt; \n  cols_label(\n    combinacoes = \"CombinaÃ§Ãµes\",\n    diff = \"DiferenÃ§a\",\n    n1 = \"n1\",\n    n2 = \"n2\",\n    se = \"Erro PadrÃ£o\",\n    q = \"EstatÃ­stica q\",\n    H0 = \"DecisÃ£o\"\n  ) |&gt; \n  fmt_number(\n    columns = c(diff, se, q),\n    decimals = 3\n  ) |&gt; \n  tab_style(\n    style = cell_fill(color = \"orange\"),\n    locations = cells_body(\n      columns = H0,\n      rows = q &gt;= qc\n    )\n  ) |&gt; \n  tab_options(\n    table.width = \"100%\",\n    column_labels.font.weight = \"bold\"\n  )\n\n\n\n\n\n\n\nCombinaÃ§Ãµes\nDiferenÃ§a\nn1\nn2\nErro PadrÃ£o\nEstatÃ­stica q\nDecisÃ£o\n\n\n\n\nLOW-BACK\n0.235\n8\n8\n0.165\n1.426\nAceita H0\n\n\nMED-BACK\n0.080\n8\n8\n0.165\n0.484\nAceita H0\n\n\nHIGH-BACK\n0.520\n9\n8\n0.160\n3.246\nAceita H0\n\n\nMED-LOW\n0.315\n9\n8\n0.160\n1.965\nAceita H0\n\n\nHIGH-LOW\n0.755\n9\n8\n0.160\n4.713\nRejeita H0\n\n\nHIGH-MED\n0.440\n9\n9\n0.155\n2.832\nAceita H0\n\n\n\n\n\n\n\nO limite crÃ­tico para o valor de \\(q\\) tabelado Ã© \\(q_{0.95,30,4} = 3.845\\) (veja em: Studentized Range q Table), deste modo somente a comparaÃ§Ã£o entre HIGH-LOW sugere ter mÃ©dias significativamente diferentes."
  },
  {
    "objectID": "content/anova/anova-simples.html#ajustando-a-anova-no-r",
    "href": "content/anova/anova-simples.html#ajustando-a-anova-no-r",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "8 Ajustando a ANOVA no R",
    "text": "8 Ajustando a ANOVA no R\nA ANOVA no R pode ser feita com o comando aov.\n\najuste = aov(DIVERSITY ~ ZINC, data = medley)\najuste\n\nCall:\n   aov(formula = DIVERSITY ~ ZINC, data = medley)\n\nTerms:\n                    ZINC Residuals\nSum of Squares  2.566612  6.516411\nDeg. of Freedom        3        30\n\nResidual standard error: 0.4660619\nEstimated effects may be unbalanced\n\n\n\n\n\n\n\n\nNotaFÃ³rmula no R\n\n\n\nA notaÃ§Ã£o de fÃ³rmula no R Ã© escrita como: Y ~ Xonde lÃª-se \\(Y\\) Ã© funÃ§Ã£o de \\(X\\).\n\n\nO comando acima fez os cÃ¡lculos da ANOVA, isto Ã©, computou as somas dos quadrados, os graus de liberdade, os quadrados mÃ©dios, o \\(F_{calculado}\\) e o valor de \\(p\\). Para visualizarmos a tabela da ANOVA escrevemos:\n\nanova(ajuste)\n\nAnalysis of Variance Table\n\nResponse: DIVERSITY\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nZINC       3 2.5666 0.85554  3.9387 0.01756 *\nResiduals 30 6.5164 0.21721                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote que os resultados coincidem com o que apresentamos anteriormente. Como o valor de \\(p\\) foi menor que \\(\\alpha = 0.05\\), concluimos que a ANOVA foi significativa, isto Ã©, indicou que ao menos um par de mÃ©dias difere entre si. Podemos fazer o teste a posteriori de Tukey com o comando:\n\nalfa = 0.05\nTukeyHSD(ajuste, conf.level = 1-alfa)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = DIVERSITY ~ ZINC, data = medley)\n\n$ZINC\n                 diff        lwr         upr     p adj\nLOW-BACK   0.23500000 -0.3986367  0.86863665 0.7457444\nMED-BACK  -0.07972222 -0.6955064  0.53606192 0.9847376\nHIGH-BACK -0.51972222 -1.1355064  0.09606192 0.1218677\nMED-LOW   -0.31472222 -0.9305064  0.30106192 0.5153456\nHIGH-LOW  -0.75472222 -1.3705064 -0.13893808 0.0116543\nHIGH-MED  -0.44000000 -1.0373984  0.15739837 0.2095597\n\n\nO resultado apresenta todas as comparaÃ§Ãµes possÃ­veis entre os grupos, mostrando as diferenÃ§as de mÃ©dias, seus intervalos de confianÃ§a a \\(95\\%\\) e os valores de \\(p\\), indicando quais destas diferenÃ§as sÃ£o significativas (\\(p \\le \\alpha\\)). Nvamente, estes resultados nos permitem concluir que somente o par HIGH-LOW difere entre si, pois p adj &lt; 0.05.\nO grÃ¡fico abaixo facilita a visualizaÃ§Ã£o das comparaÃ§Ãµes, sobretudo em situaÃ§Ãµes com muitos pares de mÃ©dias envolvidos:\n\nplot(TukeyHSD(ajuste))\n\n\n\n\n\n\n\n\nNeste grÃ¡fico, sÃ£o consideradas estatisticamente significativas as comparaÃ§Ãµes em que o intervalo de confianÃ§a nÃ£o inclui o zero."
  },
  {
    "objectID": "content/anova/anova-simples.html#pressupostos-da-anova",
    "href": "content/anova/anova-simples.html#pressupostos-da-anova",
    "title": "AnÃ¡lise de variÃ¢ncia de um fator",
    "section": "9 Pressupostos da ANOVA",
    "text": "9 Pressupostos da ANOVA\nOs pressupostos da ANOVA sÃ£o:\n\nAs observaÃ§Ãµes sÃ£o independentes e;\nA variÃ¢ncia dos resÃ­duos Ã© homogÃªnea e;\nOs resÃ­duos tÃªm distribuiÃ§Ã£o normal com mÃ©dia \\(0\\) e variÃ¢ncia consante \\(\\sigma^2\\).\n\nVamos inicialmente testar o pressuposto de homogeneidade de variÃ¢ncias com um teste \\(F\\).\n\nmedley |&gt; group_by(ZINC) |&gt; \n  summarise(Var = var(DIVERSITY)) |&gt; \n  gt()\n\n\n\n\n\n\n\nZINC\nVar\n\n\n\n\nBACK\n0.2354786\n\n\nLOW\n0.1980214\n\n\nMED\n0.2530194\n\n\nHIGH\n0.1822194\n\n\n\n\n\n\n\nNote que a maior variÃ¢ncia Ã© \\(0.2530194\\) e a menor \\(0.1822194\\).\nO teste \\(F\\) consiste em dividir a maior variÃ¢ncia pela menor:\n\nvmax = medley$DIVERSITY[medley$ZINC == \"MED\"]\nvmin = medley$DIVERSITY[medley$ZINC == \"HIGH\"]\nvar.test(vmax, vmin)\n\n\n    F test to compare two variances\n\ndata:  vmax and vmin\nF = 1.3885, num df = 8, denom df = 8, p-value = 0.6534\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3132103 6.1557698\nsample estimates:\nratio of variances \n          1.388543 \n\n\nA maior variÃ¢ncia foi 1.39 vezes maior que a menor variÃ¢ncia e o test F sugere que esta diferenÃ§a Ã© nÃ£o-significativa a \\(5\\%\\) (\\(p &lt; 0.05\\)). Isto indica que as variÃ¢ncias sÃ£o homogÃªneas.\nA verificaÃ§Ã£o visual de que as variÃ¢ncias sÃ£o homogÃªneas pode tambÃ©m ser inspecionada pelo grÃ¡fico de resÃ­duos:\n\nplot(rstudent(ajuste) ~ fitted(ajuste), pch = 16)\nabline(h = 0, col = 2)\n\n\n\n\n\n\n\n\nEm seguida avaliamos o histograma dos resÃ­duos e aplicamos um teste de normalidade (ex. teste de Shapiro-Wilk) para verificar se o pressuposto de normalidade pode ser aceito.\n\nhist(rstudent(ajuste), breaks = 10)\n\n\n\n\n\n\n\nshapiro.test(rstudent(ajuste))\n\n\n    Shapiro-Wilk normality test\n\ndata:  rstudent(ajuste)\nW = 0.96696, p-value = 0.3828\n\n\nNeste caso, o valor de \\(p &gt; 0.05\\) indica nÃ£o haver desvio da normalidade."
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html",
    "href": "content/manipulacao-dados-R/transform.html",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "",
    "text": "ApÃ³s importar uma base de dados para o R, os pacotes dplyr e tidyr sÃ£o essenciais para transformaÃ§Ã£o de data frames. As funÃ§Ãµes desses pacotes ajudam na anÃ¡lise, modelagem e comunicaÃ§Ã£o de dados. Neste seÃ§Ã£o sÃ£o apresentadas as principais funÃ§Ãµes para transformar observaÃ§Ãµes (linhas) e variÃ¡veis em um data frame a partir de uma ou mais tabelas. A Cheatsheets do dplyr apresenta outros recursos nÃ£o discutidos nesta seÃ§Ã£o."
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#ordenando-as-linhas-funÃ§Ãµes-arrange-e-desc",
    "href": "content/manipulacao-dados-R/transform.html#ordenando-as-linhas-funÃ§Ãµes-arrange-e-desc",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "1 Ordenando as linhas: funÃ§Ãµes arrange() e desc()",
    "text": "1 Ordenando as linhas: funÃ§Ãµes arrange() e desc()\nAs funÃ§Ãµes arrange() e desc() permitem ordenar a base de dados com base nos valores de uma ou mais colunas. UsarÃ¡-se o conjunto de dados iris como exemplo.\nCarregue os pacote dplyr, tidyr e readr.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\nPara carregar e visualizar as primeiras linhas da base de dados iris:\n\ndata(\"iris\")\nhead(iris, 10)\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n2           4.9         3.0          1.4         0.2  setosa\n3           4.7         3.2          1.3         0.2  setosa\n4           4.6         3.1          1.5         0.2  setosa\n5           5.0         3.6          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n7           4.6         3.4          1.4         0.3  setosa\n8           5.0         3.4          1.5         0.2  setosa\n9           4.4         2.9          1.4         0.2  setosa\n10          4.9         3.1          1.5         0.1  setosa\n\n\nPara ordenar a tabela pela coluna Sepal.Length em ordem crescente:\n\niris |&gt; \n  arrange(Sepal.Length)\n\nPara ordenar em ordem decrescente:\n\niris |&gt; \n  arrange(desc(Sepal.Length))\n\nÃ‰ possÃ­vel tambÃ©m combinar duas colunas, ordenando a tabela pela coluna Species (em ordem alfabÃ©tica decrescente) e Sepal.Length (em ordem crescente):\n\niris |&gt; \n  arrange(desc(Species), Sepal.Length)\n\nPara criar um novo objeto com a tabela ordenada\n\niris_ordenado &lt;- iris |&gt; \n  arrange(Sepal.Length)\n\niris_ordenado"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#filtrando-linhas-funÃ§Ã£o-filter",
    "href": "content/manipulacao-dados-R/transform.html#filtrando-linhas-funÃ§Ã£o-filter",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "2 Filtrando linhas: funÃ§Ã£o filter()",
    "text": "2 Filtrando linhas: funÃ§Ã£o filter()\nA funÃ§Ã£o filter() extrai linhas que satisfazem uma condiÃ§Ã£o lÃ³gica. Para filtrar as linhas referentes Ã  espÃ©cie virginica:\n\niris |&gt; \n  filter(Species == \"virginica\")\n\nPara filtrar espÃ©cies diferentes de virginica.\n\niris |&gt; \n  filter(Species != \"virginica\")\n\nPara filtrar linhas onde o comprimento das pÃ©talas seja menor que \\(1.3\\):\n\niris |&gt; \n  filter(Petal.Length &lt; 1.3)\n\nPara filtrar onde o comprimento das pÃ©talas seja menor que \\(1.3\\) e o comprimento das sÃ©palas seja maior ou igual a \\(5\\):\n\niris |&gt; \n  filter(Petal.Length &lt; 1.3 & Sepal.Length &gt;= 5)"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#selecionando-colunas-funÃ§Ã£o-select",
    "href": "content/manipulacao-dados-R/transform.html#selecionando-colunas-funÃ§Ã£o-select",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "3 Selecionando colunas: funÃ§Ã£o select()",
    "text": "3 Selecionando colunas: funÃ§Ã£o select()\nA funÃ§Ã£o select() permite extrair ou reorganizar um subconjunto de colunas de um data frame.\nPara extrair uma coluna:\n\niris |&gt; \n  select(Petal.Length)\n\nPara extrair mÃºltiplas colunas:\n\niris |&gt; \n  select(Petal.Length, Species)\n\nPara extrair um intervalo de colunas:\n\niris |&gt; \n  select(Petal.Length:Species)\n\nPara excluir uma coluna:\n\niris |&gt; \n  select(-Petal.Length)\n\nPara excluir colunas especÃ­ficas:\n\niris |&gt; \n  select(!c(Petal.Length, Species))\n\nPara selecionar colunas que comeÃ§am com â€œSepalâ€:\n\niris |&gt; \n  select(starts_with(\"Sepal\"))\n\nPara combinar filter() e select() a fim de extrair um subconjunto do data frame:\n\niris |&gt; \n  select(starts_with(\"Sepal\")) |&gt; \n  filter(Sepal.Length &lt;= 4.5)\n\n\n3.1 Selecionando/Excluindo variÃ¡veis numÃ©ricas e categÃ³ricas\nImporte o conjuntoi de dados Reservatorios_Parana_parcial.csv:\n\nres = read_delim(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n                  delim = ',',\n                  locale = locale(decimal_mark = '.',\n                                  encoding = 'latin1'))\n\n\n3.1.1 SeleÃ§Ã£o de variÃ¡veis categÃ³ricas\n\nres |&gt;\n  select(Reservatorio, Bacia, Trofia)\n\n# A tibble: 31 Ã— 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu OligotrÃƒÂ³fico\n 2 Curucaca     Iguacu OligotrÃƒÂ³fico\n 3 Foz do Areia Iguacu OligotrÃƒÂ³fico\n 4 Irai         Iguacu EutrÃƒÂ³fico   \n 5 JMF          Iguacu MesotrÃƒÂ³fico \n 6 Jordao       Iguacu OligotrÃƒÂ³fico\n 7 Passauna     Iguacu OligotrÃƒÂ³fico\n 8 Piraquara    Iguacu OligotrÃƒÂ³fico\n 9 Salto Caxias Iguacu OligotrÃƒÂ³fico\n10 Salto do Vau Iguacu OligotrÃƒÂ³fico\n# â„¹ 21 more rows\n\nres |&gt;\n  select(where(is.character))\n\n# A tibble: 31 Ã— 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu OligotrÃƒÂ³fico\n 2 Curucaca     Iguacu OligotrÃƒÂ³fico\n 3 Foz do Areia Iguacu OligotrÃƒÂ³fico\n 4 Irai         Iguacu EutrÃƒÂ³fico   \n 5 JMF          Iguacu MesotrÃƒÂ³fico \n 6 Jordao       Iguacu OligotrÃƒÂ³fico\n 7 Passauna     Iguacu OligotrÃƒÂ³fico\n 8 Piraquara    Iguacu OligotrÃƒÂ³fico\n 9 Salto Caxias Iguacu OligotrÃƒÂ³fico\n10 Salto do Vau Iguacu OligotrÃƒÂ³fico\n# â„¹ 21 more rows\n\n\n\n\n3.1.2 SeleÃ§Ã£o de variÃ¡veis numÃ©ricas\n\nres |&gt;\n  select(Fechamento, Area, pH, Condutividade, Alcalinidade, P.total, Riqueza, CPUE)\n\n# A tibble: 31 Ã— 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# â„¹ 21 more rows\n\nres |&gt;\n  select(Fechamento, Area, pH:CPUE)\n\n# A tibble: 31 Ã— 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# â„¹ 21 more rows\n\nres |&gt;\n  select(where(is.numeric))\n\n# A tibble: 31 Ã— 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# â„¹ 21 more rows\n\n\n\n\n\n3.2 ExclusÃ£o de variÃ¡veis\n\nres |&gt;\n  select(-Fechamento, -Area)\n\n# A tibble: 31 Ã— 9\n   Reservatorio Bacia  Trofia      pH Condutividade Alcalinidade P.total Riqueza\n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Cavernoso    Iguacu Oligotrâ€¦   7.4          33.1        140.      7.8      18\n 2 Curucaca     Iguacu Oligotrâ€¦   7            32.4        126.      4.7      16\n 3 Foz do Areia Iguacu Oligotrâ€¦   7.3          35.5         97      14.3      19\n 4 Irai         Iguacu EutrÃƒÂ³fâ€¦   6.9          50.2          3.3    53.4      12\n 5 JMF          Iguacu MesotrÃƒâ€¦   7.3          40.2          3.7    41.2      18\n 6 Jordao       Iguacu Oligotrâ€¦   7.1          23.7        153.      3.3      17\n 7 Passauna     Iguacu Oligotrâ€¦   8.8         126.         526      15.2      11\n 8 Piraquara    Iguacu Oligotrâ€¦   7.1          22.8         50.7     4.5       8\n 9 Salto Caxias Iguacu Oligotrâ€¦   7.3          39.6        106      12.1      21\n10 Salto do Vau Iguacu Oligotrâ€¦   6.5          23.2        279      11         8\n# â„¹ 21 more rows\n# â„¹ 1 more variable: CPUE &lt;dbl&gt;\n\nres |&gt;\n  select(!where(is.numeric))\n\n# A tibble: 31 Ã— 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu OligotrÃƒÂ³fico\n 2 Curucaca     Iguacu OligotrÃƒÂ³fico\n 3 Foz do Areia Iguacu OligotrÃƒÂ³fico\n 4 Irai         Iguacu EutrÃƒÂ³fico   \n 5 JMF          Iguacu MesotrÃƒÂ³fico \n 6 Jordao       Iguacu OligotrÃƒÂ³fico\n 7 Passauna     Iguacu OligotrÃƒÂ³fico\n 8 Piraquara    Iguacu OligotrÃƒÂ³fico\n 9 Salto Caxias Iguacu OligotrÃƒÂ³fico\n10 Salto do Vau Iguacu OligotrÃƒÂ³fico\n# â„¹ 21 more rows\n\nres |&gt;\n  select(!where(is.character))\n\n# A tibble: 31 Ã— 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# â„¹ 21 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#outros-exemplos-de-seleÃ§Ã£oexclusÃ£o-de-variÃ¡veis",
    "href": "content/manipulacao-dados-R/transform.html#outros-exemplos-de-seleÃ§Ã£oexclusÃ£o-de-variÃ¡veis",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "4 Outros exemplos de seleÃ§Ã£o/exclusÃ£o de variÃ¡veis",
    "text": "4 Outros exemplos de seleÃ§Ã£o/exclusÃ£o de variÃ¡veis\n\n4.1 all_off(), any_of(), one_of()\n\n# 1. all_of(): Seleciona todas as colunas mencionadas\nres |&gt;\n  select(all_of(c('Reservatorio', 'Bacia')))\n\n# A tibble: 31 Ã— 2\n   Reservatorio Bacia \n   &lt;chr&gt;        &lt;chr&gt; \n 1 Cavernoso    Iguacu\n 2 Curucaca     Iguacu\n 3 Foz do Areia Iguacu\n 4 Irai         Iguacu\n 5 JMF          Iguacu\n 6 Jordao       Iguacu\n 7 Passauna     Iguacu\n 8 Piraquara    Iguacu\n 9 Salto Caxias Iguacu\n10 Salto do Vau Iguacu\n# â„¹ 21 more rows\n\n# 2. any_of(): Seleciona qualquer coluna que exista na lista (ignora colunas inexistentes)\nres |&gt;\n  select(any_of(c('Reservatorio', 'Bacia', 'Turbidez'))) # funciona, any_of() ignora que `Turbidez` nÃ£o existe\n\n# A tibble: 31 Ã— 2\n   Reservatorio Bacia \n   &lt;chr&gt;        &lt;chr&gt; \n 1 Cavernoso    Iguacu\n 2 Curucaca     Iguacu\n 3 Foz do Areia Iguacu\n 4 Irai         Iguacu\n 5 JMF          Iguacu\n 6 Jordao       Iguacu\n 7 Passauna     Iguacu\n 8 Piraquara    Iguacu\n 9 Salto Caxias Iguacu\n10 Salto do Vau Iguacu\n# â„¹ 21 more rows\n\nres |&gt;\n  select(one_of(c('Reservatorio', 'Trofia', 'Turbidez'))) # funciona, one_of() avisa que `Turbidez` nÃ£o existe\n\n# A tibble: 31 Ã— 2\n   Reservatorio Trofia       \n   &lt;chr&gt;        &lt;chr&gt;        \n 1 Cavernoso    OligotrÃƒÂ³fico\n 2 Curucaca     OligotrÃƒÂ³fico\n 3 Foz do Areia OligotrÃƒÂ³fico\n 4 Irai         EutrÃƒÂ³fico   \n 5 JMF          MesotrÃƒÂ³fico \n 6 Jordao       OligotrÃƒÂ³fico\n 7 Passauna     OligotrÃƒÂ³fico\n 8 Piraquara    OligotrÃƒÂ³fico\n 9 Salto Caxias OligotrÃƒÂ³fico\n10 Salto do Vau OligotrÃƒÂ³fico\n# â„¹ 21 more rows\n\n# res |&gt;\n#   select(Reservatorio, Bacia, Turbidez) # NÃ£o funciona, pois `Turbidez` nÃ£o existe\n\n\n\n4.2 contains(), ends_with(), everything(), last_col()\n\n# 3. contains(): Seleciona colunas cujos nomes contÃªm uma string especÃ­fica\nres |&gt;\n  select(contains('to'))\n\n# A tibble: 31 Ã— 3\n   Reservatorio Fechamento P.total\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 Cavernoso          1965     7.8\n 2 Curucaca           1982     4.7\n 3 Foz do Areia       1980    14.3\n 4 Irai               2000    53.4\n 5 JMF                1970    41.2\n 6 Jordao             1996     3.3\n 7 Passauna           1978    15.2\n 8 Piraquara          1979     4.5\n 9 Salto Caxias       1998    12.1\n10 Salto do Vau       1959    11  \n# â„¹ 21 more rows\n\n# 4. ends_with(): Seleciona colunas que terminam com uma string especÃ­fica\nres |&gt;\n  select(ends_with('dade'))\n\n# A tibble: 31 Ã— 2\n   Condutividade Alcalinidade\n           &lt;dbl&gt;        &lt;dbl&gt;\n 1          33.1        140. \n 2          32.4        126. \n 3          35.5         97  \n 4          50.2          3.3\n 5          40.2          3.7\n 6          23.7        153. \n 7         126.         526  \n 8          22.8         50.7\n 9          39.6        106  \n10          23.2        279  \n# â„¹ 21 more rows\n\n# 5. everything(): Seleciona todas as colunas (pode ser usado para reorganizar)\nres |&gt;\n  select(Fechamento, pH, everything())\n\n# A tibble: 31 Ã— 11\n   Fechamento    pH Reservatorio Bacia    Area Trofia Condutividade Alcalinidade\n        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n 1       1965   7.4 Cavernoso    Iguacu   2.9  Oligoâ€¦          33.1        140. \n 2       1982   7   Curucaca     Iguacu   2    Oligoâ€¦          32.4        126. \n 3       1980   7.3 Foz do Areia Iguacu 139    Oligoâ€¦          35.5         97  \n 4       2000   6.9 Irai         Iguacu  15    EutrÃƒâ€¦          50.2          3.3\n 5       1970   7.3 JMF          Iguacu   0.45 Mesotâ€¦          40.2          3.7\n 6       1996   7.1 Jordao       Iguacu   3.4  Oligoâ€¦          23.7        153. \n 7       1978   8.8 Passauna     Iguacu  14    Oligoâ€¦         126.         526  \n 8       1979   7.1 Piraquara    Iguacu   3.3  Oligoâ€¦          22.8         50.7\n 9       1998   7.3 Salto Caxias Iguacu 124    Oligoâ€¦          39.6        106  \n10       1959   6.5 Salto do Vau Iguacu   2.9  Oligoâ€¦          23.2        279  \n# â„¹ 21 more rows\n# â„¹ 3 more variables: P.total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, CPUE &lt;dbl&gt;\n\n# 6. last_col(): Seleciona a Ãºltima coluna\nres |&gt;\n  select(last_col())\n\n# A tibble: 31 Ã— 1\n    CPUE\n   &lt;dbl&gt;\n 1  9.22\n 2 28.7 \n 3 11.6 \n 4 30.8 \n 5  5.95\n 6  7.75\n 7  7.51\n 8  4.01\n 9 20.8 \n10  2.43\n# â„¹ 21 more rows\n\n\n\n\n4.3 Expressoes regulares\n\n# 7. matches(): Seleciona colunas que correspondem a uma expressÃ£o regular\nres |&gt;\n  select(matches('^[FA]')) # Colunas que comeÃ§am com 'F ou A'\n\n# A tibble: 31 Ã— 3\n   Fechamento   Area Alcalinidade\n        &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;\n 1       1965   2.9         140. \n 2       1982   2           126. \n 3       1980 139            97  \n 4       2000  15             3.3\n 5       1970   0.45          3.7\n 6       1996   3.4         153. \n 7       1978  14           526  \n 8       1979   3.3          50.7\n 9       1998 124           106  \n10       1959   2.9         279  \n# â„¹ 21 more rows\n\n# 8. Seleciona colunas cujos nomes:\n# 1. ComeÃ§am com a letra \"A\" ou \"C\"\n# 2. Podem conter qualquer sequÃªncia de caracteres apÃ³s a primeira letra\n# 3. Terminam com as letras \"a\" ou \"e\"\nres |&gt;\n  select(matches('^[AC].*[ae]$'))\n\n# A tibble: 31 Ã— 4\n     Area Condutividade Alcalinidade  CPUE\n    &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1   2.9           33.1        140.   9.22\n 2   2             32.4        126.  28.7 \n 3 139             35.5         97   11.6 \n 4  15             50.2          3.3 30.8 \n 5   0.45          40.2          3.7  5.95\n 6   3.4           23.7        153.   7.75\n 7  14            126.         526    7.51\n 8   3.3           22.8         50.7  4.01\n 9 124             39.6        106   20.8 \n10   2.9           23.2        279    2.43\n# â„¹ 21 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#renomeando-colunas",
    "href": "content/manipulacao-dados-R/transform.html#renomeando-colunas",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "5 Renomeando colunas",
    "text": "5 Renomeando colunas\n\nres |&gt;\n  rename(Fosforo_total = P.total,\n         Captura_kg = CPUE)\n\n# A tibble: 31 Ã— 11\n   Reservatorio Bacia  Fechamento   Area Trofia    pH Condutividade Alcalinidade\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n 1 Cavernoso    Iguacu       1965   2.9  Oligoâ€¦   7.4          33.1        140. \n 2 Curucaca     Iguacu       1982   2    Oligoâ€¦   7            32.4        126. \n 3 Foz do Areia Iguacu       1980 139    Oligoâ€¦   7.3          35.5         97  \n 4 Irai         Iguacu       2000  15    EutrÃƒâ€¦   6.9          50.2          3.3\n 5 JMF          Iguacu       1970   0.45 Mesotâ€¦   7.3          40.2          3.7\n 6 Jordao       Iguacu       1996   3.4  Oligoâ€¦   7.1          23.7        153. \n 7 Passauna     Iguacu       1978  14    Oligoâ€¦   8.8         126.         526  \n 8 Piraquara    Iguacu       1979   3.3  Oligoâ€¦   7.1          22.8         50.7\n 9 Salto Caxias Iguacu       1998 124    Oligoâ€¦   7.3          39.6        106  \n10 Salto do Vau Iguacu       1959   2.9  Oligoâ€¦   6.5          23.2        279  \n# â„¹ 21 more rows\n# â„¹ 3 more variables: Fosforo_total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, Captura_kg &lt;dbl&gt;"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#agrupando-tabelas-funÃ§Ãµes-do-grupo-join",
    "href": "content/manipulacao-dados-R/transform.html#agrupando-tabelas-funÃ§Ãµes-do-grupo-join",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "6 Agrupando tabelas: funÃ§Ãµes do grupo join",
    "text": "6 Agrupando tabelas: funÃ§Ãµes do grupo join\nAs funÃ§Ãµes left_join(), right_join(), inner_join(), anti_join() e full_join() do pacote dplyr em R sÃ£o utilizadas para combinar dois data frames baseados em uma coluna ou colunas comuns. Esses tipos de joins sÃ£o amplamente utilizados em operaÃ§Ãµes de banco de dados e manipulaÃ§Ã£o de dados.\nConsidere os arquivos regiao.csv e habitat.csv do repositÃ³rio datasets.\n\nregiao &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regiao.csv\")\nhabitat &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/habitat.csv\")\nregiao\n\n# A tibble: 10 Ã— 4\n   Riacho Bacia      MunicÃ­pio      Ãrea\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;\n 1 R1     Boicucanga SÃ£o SebastiÃ£o  30.3\n 2 R4     Boicucanga SÃ£o SebastiÃ£o  30.3\n 3 R8     Boicucanga SÃ£o SebastiÃ£o  30.3\n 4 R2     CubatÃ£o    CubatÃ£o       189  \n 5 R5     CubatÃ£o    CubatÃ£o       189  \n 6 R10    CubatÃ£o    CubatÃ£o       189  \n 7 R13    CubatÃ£o    CubatÃ£o       189  \n 8 R6     Quilombo   Santos         86  \n 9 R9     Quilombo   Santos         86  \n10 R7     Quilombo   Santos         86  \n\nhabitat\n\n# A tibble: 8 Ã— 4\n  Riacho Altitude Largura Profundidade\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1           74     7.8         20.2\n2 R4           14    10.9         17.7\n3 R8          245     8.3         19.5\n4 R11         241     2.2         20.3\n5 R2           29     1.6         11.8\n6 R6           86    15.2         35.3\n7 R9           77     4.1         18.9\n8 R7           63    14.2         42.1\n\n\nTabela regiao: ContÃ©m informaÃ§Ãµes sobre a bacia hidrogrÃ¡fica, Ã¡rea da bacia e municÃ­pio de alguns riachos da regiÃ£o litorÃ¢nea de SÃ£o Paulo.\nTabela habitat: ContÃ©m informaÃ§Ãµes sobre a largura e profundidade desses riachos. Algumas entradas sÃ£o comuns Ã s duas tabelas, enquanto outras sÃ£o exclusivas de uma delas. A coluna Riacho serve como chave para combinar as informaÃ§Ãµes.\n\nFunÃ§Ã£o left_join()\nRetorna todas as linhas da tabela Ã  esquerda (regiao) e adiciona colunas da tabela Ã  direita (habitat). Linhas sem correspondÃªncia na tabela da direita terÃ£o valores de NA.\n\nregiao |&gt; left_join(y = habitat)\n\n# A tibble: 10 Ã— 7\n   Riacho Bacia      MunicÃ­pio      Ãrea Altitude Largura Profundidade\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 R1     Boicucanga SÃ£o SebastiÃ£o  30.3       74     7.8         20.2\n 2 R4     Boicucanga SÃ£o SebastiÃ£o  30.3       14    10.9         17.7\n 3 R8     Boicucanga SÃ£o SebastiÃ£o  30.3      245     8.3         19.5\n 4 R2     CubatÃ£o    CubatÃ£o       189         29     1.6         11.8\n 5 R5     CubatÃ£o    CubatÃ£o       189         NA    NA           NA  \n 6 R10    CubatÃ£o    CubatÃ£o       189         NA    NA           NA  \n 7 R13    CubatÃ£o    CubatÃ£o       189         NA    NA           NA  \n 8 R6     Quilombo   Santos         86         86    15.2         35.3\n 9 R9     Quilombo   Santos         86         77     4.1         18.9\n10 R7     Quilombo   Santos         86         63    14.2         42.1\n\n\n\n\nFunÃ§Ã£o right_join()\nRetorna todas as linhas da tabela Ã  direita (habitat) e adiciona colunas da tabela Ã  esquerda (regiao). Linhas sem correspondÃªncia na tabela da esquerda terÃ£o valores de NA.\n\nregiao |&gt; right_join(y = habitat, keep=TRUE)\n\n# A tibble: 8 Ã— 8\n  Riacho.x Bacia      MunicÃ­pio      Ãrea Riacho.y Altitude Largura Profundidade\n  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1       Boicucanga SÃ£o SebastiÃ£o  30.3 R1             74     7.8         20.2\n2 R4       Boicucanga SÃ£o SebastiÃ£o  30.3 R4             14    10.9         17.7\n3 R8       Boicucanga SÃ£o SebastiÃ£o  30.3 R8            245     8.3         19.5\n4 R2       CubatÃ£o    CubatÃ£o       189   R2             29     1.6         11.8\n5 R6       Quilombo   Santos         86   R6             86    15.2         35.3\n6 R9       Quilombo   Santos         86   R9             77     4.1         18.9\n7 R7       Quilombo   Santos         86   R7             63    14.2         42.1\n8 &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;           NA   R11           241     2.2         20.3\n\n\n\n\nFunÃ§Ã£o inner_join()\nRetorna apenas as linhas que tÃªm correspondÃªncia em ambas as tabelas.\n\nregiao |&gt; inner_join(y = habitat)\n\n# A tibble: 7 Ã— 7\n  Riacho Bacia      MunicÃ­pio      Ãrea Altitude Largura Profundidade\n  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1     Boicucanga SÃ£o SebastiÃ£o  30.3       74     7.8         20.2\n2 R4     Boicucanga SÃ£o SebastiÃ£o  30.3       14    10.9         17.7\n3 R8     Boicucanga SÃ£o SebastiÃ£o  30.3      245     8.3         19.5\n4 R2     CubatÃ£o    CubatÃ£o       189         29     1.6         11.8\n5 R6     Quilombo   Santos         86         86    15.2         35.3\n6 R9     Quilombo   Santos         86         77     4.1         18.9\n7 R7     Quilombo   Santos         86         63    14.2         42.1\n\n\n\n\nFunÃ§Ã£o anti_join()\nRetorna as linhas da tabela Ã  esquerda que nÃ£o tÃªm correspondÃªncia na tabela Ã  direita. TambÃ©m retorna todas as colunas da tabela Ã  esquerda.\n\nregiao |&gt; anti_join(y = habitat)\n\n# A tibble: 3 Ã— 4\n  Riacho Bacia   MunicÃ­pio  Ãrea\n  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 R5     CubatÃ£o CubatÃ£o     189\n2 R10    CubatÃ£o CubatÃ£o     189\n3 R13    CubatÃ£o CubatÃ£o     189\n\n\n\nhabitat |&gt; anti_join(y = regiao)\n\n# A tibble: 1 Ã— 4\n  Riacho Altitude Largura Profundidade\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R11         241     2.2         20.3\n\n\n\n\nFunÃ§Ã£o full_join()\nRetorna todas as linhas e colunas de ambas as tabelas. Nas cÃ©lulas onde nÃ£o houver correspondÃªncia, retorna NA.\n\nregiao |&gt; full_join(y = habitat, keep = TRUE)\n\n# A tibble: 11 Ã— 8\n   Riacho.x Bacia      MunicÃ­pio     Ãrea Riacho.y Altitude Largura Profundidade\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 R1       Boicucanga SÃ£o Sebastiâ€¦  30.3 R1             74     7.8         20.2\n 2 R4       Boicucanga SÃ£o Sebastiâ€¦  30.3 R4             14    10.9         17.7\n 3 R8       Boicucanga SÃ£o Sebastiâ€¦  30.3 R8            245     8.3         19.5\n 4 R2       CubatÃ£o    CubatÃ£o      189   R2             29     1.6         11.8\n 5 R5       CubatÃ£o    CubatÃ£o      189   &lt;NA&gt;           NA    NA           NA  \n 6 R10      CubatÃ£o    CubatÃ£o      189   &lt;NA&gt;           NA    NA           NA  \n 7 R13      CubatÃ£o    CubatÃ£o      189   &lt;NA&gt;           NA    NA           NA  \n 8 R6       Quilombo   Santos        86   R6             86    15.2         35.3\n 9 R9       Quilombo   Santos        86   R9             77     4.1         18.9\n10 R7       Quilombo   Santos        86   R7             63    14.2         42.1\n11 &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;          NA   R11           241     2.2         20.3"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#criando-e-modificando-colunas-com-mutate",
    "href": "content/manipulacao-dados-R/transform.html#criando-e-modificando-colunas-com-mutate",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "7 Criando e modificando colunas com mutate()",
    "text": "7 Criando e modificando colunas com mutate()\nA funÃ§Ã£o mutate() permite criar e modificar colunas em um data frame. Usando a base de dados Doubs river:\n\nlibrary(ade4)\ndata(doubs)\ndbenv &lt;- doubs$env\nhead(dbenv)\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n1   3 934 6.176  84 79  45   1  20   0 122  27\n2  22 932 3.434 100 80  40   2  20  10 103  19\n3 102 914 3.638 180 83  52   5  22   5 105  35\n4 185 854 3.497 253 80  72  10  21   0 110  13\n5 215 849 3.178 264 81  84  38  52  20  80  62\n6 324 846 3.497 286 79  60  20  15   0 102  53\n\n\n\nAjustando a escala de pH\nA coluna pH estÃ¡ multiplicada por \\(10\\). Vamos ajustar isso:\n\ndbenv &lt;- dbenv  |&gt; \n  mutate(pH = pH / 10)\n\nhead(dbenv)\n\n  dfs alt   slo flo  pH har pho nit amm oxy bdo\n1   3 934 6.176  84 7.9  45   1  20   0 122  27\n2  22 932 3.434 100 8.0  40   2  20  10 103  19\n3 102 914 3.638 180 8.3  52   5  22   5 105  35\n4 185 854 3.497 253 8.0  72  10  21   0 110  13\n5 215 849 3.178 264 8.1  84  38  52  20  80  62\n6 324 846 3.497 286 7.9  60  20  15   0 102  53\n\n\n\n\nCriando variÃ¡vel categÃ³rica\nCriar uma variÃ¡vel categÃ³rica pH_cat com nÃ­veis Elevado (maior ou igual a \\(8\\)) e Neutro (menor que \\(8\\)):\n\ndbenv &lt;- dbenv |&gt; \n  mutate(pH = pH / 10) |&gt; \n  mutate(pH_cat = if_else(pH &lt; 8, true = \"Neutro\", false = \"Elevado\"),\n         , .after = pH)\n\nhead(dbenv)\n\n  dfs alt   slo flo   pH pH_cat har pho nit amm oxy bdo\n1   3 934 6.176  84 0.79 Neutro  45   1  20   0 122  27\n2  22 932 3.434 100 0.80 Neutro  40   2  20  10 103  19\n3 102 914 3.638 180 0.83 Neutro  52   5  22   5 105  35\n4 185 854 3.497 253 0.80 Neutro  72  10  21   0 110  13\n5 215 849 3.178 264 0.81 Neutro  84  38  52  20  80  62\n6 324 846 3.497 286 0.79 Neutro  60  20  15   0 102  53\n\n\n\n\nUnindo colunas com unite()\nA funÃ§Ã£o unite() do tidyr combina duas colunas em uma nova coluna. Usando a tabela iris:\n\niris2 &lt;- iris |&gt; \n  mutate(Genus = \"Iris\", .before = Species)  |&gt;  \n  unite(scientic_name, Genus, Species, sep = \" \")\n\nhead(iris2)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width scientic_name\n1          5.1         3.5          1.4         0.2   Iris setosa\n2          4.9         3.0          1.4         0.2   Iris setosa\n3          4.7         3.2          1.3         0.2   Iris setosa\n4          4.6         3.1          1.5         0.2   Iris setosa\n5          5.0         3.6          1.4         0.2   Iris setosa\n6          5.4         3.9          1.7         0.4   Iris setosa\n\n\n\n\n\n\n\n\nNotaObservaÃ§Ã£o\n\n\n\nA funÃ§Ã£o unite() excluiu as colunas que foram unificadas da tabela. Mara mantÃª-las na tabela utilize o argumento remove = FALSE."
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#reformatando-data-frames-funÃ§Ãµes-pivot_wider-e-pivot_longer",
    "href": "content/manipulacao-dados-R/transform.html#reformatando-data-frames-funÃ§Ãµes-pivot_wider-e-pivot_longer",
    "title": "TransformaÃ§Ã£o de Dados",
    "section": "8 Reformatando data frames: funÃ§Ãµes pivot_wider() e pivot_longer()",
    "text": "8 Reformatando data frames: funÃ§Ãµes pivot_wider() e pivot_longer()\nA tabela HubbardBrook.csv (datasets) contÃ©m dados anuais de vazÃ£o e precipitaÃ§Ã£o em dois bacias hidrogrÃ¡ficas (Hornbeck et al. 1993). A primeira (Deforested) teve toda a vegetaÃ§Ã£o removida como parte de um experimento de longa duraÃ§Ã£o enquanto a outra se manteve intacta (Referenca). Os daods de origem e o experimento detalhado sÃ£o apresentados am Os dados foram retirados de tiee.esa.org\n\nhbrook &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook.csv\")\nhbrook\n\n# A tibble: 62 Ã— 4\n    Year Treatment   Flow Precipitation\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n 1  1958 Deforested  645.         1168.\n 2  1959 Deforested 1012.         1483.\n 3  1960 Deforested  825.         1321.\n 4  1961 Deforested  470.          980.\n 5  1962 Deforested  777.         1232.\n 6  1963 Deforested  774.         1139.\n 7  1964 Deforested  712.         1175.\n 8  1965 Deforested  599.         1115.\n 9  1966 Deforested 1189.         1222.\n10  1967 Deforested 1132.         1315.\n# â„¹ 52 more rows\n\n\n\nReorganizando data frames de formato longo para formato largo\nA funÃ§Ã£o pivot_wider() Ã© utilizada para transformar dados do formato longo para o formato largo. A seguir, serÃ¡ feito isso apenas para a variÃ¡vel Flow, excluindo Precipitation, separando os dados nas colunas Deforested e Reference.\n\nhbrook_largo &lt;- hbrook |&gt;\n  select(-Precipitation) |&gt;\n  pivot_wider(names_from = Treatment, values_from = Flow)\nhbrook_largo\n\n# A tibble: 31 Ã— 3\n    Year Deforested Reference\n   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1  1958       645.      567.\n 2  1959      1012.      918.\n 3  1960       825.      752.\n 4  1961       470.      436.\n 5  1962       777.      699.\n 6  1963       774.      663.\n 7  1964       712.      630.\n 8  1965       599.      547.\n 9  1966      1189.      727.\n10  1967      1132.      781.\n# â„¹ 21 more rows\n\n\n\n\nReorganizando data frames de formato largo para formato longo\nA funÃ§Ã£o pivot_longer() Ã© utilizada para transformar dados do formato largo para o formato longo, fazendo o caminho inverso de pivot_wider().\n\nhbrook_longo &lt;- hbrook_largo |&gt;\n  pivot_longer(!Year, names_to = \"Desmatamento\", values_to = \"Flow\")\nhbrook_longo\n\n# A tibble: 62 Ã— 3\n    Year Desmatamento  Flow\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1  1958 Deforested    645.\n 2  1958 Reference     567.\n 3  1959 Deforested   1012.\n 4  1959 Reference     918.\n 5  1960 Deforested    825.\n 6  1960 Reference     752.\n 7  1961 Deforested    470.\n 8  1961 Reference     436.\n 9  1962 Deforested    777.\n10  1962 Reference     699.\n# â„¹ 52 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html",
    "href": "content/manipulacao-dados-R/tidyverse.html",
    "title": "Os pacotes em tidyverse",
    "section": "",
    "text": "O Tidyverse Ã© uma coleÃ§Ã£o de pacotes em R projetados para ciÃªncia de dados que inclui ferramentas para importar, arrumar, transformar, visualizar e modelar dados, todas integradas de forma coesa para tornar a anÃ¡lise de dados mais eficiente e intuitiva. O Tidyverse facilita a prÃ¡tica de uma ciÃªncia de dados mais limpa, clara e reproduzÃ­vel. Entre os pacotes mais populares do Tidyverse estÃ£o ggplot2 para visualizaÃ§Ã£o de dados, dplyr para manipulaÃ§Ã£o de dados e tidyr para arrumaÃ§Ã£o de dados.\nAlÃ©m destes existem ainda outros que se integram bem Ã  filosofia do tidyverse como o lubridade (manipulaÃ§Ã£o de datas), o readxl (leitura de arquivos .xls e .xlsx), alÃ©m de muitos outros. Veremos algumas funÃ§Ãµes e prÃ¡ticas Ãºteis utilizando estes pacotes. Para uma visÃ£o geral de cada pacote, verifique as Cheatsheets que oferecem um resumo sobre as funÃ§Ãµes principais."
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html#instalando-os-pacotes",
    "href": "content/manipulacao-dados-R/tidyverse.html#instalando-os-pacotes",
    "title": "Os pacotes em tidyverse",
    "section": "1 Instalando os pacotes",
    "text": "1 Instalando os pacotes\nCada um dos pacotes incorporados no tidyverse pode ser instalado individualmente. Por exemplo:\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\n\nEntretando, ao instalar o tidyverse, todos sÃ£o instalados de uma Ãºnica vez:\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html#carregando-os-pacotes",
    "href": "content/manipulacao-dados-R/tidyverse.html#carregando-os-pacotes",
    "title": "Os pacotes em tidyverse",
    "section": "2 Carregando os pacotes",
    "text": "2 Carregando os pacotes\nAo iniciar uma seÃ§Ã£o, vocÃª deve sempre carregar os pacotes que irÃ¡ utilizar. No caso do tidyverse, vocÃª pode carregar cada pacote individualmente:\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nOu todos de uma Ãºnica vez:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "",
    "text": "DicaBibliotecas utilizadas nesta seÃ§Ã£o\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nA partir da FiguraÂ 1, percebemos que a maioria dos alunos tem alturas intermediÃ¡rias, enquanto poucos sÃ£o muito altos ou muito baixos, o que estÃ¡ de acordo com nossa intuiÃ§Ã£o sobre a distribuiÃ§Ã£o das alturas em adultos. Vamos construir passo-a-passo uma funÃ§Ã£o matemÃ¡tica que seja capaz de capturar este comportamento."
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#um-modelo-para-a-distribuiÃ§Ã£o-de-alturas",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#um-modelo-para-a-distribuiÃ§Ã£o-de-alturas",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "1 Um modelo para a distribuiÃ§Ã£o de alturas",
    "text": "1 Um modelo para a distribuiÃ§Ã£o de alturas\nComeÃ§aremos com a funÃ§Ã£o de crescimento exponencial:\n\\[f(x) = e^x\\]\ne de decaimento exponencial:\n\\[f(x) = e^{-x}\\]\nCombinando as duas, temos:\n\\[f(x) = e^{-\\mid x \\mid}\\]\nPara ter uma transiÃ§Ã£o mais suave, fazemos uma pequena modificaÃ§Ã£o na funÃ§Ã£o:\n\\[f(x) = e^{-x^2}\\]\nO cÃ³digo a seguir cria vetores a partir destas funÃ§Ãµes que podemos visualizar graficamente:\nx = np.linspace(-4, 4, 1000)\n\n# Crescimento exponencial\nfx = np.exp(x)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^x$')\nplt.show()\n\n# Decaimento exponencial\nfx = np.exp(-x)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-x}$')\nplt.show()\n\n# CombinaÃ§Ã£o dos dois\nfx = np.exp(-np.abs(x))\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-|x|}$')\nplt.show()\n\n# TransiÃ§Ã£o suave\nfx = np.exp(-x**2)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-x^2}$')\nplt.show()\n\n\n\n\n\n\nCrescimento exponencial\n\n\n\n\n\n\n\nDecaimento exponencial\n\n\n\n\n\n\n\n\n\nCombinando o crescimento e decaimento\n\n\n\n\n\n\n\nFazendo uma transiÃ§Ã£o suave"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-parÃ¢metro-de-dispersÃ£o-sigma",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-parÃ¢metro-de-dispersÃ£o-sigma",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "2 Inserindo o parÃ¢metro de dispersÃ£o \\(\\sigma\\)",
    "text": "2 Inserindo o parÃ¢metro de dispersÃ£o \\(\\sigma\\)\nEm \\(f(x) = e^{-x^2}\\), nÃ£o hÃ¡ nada de especial com a escolha da base de Euler (\\(e = 2.718282...\\)). PoderÃ­amos ter escolhido qualquer outro nÃºmero, por exemplo, \\(30^{-x^2}\\), o que nos daria uma funÃ§Ã£o com formato similar:\n\n# ComparaÃ§Ã£o entre e^{-x^2} e 30^{-x^2}\nfx1 = np.exp(-x**2)\nfx2 = 30**(-x**2)\n\nplt.plot(x, fx1, label=r'$f(x) = e^{-x^2}$')\nplt.plot(x, fx2, label=r'$f(x) = 30^{-x^2}$')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNote, entretanto, que a funÃ§Ã£o \\(f(x) = e^{-x^2}\\) tem um decaimento mais suave se comparado Ã  \\(f(x) = 30^{-x^2}\\), um comportamento que pode ser controlado inserindo uma constante \\(c = \\frac{1}{2\\sigma^2}\\):\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}\\]\nFazendo desta forma, o parÃ¢metro \\(\\sigma\\) passa a controlar a largura ou dispersÃ£o da curva: valores maiores de \\(\\sigma\\) tornam o decaimento mais lento e a curva mais â€œespalhadaâ€, enquanto valores menores de \\(\\sigma\\) a tornam mais estreita e concentrada ao redor de zero.\n\n\n\n\n\n\nDicaCuriosidade\n\n\n\nA escolha da constante \\(c = \\frac{1}{2\\sigma^2}\\) tem o efeito prÃ¡tico de fazer com que a concavidade da curva mude exatamente nos pontos \\(x = +\\sigma\\) e \\(x = -\\sigma\\). Na funÃ§Ã£o da distribuiÃ§Ã£o normal, \\(\\sigma\\) serÃ¡ chamado de desvio padrÃ£o.\n\n\n\n# Variando o valor de sigma\nsigmas = [0.5, 1, 2]\n\nfor sigma in sigmas:\n    fx = np.exp(-(1/(2*(sigma**2)))*x**2)\n    plt.plot(x, fx, label=fr'$\\sigma = {sigma}$')\n\nplt.legend()\nplt.title(r'$f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}$')\nplt.show()"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-parÃ¢metro-de-posiÃ§Ã£o-mu",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-parÃ¢metro-de-posiÃ§Ã£o-mu",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "3 Inserindo o parÃ¢metro de posiÃ§Ã£o \\(\\mu\\)",
    "text": "3 Inserindo o parÃ¢metro de posiÃ§Ã£o \\(\\mu\\)\nPor enquanto temos a funÃ§Ã£o:\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}\\]\nque nos permite agora alterar a abertura da curva, mas estÃ¡ centralizada em zero. Se quisermos que elaesta funÃ§Ã£o possa representar fenÃ´menos que nÃ£o estejam centrados em zero, precisamos ser capazes de deslocar a funÃ§Ã£o para a direita ou para a esquerda. Fazemos isso inserindo um novo parÃ¢metro que serÃ¡ denominado de a mÃ©dia \\(\\mu\\) da dsitribuiÃ§Ã£o:\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\]\n\n# Variando o valor de mi (mÃ©dia)\nmis = [-2, 0, 2]\nsigma = 1\n\nfor mi in mis:\n    fx = np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    plt.plot(x, fx, label=fr'$\\mu = {mi}$')\n\nplt.legend()\nplt.title(r'$f(x) = e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}$')\nplt.show()"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#usando-a-funÃ§Ã£o-como-uma-distribuiÃ§Ã£o-de-probabilidades",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#usando-a-funÃ§Ã£o-como-uma-distribuiÃ§Ã£o-de-probabilidades",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "4 Usando a funÃ§Ã£o como uma DistribuiÃ§Ã£o de Probabilidades",
    "text": "4 Usando a funÃ§Ã£o como uma DistribuiÃ§Ã£o de Probabilidades\nSe queremos utilizar a funÃ§Ã£o acima para prever a frequÃªncia relativa de alturas, precisamos que a Ã¡rea abaixo da curva seja igual a 1, o que a transforma em uma FunÃ§Ã£o de Densidade de Probabilidade (PDF).\nVemos entretanto que a Ã¡rea da funÃ§Ã£o Ã© igual a \\(\\sigma \\sqrt{2\\pi}\\).\nO que pode ser conferido obtendo a integral da funÃ§Ã£o: \\(\\int_{-\\infty}^{+\\infty} f(x) d(x)\\)\n\nfrom scipy.integrate import quad\n\n# Definindo a funÃ§Ã£o f\ndef f(x, mi, sigma):\n    if sigma &lt;= 0:\n        sigma = 1\n    fx = np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    return (fx)\n\n# Area sob a curva\nmi = 0\nsigma = 1\n\narea, erro = quad(f, -np.inf, np.inf, args = (mi, sigma))\n\nprint(f\"Ãrea sob a curva = {area:.5f}\")\n\n# 2 x raiz(2 x pi)\nprint(sigma * np.sqrt(2*np.pi))\n\nÃrea sob a curva = 2.50663\n2.5066282746310002\n\n\nPara corrigir a Ã¡rea sob a curva, inserimos \\(\\sigma \\sqrt{2\\pi}\\) no denominador da funÃ§Ã£o, ficando com:\n\\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\]\nA funÃ§Ã£o acima Ã© conhecida como DistribuiÃ§Ã£o Normal ou Curva de Gauss. Nesta funÃ§Ã£o \\(\\mu\\) Ã© a mÃ©dia, que representa o ponto central da curva, e \\(\\sigma\\) Ã© o desvio padrÃ£o que controla a abertura da curva.\nPodemos verificar agora que a Ã¡rea desta funÃ§Ã£o Ã© sempre igua a 1.\n\nfrom scipy.integrate import quad\n\n# Definindo a funÃ§Ã£o f\ndef fnormal(x, mi, sigma):\n    if sigma &lt;= 0:\n        sigma = 1\n    fx = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    return (fx)\n\n# Area sob a curva\nmi = 0\nsigma = 30\narea, erro = quad(fnormal, -np.inf, np.inf, args = (mi, sigma))\n\nprint(f\"Ãrea sob a curva = {area:.5f}\")\n\nÃrea sob a curva = 1.00000"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#biblioteca-scipy",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#biblioteca-scipy",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "5 Biblioteca SciPy",
    "text": "5 Biblioteca SciPy\nExiste uma funÃ§Ã£o pronta em python que nos dÃ¡ a funÃ§Ã£o da distribuiÃ§Ã£o normal disponÃ­vel em scipy.stats. Como jÃ¡ importamos esta bibloteca no inÃ­cio do cÃ³digo, podemos acessÃ¡-la para comparar com nossa funÃ§Ã£o fnormal:\n\nimport scipy.stats as st\n\nx = np.linspace(2, 18, 1000)\ny1 = fnormal(x, mi = 10, sigma = 2)\ny2 = st.norm.pdf(x = x, loc = 10, scale = 2)\n\nE colocar as figuras lado-a-lado:\n\nfig, axes = plt.subplots(1, 2)\n\naxes[0].plot(x, y1)\naxes[0].set_title('funÃ§Ã£o `fnormal`')\naxes[1].plot(x, y2)\naxes[1].set_title('funÃ§Ã£o scipy.stats.norm.pdf()')\n\nplt.tight_layout()"
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html",
    "href": "content/distribuicao-normal/distr-norm.html",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')\nTÃ©cnicas de estatÃ­stica descritiva nos permitem entender os padrÃµes resultantes de fenÃ´menos que jÃ¡ aconteceram, enquanto a inferÃªncia estatÃ­stica nos fornece elementos para fazer prediÃ§Ãµes sobre o que poderÃ¡ acontecer. A prediÃ§Ã£o se torna possÃ­vel pelo uso de modelos probabilÃ­sticos, entre os quais estÃ¡ a distribuiÃ§Ã£o normal de probabilidades.\nModelos probabilÃ­sticos sÃ£o definidos por funÃ§Ãµes de probabilidade e as variÃ¡veis descritas por estes modelos sÃ£o denominadas de variÃ¡veis aleatÃ³rias. Uma variÃ¡vel aleatÃ³ria resulta de um experimento aleatÃ³rio como i) medir a altura de uma pessoa; ii) tomar a temperatura em uma cidade; ii) medir a taxa de crescimento de uma bactÃ©ria; etc. A questÃ£o relevante nestes experimentos Ã© que antes de serem realizados, nÃ£o temos certeza sobre qual serÃ£o seus resultados.\nEmbora nÃ£o saibamos quais serÃ£o os resultados de um experimento aleatÃ³rio com exatidÃ£o, podemos nos basear em algum modelo probabilidades para prever a chance de um resultado observado estar dentro de determinados limites. Neste sentido, o papel de um modelo probabilÃ­stico Ã©, delimitar a incerteza ao redor dos resultados possÃ­veis de um experimento aleatÃ³rio.\nAo medir a altura de uma pessoa podemos supor que, possivelmente, o resultado ficarÃ¡ abaixo de \\(1,9\\) m. Supomos isto pois temos conhecimento de que a altura de maior parte das pessoas estÃ¡ abaixo deste limite. Se quisermos atribuir um valor de probabilidade a esta suposiÃ§Ã£o devemos:\nNeste capÃ­tulo iremos discutir pela primeira vez o modelo de distribuiÃ§Ã£o normal e aprenderemos como encontrar estas probabilidades.\nImporte a base de dados altura2022.csv\nie = read_delim(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura2022.csv\")\nA distribuiÃ§Ã£o normal de probabilidades descreve uma curva em forma de sino tambÃ©m chamada de distribuiÃ§Ã£o gaussiana. Um dos motivos que a tornaram central em estatÃ­stica foi a percepÃ§Ã£o de que o comportamento de muitos fenÃ´menos naturais podem ser descritos adequadamente por este modelo teÃ³rico. Veja por exemplo, o histograma de alturas de \\(110\\) estudantes de uma turma de IntroduÃ§Ã£o a EstatÃ­stica do curso de Bacharelado Interdisciplinar em CiÃªncias do Mar (UNIFESP). A linha vermelha sobre este histograma representa a distribuiÃ§Ã£o normal teÃ³rica. Ã€ direita desta figura estÃ¡ um histograma da temperatura mÃ©dia anual em uma cidade americana, onde tambÃ©m foi sobreposta uma curva normal teÃ³rica. Embora estes dados descrevam fenÃ´menos completamente distintos, a distribuiÃ§Ã£o normal se adequa razoavelmente bem aos dois histogramas.\nFiguraÂ 1: Altura (m) de alunos de um curso de estatÃ­stica e temperatura mÃ©dia anual de uma cidade americana.\nO segundo motivo que torna a distribuiÃ§Ã£o normal uma das mais importantes em estatÃ­stica serÃ¡ nosso tema de estudo neste e nos prÃ³ximos capÃ­tulos, pois a distribuiÃ§Ã£o normal surge como o modelo esperado para a distribuiÃ§Ã£o das mÃ©dias amostrais sob determinadas condiÃ§Ãµes, o que nos permite utilizar uma variedade de procedimentos analÃ­ticos no campo da inferÃªncia e testes de hipÃ³tese."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#o-modelo-normal-de-probabilidades",
    "href": "content/distribuicao-normal/distr-norm.html#o-modelo-normal-de-probabilidades",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "1 O modelo normal de probabilidades",
    "text": "1 O modelo normal de probabilidades\nO modelo normal de probabilidades Ã© uma funÃ§Ã£o matemÃ¡tica dada por:\n\\[f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}, x \\in \\mathbb{R} | -\\infty \\le y \\le +\\infty\\]\nA expressÃ£o envolve as quantias \\(\\mu\\) e \\(\\sigma\\), definidas como os parÃ¢metros da distribuiÃ§Ã£o que representam respectivamente, sua mÃ©dia e o desvio padrÃ£o. Para dizer que uma variÃ¡vel aleatÃ³ria \\(X\\) tem distribuiÃ§Ã£o normal por meio da expressÃ£o:\n\\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma)\\)\nEsta expressÃ£o diz de \\(X\\) Ã© normalmente distribuÃ­da (\\(\\mathcal{N}\\)) e que esta distribuiÃ§Ã£o tem parÃ¢metros \\(\\mu\\) e \\(\\sigma\\).\nA mÃ©dia de uma distribuiÃ§Ã£o normal Ã© o ponto central da curva e o desvio padrÃ£o mede o espalhamento das observaÃ§Ãµes ao redor de \\(\\mu\\). Em um fenÃ´meno descrito por valores baixos de \\(\\sigma\\), a maioria das observaÃ§Ãµes estarÃ¡ prÃ³xima a \\(\\mu\\), enquanto para valores altos de \\(\\sigma\\) as observaÃ§Ãµes estarÃ£o mais distantes de \\(\\mu\\). Deste modo, podemos alterar o formato da distribuiÃ§Ã£o normal alterando seu parÃ¢metro de posiÃ§Ã£o (i.e.Â a mÃ©dia \\(\\mu\\)) e de dispersÃ£o (i.e.Â o desvio padrÃ£o \\(\\sigma\\)).\n\n\n\n\n\n\n\n\nFiguraÂ 2: DistribuiÃ§Ãµes normais de probabilidade para diferentes combinaÃ§Ãµes de mÃ©dia e desvio padrÃ£o.\n\n\n\n\n\nSe as observaÃ§Ãµes sobre um determinado fenÃ´meno sugerem um padrÃ£o em forma de sino, podemos buscar a melhor combinaÃ§Ã£o de \\(\\mu\\) e \\(\\sigma\\) e descrever o fenÃ´meno por meio de um modelo normal. Ao fazer isto, a distribuiÃ§Ã£o normal nos ajuda a calcular as probabilidade da ocorrÃªncia de eventos futuros estarem em diferentes faixas de valores. No caso das alturas dos alunos por exemplo, vemos que a probabilidade de um aluno ter mais de \\(2\\) metros ou menos de \\(1,5\\) metros Ã© extremamente baixa. Assumindo um modelo de distribuiÃ§Ã£o normal para a distribuiÃ§Ã£o de alturas, podemos utilizar o conjunto de dados para estimar os parÃ¢metros da populaÃ§Ã£o e calcular quais seriam estas probabilidades.\n\n\n\n\n\n\nNotaUm pouco de histÃ³ria\n\n\n\nAlguns atribuem a proposiÃ§Ã£o deste modelo normal a Abraham de Moivre, um matemÃ¡tico FrancÃªs que chegou a a distribuiÃ§Ã£o normal como uma aproximaÃ§Ã£o a distribuiÃ§Ã£o binomial em seu livro The Doctrine of Chances em \\(1718\\). A distribuiÃ§Ã£o normal de probabilidades Ã© simÃ©trica, ou seja, os valores extremos sÃ£o igualmente representados acima e abaixo da regiÃ£o central (mÃ©dia). VocÃª poderÃ¡ encontrar o termo bell curve em inglÃªs, devido Ã  sua forma de sino, ou ainda distribuiÃ§Ã£o gaussiana em homenagem a Carl Friedrich Gauss um dos mais importantes matemÃ¡ticos do sÃ©culo XXI. Gauss lidou com a distribuiÃ§Ã£o normal quando desenvolveu a Teoria da distribuiÃ§Ã£o dos erros observacionais no contexto do MÃ©todo dos MÃ­nimos Quadrados em \\(1823\\)."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#entendendo-a-funÃ§Ã£o-normal",
    "href": "content/distribuicao-normal/distr-norm.html#entendendo-a-funÃ§Ã£o-normal",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "2 Entendendo a funÃ§Ã£o normal",
    "text": "2 Entendendo a funÃ§Ã£o normal\nA funÃ§Ã£o \\(f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\) Ã© uma funÃ§Ã£o de densidade de probabilidade. Antes de aplicar esta distribuiÃ§Ã£o para encontrar valores de probabilidade, vamos aprender simplesmente para descrever a funÃ§Ãµes de densidade assumindo valores particulares de \\(\\mu\\) e \\(\\sigma\\). Para isto, vamos tentar simular o histograma de alturas similar ao da FiguraÂ 1. Vamos assumir que a distribuiÃ§Ã£o de alturas tenha a seguinte media e desvio padrÃ£o:\n\\(\\mu = 1.7\\) metros\n\\(\\sigma = 0.09\\) metros\nPara uma determinada altura \\(x = 1.6\\) metros, a \\(f(x)\\) assume o valor:\n\\(f(1.6) = \\frac{1}{\\sqrt(2\\pi \\times0.09^2)}e^{-\\frac{1}{2}(\\frac{1.6 - 1.7}{0.09})^2} = 2.391\\)\nEste resultado corresponde ao ponto \\(y\\) no grÃ¡fico da distribuiÃ§Ã£o normal (FiguraÂ 3) em que \\(x = 1.6\\). Podemos encontar \\(f(x)\\) para quaisquer valores dentro dos reais \\(\\mathbb{R}\\) entre \\(-\\infty\\) e \\(+\\infty\\).\nAssim, se calcularmos \\(f(x)\\) para diferentes pontos em \\(x\\) teremos um esboÃ§o da funÃ§Ã£o de densidade normal. Na FiguraÂ 3, por exemplo, apresentamos \\(f(x)\\) para os valores:\n\\(X = 1.4, 1.45, 1.5, 1.55, 1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9, 1.95, 2\\)\nassumindo \\(\\mu = 1.7\\) e \\(\\sigma = 0.09\\)\n\n\n\n\n\n\n\n\nFiguraÂ 3: Pontos na distribuiÃ§Ã£o normal de densidade de probrabilidade.\n\n\n\n\n\n\n2.1 Calculando de \\(f(x)\\) no R: a funÃ§Ã£o dnorm()\nNo R, os resultados acima podem ser obtidos com a funÃ§Ã£o dnorm(), que fornece um modo simples para calcularmos \\(f(x)\\) na distribuiÃ§Ã£o normal. Nesta funÃ§Ã£o a letra â€˜dâ€™ vem de densidade da distribuiÃ§Ã£o normal.\nPara encontrar \\(f(x)\\) para um dado valor fazemos simplesmente:\n\nmu &lt;- 1.7\ndp &lt;- 0.11\ndnorm(1.5, mean = mu, sd = dp)\n\n[1] 0.6945048\n\n\nSe quisermos obter \\(f(x)\\) para mÃºltiplos valores de \\(x\\) podemos fazer:\n\nx &lt;- c(1.4, 1.5, 1.6, 1.7)\ndnorm(x, mean = mu, sd = dp)\n\n[1] 0.0879777 0.6945048 2.3991470 3.6267480"
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#cÃ¡lculo-de-probabilidade-com-a-funÃ§Ã£o-normal-de-densidade",
    "href": "content/distribuicao-normal/distr-norm.html#cÃ¡lculo-de-probabilidade-com-a-funÃ§Ã£o-normal-de-densidade",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "3 CÃ¡lculo de probabilidade com a funÃ§Ã£o normal de densidade",
    "text": "3 CÃ¡lculo de probabilidade com a funÃ§Ã£o normal de densidade\nEncontrar a probabilidade de uma variÃ¡vel aleatÃ³ria \\(X\\) estar dentro de uma deteminada faixa de valores significa fazer prediÃ§Ãµes a respeito da probabilidade de ocorrÃªncia de uma observaÃ§Ã£o futura. Por ser uma funÃ§Ã£o de probabilidade, a Ã¡rea abaixo de \\(f(x)\\) na distribuiÃ§Ã£o normal Ã© igual a \\(1\\).\n\\[P(-\\infty \\le X \\le +\\infty) = \\int_{-\\infty}^{+\\infty}f(x) dx = 1\\]\nAssim, se desejamos obter probabilidade de uma variÃ¡vel estar dentro de um determinado limite, devemos calcular a Ã¡rea abaixo da curva para este limite. Por exemplo, a probabilidade de uma observaÃ§Ã£o em \\(X\\) estar entre \\(x_1\\) e \\(x_2\\) serÃ¡:\n\n\n\n\n\n\n\n\nFiguraÂ 4: RepresentaÃ§Ã£o das probabilidades de um intervalo da distribuiÃ§Ã£o normal de densidade.\n\n\n\n\n\n\n3.1 Calculando probabilidades no R: a funÃ§Ã£o pnorm()\nUsando o R, a probabilidade de amostrarmos um aluno que tenha entre menos de \\(1.5\\) metros pode ser obtida por meio da funÃ§Ã£o pnorm:\n\nmu &lt;- 1.7\ndp &lt;- 0.11\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\n\n[1] 0.03451817\n\n\n\n\n\n\n\n\nNotaArgumentos da funÃ§Ã£o:\n\n\n\nq: o valor de \\(x\\)\nmean: mÃ©dia \\(\\mu\\) da funÃ§Ã£o normal\nsd: desvio padrÃ£o \\(\\sigma\\) da funÃ§Ã£o normal\nlower.tail: se a funÃ§Ã£o irÃ¡ retornar a probabilidade abaixo (TRUE) ou acima (FALSE) de q\nveja o menu de ajuda digitando ?pnorm no Console do R\n\n\nSe quisermos encontrar a probabilidade \\(P(X \\ge 1.5)\\) alteramos o parÃ¢metro lower.tail\n\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = FALSE)\n\n[1] 0.9654818\n\n\nSe desejamos obter a probabilidade de \\(x\\) estar entre \\(1.5\\)m e \\(1.7\\)m podemos fazer: \\[P(1.5 \\le X \\le 1.7) = P(X \\le 1.7) - P(X \\le 1.5)\\]\nNo R temos:\n\np1 &lt;- pnorm(q = 1.7, mean = mu, sd = dp, lower.tail = TRUE)\np2 &lt;- pnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\npfinal &lt;- p1 - p2\n\npfinal\n\n[1] 0.4654818\n\n\nou simplesmente:\n\ndiff(pnorm(q = c(1.7, 1.5),\n           mean = mu,\n           sd = dp,\n           lower.tail = TRUE)\n     )\n\n[1] -0.4654818\n\n\nAqui estÃ£o representados cada um dos intervalos calculados.\n\n\nCÃ³digo\ndfc &lt;- data.frame(X = seq(0, sup, length.out = 10000)) |&gt;\n  dplyr::mutate(dx = dnorm(X, mean = mu, sd = dp))\n\ngc1 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &lt;= 1.7),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n    \"text\", x = 1.5, y = 3,\n    label = as.expression(bquote(P(X &lt;= 1.7) == .(round(p1, 3)))),\n    color = \"#eb4034\"\n  ) +\n  theme_classic()\n\ngc2 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &lt;= 1.5),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n    \"text\", x = 1.5, y = 3,\n    label = as.expression(bquote(P(X &lt;= 1.5) == .(round(p2, 3)))),\n    color = \"#eb4034\"\n  ) +\n  theme_classic()\n\ngc3 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &gt;= 1.5 & X &lt;= 1.7),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n   \"text\",\n   x = 1.5, y = 3,\n   label = as.expression(\n      substitute(P(a &lt;= X * \",\" ~ X &lt;= b) == val,\n                  list(a = 1.5, b = 1.7, val = round(pfinal, 3)))\n   ),\n   color = \"#eb4034\"\n   ) +\n  theme_classic()\n\ngc1 / gc2 / gc3"
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#a-distribuiÃ§Ã£o-normal-padronizada",
    "href": "content/distribuicao-normal/distr-norm.html#a-distribuiÃ§Ã£o-normal-padronizada",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "4 A distribuiÃ§Ã£o normal padronizada",
    "text": "4 A distribuiÃ§Ã£o normal padronizada\nA integral para a funÃ§Ã£o normal Ã© difÃ­cil de ser calculada pois nÃ£o tem soluÃ§Ã£o analÃ­tica. Isto era um problema para os cientistas atÃ© meados do sÃ©culo \\(XX\\) que precisavam calcular valores de probabilidades para diferentes combinaÃ§Ãµes de \\(\\mu\\) e \\(\\sigma\\). Naquele momento, a soluÃ§Ã£o para facilitar a vida dos pesquisadores foi criar uma tabela descrevendo estas probabilidades em uma distribuiÃ§Ã£o normal padronizada, ou seja para valores particulares de \\(\\mu\\) e \\(\\sigma\\). Padronizar aqui, significa transfomar cada valor \\(x_i\\) de modo que as observaÃ§Ãµes resultantes tenham mÃ©dia igual a \\(0\\) e desvio padrÃ£o igual a \\(1\\).\nEsta transformaÃ§Ã£o Ã© apicada a cada observaÃ§Ã£o \\(x_i\\), obtendo-sem um valor de \\(z_i\\) correspondente por meio da expressÃ£o.\n\\[z_i = \\frac{x_i - \\mu}{\\sigma}\\]\nA transformaÃ§Ã£o \\(Z\\) Ã© Ãºtil, pois ainda que seja difÃ­cil calcular as probabilidades para uma variÃ¡vel aleatÃ³ria \\(X\\), apÃ³s a transformaÃ§Ã£o teremos uma variÃ¡vel \\(Z\\) para a qual os valores de probabilidade estÃ£o tabelados. Deste modo, \\(Z\\) Ã© uma variÃ¡vel aleatÃ³ria com \\(\\overline{z} = 0\\) e \\(s = 1\\) tal que:\n\\[Z \\sim \\mathcal{N}(0,\\,1)\\]\nApÃ³s a transformaÃ§Ã£o \\(Z\\) nos exemplos sobre altura dos alunos e da temperatura mensal temos:\n\n\nCÃ³digo\nie &lt;- ie |&gt; \n   mutate(ALTURA_z = (ALTURA - mean(ALTURA, na.rm = T))/sd(ALTURA, na.rm = T))\ntemp &lt;- temp |&gt; \n   mutate(tm_z = (tm - mean(tm, na.rm = T))/sd(tm, na.rm = T))\n\naltz_plt &lt;- ggplot(ie, aes(x = ALTURA_z)) +\n   geom_histogram(aes(y = after_stat(density)), \n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(ie$ALTURA_z, na.rm = T),\n                                          sd = sd(ie$ALTURA_z, na.rm = T))) +\n   labs(x = \"DistribuiÃ§Ã£o Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\ntempz_plt &lt;- ggplot(temp, aes(x = tm_z)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(temp$tm_z, na.rm = T),\n                                          sd = sd(temp$tm_z, na.rm = T))) +\n   labs(x = \"DistribuiÃ§Ã£o Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\n(alt_plt | temp_plt) / \n  (altz_plt | tempz_plt)\n\n\n\n\n\n\n\n\nFiguraÂ 5: DistribuiÃ§Ã£o das variÃ¡veis originais e apÃ³s a transformaÃ§Ã£o Z.\n\n\n\n\n\n\n\n\n\n\n\nNotaEscore Z\n\n\n\nO escore Z pode ser apresentado como uma medida de posiÃ§Ã£o de uma observaÃ§Ã£o na amostra (\\(z_i\\)) que representava uma medida relativa desta observaÃ§Ã£o com relaÃ§ao Ã  mÃ©dia e ao desvio padrÃ£o do conjunto de dados. Por exemplo, um valor de \\(z_i = 2\\) significa que a observaÃ§Ã£o original \\(x_i\\) estÃ¡ \\(2\\) desvios padrÃµes acima de sua respectiva mÃ©dia \\(\\mu\\).\n\n\n\n4.1 Probabilidades em uma distribuiÃ§Ã£o normal padronizada\nNos dois exemplos anteriores, verifica-se que todas as observaÃ§Ãµes estÃ£o situadas, aproximadamente, entre \\(z = -3\\) e \\(z = +3\\). De fato, a distribuiÃ§Ã£o normal padronizada ou distribuiÃ§Ã£o Z tem propriedades bem conhecidas. Como sua mÃ©dia Ã© \\(\\mu = 0\\) e seu desvio padrÃ£o Ã© \\(\\sigma = 1\\), a maior parte das observaÃ§Ãµes fica limitada entre \\(z = -3\\) e \\(z = +3\\). Para ser exato, podemos descrever as probabilidades de uma observaÃ§Ã£o estar dentro de alguns limites conhecidos. Por exemplo, \\(95\\%\\) das observaÃ§Ãµes estarÃ¡ entre \\(z = -1.96\\) e \\(z = +1.96\\), isto Ã©,\n\\[P(-1.96 \\le Z \\le +1.96) = 0.95\\]\nDe forma similar, \\(90\\%\\) da Ã¡rea central da curva se encontra entre \\(z = -1.64\\) e \\(z = +1.64\\). Estes e outros limites na distribuiÃ§Ã£o normal padronizada podem ser verificados na figura abaixo.\n\n\nCÃ³digo\n# Ver funÃ§Ã£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\n\n\n\nFiguraÂ 6: Ãreas de probabilidade em uma distribuiÃ§Ã£o Normal Padronizada (DistribuiÃ§Ã£o Z).\n\n\n\n\n\nVamos exemplificar o uso da distribuiÃ§Ã£o \\(Z\\) no cÃ¡lculo de probabilidades utilizando os dados de altura dos alunos. Para estes dados, iremos encontrar \\(P(X \\le 1.5)\\). Este procedimento consiste de:\n\n\nCÃ³digo\nmu &lt;- 1.7\ndp &lt;- 0.11\nx &lt;- 1.5\nz_1.5 &lt;- (x - mu)/dp\n\n\n\nTransformar \\(x = 1.5\\) em \\(z_{1.5}\\) por meio de \\(z_{1.5} = \\frac{1.5 - 1.7}{0.11} = -1.818\\);\n\n\n\nCÃ³digo\nmu &lt;- 1.7\ndp &lt;- 0.11\nx &lt;- 1.5\nz_1.5 &lt;- (x - mu)/dp\n\nz_1.5\n\n\n[1] -1.818182\n\n\n\nEncontrar encontrar \\(P(Z \\le z_{1.5}) = P(Z \\le -1.818) = 0.0345182\\).\n\n\n\nCÃ³digo\npnorm(q = z_1.5, mean = 0, sd = 1, lower.tail = TRUE)\n\n\n[1] 0.03451817\n\n\nCompare este resultado com o obtido anteriormente para verificar que Ã© equivalente a \\(P(X \\le 1.5)\\).\n\n\n\n\n\n\nNotaA transformaÃ§Ã£o \\(Z\\)\n\n\n\nSuponha uma variÃ¡vel aleatÃ³ria \\(X\\) nomalmente distribuÃ­da conforme \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\). Desejamos encontrar \\(m\\) tal que:\n\\(P(X \\le m) = \\alpha\\)\n\n\\(\\alpha\\) aqui representa um valor de probabilidade qualquer determinada pela Ã¡rea na distribuiÃ§Ã£o normal abaixo de \\(m\\).\n\nAo aplicar a transformaÃ§Ã£o \\(Z\\) teremos:\n\\(P(\\frac{X - \\mu}{\\sigma} \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\ncomo \\(\\frac{X - \\mu}{\\sigma} = Z\\) temos que:\n\\(P(Z \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\nPor meio desta expressÃ£o, vocÃª pode encontar \\(m\\) uma vez fornecido \\(\\alpha\\) ou encontrar \\(\\alpha\\), desde que seja fornecido \\(m\\).\nO mesmo vale se quisermos encontrar a probabilidade determinada por um intervalo definido de \\(m\\) atÃ© \\(n\\) (\\(m &lt; n\\)). Para isto fazemos:\n\\(P(m \\le X \\le n) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le \\frac{X - \\mu}{\\sigma} \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le Z \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\n\n\n\n4.2 Tabela \\(Z\\)\nAo utilizarmos um software estatÃ­stico nÃ£o Ã© necessÃ¡rio fazer esta transformaÃ§Ã£o. A transformaÃ§Ã£o \\(Z\\) era necessÃ¡ria na ausÃªncia de ferramentas computacionais, ou seja, quando a Ãºnica opÃ§Ã£o era utilizarmos a Tabela \\(Z\\) para evitar cÃ¡lculos tediosos considerando cada combinaÃ§Ã£o de \\(\\mu\\) e \\(\\sigma\\).\nA Tabela Z disponibiliza os valores de probabilidade para um grande nÃºmero de valores e Ã© apresentada na grande maioria dos livros de estatÃ­stica.\nVocÃª pode utilizar a Tabela \\(Z\\) para encontrar \\(P(X \\le 1.5)\\). Note que o valor transformado Ã© \\(z_{1.5} = -1.818\\). Este serÃ¡ o valor que iremos buscar na tabela. Para isto:\n\nEncontre a pÃ¡gina que oferece valores negativos, uma vez que \\(z_{1.5} &lt; 0\\);\nNa coluna 1 desta pÃ¡gina (coluna z) encontre a linha -1.8 que refere-se Ã  unidade, e Ã  primeira casa decimal de \\(z_{1.5}\\);\nEncontre a coluna 0.02 (quarta coluna da tabela \\(Z\\)) que apresenta a segunda casa decimal de \\(z_{1.5}\\). Isto nos leva ao valor mais prÃ³ximo do calculado (\\(z_{1.5} = -1.818\\)).\nCruze a linha escolhida no item 3 com a coluna escolhida no item 4. VocÃª irÃ¡ encontrar o valor \\(0,0344\\). Este valor e a probabilidade de obtermos um valor de \\(z \\le 1.5\\) na distribuiÃ§Ã£o normal padronizada, ou seja, \\(P(Z \\le z_{1.5})\\). A diferenÃ§a entre este valor e o encontrado com o R se deve unicamente ao limite de precisÃ£o na Tabela \\(Z\\)."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#exercÃ­cios-resolvidos",
    "href": "content/distribuicao-normal/distr-norm.html#exercÃ­cios-resolvidos",
    "title": "O modelo de distribuiÃ§Ã£o normal",
    "section": "5 ExercÃ­cios resolvidos",
    "text": "5 ExercÃ­cios resolvidos\n\n5.1 DistribuiÃ§Ã£o de comprimento\nAs comunidades de peixes em riachos de cabeceira sÃ£o compostas por espÃ©cies de pequeno porte. Rhamdioglanis transfasciatus Ã© uma destas espÃ©cies, desconhecida do pÃºblico em geral, porÃ©m muito abundante em pequenos riachos bem preservados. Dados de captura sugerem que o tamanho dos indivÃ­duos pode ser razoavelmente bem descrito por um modelo de distribuiÃ§Ã£o normal.\nImporte a base de dados rhamdioglanis.csv\n\nrh &lt;- read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/rhamdioglanis.csv', delim = ';',\n                 locale = locale(decimal_mark = ','))\n\n\n\nCÃ³digo\nggplot(rh, aes(x = Comprimento)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', color = 'black', bins = 15) +\n   stat_function(fun = dnorm, args = list(mean = mean(rh$Comprimento),\n                                          sd = sd(rh$Comprimento))) +\n   labs(x = 'Comprimento de Rhamdioglanis transfasciatus (cm)',\n        y = 'Densidade') +\n   theme_classic()\n\n\n\n\n\n\n\n\n\nSuponha o comprimento desta espÃ©cie tenha uma distribuiÃ§Ã£o normal com \\(\\mu = 10\\) cm e \\(\\sigma = 3\\) cm. Encontre:\n\nA probabilidade de capturar um indivÃ­duo maior de 14 cm de comprimento, \\(P(X \\ge 14)\\).\nA probabilidade de capturar um indivÃ­duo menor de 5 cm de comprimento, \\(P(X \\le 5)\\).\nA probabilidade de encontrar um indivÃ­duo entre 5 e 14 cm, \\(P(5 \\le X \\le 14)\\).\nSe um trecho de riacho contÃ©m 800 indivÃ­duos, quantos sÃ£o maiores que 14 cm de comprimento.\n\nRESOLUÃ‡ÃƒO\n\n\n\n\n\n\nDica\\(P(X \\ge 14)\\)\n\n\n\n\n\nVamos encontrar o respectivo valor de \\(Z\\) pela transformaÃ§Ã£o\n\\(z_{14} = \\frac{14 - 10}{3} = 1.33\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(1.33\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(1.33\\). Cruzando linha e coluna encontramos o valor \\(0,9082\\). Note que este valor representa a Ã¡rea abaixo de 1.33, isto Ã©, \\(P(Z \\le z_{14})\\). No entanto, queremos \\(P(Z \\ge z_{14})\\) que representa a Ã¡rea da curva acima de \\(1.33\\). Para isto basta fazermos \\(1 - 0,9082\\).\nDeste modo, \\(P(Z \\ge z_{14}) = 1 - P(Z \\le z_{14}) = 1 - 0,9082 = 0.0918\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaii. \\(P(X \\le 5)\\)\n\n\n\n\n\n\\(z_{5} = \\frac{5 - 10}{3} = -1.67\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(-1.67\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(-1.67\\). Cruzando linha e coluna encontramos o valor \\(0,0475\\) que representa a Ã¡rea desejada.\nDeste modo, \\(P(X \\le 5) = P(Z \\le z_{5}) = 0,0475\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaiii. \\(P(5 \\le X \\le 14)\\)\n\n\n\n\n\nVamos subtrair as quantias \\(P(Z \\le 14) - P(Z \\le 5)\\)\nEstes valores jÃ¡ foram encontrados nos itens anteriores, de modo que basta fazermos:\n\\(P(5 \\le X \\le 14) = 0,9082 - 0,0475 = 0.8607\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaiv. IndivÃ­duos maiores que 14 cm de comprimento\n\n\n\n\n\nSe a proporÃ§Ã£o de indivÃ­duos acima de 14 Ã© \\(P(X &gt; 14) = 0.0918\\) e a populaÃ§Ã£o tem \\(N = 800\\) indivÃ­duos, teremos:\n\\(0.0918 \\times 800 = 73\\) indivÃ­duos maiores que 14 cm.\n\n\n\n\n\n\n\n\n\nDicaRESOLUÃ‡ÃƒO no R\n\n\n\n\n\nO exercÃ­cio pode ser resolvido pelo R por meio da funÃ§Ã£o pnorm.\n\nmu &lt;- 10\nsigma &lt;- 3\nN &lt;- 800\nla &lt;- 14\nlb &lt;- 5\n\n\ni. \\(P(Z \\ge 14)\\)\n\npnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\n[1] 0.09121122\n\n\n\nii. \\(P(Z \\le 5)\\)\n\npnorm(q = lb, mean = mu, sd = sigma, lower.tail = TRUE)\n\n[1] 0.04779035\n\n\n\niii. \\(P(5 \\le X \\le 14)\\)\n\ndiff(\n   pnorm(q = c(lb, la),\n         mean = mu,\n         sd = sigma,\n         lower.tail = TRUE)\n   )\n\n[1] 0.8609984\n\n\n\niv. NÃºmero de indivÃ­duos maiores que \\(14\\) cm de comprimento\n\npg_la &lt;- pnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\nN * pg_la\n\n[1] 72.96898\n\n\n\n\n\n\n\n5.2 Intervalos em uma distribuiÃ§Ã£o normal\nSuponha variÃ¡vel aleatÃ³ria \\(X\\) normalmente distribuÃ­da conforme com \\(\\mu = 50\\) e \\(\\sigma = 10\\). Encontre:\n\nO valor de \\(a\\) tal que \\(P(X \\le a) = 0,10\\).\nO valor de \\(b\\) tal que \\(P(X \\ge b) = 0,85\\).\nO intervalo simÃ©trico ao redor da mÃ©dia delimitado por \\(c\\) e \\(d\\) (\\(c &lt; d\\)), que contÃ©m \\(95\\%\\) da Ã¡rea sob a curva.\nO valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\nRESOLUÃ‡ÃƒO\nVeja que neste exercÃ­cio, foram oferecidos valores de probabilidades e solicitado que vocÃª obtivesse os limites em uma distribuiÃ§Ã£o normal especÃ­fica. Este processo Ã© oposto ao do excercÃ­cio anterior.\n\n\n\n\n\n\nDicai. O valor de \\(a\\)\n\n\n\n\n\nSe \\(P(X \\le a) = 0,10\\), a Ã¡rea da curva abaixo de \\(a\\) Ã© \\(0,10\\). Procurando por este valor na tabela \\(Z\\) vemos que o valor mais prÃ³ximo Ã© \\(0,1003\\) que corresponde a um escore \\(z = -1,28\\). Vamos utilizar este valor para encontrar sua correspondÃªncia para a variÃ¡vel aleatÃ³ria \\(X\\) que tem mÃ©dia \\(\\mu = 50\\) e desvio padrÃ£o \\(\\sigma = 10\\).\n\\(z = \\frac{a - \\mu}{\\sigma} :: -1,28 = \\frac{a - 50}{10}\\)\n\\(a = (-1,28 \\times 10) + 50 = 37.2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaii. O valor de \\(b\\)\n\n\n\n\n\nSe \\(P(X \\ge b) = 0,85\\), a Ã¡rea abaixo de \\(b\\) que devemos encontrar na tabela \\(Z\\) Ã© \\(1 - 0,85 = 0.15\\). Vemos que o valor mais prÃ³ximo Ã© \\(0,1492\\) que corresponde a \\(z = -1,04\\). Ao utilizar este resultado na expressÃ£o abaixo temos:\n\\(z = \\frac{b - \\mu}{\\sigma} :: -1,04 = \\frac{b - 50}{10}\\)\n\\(b = (-1,04 \\times 10) + 50 = 39.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaO intervalo simÃ©trico ao redor da mÃ©dia delimitado por \\(c\\) e \\(d\\) (\\(c &lt; d\\)), que contÃ©m \\(95\\%\\) da Ã¡rea sob a curva.\n\n\n\n\n\nSe entre \\(c\\) e \\(d\\) estÃ¡ \\(95\\%\\) da Ã¡rea da curva, temos uma Ã¡rea de \\(1 - 0,95 = 0,05\\) fora da curva. Como o intervalo Ã© simÃ©trico, teremos \\(0,025\\) abaixo de \\(c\\) e \\(0,025\\) acima de \\(d\\).\nAo procurar na tabela \\(Z\\) por \\(0,025\\) encontraremos \\(z = -1,96\\) que equivale ena distribuiÃ§Ã£o de X a:\n\\(z = \\frac{c - \\mu}{\\sigma} :: -1,96 = \\frac{c - 50}{10}\\)\n\\(c = (-1,96 \\times 10) + 50 = 30.4\\)\nNovamente, como o intervalo Ã© simÃ©trico e a dsitribuiÃ§Ã£o de \\(Z\\) Ã© centrada em zero, o ponto \\(d\\) serÃ¡ de +\\(1,96\\) que resulta em:\n\\(z = \\frac{d - \\mu}{\\sigma} :: +1,96 = \\frac{d - 50}{10}\\)\n\\(d = (+1,96 \\times 10) + 50 = 69.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDicaiv. O valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\n\n\n\nPodemos fazer aqui:\n\\(P(50-e \\le X \\le 50+e) = P(\\frac{50-e - \\mu}{\\sigma} \\le \\frac{X-\\mu}{\\sigma} \\le \\frac{50+e-\\mu}{\\sigma}) = 0.99\\)\ncomo \\(\\mu = 50\\) e \\(\\sigma = 10\\) temos:\n\\(P(\\frac{-e}{10} \\le Z \\le \\frac{e}{10}) = 0.90\\)\nComo a Ã¡rea central ocupa \\(0,99\\) da distribuiÃ§Ã£o, restam \\(0,005\\) na cauda superior e \\(0,005\\) na cauda inferior:\n\n\n\n\n\n\n\n\n\nPara encontrar \\(-e\\) buscamos por \\(0,005\\) na tabela \\(Z\\) e encontramos \\(0,0051\\) como valor mais prÃ³ximo, referente a \\(z_{-e} = -2,57\\). Substituindo na equaÃ§Ã£o temos:\n\\(\\frac{-e}{10} \\le -2,57 :: -e = -2,57 \\times 10 :: e = 25,7\\)\n*Note na figura acima que os limite das Ã¡reas em azul sÃ£o:\n\\(\\mu - e = 50 - 25.7 = 24.3\\) e\n\\(\\mu - e = 50 + 25.7 = 75.7\\)\n\n\n\n\n\n\n\n\n\nDicaRESOLUÃ‡ÃƒO no R\n\n\n\n\n\nO exercÃ­cio pode ser resolvido pelo R por meio da funÃ§Ã£o qnorm.\n\nEm qnorm, o â€˜qâ€™ vem de quantis da distribuiÃ§Ã£o normal.\n\n\nmu = 50\nsigma = 10\n\n(a &lt;- qnorm(p = 0.10, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 37.18448\n\n(b &lt;- qnorm(p = 1-0.85, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 39.63567\n\n(c &lt;- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 30.40036\n\n(d &lt;- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = FALSE))\n\n[1] 69.59964\n\n(e &lt;- -qnorm(p = (1-0.99)/2, mean = mu, sd = sigma, lower.tail = TRUE) + 50)\n\n[1] 25.75829\n\n\n\n\n\n\n\n5.3 Quantos desvios padrÃµes?\nSuponha uma variÃ¡vel aleatÃ³ria normalmente distribuÃ­da representada por \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\), determine:\n\nO valor de \\(a\\) tal que \\(P(X &lt; a) = 0,20\\).\n\\(P(X \\le \\mu + 2\\sigma)\\).\nO valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\nRESOLUÃ‡ÃƒO\n\n\n\n\n\n\nDicai. O valor de \\(a\\) tal que \\(P(X &lt; a) = 0,20\\).\n\n\n\n\n\n\\(P(X &lt; a) = P(\\frac{X - \\mu}{\\sigma} &lt; \\frac{a - \\mu}{\\sigma}) = P(Z &lt; \\frac{a - \\mu}{\\sigma}) = 0,20\\)\nProcurando pelo valor de \\(z\\) que delimita \\(0,20\\) da Ã¡rea abaixo de \\(a\\) encontramos por \\(z = -0,84\\), de modo que:\n\\(-0,84 = \\frac{a - \\mu}{\\sigma}\\)\n\\(a = \\mu -0,84\\sigma\\)\n\n\n\n\n\n\n\n\n\nDicaii. \\(P(X \\le \\mu + 2\\sigma)\\)\n\n\n\n\n\nA expressÃ£o \\(\\mu + 2\\sigma\\) nos diz que o limite de interesse estÃ¡ \\(2\\) desvios padrÃµes acima de \\(\\mu\\). Ao procurar pelo valor de \\(z = 2,0\\) na tabela \\(Z\\), veremos que a probabilidade de interesse Ã© \\(P(X \\le \\mu + 2\\sigma) = 0,9772\\)\n\n\n\n\n\n\n\n\n\nDicaiii. O valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\n\n\n\n\nDesenvolvendo esta expressÃ£o teremos\n\\(P(-c \\le \\frac{X - \\mu}{\\sigma} \\le +c) = P(-c \\le Z \\le +c) = 0.99\\)\nFora deste intervalo simÃ©trico, teremos uma Ã¡rea de \\(0,005\\) na cauda inferior e \\(0,005\\) na cauda superior da distribuiÃ§Ã£o \\(Z\\).\nAo procurar por \\(0,005\\) na tabela \\(Z\\) encontramos \\(z = -2,57\\), de modo que \\(c = 2,57\\).\n\n\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/medidas-associacao/series.html",
    "href": "content/medidas-associacao/series.html",
    "title": "1 SÃ©ries de dados no tempo e no espaÃ§o",
    "section": "",
    "text": "1 SÃ©ries de dados no tempo e no espaÃ§o"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html",
    "href": "content/medidas-associacao/biquali.html",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas no capÃ­tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(gridExtra)\nsource('scripts/assoc-municipies.r')\nImagine que haverÃ¡ uma obra de revitalizaÃ§Ã£o de uma Ã¡rea na regiÃ£o central da cidade. A obra implicarÃ¡ na melhoria de acesso, de seguranÃ§a e na oferta de serviÃ§os. Entretanto como levarÃ¡ tempo para ser concluÃ­da, haverÃ¡ aÃ§Ãµes de remoÃ§Ã£o de moradias irregulares, interdiÃ§Ã£o de ruas e avenidas por longos perÃ­odos, etc. A prefeitura encomenda uma pesquisa para saber a opiniÃ£o dos munÃ­cipes. A cada entrevistado sÃ£o feitas duas perguntas:\nA base de dados completa estÃ¡ disponÃ­vel em datasets\nCom estas entrevistas desejamos responder Ã  seguinte questÃ£o:\nImporte a base de dados\nmun = read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Entrevista_municipes.csv',\n                  delim = ',')\n\nn_amostra = 12\nn = nrow(mun)  # NÃºmero de entrevistados\nApÃ³s entrevistar 200 pessoas selecionadas ao acaso de uma lista da moradores da cidade, foi construÃ­da uma tabela com trÃªs colunas: Entrevistado (sequÃªncia numÃ©rica do primeiro ao Ãºltimo respondente), OpiniÃ£o e Moradia.\nVeja os primeiros 12 resultados das entrevistas:\nTabelaÂ 1: Respostas dos primeiros munÃ­cipies entrevistados.\n\n\n\n\n\n\n\n\n\nEntrevistado\nOpiniao\nMoradia\n\n\n\n\n1\nA favor\nResidente\n\n\n2\nA favor\nResidente\n\n\n3\nA favor\nResidente\n\n\n4\nA favor\nResidente\n\n\n5\nContra\nNÃ£o-Residente\n\n\n6\nContra\nResidente\n\n\n7\nA favor\nNÃ£o-Residente\n\n\n8\nContra\nNÃ£o-Residente\n\n\n9\nA favor\nNÃ£o-Residente\n\n\n10\nA favor\nNÃ£o-Residente\n\n\n11\nA favor\nResidente\n\n\n12\nA favor\nNÃ£o-Residente\nEstÃ£o descritos na TabelaÂ 1 os resultados das primeiras 12 entrevistas, onde Ã© possÃ­vel ver ao menos uma combinaÃ§Ã£o de todas as possÃ­veis respostas. O entrevistado pode ser:"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#tabelas-de-frequÃªncia-e-grÃ¡ficos-de-barras",
    "href": "content/medidas-associacao/biquali.html#tabelas-de-frequÃªncia-e-grÃ¡ficos-de-barras",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "1 Tabelas de frequÃªncia e grÃ¡ficos de barras",
    "text": "1 Tabelas de frequÃªncia e grÃ¡ficos de barras\nInicialmente, vamos representar cada uma das variÃ¡veis por meio de uma tabela de frequÃªncia dos 200 entrevistados.\n\n\nCÃ³digo\nresumo_opiniao = mun |&gt; \n  group_by(Opiniao) |&gt; \n  summarise(Op_n = n()) |&gt; \n  mutate(Op_rel = Op_n/sum(Op_n))\n\nresumo_opiniao |&gt; \n  gt()\n\n\n\n\n\n\n\n\nOpiniao\nOp_n\nOp_rel\n\n\n\n\nA favor\n144\n0.72\n\n\nContra\n56\n0.28\n\n\n\n\n\n\n\nDas \\(200\\) respostas tivemos \\(144\\) pessoas A favor (\\(72\\%\\)) e \\(56\\) pessoas Contra (\\(28\\%\\)).\n\n\nCÃ³digo\nresumo_opiniao = mun |&gt; \n  group_by(Opiniao) |&gt; \n  summarise(Op_n = n()) |&gt; \n  mutate(Op_rel = Op_n/sum(Op_n))\n\nresumo_opiniao |&gt; \n  gt()\n\n\n\n\n\n\n\n\nOpiniao\nOp_n\nOp_rel\n\n\n\n\nA favor\n144\n0.72\n\n\nContra\n56\n0.28\n\n\n\n\n\n\n\nCom relaÃ§Ã£o ao local de residÃªncia:\n\n\nCÃ³digo\nresumo_morad = mun |&gt; \n  group_by(Moradia) |&gt; \n  summarise(Morad_n = n()) |&gt; \n  mutate(Morad_rel = Morad_n/sum(Morad_n))\n\nresumo_morad |&gt; \n  gt()\n\n\n\n\n\n\n\n\nMoradia\nMorad_n\nMorad_rel\n\n\n\n\nNÃ£o-Residente\n117\n0.585\n\n\nResidente\n83\n0.415\n\n\n\n\n\n\n\nResponderam Ã  entrevistas um total de \\(117\\) pessoas NÃ£o-Residente (\\(58.5\\%\\)) e \\(83\\) pessoas Residente (\\(41.5\\%\\))\nSe visualizarmos estes totais em grÃ¡ficos de barras individuais teremos:\n\n\nCÃ³digo\nplt_op = ggplot(mun, aes(x = Opiniao)) +\n  geom_bar(fill = 'darkblue', color = 'white') +\n  coord_cartesian(ylim = c(0, 150)) +\n  labs(y = 'NÃºmero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_morad = ggplot(mun, aes(x = Moradia)) +\n  geom_bar(fill = 'darkred', color = 'white') +\n  coord_cartesian(ylim = c(0, 150)) +\n  labs(y = 'NÃºmero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_op + plt_morad\n\n\n\n\n\n\n\n\nFiguraÂ 1: Respostas dos munÃ­cipies entrevistados para cada questÃ£o separadamente.\n\n\n\n\n\nExiste portanto um predomÃ­nio de pessoas A Favor e um ligeiro predomÃ­nio de entrevistados NÃ£o-Residentes.\nPara responder Ã  questÃ£o do capÃ­tulo, precisamos verificar se existe alguma associaÃ§Ã£o entre as respostas dadas Ã s duas perguntas explorando a distribuiÃ§Ã£o conjunta dos totais respondidos."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#tabelas-de-contingÃªncia",
    "href": "content/medidas-associacao/biquali.html#tabelas-de-contingÃªncia",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "2 Tabelas de contingÃªncia",
    "text": "2 Tabelas de contingÃªncia\nTabelas de contigÃªncia sÃ£o organizadas para verificarmos a associaÃ§Ã£o entre duas variÃ¡veis qualitativas. SÃ£o conhecidas tambÃ©m como tabelas de dupla entrada. Nas colunas estÃ£o os nÃ­veis da variÃ¡vel \\(X\\) e nas linhas os nÃ­veis da variÃ¡vel \\(Y\\).\nPara nosso exemplo, podemos fazer simplesmente:\n\ntcont = table(mun$Opiniao, mun$Moradia)\ntcont\n\n         \n          NÃ£o-Residente Residente\n  A favor            81        63\n  Contra             36        20\n\n\nTemos:\n\n81 - A favor e NÃ£o-Residente;\n63 - A favor e Residente;\n36 - Contra e NÃ£o-Residente;\n20 - Contra e Residente\n\nPodemos ver os totais marginais das linhas:\n\ntcont_linhas = apply(tcont, 1, sum)\ntcont_linhas\n\nA favor  Contra \n    144      56 \n\n\nOu os totais marginais das colunas:\n\ntcont_colunas = apply(tcont, 2, sum)\ntcont_colunas\n\nNÃ£o-Residente     Residente \n          117            83 \n\n\nQue sÃ£o justamente os totais que verificamos nas distribuiÃ§Ãµes individuais.\nSe quisermos ver as frequÃªncias relativas marginais podemos fazer:\n\ntrel_linha = prop.table(tcont, 1)\ntrel_linha\n\n         \n          NÃ£o-Residente Residente\n  A favor     0.5625000 0.4375000\n  Contra      0.6428571 0.3571429\n\n\nNeste caso estamos vendo as frequÃªncias relativas das linhas, isto Ã©, cada linha nesta tabela soma \\(1\\). O que vemos nesta tabela Ã© que:\n\ndos \\(144\\) entrevistados que sÃ£o A favor, cerca de \\(56.25\\%\\) sÃ£o NÃ£o-Residente, enquanto os demais \\(43.75\\%\\) sÃ£o Residente\ndos \\(56\\) entrevistados que sÃ£o Contra, cerca de \\(64.29\\%\\) sÃ£o NÃ£o-Residente, enquanto os demais \\(35.71\\%\\) sÃ£o Residente\n\nPodemos fazer exatamente o mesmo olhando para as frequÃªncias marginais por colunas:\n\ntrel_coluna = prop.table(tcont, 2)\ntrel_coluna\n\n         \n          NÃ£o-Residente Residente\n  A favor     0.6923077 0.7590361\n  Contra      0.3076923 0.2409639\n\n\nNeste caso sÃ£o as colunas que somam \\(1\\), portanto:\n\ndos \\(117\\) entrevistados que sÃ£o NÃ£o-Residente, cerca de \\(69.23\\%\\) sÃ£o A favor, enquanto os demais \\(30.77\\%\\) sÃ£o Contra\ndos \\(83\\) entrevistados que sÃ£o Residente, cerca de \\(75.9\\%\\) sÃ£o A favor, enquanto os demais \\(75.9\\%\\) sÃ£o Contra\n\nPodemos finalmente ver a frequÃªncia relativa conjunta:\n\ntrel_conjunta = prop.table(tcont)\ntrel_conjunta\n\n         \n          NÃ£o-Residente Residente\n  A favor         0.405     0.315\n  Contra          0.180     0.100\n\n\nEm que o somatÃ³rio das linhas Ã© igual a:\n\ntcont_linhas / sum(tcont_linhas)\n\nA favor  Contra \n   0.72    0.28 \n\n\nindicando os valores relativos das opiniÃµes A Favor e Contra.\nO somatÃ³rio das colunas Ã© igual a:\n\ntcont_colunas / sum(tcont_colunas)\n\nNÃ£o-Residente     Residente \n        0.585         0.415 \n\n\nindicando os valores relativos de NÃ£o-Residentes e Residentes.\nNa tabela de frequÃªncia relativa conjunta, o somatÃ³rio total da tabela deve ser igual a \\(1\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#o-grÃ¡fico-de-barras-para-duas-variÃ¡veis-qualitativas",
    "href": "content/medidas-associacao/biquali.html#o-grÃ¡fico-de-barras-para-duas-variÃ¡veis-qualitativas",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "3 O grÃ¡fico de barras para duas variÃ¡veis qualitativas",
    "text": "3 O grÃ¡fico de barras para duas variÃ¡veis qualitativas\nExistem vÃ¡rias formas de gerar um grÃ¡fico de barras combinando as duas variÃ¡veis. Se quisermos utilizar a prÃ³pria tabela de contingÃªncia obtida a partir do comando table(mun$Opiniao, mun$Moradia), podemos utilizar o comando barplot(). Por outro lado, se quisermos utilizar a tabela original de dados (objeto mun) podemos fazer uso do pacote ggplot2:\n\n\nCÃ³digo\nplt_bar1 = ggplot(mun) +\n  aes(x = Moradia, fill = Opiniao) +\n  geom_bar(color = 'white', position = 'dodge') +\n  scale_fill_manual(values = c('Contra' = 'darkred',\n                               'A favor' = 'darkblue')) +\n  coord_cartesian(ylim = c(0, 80)) +\n  labs(y = 'NÃºmero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_bar1\n\n\n\n\n\n\n\n\nFiguraÂ 2: Respostas dos munÃ­cipies entrevistados combinando local de moradia e opiniÃ£o.\n\n\n\n\n\nVeja que nesta figura, existem mais opiniÃµes A favor, independente do entrevistado ser ou nÃ£o residente da regiÃ£o central. Este padrÃ£o Ã© o mesmo que observamos no grÃ¡fico da variÃ¡vel OpiniÃ£o isoladamente, o que sugere nÃ£o haver associaÃ§Ã£o entre as variÃ¡veis OpiniÃ£o e Moradia. Ao que parece, a opiniÃ£o de um entrevistado sobre a construÃ§Ã£o da obra nÃ£o depende de seu local de moradia.\n\n\n\n\n\n\nNotaExemplos de associaÃ§Ãµes entre duas variÃ¡veis\n\n\n\nAbaixo sÃ£o apresentadas quatro situaÃ§Ãµes em que existe associaÃ§Ã£o OpiniÃ£o e Moradia.\n\n\n\n\n\n\n\n\n\n\n\nEm todos estes exemplos, note que a relaÃ§Ã£o as opiniÃµes A favor ou Contra dependem se o entrevistado Ã© ou nÃ£o Residente na regiÃ£o. Esses padrÃµes configuram diferentes tipos de associaÃ§Ã£o entre as variÃ¡veis OpiniÃ£o e Moradia, a saber:\n\nFigura A: NÃ£o-Residentes tendem a ser A favor e Residentes sÃ£o em sua maioria Contra;\nFigura B: todos tendem a ser Contra, mas a diferenÃ§a de opiniÃµes Ã© maior entre os Residentes;\nFigura C: NÃ£o-Residentes tendem a ser Contra, enquanto nÃ£o parece haver diferenÃ§as entre os Residentes;\nFigura D: Residentes tendem a ser A favor, enquanto nÃ£o parece haver diferenÃ§as entre os Residentes;"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#medindo-a-discrepÃ¢ncia-com-o-Ã­ndice-de-chi2-de-pearson",
    "href": "content/medidas-associacao/biquali.html#medindo-a-discrepÃ¢ncia-com-o-Ã­ndice-de-chi2-de-pearson",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "4 Medindo a discrepÃ¢ncia com o Ã­ndice de \\(\\chi^2\\) de Pearson",
    "text": "4 Medindo a discrepÃ¢ncia com o Ã­ndice de \\(\\chi^2\\) de Pearson\nO Ã­ndice de qui-quadrado (\\(\\chi^2\\)) mede a discrepÃ¢ncia entre os valores observados e os valores esperados em uma tabela de contingÃªncia.\nDigamos que um municÃ­pio tenha \\(20\\%\\) de sua populaÃ§Ã£o morando em Ã¡rea Rural e os outros \\(80\\%\\) em Ã¡rea Urbana. Se fizermos uma amostragem ao acaso dos moradores Ã© esperado que esta frequÃªncia relativa se reflita na amostra. Neste caso se sorteamos \\(200\\) pessoas, seria esperado:\n\nZona Rural: \\(40\\) moradores\nZona Urbana \\(160\\) moradores\n\nEntretando, se fazemos um sorteio ao acaso, haverÃ¡ alguma variaÃ§Ã£o ao redor destes valores, de modo que as frequÃªncias observadas (\\(o\\)) deverÃ£o ser diferentes das esperadas (\\(e\\)). O \\(\\chi^2\\) mede a discrepÃ¢ncia entre \\(o\\) e \\(e\\) para cada cÃ©lula de uma tabela de contigÃªncia como:\n\\[\\chi^2 = \\sum_{i=1}^{n}\\frac{(o_i - e_i)^2}{e_i}\\] Para uma tabela de frequÃªncias, devemos determinar portanto os valores de \\(o_i\\) e \\(e_i\\).\nSuponha que uma amostra de \\(200\\) moradores tenha resultado em:\n\n\nCÃ³digo\nset.seed(10)\nnor = sum(rbinom(n = n, size = 1, prob = pr))\nMoradia_obs = data.frame(Regiao = c(rep('Rural', nor),\n                           rep('Urbana', n - nor)))\n\ntb_dfo = table(Moradia_obs)\ntb_dfo\n\n\nRegiao\n Rural Urbana \n    31    169 \n\n\nAs frequÃªncias observadas e esperadas serÃ£o:\n\nZona Rural:\n\n\\(o_{Rural} = 31\\)\n\\(e_{Rural} = 0.2 \\times 200 = 40\\)\n\nZona Urbana\n\n\\(o_{Urbana} = 169\\)\n\\(e_{Urbana} = 0.8 \\times 200 = 160\\)\nDe modo que o valor de \\(\\chi^2\\) serÃ¡:\n\\(\\chi^2 = \\frac{(31 - 40)^2}{40} + \\frac{(169 - 160)^2}{160} = \\frac{(-9)^2}{40} + \\frac{(9)^2}{160} = 2.025 + 0.50625 = 2.53125\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#o-Ã­ndice-de-chi2-em-uma-tabela-de-contigÃªncia",
    "href": "content/medidas-associacao/biquali.html#o-Ã­ndice-de-chi2-em-uma-tabela-de-contigÃªncia",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "5 O Ã­ndice de \\(\\chi^2\\) em uma tabela de contigÃªncia",
    "text": "5 O Ã­ndice de \\(\\chi^2\\) em uma tabela de contigÃªncia\nNo exemplo acima, as contagens esperadas foram definidas a partir de um modelo que dizia que as populaÃ§Ãµes rurais e urbanas se dividiam nas proporÃ§Ãµes \\(20\\%:80\\%\\). Em uma tabela de contigÃªncia, a hipÃ³tese em verificaÃ§Ã£o Ã© a de que nÃ£o hÃ¡ associaÃ§Ã£o entre \\(X\\) e \\(Y\\). Se for assim, Ã© esperado que as frequÃªncias conjuntas sejam porporcionais Ã s frequÃªncias marginais. Vamos apresentar esta ideia utilizando uma notaÃ§Ã£o geral para tabelas de contingÃªncia e, em seguida, discutir com um exemplo.\nA tabela TabelaÂ 2 apresenta \\(r\\) linhas por \\(s\\) colunas com as contagens de todas as combinaÃ§Ãµes dos nÃ­veis da variÃ¡vel \\(X\\) (NÃ­veis \\(A_{1}\\) a \\(A_{r}\\)) e da variÃ¡vel \\(Y\\) (NÃ­veis \\(B_{1}\\) a \\(B_{s}\\)). Os totais marginais de \\(X\\) e \\(Y\\) sÃ£o expressos respectivamente na Ãºltima coluna e na Ãºltima linha.\n\n\n\nTabelaÂ 2: RepresentaÃ§Ã£o de uma tabela de contigÃªncia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX âŸ Y\n\\(B_{1}\\)\n\\(B_{2}\\)\n\\(\\cdots\\)\n\\(B_{j}\\)\n\\(\\cdots\\)\n\\(B_{s}\\)\nTotais em \\(X\\)\n\n\n\n\n\\(A_{1}\\)\n\\(n_{11}\\)\n\\(n_{12}\\)\n\\(\\cdots\\)\n\\(n_{1j}\\)\n\\(\\cdots\\)\n\\(n_{1s}\\)\n\\(n_{1.}\\)\n\n\n\\(A_{2}\\)\n\\(n_{21}\\)\n\\(n_{22}\\)\n\\(\\cdots\\)\n\\(n_{2j}\\)\n\\(\\cdots\\)\n\\(n_{2s}\\)\n\\(n_{2.}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(A_{i}\\)\n\\(n_{i1}\\)\n\\(n_{i2}\\)\n\\(\\cdots\\)\n\\(n_{ij}\\)\n\\(\\cdots\\)\n\\(n_{is}\\)\n\\(n_{i.}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(A_{r}\\)\n\\(n_{r1}\\)\n\\(n_{r2}\\)\n\\(\\cdots\\)\n\\(n_{rj}\\)\n\\(\\cdots\\)\n\\(n_{rs}\\)\n\\(n_{r.}\\)\n\n\nTotais em \\(Y\\)\n\\(n_{.1}\\)\n\\(n_{.2}\\)\n\\(\\cdots\\)\n\\(n_{.j}\\)\n\\(\\cdots\\)\n\\(n_{rs}\\)\n\\(n\\)\n\n\n\n\n\n\nSob a hipÃ³tese de nÃ£o-associaÃ§Ã£o entre \\(X\\) e \\(Y\\) teremos que:\n\\(\\frac{n_{i1}}{n_{.1}} = \\frac{n_{i2}}{n_{.2}} = \\cdots = \\frac{n_{is}}{n_{.s}} = \\frac{n_{i.}}{n}\\)\ne assim:\n\\(\\frac{n_{ij}}{n_{.j}} = \\frac{n_{i.}}{n}\\)\nDeste modo:\n\\(n_{ij}^{e} = \\frac{n_{i.} \\times n_{.j}}{n}\\)\n\n\n\n\n\n\nNotaObservaÃ§Ãµes\n\n\n\nA notaÃ§Ã£o \\(n_{ij}^{e}\\) estÃ¡ sendo utilizada para denotar que a expressÃ£o acima determina a contagem de cada cÃ©lula da tabela sob a hipÃ³tese de nÃ£o associaÃ§Ã£o e portanto, se refere ao valor esperado de \\(n_{ij}\\).\n\n\nTendo definido os valores esperados em uma tabela de contingÃªncia de \\(r \\times s\\), o \\(\\chi^2\\) Ã© dado por:\n\\[\\chi^2 = \\sum_{i=1}^{r}\\sum_{j=1}^{s}\\frac{(n_{ij} - n_{ij}^{e})^2}{n_{ij}^{e}}\\]\nRetornando ao exemplo das entrevistas\nA tabela de contingÃªncia contendo os dados observados do inÃ­cio do capÃ­tulo pode ser escrita como:\n\n\n\nTabelaÂ 3: Resultados das entrevistas dos 200 munÃ­cipies.\n\n\n\n\n\n\n\n\n\n\n\n\nNÃ£o-Residente\nResidente\nTotal OpiniÃ£o\n\n\n\n\nA favor\n81\n63\n144\n\n\nContra\n36\n20\n56\n\n\nTotal Moradia\n117\n83\n200\n\n\n\n\n\n\nOs Valores esperados na linha \\(i\\) e coluna \\(j\\) sÃ£o:\n\nLinha \\(1\\) - Coluna \\(1\\) (NÃ£o-Residente - A favor):\n\n\\(n_{ii}^{e} = \\frac{n_{1.} \\times n_{.1}}{n} =  \\frac{144 \\times 117}{200} = 84.24\\)\n\nLinha \\(1\\) - Coluna \\(2\\) (Residente - A favor):\n\n\\(n_{ii}^{e} = \\frac{n_{1.} \\times n_{.2}}{n} =  \\frac{144 \\times 83}{200} = 59.76\\)\n\nLinha \\(2\\) - Coluna \\(1\\) (NÃ£o-Residente - Contra):\n\n\\(n_{ii}^{e} = \\frac{n_{2.} \\times n_{.1}}{n} =  \\frac{56 \\times 117}{200} = 32.76\\)\n\nLinha \\(2\\) - Coluna \\(2\\) (Residente - Contra):\n\n\\(n_{ii}^{e} = \\frac{n_{2.} \\times n_{.2}}{n} =  \\frac{56 \\times 83}{200} = 23.24\\)\nDe modo que a tabela com os valores esperados serÃ¡:\n\n\n\nTabelaÂ 4: Valores esperados na hipÃ³tese de nÃ£o-associaÃ§Ã£o entre Opiniao e locals de Moradia dos 200 munÃ­cipies entrevistados.\n\n\n\n\n\n\n\n\n\n\n\n\nNÃ£o-Residente\nResidente\nTotal OpiniÃ£o\n\n\n\n\nA favor\n84.24\n59.76\n144\n\n\nContra\n32.76\n23.24\n56\n\n\nTotal Moradia\n117\n83\n200\n\n\n\n\n\n\nFinalmente, o valor de \\(\\chi^2\\) pode ser calculado por:\n\\(\\chi^2 = \\frac{(81 - 84.24)^2}{84.24} + \\frac{(36 - 32.76)^2}{84.24} + \\frac{(63 - 59.76)^2}{84.24} + \\frac{(20 - 23.24)^2}{84.24} = 1.072\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#valores-de-chi2-quando-existe-associaÃ§Ã£o",
    "href": "content/medidas-associacao/biquali.html#valores-de-chi2-quando-existe-associaÃ§Ã£o",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "6 Valores de \\(\\chi^2\\) quando existe associaÃ§Ã£o",
    "text": "6 Valores de \\(\\chi^2\\) quando existe associaÃ§Ã£o\nO valor de \\(\\chi^2\\) serÃ¡ zero somente se os valores observados forem exatamente iguais aos valores esperados. Pequenas discrepÃ¢ncias irÃ£o gerar valores de \\(\\chi^2\\) acima de zero, que se tornarÃ£o mais altos Ã  medida que aumentam as diferenÃ§as entre \\(n_{ij}\\) e \\(n_{ij}^e\\).\n\n\n\n\n\n\nNotaQuantificando as associaÃ§Ãµes\n\n\n\nAbaixo estÃ£o diferentes exemplos em que existe associaÃ§Ã£o entre OpiniÃ£o e Moradia. Compare os valores e os grÃ¡ficos abaixo aos que fizemos no exemplo do capÃ­tulo e veja que todos os valores de \\(\\chi^2\\) sÃ£o mais elevados.\n\n\n\n\n\n\n\n\n\n\n\nTente aplicar a fÃ³rmula do \\(\\chi^2\\) para chegar aos resultados apresentados em cada exemplo."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#variaÃ§Ãµes-do-Ã­ndice-de-chi2",
    "href": "content/medidas-associacao/biquali.html#variaÃ§Ãµes-do-Ã­ndice-de-chi2",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "7 VariaÃ§Ãµes do Ã­ndice de \\(\\chi^2\\)",
    "text": "7 VariaÃ§Ãµes do Ã­ndice de \\(\\chi^2\\)\nO valor de \\(\\chi^2\\) aumenta com o tamanho da amostra, o que torna difÃ­cil comparaÃ§Ãµes entre diferentes estudos. Para corrigir este efeito existe o coeficiente de contigÃªncia de Pearson (\\(C\\)) que Ã© baseado no resultado de \\(\\chi^2\\)\n\\[C = \\sqrt{\\frac{\\chi^2}{\\chi^2 + n}}\\]\nem que \\(n\\) Ã© o tamanho da amostra.\nO valor mÃ¡ximo de \\(C\\) depende do nÃºmero de linhas (\\(r\\)) e de colunas (\\(s\\)) na tabela de contingÃªcia. Podemos definir um coeficiente que esteja limitado entre \\(0\\) e \\(1\\):\n\\[T = \\sqrt{\\frac{\\frac{\\chi^2}{n}}{(r-1) \\times (s-1)}}\\] O valor \\(T = 0\\) ocorre quando nÃ£o hÃ¡ associaÃ§Ã£o (\\(\\chi^2 = 0\\)) e o valor mÃ¡ximo de \\(T = 1\\) sÃ³ serÃ¡ atingido se houver associaÃ§Ã£o e \\(r = s\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#obtendo-o-Ã­ndice-de-chi2-de-uma-tabela-de-dados",
    "href": "content/medidas-associacao/biquali.html#obtendo-o-Ã­ndice-de-chi2-de-uma-tabela-de-dados",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas",
    "section": "8 Obtendo o Ã­ndice de \\(\\chi^2\\) de uma tabela de dados",
    "text": "8 Obtendo o Ã­ndice de \\(\\chi^2\\) de uma tabela de dados\nA funÃ§Ã£o para o cÃ¡lculo do \\(\\chi^2\\) no R Ã© chisq.test e pode ser utilizada a partir da tabela de contigÃªncia gerada pela funÃ§Ã£o table:\n\ntcont = table(mun$Opiniao, mun$Moradia)\nchisq.test(tcont)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tcont\nX-squared = 0.76697, df = 1, p-value = 0.3812\n\n\nO resultado mostra o o valor de \\(\\chi^2\\) calculado (X-squared) e outras duas quantias denominadas de graus de liberdade (df) e valor de p (p-value), tÃ³picos abordados em inferÃªncia estatÃ­stica.\nNote que o resultado Ã© diferente do que obtivemos neste capÃ­tulo. Isto ocorre pois, por padrÃ£o, a funÃ§Ã£o utiliza a correÃ§Ã£o de Yates, em que \\(\\chi_{Yates}^{2}\\) Ã© calculado por:\n\\[\\chi_{Yates}^{2} = \\sum_{i=1}^{r}\\sum_{j=1}^{s}\\frac{(|n_{ij} - n_{ij}^{e}| - 0,5)^2}{n_{ij}^{e}}\\]\nO termo \\(|n_{ij} - n_{ij}^{e}|\\) se refere ao mÃ³dulo da distÃ¢ncia entre os valores observados e calculados.\nSe quisermos obter exatamente os resultados descritos no exemplo deste capÃ­tulo, basta fazermos:\n\nchisq.test(tcont, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  tcont\nX-squared = 1.0724, df = 1, p-value = 0.3004"
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html",
    "href": "content/amostragem/tipos-amostragem.html",
    "title": "Amostrando uma populaÃ§Ã£o estatÃ­stica",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas no capÃ­tulo\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nlibrary(knitr)\nO objetivo da amostragem Ã© descrever caracterÃ­sticas da populaÃ§Ã£o estatÃ­stica por meio de caracterÃ­sticas da amostra. Por exemplo, em um estudo sobre o tamanho do pescado em uma Ã¡rea de pesca, a populaÃ§Ã£o estatÃ­stica sÃ£o os comprimentos de todos os peixes que podem ser pescados na regiÃ£o. A populaÃ§Ã£o estatÃ­stica pode ser descrita por parÃ¢metros que representam medidas de centro como o comprimento mÃ©dio (\\(\\mu\\)), ou por medidas de variaÃ§Ã£o como o desvio padrÃ£o (\\(\\sigma\\)), que representam o grau de dispersÃ£o das unidades amostrais ao redor da mÃ©dia. Se amostramos n elementos desta populaÃ§Ã£o, a mÃ©dia amostral (\\(\\overline{X}\\)) e o desvio padrÃ£o amostral (\\(s\\)) dos diÃ¢metros serÃ£o os estimadores destas caracterÃ­sticas.\nDependendo da questÃ£o envolvida e do conhecimento prÃ©vio sobre a populaÃ§Ã£o, diferentes mÃ©todos de amostragem sÃ£o apropriados. A teoria da amostragem Ã© a Ã¡rea da ciÃªncia que estuda estes mÃ©todos. Neste capÃ­tulo vamos discutir trÃªs tipos de amostragem: aleatÃ³ria simples, estratificada e sistemÃ¡tica."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-aleatÃ³ria-simples",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-aleatÃ³ria-simples",
    "title": "Amostrando uma populaÃ§Ã£o estatÃ­stica",
    "section": "1 Amostragem aleatÃ³ria simples",
    "text": "1 Amostragem aleatÃ³ria simples\nÃ‰ aquela em que cada elemento da populaÃ§Ã£o tem a mesma probabilidade de ser selecionado para compor a amostra. Se a populaÃ§Ã£o consiste de \\(1000\\) elementos, cada um terÃ¡ uma probabilidade de \\(\\frac{1}{1000}\\) de ser escolhido. Isto isenta o pesquisador de tomar qualquer decisÃ£o com base em julgamentos prÃ©-concebidos, sobre quais elementos devem ou nÃ£o compor a amostra.\n\n\nCÃ³digo\nset.seed(1)\npop = c(3, 10, 14, 19, 27, 28, 29, 41, 42, 43)\nN = length(pop)\nAm1 = sort(pop)[1:5]\nset.seed(2)\nAm2 = sample(pop, size = 5, replace = F)\n\n\nSuponha uma populaÃ§Ã£o hipotÃ©tica de somente \\(10\\) elementos:\nPopulaÃ§Ã£o: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nEm uma amostra aleatÃ³ria simples de cinco elementos, qualquer combinaÃ§Ã£o destes \\(10\\) elementos Ã© igualmente provÃ¡vel. Se por puro acaso sortearmos uma amostra aleatÃ³ria contendo os cinco menores valores da populaÃ§Ã£o:\nAmostra 1: 3, 10, 14, 19, 27\nA amostra seria tÃ£o aleatÃ³ria e vÃ¡lida do ponto de vista estatÃ­stico quanto qualquer outra como:\nAmostra 2: 27, 28, 42, 3, 43\nIsto significa que uma amostra aleatÃ³ria pode nÃ£o ser necessariamente representativa da populaÃ§Ã£o. Amostras pequenas por exemplo, tÃªm uma chance maior de selecionar apenas valores extremos, ou seja, os maiores ou menores elementos da populaÃ§Ã£o. A mÃ©dia amostral (\\(\\overline{X}\\)) calculada para estas amostras estarÃ¡ distante da mÃ©dia populacional (\\(\\mu\\)). No entanto, a importÃ¢ncia central da amostragem aleatÃ³ria em estatÃ­stica estÃ¡ no fato de que a aleatoriedade produz, em mÃ©dia, amostras representativas da populaÃ§Ã£o. Deste modo, Ã© esperado que na maioria das vezes, uma amostra aleatÃ³ria gere mÃ©dias amostrais prÃ³ximas Ã  mÃ©dia populacional. Por este motivo, Ã© fundamental prezar pela aleatoriedade no processo amostral, pois de outro modo nÃ£o poderemos garantir que a inferÃªncia seja vÃ¡lida com base nas leis de probabilidade.\nO modo mais direto de se obter uma amostra aleatÃ³ria Ã© por meio de sorteio. ApÃ³s atribuir nÃºmeros de 1 a \\(N\\) a cada unidade amostral, estas unidades sÃ£o sorteadas atÃ© que seja atingido o tamanho \\(n\\) desejado. Na prÃ¡tica, nem sempre Ã© simples, ou mesmo possÃ­vel obter uma amostra aleatÃ³ria nestes moldes. NÃ£o seria possÃ­vel enumerar todos os peixes de uma regiÃ£o para, apÃ³s um sorteio, tomar as medidas somente dequeles selecionados. Entretanto, se empregarmos mÃ©todos de captura em que indivÃ­duos de todos os tamanhos sejam igualmente sujeitos a serem capturados poderÃ­amos no aproximar do que seria uma amostra verdsadeiramente aleatÃ³ria. Outras dificuldades prÃ¡ticas surgiriam neste estudo como por exemplo: garantir acesso irrestrito Ã  toda a Ã¡rea de ocorrÃªncia da espÃ©cie, tempo disponÃ­vel para percorrer a toda regiÃ£o. QuestÃµes como estas nÃ£o desmerecem o requisito bÃ¡sico de se obter uma amostra aleatÃ³ria, mas devem nos auxiliar a decidir como conciliar a prÃ¡tica experimental com a necessidade de garantirmos uma amostra aleatÃ³ria."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-aleatÃ³ria-estratificada",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-aleatÃ³ria-estratificada",
    "title": "Amostrando uma populaÃ§Ã£o estatÃ­stica",
    "section": "2 Amostragem aleatÃ³ria estratificada",
    "text": "2 Amostragem aleatÃ³ria estratificada\nSe tivermos algum conhecimento prÃ©vio de como a populaÃ§Ã£o estÃ¡ estruturada, a amostra aleatÃ³ria simples, embora nÃ£o esteja incorreta, pode nÃ£o ser a estratÃ©gia mais eficiente do ponto de vista estatÃ­stico. Se for possivel identificar estratos ou subgrupos dentro da populaÃ§Ã£o, podemos conduzir uma amostragem aleatÃ³ria estatificada.\nVoltemos ao exemplo do comprimento do pescado. Suponha que existam duas Ã¡reas de ocorrÃªncia da espÃ©cie. Uma delas sujeita a intensa atividade pesqueira e outra sendo uma Ã¡rea protegida. PoderÃ­amos supor que na Ã¡rea protegida estejam os maiores indivÃ­duos, justamente porque nesta Ã¡rea nÃ£o hÃ¡ atividade de pesca (que em geral busca indivÃ­duos maiores). Dizemos que os comprimentos em cada uma das duas regiÃµes compÃµem estratos da populaÃ§Ã£o estatÃ­stica.\nNesta situaÃ§Ã£o, uma amostra puramente aleatÃ³ria sem considerar a existÃªncia dos dois estratos pode fazer com que, puramente ao acaso, um deles se torne mais representados na amostra. Se por exemplo da maioria dos pontos selecionados estiverem na regiÃ£o intensamente pescada, o comprimento mÃ©dio da amostra (\\(\\overline{X}\\)) tenderÃ¡ a ficar consistentemente abaixo de \\(\\mu\\). A chance disto ocorrer se torna maior principalmente se o tamanho amostral for pequeno.\nEntretanto, se a seleÃ§Ã£o dos indivÃ­duos foi feita por meio de sorteio, o simples fato de observarmos este padrÃ£o nÃ£o seria por si sÃ³ justificativa para refarzermos a amostra. O ponto relevante aqui Ã© que em uma amostra aleatÃ³ria simples, estes extremos indesejÃ¡veis (um estrato mais representado que outro) sÃ£o mais provÃ¡veis de acontecer.\nSe temos conhecimento da existÃªncia dos dois estratos portanto, a amostragem aleatÃ³ria estratificada seria a mais indicada. Neste tipo de amostragem, o esforÃ§o amostral Ã© subdividido entre os estratos. O tamanho amostral em cada estrato serÃ¡ o mesmo, ou proporcional ao seu tamanho. Uma vez definirmos os tamanhos amostrais que serÃ¡ aplicado aos estratos, as unidades sÃ£o selecionadas por meio de uma amostragem aleatÃ³ria simples em cada um.\nA amostragem aleatÃ³ria estratificada garante que todos os estratos estejam presentes na amostra conforme sua representatividade na populaÃ§Ã£o. Ao fazer isto, as estimativas da amostra tenderÃ£o a se concentrar mais prÃ³ximas ao parÃ¢metro da populaÃ§Ã£o. Deste modo, quando os estratos sÃ£o identificados corretamente, a principal vantagem da amostra aleatÃ³ria estratificada sobre a amostra aleatÃ³ria simples estÃ¡ em aumentar a precisÃ£o das estimativas. Mais a frente iremos discutir os conceitos de precisÃ£o e acurÃ¡cia e relacionÃ¡-los com as estratÃ©gias amostrais discutidas aqui."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-sistemÃ¡tica",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-sistemÃ¡tica",
    "title": "Amostrando uma populaÃ§Ã£o estatÃ­stica",
    "section": "3 Amostragem sistemÃ¡tica",
    "text": "3 Amostragem sistemÃ¡tica\nEm uma amostragem sistemÃ¡tica o pesquisador escolhe um elemento inicial e toma medidas a cada \\(k\\) ocorrÃªncias, seguindo a ordem de observaÃ§Ã£o. No caso do comprimento de pescado, para facilitar a tomada de dados, o pesquisador pode medir o primeiro peixe coletado e, em seguida, medir os peixes em intervalos regulares, por exemplo a cada \\(10\\) observados.\nA escolha da amostragem sistemÃ¡tica ao invÃ©s de uma amostragem aleatÃ³ria simples, deve-se Ã  sua praticidade. Se a caracterÃ­stica de interesse das unidades amostrais estiver disposta de forma aleatÃ³ria ao longo da sequÃªncia escolhida, a amostragem aleatÃ³ria e sistemÃ¡tica irÃ£o gerar resultados similares. Na maioria dos casos, Ã© isto que o pesquisador assume (ainda que implicitamente) quando opta por uma amostragem sistemÃ¡tica."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#erro-amostral-acurÃ¡cia-e-precisÃ£o",
    "href": "content/amostragem/tipos-amostragem.html#erro-amostral-acurÃ¡cia-e-precisÃ£o",
    "title": "Amostrando uma populaÃ§Ã£o estatÃ­stica",
    "section": "4 Erro amostral, acurÃ¡cia e precisÃ£o",
    "text": "4 Erro amostral, acurÃ¡cia e precisÃ£o\nComo as estimativas sÃ£o obtidas de um subconjunto da populaÃ§Ã£o (a amostra), Ã© regra que o resultado obtido de uma amostra aleatÃ³ria particular, nÃ£o serÃ¡ igual ao verdadeiro valor da populaÃ§Ã£o (o parÃ¢metro), embora exista uma grande probabilidade estar prÃ³ximo.\n\nErro amostral: Ã© a diferenÃ§a entre uma estimativa em particular e o parÃ¢metro na populaÃ§Ã£o e portanto, Ã© inerente Ã  variabilidade do processo de amostragem. Suponha que, puramente ao acaso, a amostra inclua os menores elementos da populaÃ§Ã£o. A mÃ©dia amostral (\\(\\overline{X}\\)) estarÃ¡ muito abaixo da mÃ©dia populacional (\\(\\mu\\)) e o erro amostral serÃ¡ grande. Se calcularmos a mÃ©dia (\\(\\overline{X}\\)) de uma amostra particular, o erro amostral serÃ¡ dado por:\n\n\\[E = \\overline{X} - \\mu\\]\nA estatÃ­stica estuda o comportamento probabilÃ­stico dos erros amostrais. Existe tambÃ©m o erro nÃ£o amostral que decorre de equÃ­vocos de amostragem, inexperiÃªncia do amostrador, falha de equipamentos, enganos no cÃ´mputo dos resultados, etc. A estatÃ­stica nÃ£o lida com este tipo de erro.\n\nAcurÃ¡cia: se refere Ã  proximidade entre o parÃ¢metro e o estimador. Um estimador acurado Ã©, em mÃ©dia, igual ao parÃ¢metro populacional. Diferente do erro amostral, a acurÃ¡cia nÃ£o se refere a uma estimativa em particular, mas ao valor esperado do estimador, caso a amostragem fosse repetida um grande nÃºmero de vezes. Um estimador nÃ£o-acurado (viciado) resulta em valores consistentemente diferentes do parÃ¢metro, podendo estar acima (viÃ©s positivo) ou abaixo (viÃ©s negativo) do valor populacional. A mÃ©dia aritmÃ©tica amostral (\\(\\overline{X}\\)) Ã© um estimador nÃ£o-viciado da mÃ©dia populacional (\\(\\mu\\)) pois:\n\n\\[\\mu_{\\overline{X}} = \\mu\\]\n\nPrecisÃ£o: tem relaÃ§Ã£o com a variabilidade do estimador. Estimadores que geram estimativas similares entre si sÃ£o mais precisos. PorÃ©m, se as estimativas estiverem distantes de sua mÃ©dia, o estimador Ã© dito pouco preciso. Exemplo: Para uma populaÃ§Ã£o normalmente distribuÃ­da, tanto a mÃ©dia aritmÃ©tica quanto a mediana sÃ£o estimadores acurados. Entretanto, a variÃ¢ncia da mediana Ã© maior que da mÃ©dia aritmÃ©tica. Dizemos portanto, que a mÃ©dia aritmÃ©tica Ã© um estimador mais preciso que a mediana. A precisÃ£o de um estimador Ã© medida pelo erro padrÃ£o da mÃ©dia.\n\n\\[\\sigma_{\\overline{X}} =\\frac{\\sigma}{\\sqrt{n}}\\]\nA figura abaixo Ã© comnmente utilizada para representar os conceitos de preciÃ§Ã£o e acurÃ¡cia. O centro do alvo Ã© o valor do parÃ¢metro populacional e os pontos em preto sÃ£o as estimativas. Estimadores acurados geram, em mÃ©dia, estimativas ao redor do parÃ¢metro populacional (viÃ©s \\(= 0\\)). Estimadores nÃ£o-acurados geram, em mÃ©dia, valores deslocados do parÃ¢metro populacional (viÃ©s \\(\\ne 0\\)). Estimadores precisos resultam sempre em estimativas prÃ³ximas entre si, enquanto estimadores nÃ£o precisos resultam em estimativas distantes umas das outras.\n\n\n\n\n\n\nFiguraÂ 1: RepresentaÃ§Ã£o dos conceitos de precisÃ£o e acurÃ¡cia.\n\n\n\n\n4.1 Erro amostral\nVoltemos Ã  nossa populaÃ§Ã£o fictÃ­cia com \\(N = 10\\) elementos:\nPopulaÃ§Ã£o: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nPara esta populaÃ§Ã£o em particular nÃ³s conhecemos a mÃ©dia populacional (\\(\\mu\\) = 25.6), de modo que serÃ¡ possÃ­vel comparÃ¡-la com as estimativas amostrais.\n\n\nCÃ³digo\nset.seed(4)\nn = 5\nAm1 = sample(pop, size = n, replace = F)\nsomaAm1 = paste(Am1, collapse = \"+\")\nmp = round(mean(pop),1)\nmAm1 = round(mean(Am1),1)\nE1 = mAm1 - mp\n\n\nVamos tomar uma amostra aleatÃ³ria de tamanho \\(n = 5\\):\nAmostra 1: \\(41, 14, 42, 29, 19\\)\nPara esta amostra, a mÃ©dia vale: \\(\\overline{X} =\\frac{41+14+42+29+19}{5} = 29\\).\nOs valores \\(\\mu = 25.6\\) e \\(\\overline{X} = 29\\) nÃ£o sÃ£o idÃªnticos, pois a amostra contÃ©m somente alguns elementos da populaÃ§Ã£o. A diferenÃ§a entre \\(\\mu\\) e \\(\\overline{X}\\) Ã© o chamamos de erro amostral.\nNeste caso, o erro amostral Ã©:\nErro amostral 1: \\(E_1 = 29  -  25.6  =  3.4\\)\nSe tomarmos outra amostra aleatÃ³ria, teremos outro conjunto de unidades amostrais, e consequentemente, um \\(\\overline{X}\\) e um erro amostral diferentes. Por exemplo:\n\n\nCÃ³digo\nset.seed(3)\nn = 5\nAm2 = sample(pop, size = n, replace = F)\nmAm2 = round(mean(Am2),1)\nE2 = mAm2 - mp\n\n\nAmostra 2: \\(27, 29, 19, 10, 14\\)\nMÃ©dia amostral 2: \\(\\overline{X_2} = 19.8\\)\nErro amostral 2: \\(E_2 = 19.8  -  25.6  =  -5.8\\)\n\n\n4.2 AcurÃ¡cia\n\n\nCÃ³digo\nN = length(pop)\nn = 5\nCT = choose(N,n)\n\n\nAtÃ© agora, analisamos duas amostras diferentes da populaÃ§Ã£o. PorÃ©m, quantas amostras distintas seriam possÃ­veis? Para uma amostragem sem reposiÃ§Ã£o, a teoria combinatÃ³ria nos diz que sÃ£o possÃ­veis:\n\\[{{10}\\choose{5}} = \\frac{10!}{(10-5)! \\times 5!} = 252\\]\nformas diferentes de combinarmos \\(N = 10\\) elementos em amostras de tamanho \\(n = 5\\).\n\n\nCÃ³digo\nset.seed(8)\nR = 8\nA15 = replicate(n = R, sample(pop, size = n, replace = F))\ncolnames(A15) = paste(\"A\", 1:ncol(A15), sep = \"\")\nMedias = round(apply(A15, 2, mean),2)\n\n\nInicialmente vamos avaliar a questÃ£o com um nÃºmero menor. Sejam por exemplo, 8 amostras tomadas aleatoriamente, gerando os resultados a seguir:\n\n\nCÃ³digo\nA15 |&gt; \n  as.data.frame() |&gt; \n  add_column('Obs' = rep('', times = nrow(A15)), .before = 'A1') |&gt; \n  rbind(Obs = c('MÃ©dias', Medias)) |&gt; \n  gt() |&gt; \n  tab_style(\n    style = list(cell_fill(color = \"lightblue\")),\n    locations = cells_body(\n      rows = Obs == \"MÃ©dias\"\n    )\n  ) |&gt; \n  cols_width(\n    everything() ~ px(150)\n  )\n\n\n\n\nTabelaÂ 1: Oito amostras de tamanho n = 5 da populaÃ§Ã£o estatÃ­stica.\n\n\n\n\n\n\n\n\n\nObs\nA1\nA2\nA3\nA4\nA5\nA6\nA7\nA8\n\n\n\n\n\n19\n29\n10\n19\n42\n29\n28\n43\n\n\n\n29\n43\n14\n41\n29\n10\n42\n28\n\n\n\n10\n28\n42\n43\n41\n27\n10\n42\n\n\n\n42\n3\n28\n28\n14\n42\n43\n27\n\n\n\n43\n27\n29\n3\n28\n43\n27\n19\n\n\nMÃ©dias\n28.6\n26\n24.6\n26.8\n30.8\n30.2\n30\n31.8\n\n\n\n\n\n\n\n\n\n\nCada coluna desta matriz corresponde a uma possÃ­vel amostra aleatÃ³ria e suas respectivas mÃ©dias.\nAlgumas amostras tiveram mÃ©dias muito distantes de \\(\\mu\\), como: \\(\\overline{X_{A8}} = 31.8\\) ou \\(\\overline{X_{A3}} = 24.6\\). Esta variaÃ§Ã£o Ã© natural do processo amostral. Os mÃ©todos de amostragem e de inferÃªncia estatÃ­stica tratam justamente de como interpretar e como lidar com esta variaÃ§Ã£o. Para entender melhor este processo, vamos obter todas as 252 combinaÃ§Ãµes possÃ­veis de amostras com \\(n = 5\\) e, em seguida, extrair suas respectivas mÃ©dias.\nOs resultados das 252 mÃ©dias possÃ­veis podem ser vistos a seguir ordenados da menor para a maior mÃ©dia possÃ­vel:\n\n\nCÃ³digo\nAllcomb = combn(x = pop, m = 5)\nM_Allcomb = apply(Allcomb,2,mean)\nM_Allcomb_round = round(M_Allcomb,1)\nknitr::kable(matrix(M_Allcomb_round,nc = 14, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.6\n14.8\n15.0\n17.4\n17.6\n17.8\n16.4\n16.6\n19.0\n19.2\n19.4\n16.8\n19.2\n19.4\n\n\n19.6\n19.4\n19.6\n19.8\n22.0\n22.2\n22.4\n17.4\n17.6\n20.0\n20.2\n20.4\n17.8\n20.2\n\n\n20.4\n20.6\n20.4\n20.6\n20.8\n23.0\n23.2\n23.4\n19.4\n21.8\n22.0\n22.2\n22.0\n22.2\n\n\n22.4\n24.6\n24.8\n25.0\n22.2\n22.4\n22.6\n24.8\n25.0\n25.2\n25.0\n25.2\n25.4\n27.8\n\n\n18.2\n18.4\n20.8\n21.0\n21.2\n18.6\n21.0\n21.2\n21.4\n21.2\n21.4\n21.6\n23.8\n24.0\n\n\n24.2\n20.2\n22.6\n22.8\n23.0\n22.8\n23.0\n23.2\n25.4\n25.6\n25.8\n23.0\n23.2\n23.4\n\n\n25.6\n25.8\n26.0\n25.8\n26.0\n26.2\n28.6\n21.2\n23.6\n23.8\n24.0\n23.8\n24.0\n24.2\n\n\n26.4\n26.6\n26.8\n24.0\n24.2\n24.4\n26.6\n26.8\n27.0\n26.8\n27.0\n27.2\n29.6\n25.6\n\n\n25.8\n26.0\n28.2\n28.4\n28.6\n28.4\n28.6\n28.8\n31.2\n28.6\n28.8\n29.0\n31.4\n31.6\n\n\n19.6\n19.8\n22.2\n22.4\n22.6\n20.0\n22.4\n22.6\n22.8\n22.6\n22.8\n23.0\n25.2\n25.4\n\n\n25.6\n21.6\n24.0\n24.2\n24.4\n24.2\n24.4\n24.6\n26.8\n27.0\n27.2\n24.4\n24.6\n24.8\n\n\n27.0\n27.2\n27.4\n27.2\n27.4\n27.6\n30.0\n22.6\n25.0\n25.2\n25.4\n25.2\n25.4\n25.6\n\n\n27.8\n28.0\n28.2\n25.4\n25.6\n25.8\n28.0\n28.2\n28.4\n28.2\n28.4\n28.6\n31.0\n27.0\n\n\n27.2\n27.4\n29.6\n29.8\n30.0\n29.8\n30.0\n30.2\n32.6\n30.0\n30.2\n30.4\n32.8\n33.0\n\n\n23.4\n25.8\n26.0\n26.2\n26.0\n26.2\n26.4\n28.6\n28.8\n29.0\n26.2\n26.4\n26.6\n28.8\n\n\n29.0\n29.2\n29.0\n29.2\n29.4\n31.8\n27.8\n28.0\n28.2\n30.4\n30.6\n30.8\n30.6\n30.8\n\n\n31.0\n33.4\n30.8\n31.0\n31.2\n33.6\n33.8\n28.8\n29.0\n29.2\n31.4\n31.6\n31.8\n31.6\n\n\n31.8\n32.0\n34.4\n31.8\n32.0\n32.2\n34.6\n34.8\n33.4\n33.6\n33.8\n36.2\n36.4\n36.6\n\n\n\n\n\nA menor e maior mÃ©dias possÃ­veis sÃ£o 14.6 e 36.6 respectivamente. Estes valores sÃ£o os mais distantes do parÃ¢metro populacional (\\(\\mu = 25.6\\)) e ocorrem puramente ao acaso quanto sÃ£o amostrados os 5 menores (3, 10, 14, 19, 27) ou os 5 maiores (43, 42, 41, 29, 28) elementos da populaÃ§Ã£o estatÃ­stica. Estes casos extremos sÃ£o raros. Em nosso exemplo, valores superiores a 33.8 ou inferiores a 17.4 sÃ£o muito improvÃ¡veis.\nPodemos avaliar graficamente a distribuiÃ§Ã£o das mÃ©dias amostrais atravÃ©s de um histograma. A grande maioria das mÃ©dias amostrais concentra-se na porÃ§Ã£o intermediÃ¡ria do grÃ¡fico entre estes limites. Por exemplo, somente 3.2% das observaÃ§Ãµes estÃ£o acima de 33.8. Da mesma forma, somente 3.2% das observaÃ§Ãµes estÃ£o abaixo de 17.4\n\n\nCÃ³digo\nM_Allcomb_df = data.frame(M = as.numeric(M_Allcomb))\n\ngp5 &lt;- ggplot(M_Allcomb_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"MÃ©dias\",\n       y = \"FrequÃªncia\") +\n  theme_classic()\n\ngp5\n\n\n\n\n\n\n\n\nFiguraÂ 2: Histograma das 252 mÃ©dias amostrais obtidas a partis de amostras de tamanho n = 5.\n\n\n\n\n\nSe calcularmos a mÃ©dia das mÃ©dias (\\(\\mu_{\\overline{X}}\\)), ou seja, somarmos todos estes valores e dividirmos por 252, o resultado serÃ¡ 25.6, que Ã© exatamente o valor da mÃ©dia populacional \\(\\mu\\). Isto tÃªm uma implicaÃ§Ã£o central em inferÃªncia estatÃ­stica. Significa que a mÃ©dia amostral \\(\\overline{X}\\) Ã© um estimador acurado (= nÃ£o-viciado), pois tende a estimar corretamente o valor da mÃ©dia populacional \\(\\mu\\). Ou seja, o histograma acima estÃ¡ centrado ao redor de \\(\\mu\\), o que significa que em mÃ©dia uma amostra particular tem maior probabilidade de expressar um \\(\\overline{X}\\) prÃ³ximo ao valor populacional.\n\n\n4.3 PrecisÃ£o: o erro padrÃ£o da mÃ©dia (\\(\\sigma_{\\overline{X}}\\))\n\n\nCÃ³digo\nn2 = 7\nAllcomb7 = combn(x = pop, m = n2)\nM_Allcomb7 = apply(Allcomb7,2,mean)\nM_Allcomb7_round = round(M_Allcomb7,1)\nCT2 = choose(N,n2)\n\n\nSuponha agora que tomemos ao acaso amostras com \\(n = 7\\) desta mesma populaÃ§Ã£o. Existem ao todo:\n\\[{{10}\\choose{7}} = \\frac{10!}{(10-7)! \\times 7!} = 120\\]\namostras diferentes de tamanho \\(n = 7\\) que podem ser retiradas de uma populaÃ§Ã£o de tamanho \\(n = 10\\). Se tomarmos estas 120 amostras e calcularmos suas respectivas mÃ©dias amostrais, teremos os resultados abaixo:\n\n\nCÃ³digo\nknitr::kable(matrix(M_Allcomb7_round,nc = 12, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.6\n20.3\n20.4\n20.6\n20.4\n20.6\n20.7\n22.3\n22.4\n22.6\n20.6\n20.7\n\n\n20.9\n22.4\n22.6\n22.7\n22.6\n22.7\n22.9\n24.6\n21.7\n21.9\n22.0\n23.6\n\n\n23.7\n23.9\n23.7\n23.9\n24.0\n25.7\n23.9\n24.0\n24.1\n25.9\n26.0\n22.4\n\n\n22.6\n22.7\n24.3\n24.4\n24.6\n24.4\n24.6\n24.7\n26.4\n24.6\n24.7\n24.9\n\n\n26.6\n26.7\n25.7\n25.9\n26.0\n27.7\n27.9\n28.0\n23.0\n23.1\n23.3\n24.9\n\n\n25.0\n25.1\n25.0\n25.1\n25.3\n27.0\n25.1\n25.3\n25.4\n27.1\n27.3\n26.3\n\n\n26.4\n26.6\n28.3\n28.4\n28.6\n27.0\n27.1\n27.3\n29.0\n29.1\n29.3\n30.4\n\n\n24.0\n24.1\n24.3\n25.9\n26.0\n26.1\n26.0\n26.1\n26.3\n28.0\n26.1\n26.3\n\n\n26.4\n28.1\n28.3\n27.3\n27.4\n27.6\n29.3\n29.4\n29.6\n28.0\n28.1\n28.3\n\n\n30.0\n30.1\n30.3\n31.4\n28.6\n28.7\n28.9\n30.6\n30.7\n30.9\n32.0\n32.7\n\n\n\n\n\n\n\nCÃ³digo\nM_Allcomb7_df = data.frame(M = as.numeric(M_Allcomb7))\n\ngp7 &lt;- ggplot(M_Allcomb7_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"MÃ©dia\",\n       y = \"FrequÃªncia\") +\n  theme_classic()\n\ngp7\n\n\n\n\n\n\n\n\nFiguraÂ 3: Histograma das 120 mÃ©dias amostrais obtidas a partis de amostras de tamanho n = 7\n\n\n\n\n\n\n\nCÃ³digo\nmu_pop = mean(pop)\nN = length(pop)\nvar_pop = mean((pop - mu_pop)^2)\nsigma_pop = sqrt(var_pop)\n\nep5 = sigma_pop/sqrt(n)\nep7 = sigma_pop/sqrt(n2)\n\n\nSe compararmos os histogramas com \\(n = 5\\) e \\(n = 7\\) (FiguraÂ 2 e FiguraÂ 3), veremos que os dois resultam em estimadores acurados, pois \\(\\mu_{\\overline{X}} = \\mu\\). No entando, o intervalo de variaÃ§Ã£o Ã© menor para amostras de tamanho \\(n = 7\\). Para esta figura, os valores estÃ£o mais concentrados ao redor da mÃ©dia. Portanto, Ã  medida que aumenta o tamanho amostral, diminui a dispersÃ£o das mÃ©dias amostrais ao redor de \\(\\mu\\). Assim, para amostras grandes torna-se mais improvÃ¡vel obter uma mÃ©dia amostral distante da mÃ©dia populacional. Dizemos entÃ£o que conforme aumenta o tamanho amostral, conseguimos estimativas mais precisas.\nA precisÃ£o de um estimador pode ser medida pelo Erro padrÃ£o da mÃ©dia (\\(\\sigma_{\\overline{X}}\\)) que pode ser calculado por:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nO erro padrÃ£o da mÃ©dia Ã© o desvio padrÃ£o de todas as mÃ©dias amostrais que poderiam ser obtidas de uma amostra com tamanho \\(n\\). Para nosso exemplo com \\(n = 5\\), \\(\\sigma_{\\overline{X}}\\) = 5.93, enquanto para \\(n = 7\\), \\(\\sigma_{\\overline{X}}\\) = 5.01. Dizemos que o Ãºltimo exemplo fornece estimativas mais precisas.\n\n\n\n\n\n\nNotaErro padrÃ£o amostral\n\n\n\nNa prÃ¡tica cientÃ­fica nÃ£o conhecemos o desvio padrÃ£o populacional \\(\\sigma\\) e, consequentemente, nÃ£o temos obter o erro padrÃ£o populacional \\(\\sigma_{\\overline{X}}\\). No entanto, dado que temos uma amostra particular, podemos estimÃ¡-lo a partir do desvio padrÃ£o amostral \\(\\sigma_{\\overline{X}}\\) pela expressÃ£o:\n\\[s_{\\overline{X}} = \\frac{s}{\\sqrt{n}}\\]\nem que \\(s_{\\overline{X}}\\) Ã© denominado de erro padrÃ£o amostral\n\n\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html",
    "href": "content/inferencia-estatistica/teorema-central-limite.html",
    "title": "DistribuiÃ§Ã£o das mÃ©dias amostrais",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource(\"scripts/tcl-simetry.r\")"
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html#teorema-central-do-limite",
    "href": "content/inferencia-estatistica/teorema-central-limite.html#teorema-central-do-limite",
    "title": "DistribuiÃ§Ã£o das mÃ©dias amostrais",
    "section": "1.1 Teorema Central do Limite",
    "text": "1.1 Teorema Central do Limite\nSeja uma populaÃ§Ã£o estatÃ­stica com mÃ©dia \\(\\mu\\) e desvio padrÃ£o \\(\\sigma\\). A distribuiÃ§Ã£o das mÃ©dias amostrais desta populaÃ§Ã£o tenderÃ¡ a apresentar uma distribuiÃ§Ã£o normal de probabilidades com mÃ©dia \\(\\mu\\) e desvio padrÃ£o \\(\\frac{\\sigma}{\\sqrt(n)}\\) Ã  medida que o tamanho amostral \\(n\\) aumenta, ainda que a distribuiÃ§Ã£o das observaÃ§Ãµes originais nÃ£o possua uma distribuiÃ§Ã£o normal.\nSegundo o TCL, as mÃ©dias amostrais \\(\\overline{X}\\) de um experimento distribuem-se como:\n\\[\\overline{X} \\sim \\mathcal{N}(\\mu_{\\overline{X}},\\,\\sigma^{2}_{\\overline{X}})\\]\nem que \\(\\mu_{\\overline{X}} = \\mu\\) \\(\\sigma^{2}_{\\overline{X}} = \\frac{\\sigma^2}{n}\\)\nNote que a variÃ¢ncia de \\(\\overline{X}\\) depende do tamanho amostral \\(n\\).\n\n1.1.1 Probabilidades na amostra original e na distribuiÃ§Ã£o de mÃ©dias\nSeja uma variÃ¡vel \\(X\\) qualquer com \\(\\mu = 50\\) e \\(\\sigma = 10\\). As figuras abaixo comparam as probabilidades acima de \\(x_1 = 55\\) para as observaÃ§Ãµes originais e para as distribuiÃ§Ãµes de mÃ©dias amostrais de tamanho \\(n_1 = 2\\) e \\(n_2 = 10\\).\n\n\n\n\n\n\n\n\nFiguraÂ 3: Probabilidades na amostra original e na distribuiÃ§Ã£o de mÃ©dias.\n\n\n\n\n\nNote que existe uma probabilidade razoÃ¡vel de que uma determinada observaÃ§Ã£o em \\(X\\) esteja acima de \\(55\\), \\(P(X \\leq 55) = 0.309\\). No entando se tomarmos ao acaso uma amostra de tamanho \\(n_1 = 2\\), a probabilidade de que a mÃ©dia destas duas amostras esteja acima de \\(55\\) diminui para \\(P(\\overline{X} \\leq 55) = 0.24\\). Se tormarmos uma amostra ainda maior (\\(n_2 = 10\\)), a probabilidade se reduz ainda mais para \\(P(\\overline{X} \\leq 55) = 0.057\\).\nVemos portanto que a precisÃ£o de um experimento aumenta Ã  medida que aumentamos o tamanho amostral, pois para amostras grandes, a probabilidade de obtermos um \\(\\overline{X}\\) distante de \\(\\mu\\) torna-se cada vez menor.\n\n\n1.1.2 DistribuiÃ§Ãµes nÃ£o-normais\nO TCL Ã© vÃ¡lido inclusive para distribuiÃ§Ãµes nÃ£o-normais. Isto torna a distribuiÃ§Ã£o normal uma das mais importantes em inferÃªncia estatÃ­stica, pois ainda que o resultado de um experimento particular seja descrito por qualquer outro modelo de probabilidades, as mÃ©dias das amostras deste experimento seguirÃ£o uma distribuiÃ§Ã£o normal, Ã  medida que \\(n\\) aumenta. Isto justifica muitos dos processos de anÃ¡lise e inferÃªncia estatÃ­stica que serÃ£o descritos nos capÃ­tulos posteriores.\nA FiguraÂ 4, simula a distribuiÃ§Ã£o de mÃ©dias amostrais para variÃ¡veis com diferentes distribuiÃ§Ãµes de probabiidades e tamanhos crescentes de \\(n\\). Podemos observar que independente do formato da distribuiÃ§Ã£o original, a distribuiÃ§Ã£o das mÃ©dias amostrais tende Ã  normalidade. O padrÃ£o normal aparece mais rÃ¡pido se a distribuiÃ§Ã£o original Ã© simÃ©trica. Ainda que para populaÃ§Ãµes estatÃ­sticas com distribuiÃ§Ãµes assimÃ©tricas, seja necessÃ¡rio um tamanho amostral maior para que se alcance a normalidade, a figura mostra que a partir de \\(n = 30\\) todas as distribuiÃ§Ãµes parecem se aproximar do que seria esperado um modelo normal.\n\n\n\n\n\n\n\n\nFiguraÂ 4: DemostraÃ§Ã£o empÃ­rica do Teorema Central do Limite, mostrando a tendÃªncia Ã  normalidade de \\(\\bar{X}\\) Ã  medina que \\(n\\) aumenta."
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html#exercÃ­cios-resolvidos",
    "href": "content/inferencia-estatistica/teorema-central-limite.html#exercÃ­cios-resolvidos",
    "title": "DistribuiÃ§Ã£o das mÃ©dias amostrais",
    "section": "1.2 ExercÃ­cios resolvidos:",
    "text": "1.2 ExercÃ­cios resolvidos:\n\n1.2.1 Tamanho mÃ©dio de robalos no mercado de peixes\nEm 2014 no estuÃ¡rio do rio ItanhaÃ©m - SP foi pescado o â€œmaior robalo jÃ¡ encontradoâ€ (G1 Santos). O peixe tinha \\(133\\) cm e \\(27,8\\) kg . Em 2018 em Bertioga, tambÃ©m no litoral de SP: â€œRobalo â€˜giganteâ€™ quebra recordes e vira atraÃ§Ã£oâ€ (G1 Santos) pesando \\(33\\) kg. Finalmente, em â€œuma das salas da ColÃ´nia de Pesca Z2 de Atafonaâ€ RJ estÃ¡ uma imagem de um robalo de \\(28\\) kg capturado muitas dÃ©cadas atrÃ¡s (Ambiente Cult)\n\n\n\n\n\n\n\n\n\n\n\n(a) ItanhaÃ©m 2014\n\n\n\n\n\n\n\n\n\n\n\n(b) Bertioga 2018\n\n\n\n\n\n\n\n\n\n\n\n(c) Atafona, sem data\n\n\n\n\n\n\n\nFiguraÂ 5: Grandes robalos\n\n\n\nEstas capturas viram notÃ­cias pois sÃ£o inusitadas. Dados de desembarque sugerem que a distribuiÃ§Ã£o de tamanho de robalos comumente capturados estÃ¡ muito abaixo destes limites (FiguraÂ 6) (Ximenes-Carvalho 2006) ( Acesse aqui o trabalho completo).\n\n\nCÃ³digo\nTabelaI &lt;- data.frame(\n  compmedio = c(25.2, 34.4, 40.7, 46.3, 51.7, 56.5, 61.2, 65.8, 70.3, 73.4, 76.2),\n  N = c(130,130,112,100,82,64,47,30,18,12,6)\n)\n\ntabelaI_plt &lt;- ggplot(data = TabelaI, mapping = aes(x = compmedio, y = N)) +\n   geom_col(fill = 'dodgerblue4', color = 'black') +\n   labs(y = 'NÃºmero de indivÃ­duos analisados',\n        x = 'Comprimento mÃ©dio (cm)') +\n   theme_classic()\n\n\n\n\nCÃ³digo\ntabelaI_plt\n\n\n\n\n\n\n\n\nFiguraÂ 6: Dados de desembarque no Mercado de SÃ£o Pedro (NiterÃ³i, RJ). ExtraÃ­dos de XIMENES-CARVALHO, 2006.\n\n\n\n\n\nA distribuiÃ§Ã£o de tamanhos na FiguraÂ 6 Ã© altamente assimÃ©trica e claramente nÃ£o-normal. Um dos motivos para este forte grau de assimetria deve-se ao limite inferior de captura, pois a captura e comercializaÃ§Ã£o de animais muito pequenos Ã© proibida.\nSuponha que o comprimento de robalos (\\(L\\)) disponÃ­veis para compra tenha mÃ©dia \\(\\mu = 44.1\\) e desvio padrÃ£o \\(\\sigma = 13.4\\). VocÃª compra 10 robalos escolhidos ao acaso dos que estÃ£o disponÃ­veis. Qual a probabilidade de que:\n\nO tamanho mÃ©dio de uma compra esteja acima de \\(52,4\\) cm, isto Ã© \\(P(\\overline{L} &gt; 52,4)\\)?\nEm \\(95\\%\\) das vezes que fizer a compra, determine o intervalo simÃ©trico que conterÃ¡ o tamanho mÃ©dio dos robalos selecionados, isto Ã© \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\nResponda novamente aos itens i. e ii. no caso de sua compra constar de \\(4\\) robalos.\n\nRESOLUÃ‡ÃƒO\nAinda que a distribuiÃ§Ã£o original claramente nÃ£o siga uma distribuiÃ§Ã£o normal, podemos utilizar o TCL para estimarmos as probabilidades de obter uma mÃ©dia amostral \\(\\overline{X}\\) a determinada distÃ¢ncia de \\(\\mu\\). Para isto, no entanto devemos recordar que o desvio padrÃ£o das mÃ©dias amostrais serÃ¡ dado por: \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\n\n\n\n\n\n\nDicai. \\(P(\\overline{L} &gt; 52,4)\\)\n\n\n\n\n\nCom base no TCL, uma amostra de \\(n = 10\\) terÃ¡ mÃ©dia normalmente distribuÃ­da com parÃ¢metros \\(\\mu\\) e \\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{10}}\\). Podemos assim, realizar a transformaÃ§Ã£o \\(Z\\) como segue:\n\\(Z_{\\overline{L}} = \\frac{\\overline{L} - \\mu}{\\sigma_{\\mu}} = \\frac{\\overline{L} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\\(Z_{\\overline{L}} = \\frac{52,4 - 44.1}{\\frac{13.4}{\\sqrt{10}}} = 1.96\\)\nSe buscarmos na Tabela Z, veremos que a Ã¡rea da distribuiÃ§Ã£o normal padronizada abaixo de \\(1.96\\) Ã© de \\(0,975\\). Consequentemente \\(P(\\overline{L} &gt; 52,4) = 1 - 0,975 = 0,025\\)\n\n\n\n\n\n\n\n\n\nDicaii. \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\n\n\n\nSe o intervalo Ã© simÃ©trico e contÃ©m \\(0,95\\) das observaÃ§Ãµes, restam \\(0,025\\) em cada uma das caudas. Vimos no item anterior que \\(z = 1,96\\) que delimita \\(0,025\\) da cauda superior. Portanto os limites aqui serÃ£o dados por: \\(a = -1.96\\) e \\(b = 1.96\\). Na distribuiÃ§Ã£o original estes limites resultarÃ£o em:\n\\(-1,96 = \\frac{a - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: a = 44.1 -1,96 \\frac{13.4}{\\sqrt{10}} = 35.8\\) cm\ne\n\\(+1,96 = \\frac{b - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: b = 44.1 +1,96 \\frac{13.4}{\\sqrt{10}} = 52.4\\) cm\n\n\n\n\n\n\n\n\n\nDicaReduzindo para \\(n = 4\\) robalos\n\n\n\n\n\nAqui vocÃª deve repetir exatamente os passos de i. e ii. substituindo \\(n = 10\\) por \\(n = 4\\).\n\n\n\n\n\n\n\n\n\nDicaRESOLUÃ‡ÃƒO no R:\n\n\n\n\n\n\n\\(P(\\overline{L} &gt; 52,4)\\)\n\n\npnorm(52.4, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\n\n[1] 0.02507255\n\n\n\n\\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\na &lt;- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = TRUE)\na\n\n[1] 35.79475\n\nb &lt;- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\nb\n\n[1] 52.40525\n\n\n\nRepita os comandos acima para \\(n = 4\\)\n\n\n\n\n\n\n\n\n\n\nAvisoAtenÃ§Ã£o\n\n\n\nNeste exercÃ­cio aplicamos o que aprendemos sobre o TCL para estimar probabilidades de eventos, assumindo a distribuiÃ§Ã£o normal das mÃ©dias amostaris. Ã‰ importante resaltar, no entanto, que a distribuiÃ§Ã£o altamente assimÃ©trica do comprimento dos robalos (FiguraÂ 6) e um tamanho amostral reduzido (\\(n = 10\\) e \\(n = 4\\)) dificilmente justificariam o uso do TCL como vemos na FiguraÂ 4.\n\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/introducao-r/data-frames.html",
    "href": "content/introducao-r/data-frames.html",
    "title": "(BÃ¡sico da) ManipulaÃ§Ã£o de data frames",
    "section": "",
    "text": "Embora seja possivel criar um data frame entrando com os dados diretamente via linha de comando, Ã© mais eficiente importÃ¡-los a partir de arquivos texto (.csv, .txt)."
  },
  {
    "objectID": "content/introducao-r/data-frames.html#importando-arquivos-.csv",
    "href": "content/introducao-r/data-frames.html#importando-arquivos-.csv",
    "title": "(BÃ¡sico da) ManipulaÃ§Ã£o de data frames",
    "section": "1 Importando arquivos .csv",
    "text": "1 Importando arquivos .csv\nUm arquivo do tipo .csv pode ser lido com a funÃ§Ã£o read.csv. FaÃ§a o download do conjunto de dados dbenv.csv disponÃ­vel no repositÃ³rio datasets e salve-o em sua pasta de trabalho (ex. \"C:/seu_caminho/Introducao_R\"). Ao abrir o arquivo em algum editor de texto verÃ¡ que ele Ã© composto por \\(30\\) linhas por \\(11\\) colunas.\nApÃ³s fazer o download, vocÃª pode importar o conjunto de dados utilizando o comando:\n\ndbenv &lt;- read.csv(file = \"C:/seu_caminho/Introducao_R/dbenv.csv\", \n                 header = TRUE, dec = '.', sep = ',')\n\nA funÃ§Ã£o read.csv possui diferentes argumentos. A argumento header define se a primeira linha consiste do cabeÃ§alho (TRUE) ou nÃ£o (FALSE). O argumento dec define se o separador decimal consiste de vÃ­rgula ou ponto e o argumento sep informa sobre qual Ã© o caracter separador de colunas utilizado no arquivo. No arquivo em questÃ£o as colunas sÃ£o separadas por vÃ­rgulas. Outros tipos de separadores comuns sÃ£o ponto-e-vÃ­rgula ou tabulaÃ§Ãµes.\nConfira os nomes das \\(11\\) variÃ¡veis (cabeÃ§alho), a dimensÃ£o da tabela (nÃºmero de linhas e colunas) e sua estrutura (um data.frame formado por \\(11\\) vetores numÃ©ricos).\n\ndbenv\n\n    dfs alt   slo  flo pH har pho nit amm oxy bdo\n1     3 934 6.176   84 79  45   1  20   0 122  27\n2    22 932 3.434  100 80  40   2  20  10 103  19\n3   102 914 3.638  180 83  52   5  22   5 105  35\n4   185 854 3.497  253 80  72  10  21   0 110  13\n5   215 849 3.178  264 81  84  38  52  20  80  62\n6   324 846 3.497  286 79  60  20  15   0 102  53\n7   268 841 4.205  400 81  88   7  15   0 111  22\n8   491 792 3.258  130 81  94  20  41  12  70  81\n9   705 752 2.565  480 80  90  30  82  12  72  52\n10  990 617 4.605 1000 77  82   6  75   1 100  43\n11 1234 483 3.738 1990 81  96  30 160   0 115  27\n12 1324 477 2.833 2000 79  86   4  50   0 122  30\n13 1436 450 3.091 2110 81  98   6  52   0 124  24\n14 1522 434 2.565 2120 83  98  27 123   0 123  38\n15 1645 415 1.792 2300 86  86  40 100   0 117  21\n16 1859 375 3.045 1610 80  88  20 200   5 103  27\n17 1985 348 1.792 2430 80  92  20 250  20 102  46\n18 2110 332 2.197 2500 80  90  50 220  20 103  28\n19 2246 310 1.792 2590 81  84  60 220  15 106  33\n20 2477 286 2.197 2680 80  86  30 300  30 103  28\n21 2812 262 2.398 2720 79  85  20 220  10  90  41\n22 2940 254 2.708 2790 81  88  20 162   7  91  48\n23 3043 246 2.565 2880 81  97 260 350 115  63 164\n24 3147 241 1.386 2976 80  99 140 250  60  52 123\n25 3278 231 1.792 3870 79 100 422 620 180  41 167\n26 3579 214 1.792 3910 79  94 143 300  30  62  89\n27 3732 206 2.565 3960 81  90  58 300  26  72  63\n28 3947 195 1.386 4320 83 100  74 400  30  81  45\n29 4220 183 1.946 6770 78 110  45 162  10  90  42\n30 4530 172 1.099 6900 82 109  65 160  10  82  44\n\ncolnames(dbenv)\n\n [1] \"dfs\" \"alt\" \"slo\" \"flo\" \"pH\"  \"har\" \"pho\" \"nit\" \"amm\" \"oxy\" \"bdo\"\n\ndim(dbenv)\n\n[1] 30 11\n\n\n\n\n\n\n\n\nNotaAcessando .csv em uma url\n\n\n\nComo este arquivo estÃ¡ em um repositÃ³rio na nuvem, poderia ser lido acessando diretamente sua url, sem a necessidade de fazer o download:\n\ndbenv &lt;- read.csv(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/dbenv.csv\", \n                 header = TRUE, dec = '.', \n                 sep = ',')\n\n\n\n\n\n\n\n\n\nNotaIniciando uma seÃ§Ã£o de trabalho\n\n\n\nUma seÃ§Ã£o no R, se refere ao ambiente em que ficam armazenados os objetos (vetores, matrizes, data frames, etc.) criados durante o processo de manipulaÃ§Ã£o e anÃ¡lise de dados. Ao fechar uma seÃ§Ã£o do R (ex. ao sair do RStudio), esta pode ser salva guardando os objetos criados. O arquivo de uma seÃ§Ã£o Ã© salvo com extensÃ£o .RData.\nAo abrir um novo script (com extensÃ£o .r) em um editor de texto Ã© importante definir o diretÃ³rio de trabalho, que serÃ¡ o local onde ficarÃ£o dados e onde serÃ£o salvos os resultados do trabalho (ex. figuras, tabelas, etc.). No RStudio, um novo script pode ser aberto via menu Arquivo --&gt; Novo script. Ao iniciar o R-Studio abre-se uma nova seÃ§Ã£o. O diretÃ³rio desta seÃ§Ã£o pode ser verificado pelo comando:\n\ngetwd()\n\nPara criar uma pasta (ex. Introducao_R) e direcionar a seÃ§Ã£o de trabalho para esta pasta utiliza-se a funÃ§Ã£o setwd():\n\nsetwd(\"C:/seu_caminho/Introducao_R\")\n\nA funÃ§Ã£o getwd() pode ser utilizada para verificar se a alteraÃ§Ã£o de diretÃ³rio foi realizada\n\ngetwd()\n\n\n\nC:/seu_caminho/Introducao_R\n\n\nA partir deste momento o R irÃ¡ ler e salvar aquivos sempre a partir desse diretÃ³rio."
  },
  {
    "objectID": "content/introducao-r/data-frames.html#manipulaÃ§Ã£o-de-data-frames",
    "href": "content/introducao-r/data-frames.html#manipulaÃ§Ã£o-de-data-frames",
    "title": "(BÃ¡sico da) ManipulaÃ§Ã£o de data frames",
    "section": "2 ManipulaÃ§Ã£o de data frames",
    "text": "2 ManipulaÃ§Ã£o de data frames\n\n2.1 SeleÃ§Ã£o de linhas e colunas em data frames\nNo data frame os nomes das colunas e linhas podem ser acessados por:\n\ncolnames(dbenv)\n\n [1] \"dfs\" \"alt\" \"slo\" \"flo\" \"pH\"  \"har\" \"pho\" \"nit\" \"amm\" \"oxy\" \"bdo\"\n\n\n\nrownames(dbenv)\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\" \"26\" \"27\" \"28\" \"29\" \"30\"\n\n\nOs nÃºmeros â€œentre aspasâ€ significam que estÃ£o sendo lidos como caracteres.\nColunas especÃ­ficas podem ser acessadas por meio de seus nomes:\n\ncolunas &lt;- c(\"dfs\", \"flo\", \"oxy\")\ndbenv[,colunas]\n\n    dfs  flo oxy\n1     3   84 122\n2    22  100 103\n3   102  180 105\n4   185  253 110\n5   215  264  80\n6   324  286 102\n7   268  400 111\n8   491  130  70\n9   705  480  72\n10  990 1000 100\n11 1234 1990 115\n12 1324 2000 122\n13 1436 2110 124\n14 1522 2120 123\n15 1645 2300 117\n16 1859 1610 103\n17 1985 2430 102\n18 2110 2500 103\n19 2246 2590 106\n20 2477 2680 103\n21 2812 2720  90\n22 2940 2790  91\n23 3043 2880  63\n24 3147 2976  52\n25 3278 3870  41\n26 3579 3910  62\n27 3732 3960  72\n28 3947 4320  81\n29 4220 6770  90\n30 4530 6900  82\n\n\nOu por suas posiÃ§Ãµes:\n\ncolunas_num &lt;- c(1, 3, 4)\ndbenv[,colunas_num]\n\n    dfs   slo  flo\n1     3 6.176   84\n2    22 3.434  100\n3   102 3.638  180\n4   185 3.497  253\n5   215 3.178  264\n6   324 3.497  286\n7   268 4.205  400\n8   491 3.258  130\n9   705 2.565  480\n10  990 4.605 1000\n11 1234 3.738 1990\n12 1324 2.833 2000\n13 1436 3.091 2110\n14 1522 2.565 2120\n15 1645 1.792 2300\n16 1859 3.045 1610\n17 1985 1.792 2430\n18 2110 2.197 2500\n19 2246 1.792 2590\n20 2477 2.197 2680\n21 2812 2.398 2720\n22 2940 2.708 2790\n23 3043 2.565 2880\n24 3147 1.386 2976\n25 3278 1.792 3870\n26 3579 1.792 3910\n27 3732 2.565 3960\n28 3947 1.386 4320\n29 4220 1.946 6770\n30 4530 1.099 6900\n\n\nO mesmo Ã© vÃ¡lido para as linhas.\n\nlinhas &lt;- c(\"3\", \"7\", \"9\")\ndbenv[linhas,]\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n3 102 914 3.638 180 83  52   5  22   5 105  35\n7 268 841 4.205 400 81  88   7  15   0 111  22\n9 705 752 2.565 480 80  90  30  82  12  72  52\n\n\n\nlinhas_num &lt;- c(3, 7, 9)\ndbenv[linhas_num,]\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n3 102 914 3.638 180 83  52   5  22   5 105  35\n7 268 841 4.205 400 81  88   7  15   0 111  22\n9 705 752 2.565 480 80  90  30  82  12  72  52\n\n\nSub-conjunto do data frame podem ser selecionados combinando esses procedimentos.\n\ndbenv[linhas,colunas]\n\n  dfs flo oxy\n3 102 180 105\n7 268 400 111\n9 705 480  72\n\n\n\n\n2.2 Adicionando novas colunas\nEste conjunto de dados mostra medidas fÃ­sicas e quÃ­micas obtidas em um riacho amostrado desde a cabeceira atÃ© a foz. O ponto mais alto (934 m de altitude) estÃ¡ a 3 km da cabeceira enquanto o ponto mais baixo estÃ¡ a 172 m de altitude e a 4530 km da cabeceira. Vamos criar uma nova variÃ¡vel categorizando os trechos do rio em Alto, Medio e Baixo assumindo a seguinte relaÃ§Ã£o:\n\n\\(0\\) a \\(300\\) m: Baixo;\n\\(300\\) a \\(600\\) m: MÃ©dio;\nAcima de \\(600\\) m: Alto.\n\n\nelv_cat &lt;- cut(dbenv$alt, breaks = c(0, 300, 600, 1000), \n              labels = c(\"Baixo\", \"Medio\", \"Alto\"))\n\nA inserÃ§Ã£o do novo objeto elv_cat no data frame pode ser feito simplesmente por:\n\ndbenv$trecho &lt;- elv_cat\n\nA nova coluna denominada trecho foi inserida no data frame, como pode ser visto:\n\nhead(dbenv)\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo trecho\n1   3 934 6.176  84 79  45   1  20   0 122  27   Alto\n2  22 932 3.434 100 80  40   2  20  10 103  19   Alto\n3 102 914 3.638 180 83  52   5  22   5 105  35   Alto\n4 185 854 3.497 253 80  72  10  21   0 110  13   Alto\n5 215 849 3.178 264 81  84  38  52  20  80  62   Alto\n6 324 846 3.497 286 79  60  20  15   0 102  53   Alto\n\n\nO mesmo pode ser realizado com a funÃ§Ã£o transform(). Vamos utilizÃ¡-la para criar uma nova variÃ¡vel categÃ³rica a partir do oxigÃªnio dissolvido, considerando 3 nÃ­veis de satuaÃ§Ã£o: Pobre (\\(0\\) a \\(5\\)), MÃ©dio (\\(5\\) a \\(8\\)) e Saturado (acima de \\(8\\)).\n\ndbenv &lt;- transform(dbenv,  \n saturacao = cut(dbenv$oxy, breaks = c(0, 40, 109, 124), \n           labels = c(\"Pobre\", \"Medio\", \"Saturado\")))\n\nVeja agora o data frame\n\ndbenv\n\n    dfs alt   slo  flo pH har pho nit amm oxy bdo trecho saturacao\n1     3 934 6.176   84 79  45   1  20   0 122  27   Alto  Saturado\n2    22 932 3.434  100 80  40   2  20  10 103  19   Alto     Medio\n3   102 914 3.638  180 83  52   5  22   5 105  35   Alto     Medio\n4   185 854 3.497  253 80  72  10  21   0 110  13   Alto  Saturado\n5   215 849 3.178  264 81  84  38  52  20  80  62   Alto     Medio\n6   324 846 3.497  286 79  60  20  15   0 102  53   Alto     Medio\n7   268 841 4.205  400 81  88   7  15   0 111  22   Alto  Saturado\n8   491 792 3.258  130 81  94  20  41  12  70  81   Alto     Medio\n9   705 752 2.565  480 80  90  30  82  12  72  52   Alto     Medio\n10  990 617 4.605 1000 77  82   6  75   1 100  43   Alto     Medio\n11 1234 483 3.738 1990 81  96  30 160   0 115  27  Medio  Saturado\n12 1324 477 2.833 2000 79  86   4  50   0 122  30  Medio  Saturado\n13 1436 450 3.091 2110 81  98   6  52   0 124  24  Medio  Saturado\n14 1522 434 2.565 2120 83  98  27 123   0 123  38  Medio  Saturado\n15 1645 415 1.792 2300 86  86  40 100   0 117  21  Medio  Saturado\n16 1859 375 3.045 1610 80  88  20 200   5 103  27  Medio     Medio\n17 1985 348 1.792 2430 80  92  20 250  20 102  46  Medio     Medio\n18 2110 332 2.197 2500 80  90  50 220  20 103  28  Medio     Medio\n19 2246 310 1.792 2590 81  84  60 220  15 106  33  Medio     Medio\n20 2477 286 2.197 2680 80  86  30 300  30 103  28  Baixo     Medio\n21 2812 262 2.398 2720 79  85  20 220  10  90  41  Baixo     Medio\n22 2940 254 2.708 2790 81  88  20 162   7  91  48  Baixo     Medio\n23 3043 246 2.565 2880 81  97 260 350 115  63 164  Baixo     Medio\n24 3147 241 1.386 2976 80  99 140 250  60  52 123  Baixo     Medio\n25 3278 231 1.792 3870 79 100 422 620 180  41 167  Baixo     Medio\n26 3579 214 1.792 3910 79  94 143 300  30  62  89  Baixo     Medio\n27 3732 206 2.565 3960 81  90  58 300  26  72  63  Baixo     Medio\n28 3947 195 1.386 4320 83 100  74 400  30  81  45  Baixo     Medio\n29 4220 183 1.946 6770 78 110  45 162  10  90  42  Baixo     Medio\n30 4530 172 1.099 6900 82 109  65 160  10  82  44  Baixo     Medio\n\n\n\n\n2.3 FamÃ­lia apply e aggregate\nEm muitas situaÃ§Ãµes temos interesse aplicar uma determinada funÃ§Ã£o a cada linha ou a cada coluna de um data frame ou ainda para grupos distintos de linhas.\nObserve por exemplo que se extraÃ­mos a mÃ©dia aritmÃ©tica da coluna pH (\\(\\times 10\\)).\n\nmean(dbenv$pH)  # mÃ©dia aritmÃ©tica\n\n[1] 80.5\n\n\nO resultado Ã© calculado para toda a coluna.\n\n\nFunÃ§Ã£o tapply\nPodemos estar interessados no entanto, em extrair as mÃ©dias separadamente para os trechos alto, mÃ©dio e baixo do rio. A funÃ§Ã£o tapply() Ã© Ãºtil nestas situaÃ§Ãµes.\n\ntapply(dbenv$pH, dbenv$trecho, mean)\n\n   Baixo    Medio     Alto \n80.27273 81.22222 80.10000 \n\n\nA funÃ§Ã£o acima, pode ser lida do modo:\n\nSelecione a coluna pH;\nAgrupe os elementos em funÃ§Ã£o dos nÃ­veis em trecho (Baixo, Medio, Alto);\nCalcule a mÃ©dia aritmÃ©tica para cada sub-grupo.\n\nNote que o resultado foi um vetor em que cada elemento corresponde Ã  mÃ©dia de um sub-grupo. FunÃ§Ãµes que retornam mais de um valor resultam em um objeto no formato de lista. A funÃ§Ã£o range() por exemplo, retorna dois valores (mÃ­nimo e mÃ¡ximo). Ao utilizÃ¡-la junto Ã  funÃ§Ã£o tapply() termos como resultado uma lista composta por um vetor para cada subgrupo.\n\ntapply(dbenv$pH, dbenv$trecho, range)\n\n$Baixo\n[1] 78 83\n\n$Medio\n[1] 79 86\n\n$Alto\n[1] 77 83\n\n\n\n\nFunÃ§Ã£o apply\nPodemos aplicar uma determinada funÃ§Ã£o a todas as linhas ou colunas de um data frame (ou matriz).\n\napply(dbenv[,1:5], MARGIN = 2, mean)\n\n        dfs         alt         slo         flo          pH \n1879.033333  481.500000    2.757733 2220.100000   80.500000 \n\n\nO argumento MARGIN = 2 diz que desejamos aplicar a funÃ§Ã£o Ã¡s colunas da matriz. Com MARGIN = 1 aplicamos a funÃ§Ã£o Ã s linhas da matriz.\n\n\nFunÃ§Ã£o lapply\nSe o objeto Ã© do formato lista, o comando lapply() aplica uma funÃ§Ã£o a cada elemento da lista. Considere a lista:\n\nnossalista &lt;- list(Ilha = c(\"Ilhabela\", \"Anchieta\", \"Cardoso\"), \n                  Areaskm2 = c(347.5, 8.3, 131), \n                  Bioma = rep(\"Mata Atlantica\",3),\n                  Lat = c(23, 25, 23),\n                  Long = c(45, 47, 45))\n\nVeja os resultados dos comandos abaixo:\n\nlapply(nossalista, sort)\n\n$Ilha\n[1] \"Anchieta\" \"Cardoso\"  \"Ilhabela\"\n\n$Areaskm2\n[1]   8.3 131.0 347.5\n\n$Bioma\n[1] \"Mata Atlantica\" \"Mata Atlantica\" \"Mata Atlantica\"\n\n$Lat\n[1] 23 23 25\n\n$Long\n[1] 45 45 47\n\n\n\n\n\n\n\n\nNota\n\n\n\nExistem outras funÃ§Ãµes neste grupo, Veja o help() destas funÃ§Ãµes pois sÃ£o extremamente Ãºteis na manipulaÃ§Ã£o de data frames e listas.\n\n?tapply\n?apply\n?lapply\n?mapply\n?replicate\n\n\n\n\n\nFunÃ§Ã£o aggregate\nA funÃ§Ã£o tapply() aplica uma funÃ§Ã£o a subgrupos de uma Ãºnica coluna. A funÃ§Ã£o aggregate() faz o mesmo, porÃ©m para mÃºltiplas colunas agrupadas de acordo com uma ou mais categorias. O comando abaixo calcula os valores mÃ©dios das variÃ¡veis para os trechos alto, mÃ©dio e baixo combinados com nÃ­veis de \\(pH\\).\n\nmedia.trecho &lt;- aggregate(dbenv[, 1:11], \n                         by = list(TRECHO = dbenv$trecho,\n                                   ALCALINO = dbenv$pH &gt;= 80),\n                         FUN = mean)\nmedia.trecho\n\n  TRECHO ALCALINO      dfs      alt      slo       flo       pH      har\n1  Baixo    FALSE 3472.250 222.5000 1.982000 4317.5000 78.75000 97.25000\n2  Medio    FALSE 1324.000 477.0000 2.833000 2000.0000 79.00000 86.00000\n3   Alto    FALSE  439.000 799.0000 4.759333  456.6667 78.33333 62.33333\n4  Baixo     TRUE 3402.286 228.5714 1.986571 3786.5714 81.14286 95.57143\n5  Medio     TRUE 1754.625 393.3750 2.501500 2206.2500 81.50000 91.50000\n6   Alto     TRUE  284.000 847.7143 3.396429  258.1429 80.85714 74.28571\n        pho       nit        amm       oxy      bdo\n1 157.50000 325.50000 57.5000000  70.75000 84.75000\n2   4.00000  50.00000  0.0000000 122.00000 30.00000\n3   9.00000  36.66667  0.3333333 108.00000 41.00000\n4  92.42857 274.57143 39.7142857  77.71429 73.57143\n5  31.62500 165.62500  7.5000000 111.62500 30.50000\n6  16.00000  36.14286  8.4285714  93.00000 40.57143"
  },
  {
    "objectID": "content/introducao-r/data-frames.html#exportando-um-data-frame",
    "href": "content/introducao-r/data-frames.html#exportando-um-data-frame",
    "title": "(BÃ¡sico da) ManipulaÃ§Ã£o de data frames",
    "section": "3 Exportando um data frame",
    "text": "3 Exportando um data frame\nFinalmente, podemos exportar o data frame media.trecho obtido acima para um arquivo Mediaportecho.csv.\n\nwrite.table(media.trecho, file = \"C:/seu_caminho/Introducao_R/Mediaportecho.csv\", \n            sep = \",\", dec = '.', row.names = FALSE, \n            col.names = TRUE)"
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html",
    "href": "content/estatistica-descritiva/varquant.html",
    "title": "Descrevendo variÃ¡veis quantitativas",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nVariÃ¡veis quantitativas podem ser discretas ou contÃ­nuas. A descriÃ§Ã£o dos padrÃµes de distribuiÃ§Ã£o para esses tipos de variÃ¡veis Ã© feita utilizando tabelas (frequÃªncia e frequÃªncia acumulada) e grÃ¡ficos (histogramas ou grÃ¡ficos de frequÃªncia acumulada)."
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html#tabelas-de-frequÃªncia-para-variÃ¡veis-quantitativas",
    "href": "content/estatistica-descritiva/varquant.html#tabelas-de-frequÃªncia-para-variÃ¡veis-quantitativas",
    "title": "Descrevendo variÃ¡veis quantitativas",
    "section": "1 Tabelas de frequÃªncia para variÃ¡veis quantitativas",
    "text": "1 Tabelas de frequÃªncia para variÃ¡veis quantitativas\nA construÃ§Ã£o de tabelas de frequÃªncias para variÃ¡veis quantitativas necessita que agrupemos as observaÃ§Ãµes em faixas de valores. Veja as observaÃ§Ãµes abaixo por exemplo:\n\\(X =\\) {2.66, 3.72, 5.73, 9.08, 2.02, 8.98, 9.45, 6.61, 6.29, 0.62}\nPodemos agrupÃ¡-las nas seguintes faixas de valores:\n(0,2], (2,4], (4,6], (6,8], (8,10]\nEstas faixas de valores sÃ£o denominadas de intervalos de classe. Se alocadas nestes intervalos, as observaÃ§Ãµes ficam:\n\nX &lt;- c(2.66, 3.72, 5.73, 9.08, 2.02, 8.98, 9.45, 6.61, 6.29, 0.62)\nClasses &lt;- cut(X, seq(0, 10, by = 2))\n\ndf &lt;- data.frame(X, Classes)\n\ndf |&gt; \n  gt()\n\n\n\n\n\n\n\nX\nClasses\n\n\n\n\n2.66\n(2,4]\n\n\n3.72\n(2,4]\n\n\n5.73\n(4,6]\n\n\n9.08\n(8,10]\n\n\n2.02\n(2,4]\n\n\n8.98\n(8,10]\n\n\n9.45\n(8,10]\n\n\n6.61\n(6,8]\n\n\n6.29\n(6,8]\n\n\n0.62\n(0,2]\n\n\n\n\n\n\n\nUma tabela de frequÃªncia para estas observaÃ§Ãµes Ã© construÃ­da contando o nÃºmero de observaÃ§Ãµes por intervalo de classes. Neste caso:\n\ndf |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,2]\n1\n\n\n(2,4]\n3\n\n\n(4,6]\n1\n\n\n(6,8]\n2\n\n\n(8,10]\n3\n\n\n\n\n\n\n\nNa coluna Frequencia, temos o nÃºmero de observaÃ§Ãµes da variÃ¡vel X para cada um dos intervalos de classe.\n\n1.1 Alterando o tamanho dos intervalos de classe\nNo exemplo anterior, definimos os limites dos intervalos de classe de 2 em 2 unidades. PoderÃ­amos ter escolhido outros tamanhos, por exemplo, de 4 em 4. Neste caso terÃ­amos:\n\nClasses &lt;- cut(X, seq(0, 12, by = 4))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,4]\n4\n\n\n(4,8]\n3\n\n\n(8,12]\n3\n\n\n\n\n\n\n\nNote que ao escolhermos o tamanho dos intervalos de classe, estamos criando a variÃ¡vel qualitativa ordinal Classes, a partir do agrupamento das observaÃ§Ãµes em X. Neste sentido, nÃ£o hÃ¡ um Ãºnico tamanho correto para os intervalos de classe. O objetivo Ã© encontrar um tamanho que permita evidenciar os padrÃµes de distribuiÃ§Ã£o da variÃ¡vel sem perdermos muitos detalhes.\nPoderÃ­amos escolher um tamanho muito grande, de 5 em 5. Neste caso, terÃ­amos somente 2 grupos.\n\nClasses &lt;- cut(X, seq(0, 10, by = 5))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,5]\n4\n\n\n(5,10]\n6\n\n\n\n\n\n\n\nPor outro lado, poderÃ­amos escolher um tamanho muito pequeno, por exemplo, de 1 em 1.\n\nClasses &lt;- cut(X, seq(0, 10, by = 1))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,1]\n1\n\n\n(2,3]\n2\n\n\n(3,4]\n1\n\n\n(5,6]\n1\n\n\n(6,7]\n2\n\n\n(8,9]\n1\n\n\n(9,10]\n2\n\n\n\n\n\n\n\nNas duas situaÃ§Ãµes, nÃ£o Ã© possÃ­vel evidenciar os padrÃµes de distribuiÃ§Ã£o da variÃ¡vel X. Na primeira, perdemos muita informaÃ§Ã£o agrupando as observaÃ§Ãµes em somente duas faixas e, na Ãºltima, perdemos a capacidade de visualizar os padrÃµes de distribuiÃ§Ã£o de X.\n\n\n1.2 Tabela de frequÃªncia para a CPUE\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nNo objeto res, temos 8 variÃ¡veis quantitativas: Fechamento, Area, pH, Condutividade, Alcalinidade, P.total, Riqueza, CPUE. Vamos verificar como fica uma tabela de frequÃªncias para a variÃ¡vel CPUE, que expressa a captura em \\(kg\\) de peixes em cada reservatÃ³rio. Inicialmente, vamos selecionar somente esta coluna da tabela e visualizÃ¡-la em ordem crescente.\n\nsort(res$CPUE)\n\n [1]  2.05  2.43  4.01  4.71  5.60  5.95  6.29  7.35  7.51  7.75  7.95  9.22\n[13]  9.40 11.59 11.73 11.74 12.55 13.04 13.12 13.67 13.72 13.86 16.10 16.50\n[25] 17.95 20.83 20.92 21.82 24.88 28.73 30.76\n\n\nVemos que o menor valor Ã© 2.05 \\(kg\\) e o maior 30.76 \\(kg\\). Assumindo que temos 31 observaÃ§Ãµes, vamos criar um intervalo de classes de 5 em 5 unidades. Para isso, criaremos a variÃ¡vel cl_cpue, que serÃ¡ uma sequÃªncia de \\(0\\) a \\(35\\), com tamanho \\(5\\). Os valores nesta sequÃªncia sÃ£o os limites de classe.\n\ncl_cpue &lt;- seq(from = 0, to = 35, by = 5)\ncl_cpue\n\n[1]  0  5 10 15 20 25 30 35\n\n\nUtilizaremos os limites de classe para gerar uma nova coluna, delimitando os intervalos a que cada observaÃ§Ã£o pertence. Para isso, utilizaremos a funÃ§Ã£o cut.\n\ntab_cpue &lt;- res |&gt; \n  select(CPUE) |&gt; \n  mutate(int_cpue = cut(CPUE, breaks = cl_cpue))\n\nE veremos a tabela em ordem crescente de classes para facilitar a identificaÃ§Ã£o de padrÃµes.\n\ntab_cpue |&gt; \n  arrange(CPUE) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE\nint_cpue\n\n\n\n\n2.05\n(0,5]\n\n\n2.43\n(0,5]\n\n\n4.01\n(0,5]\n\n\n4.71\n(0,5]\n\n\n5.60\n(5,10]\n\n\n5.95\n(5,10]\n\n\n6.29\n(5,10]\n\n\n7.35\n(5,10]\n\n\n7.51\n(5,10]\n\n\n7.75\n(5,10]\n\n\n7.95\n(5,10]\n\n\n9.22\n(5,10]\n\n\n9.40\n(5,10]\n\n\n11.59\n(10,15]\n\n\n11.73\n(10,15]\n\n\n11.74\n(10,15]\n\n\n12.55\n(10,15]\n\n\n13.04\n(10,15]\n\n\n13.12\n(10,15]\n\n\n13.67\n(10,15]\n\n\n13.72\n(10,15]\n\n\n13.86\n(10,15]\n\n\n16.10\n(15,20]\n\n\n16.50\n(15,20]\n\n\n17.95\n(15,20]\n\n\n20.83\n(20,25]\n\n\n20.92\n(20,25]\n\n\n21.82\n(20,25]\n\n\n24.88\n(20,25]\n\n\n28.73\n(25,30]\n\n\n30.76\n(30,35]\n\n\n\n\n\n\n\nA nova tabela tab_cpue tem agora duas colunas: os valores numÃ©ricos de CPUE e os valores transformados em intervalos de classe, int_cpue. Ã‰ com esta Ãºltima que montaremos a tabela de frequÃªncia.\n\nfre_cpue &lt;- tab_cpue |&gt; \n  group_by(int_cpue) |&gt; \n  summarise(Frequencia = n())\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\n\n\n\n\n(0,5]\n4\n\n\n(5,10]\n9\n\n\n(10,15]\n9\n\n\n(15,20]\n3\n\n\n(20,25]\n4\n\n\n(25,30]\n1\n\n\n(30,35]\n1\n\n\n\n\n\n\n\nE, em seguida, de frequÃªncia relativa:\n\nfre_cpue &lt;- fre_cpue |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\nFreq_relativa\n\n\n\n\n(0,5]\n4\n0.12903226\n\n\n(5,10]\n9\n0.29032258\n\n\n(10,15]\n9\n0.29032258\n\n\n(15,20]\n3\n0.09677419\n\n\n(20,25]\n4\n0.12903226\n\n\n(25,30]\n1\n0.03225806\n\n\n(30,35]\n1\n0.03225806\n\n\n\n\n\n\n\nVeja que os intervalos de (5,10] e (10,15] contÃªm o maior nÃºmero de observaÃ§Ãµes, cerca de 29% cada um, e que acima de \\(25\\) \\(kg\\) temos somente duas observaÃ§Ãµes.\n\n\n1.3 Tabela de frequÃªncia acumulada\nOutra forma de representar o padrÃ£o de distribuiÃ§Ã£o para uma variÃ¡vel quantitativa Ã© apresentÃ¡-la em uma tabela de frequÃªncia acumulada. Fazemos isso somando de forma cumulativa as observaÃ§Ãµes em cada classe de intervalo e criando duas colunas adicionais de frequÃªncia acumulada e de frequÃªncia relativa acumulada.\n\nfre_cpue &lt;- fre_cpue |&gt; \n  mutate(F_acumulada = cumsum(Frequencia),\n         FR_acumulada = cumsum(Freq_relativa))\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\nFreq_relativa\nF_acumulada\nFR_acumulada\n\n\n\n\n(0,5]\n4\n0.12903226\n4\n0.1290323\n\n\n(5,10]\n9\n0.29032258\n13\n0.4193548\n\n\n(10,15]\n9\n0.29032258\n22\n0.7096774\n\n\n(15,20]\n3\n0.09677419\n25\n0.8064516\n\n\n(20,25]\n4\n0.12903226\n29\n0.9354839\n\n\n(25,30]\n1\n0.03225806\n30\n0.9677419\n\n\n(30,35]\n1\n0.03225806\n31\n1.0000000\n\n\n\n\n\n\n\nVeja agora que a Ãºltima linha da coluna de frequÃªncia acumulada Ã© igual ao nÃºmero de observaÃ§Ãµes total e que a da frequÃªncia relativa acumulada Ã© igual a 1."
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html#representaÃ§Ã£o-grÃ¡fica-histogramas",
    "href": "content/estatistica-descritiva/varquant.html#representaÃ§Ã£o-grÃ¡fica-histogramas",
    "title": "Descrevendo variÃ¡veis quantitativas",
    "section": "2 RepresentaÃ§Ã£o grÃ¡fica: histogramas",
    "text": "2 RepresentaÃ§Ã£o grÃ¡fica: histogramas\nHistogramas sÃ£o representaÃ§Ãµes das tabelas de frequÃªncia e de frequÃªncia relativa. Um histograma da coluna CPUE pode ser feito com o comando:\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nOs intervalos de classe foram escolhidos automaticamente pela funÃ§Ã£o geom_histogram. Se quisermos ter o controle sobre estes intervalos, podemos adicionar o argumento breaks e a sequÃªncia com os limites de classe que criamos anteriormente:\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram(breaks = cl_cpue)\n\n\n\n\n\n\n\n\nA formataÃ§Ã£o do histograma acima pode ser melhorada de diversas formas, por exemplo:\n\nggplot(res, aes(x = CPUE, label = after_stat(count))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'FrequÃªncia') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nModificamos a cor do preenchimento (fill = 'darkblue'), e identificamos as barras individualmente traÃ§ando uma linha branca entre elas (color = 'white');\nReescrevemos o rÃ³tulo dos eixos \\(x\\) e \\(y\\) (labs());\nIdentificamos as frequÃªncias em cada barra individualmente com o argumento label = after_stat(count) e a funÃ§Ã£o geom_text;\nModificamos o tema do grÃ¡fico para obter uma alteraÃ§Ã£o geral na aparÃªncia da figura. Existem diversos outros temas possÃ­veis que podem ser vistos aqui.\n\nUm histograma com a frequÃªncia relativa pode ser obtido com:\n\nggplot(res, aes(x = CPUE,\n                y = after_stat(count)/sum(after_stat(count)),\n                label = round(after_stat(count)/sum(after_stat(count)), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'FrequÃªncia relativa') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\nAqui fizemos duas mudanÃ§as: + Inserimos o argumento y = after_stat(count)/sum(after_stat(count)) para dizer que as barras em \\(y\\) devem mostrar a contagem do nÃºmero de observaÃ§Ãµes em cada intervalo dividido pelo total; + Modificamos o argumento label = round(after_stat(count)/sum(after_stat(count)), 2) de modo que tambÃ©m mostre a frequÃªncia relativa, utilizando a funÃ§Ã£o round.\n\n2.1 Representando frequÃªncias acumuladas\nA Ãºnica modificaÃ§Ã£o neste caso serÃ¡ identificarmos o eixo \\(y\\) por sua contagem acumulada: y = cumsum(after_stat(count)).\n\nggplot(res, aes(x = CPUE,\n                y = cumsum(after_stat(count)),\n                label = round(cumsum(after_stat(count)), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'FrequÃªncia acumulada') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\nPara fazer o mesmo mostrando as frequÃªncias relativas, fazemos:\n\nggplot(res, aes(x = CPUE,\n                y = cumsum(after_stat(count)/sum(after_stat(count))),\n                label = round(cumsum(after_stat(count)/sum(after_stat(count))), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'FrequÃªncia acumulada relativa') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()"
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html",
    "href": "content/estatistica-descritiva/varqualit.html",
    "title": "Descrevendo variÃ¡veis qualitativas",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nVariÃ¡veis qualitativas podem ser categÃ³ricas nÃ£o ordenadas ou categÃ³ricas ordenadas. A descriÃ§Ã£o de variÃ¡veis desta natureza se dÃ¡ por meio da contagem e da representaÃ§Ã£o dos nÃ­veis destas variÃ¡veis por meio da contagem total, pelos valores relativos ou percentuais.\nImporte a base de dados Reservatorios_Parana_parcial.csv.\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"UTF-8\")\n)\nNa tabela, temos 3 variÃ¡veis categÃ³ricas: Reservatorio, Bacia e Trofia. A primeira identifica cada reservatÃ³rio pelo seu nome. A segunda Ã© uma variÃ¡vel categÃ³rica nÃ£o ordenada (nÃ­vel de mensuraÃ§Ã£o nominal) e a terceira uma variÃ¡vel categÃ³rica ordenada (nÃ­vel de mensuraÃ§Ã£o ordinal)."
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#representaÃ§Ã£o-em-tabelas-de-frequÃªncia",
    "href": "content/estatistica-descritiva/varqualit.html#representaÃ§Ã£o-em-tabelas-de-frequÃªncia",
    "title": "Descrevendo variÃ¡veis qualitativas",
    "section": "1 RepresentaÃ§Ã£o em tabelas de frequÃªncia",
    "text": "1 RepresentaÃ§Ã£o em tabelas de frequÃªncia\nSe uma variÃ¡vel Ã© descrita no nÃ­vel de mensuraÃ§Ã£o nominal, como Ã© o caso de Bacia, podemos obter a frequÃªncia com que cada um dos nÃ­veis aparece na variÃ¡vel. Essa contagem pode ser obtida por meio de uma tabela de frequÃªncias.\n\nfbacia &lt;- res |&gt; \n  group_by(Bacia) |&gt; \n  summarise(Frequencia = n())\n\nfbacia |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\n\n\n\n\nIguacu\n13\n\n\nIvai\n2\n\n\nLitoranea\n4\n\n\nParanapanema\n7\n\n\nPiriqui\n2\n\n\nTibagi\n3\n\n\n\n\n\n\n\nO resultado mostra que existem 13 reservatÃ³rios na tabela pertencentes Ã  bacia do rio Iguacu, 2 Ã  bacia do rio Ivai e assim por diante. Confira estas contagens na base de dados.\nAs linhas da tabela estÃ£o organizadas em ordem alfabÃ©tica. Para facilitar a visualizaÃ§Ã£o, podemos ordenÃ¡-las de modo decrescente como funÃ§Ã£o do nÃºmero de reservatÃ³rios por bacia.\n\nfbacia &lt;- fbacia |&gt; \n  arrange(desc(Frequencia))\n\nfbacia |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\n\n\n\n\nIguacu\n13\n\n\nParanapanema\n7\n\n\nLitoranea\n4\n\n\nTibagi\n3\n\n\nIvai\n2\n\n\nPiriqui\n2\n\n\n\n\n\n\n\nPodemos olhar tambÃ©m para a frequÃªncia relativa do nÃºmero de reservatÃ³rios por bacia.\n\nfbacia_rel &lt;- fbacia |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nfbacia_rel |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\nFreq_relativa\n\n\n\n\nIguacu\n13\n0.41935484\n\n\nParanapanema\n7\n0.22580645\n\n\nLitoranea\n4\n0.12903226\n\n\nTibagi\n3\n0.09677419\n\n\nIvai\n2\n0.06451613\n\n\nPiriqui\n2\n0.06451613\n\n\n\n\n\n\n\nA caracterÃ­stica da frequÃªncia relativa Ã© que o somatÃ³rio da coluna deve ser igual a 1, enquanto a frequÃªncia numÃ©rica tem o somatÃ³rio igual ao nÃºmero de linhas na tabela.\n\nfbacia_rel |&gt; \n  summarise_if(is.numeric, sum) |&gt; \n  gt()\n\n\n\n\n\n\n\nFrequencia\nFreq_relativa\n\n\n\n\n31\n1"
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#tabelas-de-frequÃªncia-para-variÃ¡veis-categÃ³ricas-ordenadas",
    "href": "content/estatistica-descritiva/varqualit.html#tabelas-de-frequÃªncia-para-variÃ¡veis-categÃ³ricas-ordenadas",
    "title": "Descrevendo variÃ¡veis qualitativas",
    "section": "2 Tabelas de frequÃªncia para variÃ¡veis categÃ³ricas ordenadas",
    "text": "2 Tabelas de frequÃªncia para variÃ¡veis categÃ³ricas ordenadas\nA caracterÃ­stica da variÃ¡vel Trofia difere da anterior unicamente por ser uma variÃ¡vel categÃ³rica ordenada que, no caso, expressa o grau de eutrofizaÃ§Ã£o dos reservatÃ³rios. Neste sentido, a Ãºnica mudanÃ§a na representaÃ§Ã£o da variÃ¡vel se deve ao fato de que existe uma sequÃªncia natural para representar os nÃ­veis. Podemos indicar que uma determinada variÃ¡vel Ã© categÃ³rica ordenada fazendo uma pequena alteraÃ§Ã£o na base de dados.\nSe montarmos uma tabela de frequÃªncia da variÃ¡vel Trofia, teremos as linhas organizadas em ordem alfabÃ©tica:\n\nftrofia &lt;- res |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nEutrÃ³fico\n2\n\n\nMesotrÃ³fico\n3\n\n\nOligotrÃ³fico\n24\n\n\nNA\n2\n\n\n\n\n\n\n\nSe desejarmos que as colunas apareÃ§am como funÃ§Ã£o do nÃ­vel de eutrofizaÃ§Ã£o, devemos primeiro transformar a variÃ¡vel Trofia em um fator ordenado, que Ã© o modo como o R interpreta uma variÃ¡vel categÃ³rica ordenada.\nInicialmente, use o comando abaixo para verificar que o R entende a variÃ¡vel Trofia como um character (&lt;chr&gt;).\n\nglimpse(res)\n\nRows: 31\nColumns: 11\n$ Reservatorio  &lt;chr&gt; \"Cavernoso\", \"Curucaca\", \"Foz do Areia\", \"Irai\", \"JMF\", â€¦\n$ Bacia         &lt;chr&gt; \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacâ€¦\n$ Fechamento    &lt;dbl&gt; 1965, 1982, 1980, 2000, 1970, 1996, 1978, 1979, 1998, 19â€¦\n$ Area          &lt;dbl&gt; 2.90, 2.00, 139.00, 15.00, 0.45, 3.40, 14.00, 3.30, 124.â€¦\n$ Trofia        &lt;chr&gt; \"OligotrÃ³fico\", \"OligotrÃ³fico\", \"OligotrÃ³fico\", \"EutrÃ³fiâ€¦\n$ pH            &lt;dbl&gt; 7.4, 7.0, 7.3, 6.9, 7.3, 7.1, 8.8, 7.1, 7.3, 6.5, 8.6, 9â€¦\n$ Condutividade &lt;dbl&gt; 33.1, 32.4, 35.5, 50.2, 40.2, 23.7, 125.6, 22.8, 39.6, 2â€¦\n$ Alcalinidade  &lt;dbl&gt; 139.80, 125.70, 97.00, 3.30, 3.70, 152.70, 526.00, 50.67â€¦\n$ P.total       &lt;dbl&gt; 7.8, 4.7, 14.3, 53.4, 41.2, 3.3, 15.2, 4.5, 12.1, 11.0, â€¦\n$ Riqueza       &lt;dbl&gt; 18, 16, 19, 12, 18, 17, 11, 8, 21, 8, 24, 21, 22, 15, 10â€¦\n$ CPUE          &lt;dbl&gt; 9.22, 28.73, 11.59, 30.76, 5.95, 7.75, 7.51, 4.01, 20.83â€¦\n\n\nIremos transformar esta variÃ¡vel para que o R a interprete como uma variÃ¡vel categÃ³rica ordenada.\n\nres &lt;- res |&gt; \n  mutate(Trofia = factor(Trofia, ordered = TRUE, \n                         levels = c(\"OligotrÃ³fico\", \n                                    \"MesotrÃ³fico\", \n                                    \"EutrÃ³fico\")))\n\nApÃ³s aplicarmos este comando, vemos que agora o R reconhece esta variÃ¡vel como do tipo &lt;ord&gt;:\n\nglimpse(res)\n\nRows: 31\nColumns: 11\n$ Reservatorio  &lt;chr&gt; \"Cavernoso\", \"Curucaca\", \"Foz do Areia\", \"Irai\", \"JMF\", â€¦\n$ Bacia         &lt;chr&gt; \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacâ€¦\n$ Fechamento    &lt;dbl&gt; 1965, 1982, 1980, 2000, 1970, 1996, 1978, 1979, 1998, 19â€¦\n$ Area          &lt;dbl&gt; 2.90, 2.00, 139.00, 15.00, 0.45, 3.40, 14.00, 3.30, 124.â€¦\n$ Trofia        &lt;ord&gt; OligotrÃ³fico, OligotrÃ³fico, OligotrÃ³fico, EutrÃ³fico, Mesâ€¦\n$ pH            &lt;dbl&gt; 7.4, 7.0, 7.3, 6.9, 7.3, 7.1, 8.8, 7.1, 7.3, 6.5, 8.6, 9â€¦\n$ Condutividade &lt;dbl&gt; 33.1, 32.4, 35.5, 50.2, 40.2, 23.7, 125.6, 22.8, 39.6, 2â€¦\n$ Alcalinidade  &lt;dbl&gt; 139.80, 125.70, 97.00, 3.30, 3.70, 152.70, 526.00, 50.67â€¦\n$ P.total       &lt;dbl&gt; 7.8, 4.7, 14.3, 53.4, 41.2, 3.3, 15.2, 4.5, 12.1, 11.0, â€¦\n$ Riqueza       &lt;dbl&gt; 18, 16, 19, 12, 18, 17, 11, 8, 21, 8, 24, 21, 22, 15, 10â€¦\n$ CPUE          &lt;dbl&gt; 9.22, 28.73, 11.59, 30.76, 5.95, 7.75, 7.51, 4.01, 20.83â€¦\n\n\nE se fizermos:\n\nres$Trofia\n\n [1] OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico EutrÃ³fico    MesotrÃ³fico \n [6] OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico\n[11] OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico MesotrÃ³fico \n[16] OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico MesotrÃ³fico  OligotrÃ³fico\n[21] OligotrÃ³fico OligotrÃ³fico OligotrÃ³fico &lt;NA&gt;         OligotrÃ³fico\n[26] OligotrÃ³fico EutrÃ³fico    OligotrÃ³fico OligotrÃ³fico &lt;NA&gt;        \n[31] OligotrÃ³fico\nLevels: OligotrÃ³fico &lt; MesotrÃ³fico &lt; EutrÃ³fico\n\n\nTemos agora a indicaÃ§Ã£o de que hÃ¡ uma ordenaÃ§Ã£o sequencial nos nÃ­veis de trofia em que OligotrÃ³fico &lt; MesotrÃ³fico &lt; EutrÃ³fico.\nA partir de agora, se extrairmos uma tabela de frequÃªncia relativa, as linhas serÃ£o apresentadas na ordem prÃ©-definida.\n\nftrofia &lt;- res |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nOligotrÃ³fico\n24\n\n\nMesotrÃ³fico\n3\n\n\nEutrÃ³fico\n2\n\n\nNA\n2\n\n\n\n\n\n\n\nNa tabela acima, a Ãºltima linha aparece vazia, pois hÃ¡ casos sem informaÃ§Ã£o, isto Ã©, com dados faltantes que sÃ£o representados por NA. Caso vocÃª nÃ£o queira representar os dados faltantes, Ã© possÃ­vel utilizar a funÃ§Ã£o drop_na() para excluir estas linhas.\n\nftrofia &lt;- res |&gt; \n  drop_na(Trofia) |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nOligotrÃ³fico\n24\n\n\nMesotrÃ³fico\n3\n\n\nEutrÃ³fico\n2\n\n\n\n\n\n\n\nPodemos adicionar uma coluna de frequÃªncia relativa como fizemos anteriormente.\n\nftrofia_rel &lt;- ftrofia |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nftrofia_rel |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\nFreq_relativa\n\n\n\n\nOligotrÃ³fico\n24\n0.82758621\n\n\nMesotrÃ³fico\n3\n0.10344828\n\n\nEutrÃ³fico\n2\n0.06896552"
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#representaÃ§Ã£o-grÃ¡fica",
    "href": "content/estatistica-descritiva/varqualit.html#representaÃ§Ã£o-grÃ¡fica",
    "title": "Descrevendo variÃ¡veis qualitativas",
    "section": "3 RepresentaÃ§Ã£o grÃ¡fica",
    "text": "3 RepresentaÃ§Ã£o grÃ¡fica\nVariÃ¡veis categÃ³ricas nÃ£o ordenadas ou ordenadas podem ser representadas por grÃ¡ficos de barras.\n\n\n\n\n\n\nNotaO pacote ggplot2\n\n\n\nUtilizaremos o pacote ggplot2 para representar graficamente as variÃ¡veis. O ggplot2 Ã© instalado e habilitado juntamente com o tidyverse, de modo que neste momento vocÃª jÃ¡ o tem habilitado em sua sessÃ£o do R.\nPara uma rÃ¡pida explicaÃ§Ã£o do ggplot2, veja aqui. Para uma explicaÃ§Ã£o detalhada, veja o site oficial (ggplot2){target=â€œ_blankâ€} e o livro ggplot2: Elegant Graphics for Data Analysis.\n\n\n\n3.1 Criando um grÃ¡fico no ggplot2\nUm grÃ¡fico no ggplot2 Ã© feito em camadas que devem ter minimamente:\n\nA definiÃ§Ã£o da tabela de dados;\nA estÃ©tica grÃ¡fica indicando quais variÃ¡veis serÃ£o representadas e suas posiÃ§Ãµes no grÃ¡fico;\nO formato da representaÃ§Ã£o por meio de geometrias grÃ¡ficas (ex. grÃ¡ficos de pontos, linhas, barras, etc.).\n\nEsta abordagem permite que tenhamos um mÃ©todo consistente para construir diferentes tipos de grÃ¡ficos.\nGrÃ¡fico de frequÃªncia\nUm grÃ¡fico de barras da variÃ¡vel Bacia ficaria:\n\nggplot(data = res) + # define tabela de dados\n  aes(x = Bacia) +   # define a estÃ©tica grÃ¡fica\n  geom_bar()         # define a geometria grÃ¡fica\n\n\n\n\n\n\n\n\nVamos entender o comando:\n\nggplot(res): define a tabela de dados que serÃ¡ utilizada.\naes(x = Bacia): define que o eixo x deste grÃ¡fico deverÃ¡ conter os nÃ­veis da variÃ¡vel Bacia.\ngeom_bar(): define o tipo grÃ¡fico, que no ggplot2 Ã© denominado de geometria grÃ¡fica.\n\nEstes argumentos devem ser inseridos sequencialmente separados pelo sÃ­mbolo +.\nO argumento geom_bar() espera como argumento uma variÃ¡vel qualitativa em um dos eixos. Por padrÃ£o, a funÃ§Ã£o farÃ¡ a contagem dos nÃ­veis dentro da variÃ¡vel e representarÃ¡ no eixo y.\nPoderÃ­amos ter feito o mesmo grÃ¡fico de barras indicando que a variÃ¡vel Bacia seria representada no eixo y, o que resultaria em um grÃ¡fico de barras invertido conforme abaixo:\n\nggplot(data = res) +\n  aes(y = Bacia) +\n  geom_bar()\n\n\n\n\n\n\n\n\nA estÃ©tica grÃ¡fica (aes()) nÃ£o precisa estar em uma linha separada. TambÃ©m nÃ£o Ã© obrigatÃ³rio escrevermos data = res. De fato, Ã© mais comum escrevermos esta sequÃªncia de argumentos como:\n\nggplot(res, mapping = aes(x = Bacia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nou simplesmente:\n\nggplot(res, aes(x = Bacia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\no que irÃ¡ gerar os mesmos resultados.\nFinalmente, poderÃ­amos organizar as barras em ordem decrescente como fizemos com as tabelas de frequÃªncia, utilizando a funÃ§Ã£o fct_infreq():\n\nggplot(res, aes(x = fct_infreq(Bacia))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nou em ordem crescente, revertendo o comando anterior com a funÃ§Ã£o fct_rev().\n\nggplot(res, aes(x = fct_rev(fct_infreq(Bacia)))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nFormatando a figura\nPara tornar a figura mais autoexplicativa, podemos adicionar camadas identificando os eixos e fornecendo tÃ­tulo, subtÃ­tulo e outras informaÃ§Ãµes:\n\nggplot(res, aes(x = Bacia)) +\n  geom_bar() +\n  labs(\n    title = \"ReservatÃ³rios do Estado do ParanÃ¡\",\n    subtitle = \"ReservatÃ³rios por bacia hidrogrÃ¡fica\",\n    caption = \"Dados obtidos do livro: Biocenoses em ReservatÃ³rios\",\n    x = \"Bacia hidrogrÃ¡fica\",\n    y = \"FrequÃªncia\"\n  )\n\n\n\n\n\n\n\n\nGrÃ¡fico de frequÃªncia relativa\nUtilizando o ggplot2, Ã© simples construir um grÃ¡fico de frequÃªncia relativa.\n\nggplot(res, aes(x = Bacia, y = after_stat(prop), group = 1)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nVeja que para isso transformamos as contagens em proporÃ§Ãµes. Se quisermos transformar em percentuais, entÃ£o:\n\nggplot(res, aes(x = Bacia, y = after_stat(prop), group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\n\nOutras opÃ§Ãµes para construir um grÃ¡fico de barras\nAs figuras que acabamos de fazer apresentam, de modo grÃ¡fico, as mesmas informaÃ§Ãµes das tabelas de frequÃªncia vistas no inÃ­cio do capÃ­tulo sem que fosse necessÃ¡rio construir a tabela de frequÃªncia, pois o comando geom_bar() jÃ¡ realiza esta contagem.\nEntretanto, caso jÃ¡ tivÃ©ssemos a tabela de frequÃªncia, tambÃ©m poderÃ­amos utilizÃ¡-la diretamente. No inÃ­cio do capÃ­tulo, construÃ­mos a tabela fbacia_rel, onde tÃ­nhamos 3 colunas: Bacia, Frequencia, Freq_relativa.\nPodemos construir grÃ¡ficos de barras das tabelas Frequencia ou Freq_relativa da seguinte forma:\n\nggplot(fbacia_rel, aes(x = Bacia, y = Frequencia)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\ne\n\nggplot(fbacia_rel, aes(x = Bacia, y = Freq_relativa)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nPara utilizar diretamente uma tabela de frequÃªncias, devemos oferecer a variÃ¡vel do eixo x, do eixo y e, no comando geom_bar(), adicionar o argumento stat = \"identity\". Feito isso, o comando utiliza diretamente os nÃºmeros disponÃ­veis em cada linha da coluna Frequencia.\n\nGrÃ¡fico de frequÃªncia para variÃ¡veis categÃ³ricas ordenadas\nPara variÃ¡veis categÃ³ricas ordenadas, valem os mesmos comandos apresentados acima. Usamos a funÃ§Ã£o geom_bar() para construir os grÃ¡ficos de barras. A diferenÃ§a Ã© que, antes da construÃ§Ã£o, Ã© necessÃ¡rio que a variÃ¡vel em questÃ£o tenha sido transformada para um fator ordenado.\nLembrando o que fizemos no inÃ­cio do capÃ­tulo, esta transformaÃ§Ã£o pode ser feita para a variÃ¡vel Trofia com os comandos:\n\nres &lt;- res |&gt; \n  mutate(Trofia = factor(Trofia, ordered = TRUE, \n                         levels = c(\"OligotrÃ³fico\", \n                                    \"MesotrÃ³fico\", \n                                    \"EutrÃ³fico\")))\n\nFeito isso, o comando geom_bar() vai organizar os nÃ­veis de acordo com a sequÃªncia definida:\n\nggplot(res, aes(x = Trofia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nE caso seja necessÃ¡rio retirar reservatÃ³rios com dados faltantes em Trofia, podemos fazer:\n\nres |&gt; \n  drop_na(Trofia) |&gt; \n  ggplot(aes(x = Trofia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotaPrÃ©-processamento do data-frame para o ggplot2\n\n\n\nNo comando acima, a tabela de dados nÃ£o foi inserida dentro do comando ggplot(). Ela foi inicialmente processada para remoÃ§Ã£o de NAs com a funÃ§Ã£o drop_na() e o operador |&gt; foi utilizado para inserir o resultado do processamento no ggplot(). Esta Ã© outra maneira de combinar capacidade de processamento de dados no R com a representaÃ§Ã£o grÃ¡fica do pacote ggplot2."
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html",
    "href": "content/estatistica-descritiva/escorez.html",
    "title": "Medidas de posiÃ§Ã£o: transformaÃ§Ã£o Z",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')\nO Ã­ndice (ou escore) \\(Z\\) indica a posiÃ§Ã£o de uma observaÃ§Ã£o particular (\\(X_i\\)) dentro de uma distribuiÃ§Ã£o, relacionando a posiÃ§Ã£o de \\(X_i\\) com a mÃ©dia e o desvio padrÃ£o da distribuiÃ§Ã£o de \\(X\\). Suponha uma variÃ¡vel com mÃ©dia \\(\\overline{X}\\) e desvio padrÃ£o \\(s\\). O Ã­ndice de \\(Z_i\\) para uma observaÃ§Ã£o \\(i\\) particular Ã© calculado por:\n\\[Z_i = \\frac{X_i - \\overline{X}}{s}\\]\nSeja, por exemplo, a variÃ¡vel \\(X\\):\nCÃ³digo\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\nnX &lt;- length(X)\nsX &lt;- sort(X)\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\nCom mÃ©dia e desvio padrÃ£o \\(\\overline{X} = 10.39\\) e \\(s = 1.82\\), respectivamente.\nO Ã­ndice \\(Z_i\\) para a \\(3a\\) observaÃ§Ã£o \\(X_{3} = 8.3\\) pode ser obtido por:\nCÃ³digo\ni &lt;- 3\nXm &lt;- mean(X)\nXsd &lt;- sd(X)\nZi &lt;- (X[i] - Xm) / Xsd\n\\(Z_8.3 = \\frac{8.3 - 10.39}{1.82} = -1.15\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#interpretando-o-valor-de-z",
    "href": "content/estatistica-descritiva/escorez.html#interpretando-o-valor-de-z",
    "title": "Medidas de posiÃ§Ã£o: transformaÃ§Ã£o Z",
    "section": "1 Interpretando o valor de \\(Z\\)",
    "text": "1 Interpretando o valor de \\(Z\\)\nO cÃ¡lculo do Ã­ndice \\(Z\\) passa pela centralizaÃ§Ã£o e padronizaÃ§Ã£o da variÃ¡vel \\(X\\):\n\nCentralizaÃ§Ã£o: a porÃ§Ã£o \\(X_i - \\overline{X}\\) mede o desvio de cada observaÃ§Ã£o, isto Ã©, a distÃ¢ncia (positiva ou negativa) entre \\(X_i\\) e \\(\\overline{X}\\). O termo centralizaÃ§Ã£o refere-se ao comportamento dos desvios estarem distribuÃ­dos ao redor de zero, isto Ã©, a mÃ©dia dos desvios Ã© zero.\n\n\\[\\sum_{i=1}^{n}\\frac{(X_i - \\overline{X})}{n} = 0\\]\n\nPadronizaÃ§Ã£o: ao dividirmos a quantia \\(X_i - \\overline{X}\\) pelo desvio padrÃ£o de \\(X\\), obtemos a nova variÃ¡vel denominada \\(Z\\). O termo padronizaÃ§Ã£o refere-se ao fato de o desvio padrÃ£o de \\(Z\\) ser igual a \\(1\\).\n\nA transformaÃ§Ã£o \\(Z\\) consiste, portanto, em gerar uma nova variÃ¡vel com mÃ©dia \\(\\overline{Z} = 0\\) e desvio padrÃ£o \\(s_{Z} = 1\\).\nDeste modo, o valor de \\(Z_i\\) associado a uma observaÃ§Ã£o \\(X_i\\) particular nos indica quantos desvios padrÃµes \\(X_i\\) estÃ¡ acima ou abaixo da mÃ©dia de seu grupo.\n\n\n\n\n\n\nNotaRelaÃ§Ã£o \\(Z\\) e \\(X\\)\n\n\n\n\nSe \\(Z_i = 0\\), entÃ£o \\(X_i = \\overline{X}\\);\nSe \\(Z_i &gt; 0\\), entÃ£o \\(X_i &gt; \\overline{X}\\);\nSe \\(Z_i &lt; 0\\), entÃ£o \\(X_i &lt; \\overline{X}\\);\n\n\n\nPara uma distribuiÃ§Ã£o com mÃ©dia igual a \\(10\\) e desvio padrÃ£o igual a \\(3\\), por exemplo, uma observaÃ§Ã£o \\(X_i = 16\\) terÃ¡ um valor de \\(Z = \\frac{16-10}{3} = 2\\), indicando que estÃ¡ dois desvios padrÃµes acima da mÃ©dia de \\(X\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#cÃ¡lculo-de-z-no-ambiente-r",
    "href": "content/estatistica-descritiva/escorez.html#cÃ¡lculo-de-z-no-ambiente-r",
    "title": "Medidas de posiÃ§Ã£o: transformaÃ§Ã£o Z",
    "section": "2 CÃ¡lculo de \\(Z\\) no ambiente R",
    "text": "2 CÃ¡lculo de \\(Z\\) no ambiente R\nSeja:\n\n\nCÃ³digo\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\n\n\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\n\\(Z\\) pode ser obtido pelos comandos:\n\nXm &lt;- mean(X)\nXsd &lt;- sd(X)\nZ &lt;- (sort(X) - Xm) / Xsd\n\nPodemos ver na TabelaÂ 1 os valores de cada observaÃ§Ã£o \\(X_i\\) e dos respectivos valores de \\(Z_i\\) em ordem crescente.\n\n\nCÃ³digo\nPosicao_k &lt;- paste(1:length(X), \"a PosiÃ§Ã£o\", sep = \"\")\ndf &lt;- tibble(`Posicao k` = Posicao_k, `X ordenado` = sX, Z = round(Z, 2)) |&gt;\n  add_row(\n    `Posicao k` = c(\"MÃ©dia\", \"Desvio padrÃ£o\"),\n    `X ordenado` = c(round(mean(sX), 2), round(sd(sX), 2)),\n    Z = c(round(mean(Z), 2), round(sd(Z), 2))\n  )\n\ndf |&gt;\n  gt()\n\n\n\n\nTabelaÂ 1: AssociaÃ§Ã£o entre uma distribuiÃ§Ã£o X e a transformaÃ§Ã£o Z.\n\n\n\n\n\n\n\n\n\nPosicao k\nX ordenado\nZ\n\n\n\n\n1a PosiÃ§Ã£o\n5.60\n-2.63\n\n\n2a PosiÃ§Ã£o\n8.30\n-1.15\n\n\n3a PosiÃ§Ã£o\n8.40\n-1.09\n\n\n4a PosiÃ§Ã£o\n8.70\n-0.93\n\n\n5a PosiÃ§Ã£o\n8.80\n-0.87\n\n\n6a PosiÃ§Ã£o\n9.40\n-0.54\n\n\n7a PosiÃ§Ã£o\n9.90\n-0.27\n\n\n8a PosiÃ§Ã£o\n10.00\n-0.21\n\n\n9a PosiÃ§Ã£o\n10.40\n0.01\n\n\n10a PosiÃ§Ã£o\n10.70\n0.17\n\n\n11a PosiÃ§Ã£o\n10.80\n0.23\n\n\n12a PosiÃ§Ã£o\n11.00\n0.34\n\n\n13a PosiÃ§Ã£o\n11.20\n0.45\n\n\n14a PosiÃ§Ã£o\n11.20\n0.45\n\n\n15a PosiÃ§Ã£o\n11.50\n0.61\n\n\n16a PosiÃ§Ã£o\n11.60\n0.66\n\n\n17a PosiÃ§Ã£o\n11.90\n0.83\n\n\n18a PosiÃ§Ã£o\n12.20\n0.99\n\n\n19a PosiÃ§Ã£o\n13.00\n1.43\n\n\n20a PosiÃ§Ã£o\n13.20\n1.54\n\n\nMÃ©dia\n10.39\n0.00\n\n\nDesvio padrÃ£o\n1.82\n1.00\n\n\n\n\n\n\n\n\n\n\nPodemos comparar graficamente as distribuiÃ§Ãµes das variÃ¡veis \\(X\\) e \\(Z\\).\n\n\nCÃ³digo\nhX &lt;- ggplot(df, aes(x = `X ordenado`)) +\n  geom_histogram(fill = 'darkblue', color = 'white', bins = 9) +\n  ylab('FrequÃªncia') +\n  scale_x_continuous(n.breaks = 7) +\n  theme_classic(base_size = 20)\n\nhZ &lt;- ggplot(df, aes(x = Z)) +\n  geom_histogram(fill = 'darkblue', color = 'white', bins = 9) +\n  ylab('FrequÃªncia') +\n  scale_x_continuous(n.breaks = 7) +\n  theme_classic(base_size = 20)\n\nhX / hZ\n\n\n\n\n\n\n\n\nFiguraÂ 1: Histogramas representando a distribuiÃ§Ã£o de X e Z.\n\n\n\n\n\nVeja na TabelaÂ 1 que conforme o valor de \\(X_i\\) se distancia da mÃ©dia de \\(X = 10.39\\), mais distante de zero serÃ¡ o valor de \\(Z_i\\). Neste exemplo, as observaÃ§Ãµes mais extremas de \\(X\\) estÃ£o, respectivamente, a -2.63 desvios padrÃµes abaixo e 1.54 desvios padrÃµes acima da mÃ©dia. Como discutido acima, a nova variÃ¡vel \\(Z\\) tem mÃ©dia \\(\\overline{Z} = 0\\) (estÃ¡ centralizada) e desvio padrÃ£o \\(s_Z = 1\\) (estÃ¡ padronizada)."
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#obtendo-a-transformaÃ§Ã£o-z-a-partir-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/escorez.html#obtendo-a-transformaÃ§Ã£o-z-a-partir-de-uma-tabela-de-dados",
    "title": "Medidas de posiÃ§Ã£o: transformaÃ§Ã£o Z",
    "section": "3 Obtendo a transformaÃ§Ã£o \\(Z\\) a partir de uma tabela de dados",
    "text": "3 Obtendo a transformaÃ§Ã£o \\(Z\\) a partir de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUtilizando a funÃ§Ã£o mutate, vamos manter somente a variÃ¡vel CPUE e criar outra coluna denominada CPUE_z.\n\ndf_z &lt;- res |&gt; \n  select(CPUE) |&gt; \n  mutate(CPUE_z = (CPUE - mean(CPUE)) / sd(CPUE)) |&gt; \n  round(2)\n\ndf_z |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE\nCPUE_z\n\n\n\n\n9.22\n-0.47\n\n\n28.73\n2.17\n\n\n11.59\n-0.15\n\n\n30.76\n2.45\n\n\n5.95\n-0.92\n\n\n7.75\n-0.67\n\n\n7.51\n-0.70\n\n\n4.01\n-1.18\n\n\n20.83\n1.10\n\n\n2.43\n-1.39\n\n\n12.55\n-0.02\n\n\n11.73\n-0.13\n\n\n13.72\n0.14\n\n\n16.50\n0.52\n\n\n4.71\n-1.08\n\n\n7.95\n-0.64\n\n\n13.12\n0.06\n\n\n16.10\n0.46\n\n\n11.74\n-0.13\n\n\n17.95\n0.71\n\n\n13.86\n0.16\n\n\n13.04\n0.05\n\n\n7.35\n-0.73\n\n\n20.92\n1.12\n\n\n13.67\n0.13\n\n\n21.82\n1.24\n\n\n6.29\n-0.87\n\n\n9.40\n-0.45\n\n\n5.60\n-0.96\n\n\n2.05\n-1.45\n\n\n24.88\n1.65\n\n\n\n\n\n\n\nSe calcularmos a mÃ©dia e o desvio padrÃ£o das variÃ¡veis, veremos que CPUE mantÃ©m os valores originais, enquanto CPUE_z terÃ¡ mÃ©dia igual a \\(0\\) e desvio padrÃ£o igual a \\(1\\).\n\ndf_z |&gt; \n  summarize(CPUE_media = mean(CPUE),\n            CPUE_dp = sd(CPUE),\n            CPUE_z_media = round(mean(CPUE_z), 2),\n            CPUE_z_dp = round(sd(CPUE_z), 2)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_media\nCPUE_dp\nCPUE_z_media\nCPUE_z_dp\n\n\n\n\n12.70097\n7.3701\n0\n1"
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#valores-esperados-de-z-em-uma-distribuiÃ§Ã£o-normal-padronizada",
    "href": "content/estatistica-descritiva/escorez.html#valores-esperados-de-z-em-uma-distribuiÃ§Ã£o-normal-padronizada",
    "title": "Medidas de posiÃ§Ã£o: transformaÃ§Ã£o Z",
    "section": "4 Valores esperados de \\(Z\\) em uma distribuiÃ§Ã£o normal padronizada",
    "text": "4 Valores esperados de \\(Z\\) em uma distribuiÃ§Ã£o normal padronizada\nA interpretaÃ§Ã£o de \\(Z\\) faz sentido quando desejamos posicionar uma determinada observaÃ§Ã£o \\(X_i\\) como funÃ§Ã£o da mÃ©dia e desvio padrÃ£o de seu grupo. Adicionalmente, se uma variÃ¡vel \\(X\\) puder ser descrita adequadamente por uma distribuiÃ§Ã£o normal de probabilidades, existe uma regra empÃ­rica que permite determinar os percentuais das observaÃ§Ãµes acima e abaixo de limites conhecidos.\n\n\nCÃ³digo\n# Ver funÃ§Ã£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg()\n\n\n\n\n\n\n\n\nFiguraÂ 2: Ãreas de probabilidade em uma distribuiÃ§Ã£o normal.\n\n\n\n\n\nNa FiguraÂ 2, vemos que existe uma probabilidade de aproximadamente \\(68\\%\\) de que uma observaÃ§Ã£o tomada ao acaso esteja entre os limites de \\(-1\\) e \\(1\\) desvios padrÃµes da mÃ©dia. Existe ainda uma probabilidade de aproximadamente \\(95\\%\\) de que uma observaÃ§Ã£o esteja entre \\(-2\\) e \\(2\\) desvios padrÃµes da mÃ©dia. Por outro lado, Ã© muito improvÃ¡vel encontrarmos ao acaso uma observaÃ§Ã£o a mais de \\(3\\) desvios padrÃµes distantes da mÃ©dia. Isto deverÃ¡ ocorrer em somente cerca de \\(0,26\\%\\) dos casos em que sortearmos uma amostra aleatoriamente.\n\n\n\n\n\n\nNotaUso da distribuiÃ§Ã£o normal empÃ­rica\n\n\n\nSuponha que a distribuiÃ§Ã£o de altura de homens adultos siga uma distribuiÃ§Ã£o normal com mÃ©dia \\(\\mu = 175\\) cm e desvio padrÃ£o \\(\\sigma = 10\\) cm.\n\n\nCÃ³digo\nmH &lt;- 175\nsdH &lt;- 10\nlim &lt;- 2\nlinf &lt;- round(mH - lim * sdH, 2)\nlsup &lt;- round(mH + lim * sdH, 2)\n\n\nNeste caso, se tomarmos os limites entre \\(-2\\) e \\(+2\\) desvios padrÃµes teremos:\n\\(\\mu - 2 \\times \\sigma = 175 - 2 \\times 10 = 155\\) cm\ne\n\\(\\mu + 2 \\times \\sigma = 175 + 2 \\times 10 = 195\\) cm\nEstes resultados sugerem que nesta populaÃ§Ã£o temos somente cerca de \\(5\\%\\) dos homens adultos com mais de \\(195\\) cm ou menos de \\(155\\) cm de altura."
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html",
    "title": "Probabilidade condicional e independÃªncia",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(ggVennDiagram)\nsource(\"scripts/conditional-tree.r\")"
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#probabilidade-condicional",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#probabilidade-condicional",
    "title": "Probabilidade condicional e independÃªncia",
    "section": "1 Probabilidade Condicional",
    "text": "1 Probabilidade Condicional\nConsideremos o experimento â€œvirar uma estrutura (folha ou galho) e contar o nÃºmero de itensâ€:\n\\(\\Omega = \\{(F0), (F1), (F2), (F3), (F4), (F5), (F6), (G0), (G1), (G2), (G3), (G4)\\}\\)\nSejam definidos os eventos:\n\n\\(A\\): â€œvirar uma folhaâ€:\n\\[A = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6)}\\}.\\]\n\\(B\\): â€œobter 3 ou mais itensâ€:\n\\[B = \\{\\text{(F3), (F4), (F5), (F6), (G3), (G4)}\\}.\\]\n\nQue podem ser representados no diagrama de Venn:\n\n\n\n\n\n\n\n\n\nPodemos perguntar:\n\nConsiderando que tenha sido virada uma folha, qual a probabilidade de que tenham sido obtidos mais de 3 itens?\n\nAo informar que a estrutura era uma folha, sabemos que nem todos os eventos de \\(\\Omega\\) podem ter ocorrido. Neste exemplo, somente as 7 observaÃ§Ãµes do evento e \\(A\\) consistem de uma folha.\nDestas, apenas 4 possuem mais de 3 itens, de modo a resposta Ã  pergunta seria \\(\\frac{4}{7}\\). Este resultado Ã© conhecido como probabilidade condicional, denotada pelo sÃ­mbolo (\\(|\\)). Neste exemplo especÃ­fico estamos perguntando:\n\nDado que \\(A\\) OCORREU, qual a probabilidade de que \\(B\\) ocorra? Simbolicamente, esta questÃ£o Ã© escrita como \\(P(B|A)\\) e lida como probabilidade de \\(B\\) dado \\(A\\).\n\n\\[P(B|A) = \\frac{4}{7} = 0.57\\]\nEsta probabilidade condicional foi calculada pelo nÃºmero de observaÃ§Ãµes favorÃ¡veis Ã  intersecÃ§Ã£o de \\(A\\) e \\(B\\) (\\(A \\cap B\\)) relativa ao nÃºmero de observaÃ§Ãµes do evento \\(A\\). Isto significa que ao sabermos parte dos resultados, o espaÃ§o amostral inicial foi reduzido, neste caso, ao espaÃ§o coincidente com \\(A\\).\nDeste modo, a probabilidade condicional pode ser expressacomo:\n\\[P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}\\]\nque neste exemplo serÃ¡:\n\\[P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{4}{7} = 0.57\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#representaÃ§Ã£o-de-eventos-diagrama-de-Ã¡rvore",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#representaÃ§Ã£o-de-eventos-diagrama-de-Ã¡rvore",
    "title": "Probabilidade condicional e independÃªncia",
    "section": "2 RepresentaÃ§Ã£o de eventos: diagrama de Ã¡rvore",
    "text": "2 RepresentaÃ§Ã£o de eventos: diagrama de Ã¡rvore\nQuando lidamos com experimentos em etapas ou eventos sequenciais, um diagrama de Ã¡rvore ajuda a visualizar cada estÃ¡gio, indicando as probabilidades e as condicionais:\n\n\n\n\n\n\n\n\n\nNesse diagrama, cada ramo representa um cenÃ¡rio: por exemplo, ao ocorrer \\(A\\), \\(B\\) pode acontecer com \\(P(B \\mid A)\\), resultando na intersecÃ§Ã£o \\(A \\cap B\\). Assim, o diagrama possibilita mapear todos os cenÃ¡rios possÃ­veis de maneira organizada."
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes",
    "title": "Probabilidade condicional e independÃªncia",
    "section": "3 Eventos independentes",
    "text": "3 Eventos independentes\nDois eventos \\(A\\) e \\(B\\) sÃ£o independentes quando conhecer a ocorrÃªncia de um deles nÃ£o altera a probabilidade do outro, ou seja, conhecer \\(A\\) nÃ£o nos diz nada sobre a probabilidade de ocorrÃªncia de \\(B\\), de modo que \\(P(B) = P(B \\mid A)\\).\nNo experimento â€œvirar uma estrutura e contar o nÃºmero de itensâ€, temos por exemplo.\n\\(P(B) = 0.5\\)\ne que\n\\(P(B \\mid A) = 0.57\\)\nPortanto, ao sabermos que a estrutura virada foi uma folha, a probalidade de que tenham sido observados 3 ou mais items foi alterada.\nOs eventos \\(A\\) e \\(B\\) sÃ£o portanto eventos dependentes em que \\(P(B) \\neq P(B \\mid A)\\).\n\n3.1 Exemplo de eventos independentes\nSuponha que foram investigadas 600 pessoas, classificadas por idade e local de origem. Nesse contexto temos os eventos:\n\n\\(A\\): ter atÃ© 20 anos; \\(\\overline{A}\\): ter mais de 20 anos.\n\n\\(B\\): ser da cidade; \\(\\overline{B}\\): ser de fora da cidade.\n\nConsidere a matriz:\n\n\n\n\n\n\n\n\nidade\nDa cidade\nDe fora da cidade\n\n\n\n\nAtÃ© 20\n30\n170\n\n\nMais de 20\n60\n340\n\n\n\n\n\n\n\nAs probabilidades sÃ£o:\n\\(P(A) = \\frac{200}{600} = 0.33\\)\n\\(P(\\overline{A}) \\;=\\; \\frac{400}{600} = 0.67\\)\n\\(P(B) = \\frac{90}{600} = 0.15\\)\n\\(P(\\overline{B}) \\;=\\; \\frac{510}{600} = 0.85\\)\nSabendo, por exemplo, que a pessoa tem mais de 20 anos, a probabilidade de ela ser da cidade Ã©:\n\\[P(B \\mid A) = \\frac{60}{400} = 0.15.\\]\nUma vez que \\(P(B) = P(B \\mid A)\\), entÃ£o \\(A\\) e \\(B\\) sÃ£o eventos independentes."
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes-vs-mutuamente-exclusivos",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes-vs-mutuamente-exclusivos",
    "title": "Probabilidade condicional e independÃªncia",
    "section": "4 Eventos independentes vs mutuamente exclusivos",
    "text": "4 Eventos independentes vs mutuamente exclusivos\n\nDois eventos sÃ£o mutuamente exclusivos quando \\(P(A \\cap B) = 0\\). Se ambos ocorrerem, excluem-se mutuamente. Logo, se \\(A\\) ocorre, \\(B\\) nÃ£o pode ocorrer. Nesse caso, \\(P(B \\mid A) = 0\\), caracterizando dependÃªncia, pois a informaÃ§Ã£o de \\(A\\) determina que \\(B\\) nÃ£o ocorrerÃ¡.\nDois eventos sÃ£o independentes se \\(P(A \\cap B) = P(A)\\times P(B)\\). Isso significa que conhecer \\(A\\) nÃ£o altera a probabilidade de \\(B\\). Se \\(P(A)\\) e \\(P(B)\\) forem nÃ£o nulos, entÃ£o nÃ£o podem ser ao mesmo tempo mutuamente exclusivos e independentes.\n\nA representaÃ§Ã£o de eventos mutuamente exclusivos no diagrama de Ã¡rvore Ã© ilustrada por \\(P(B \\mid A)=0\\), pois, ao ocorrer \\(A\\), jÃ¡ se sabe que \\(B\\) nÃ£o ocorrerÃ¡. Assim, eventos mutuamente exclusivos implica serem eventos dependentes. Se nÃ£o hÃ¡ exclusividade, os eventos podem ou nÃ£o ser independentes, dependendo de \\(P(B)\\) em relaÃ§Ã£o a \\(P(B \\mid A)\\)."
  },
  {
    "objectID": "content/fundamentos-probabilidade/espaco-amostral.html",
    "href": "content/fundamentos-probabilidade/espaco-amostral.html",
    "title": "EspaÃ§o de possibilidades de um experimento",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nConsidere uma pesquisa para determinar os locais de ocorrÃªncia de uma espÃ©cie de peixe endÃªmica de riachos costeiros de Mata AtlÃ¢ntica no sudeste do Brasil. A pesquisa envolve amostrar trechos de riachos em diferentes bacias hidrogrÃ¡ficas da regiÃ£o. Ao amostrar um determinado riacho, o pesquisador nÃ£o sabe antecipadamente se irÃ¡ ou nÃ£o encontrar a espÃ©cie. Em probabilidade, chamamos esse ato de experimento aleatÃ³rio, pois o resultado sÃ³ Ã© conhecido apÃ³s a realizaÃ§Ã£o.\nEmbora nÃ£o saibamos o resultado de um experimento especÃ­fico, sabemos quais sÃ£o os resultados possÃ­veis. Neste exemplo, vamos assumir que existem apenas dois resultados para o ato de amostrar um riacho: ou a espÃ©cie ocorre, ou nÃ£o ocorre.\nNo caso em questÃ£o:\n\\(\\Omega = {(ocorre), (nÃ£o-ocorre)}\\)"
  },
  {
    "objectID": "content/fundamentos-probabilidade/espaco-amostral.html#probabilidades-de-um-evento",
    "href": "content/fundamentos-probabilidade/espaco-amostral.html#probabilidades-de-um-evento",
    "title": "EspaÃ§o de possibilidades de um experimento",
    "section": "1 Probabilidades de um evento",
    "text": "1 Probabilidades de um evento\nMesmo sem saber o resultado de um experimento particular, podemos perguntar sobre a chance de cada evento ocorrer. Em termos probabilÃ­sticos, estamos interessados em \\(P(ocorre)\\). Quando \\(P(ocorre) = 0\\), significa que a espÃ©cie jamais ocorre nos riachos; quando \\(P(ocorre) = 1\\), significa que a espÃ©cie ocorre em todos os riachos. Na prÃ¡tica, a probabilidade ficarÃ¡ entre esses extremos: \\(0 \\le P(ocorre) \\le 1\\).\nPodemos estimar essa probabilidade empiricamente. Suponha que planejamos amostrar um determinado nÃºmero de riachos, observando quantas vezes a espÃ©cie Ã© capturada.\nDigamos que em certo dia foram amostrados 10 riachos e a espÃ©cie foi registrada em 4 deles. Nossa estimativa da probabilidade de ocorrÃªncia serÃ¡:\n\\[P(ocorre) = \\frac{\\#ocorres}{\\#riachos} = \\frac{4}{10} = 0.4\\]\nNaturalmente, como os dois eventos no espaÃ§o amostral sÃ£o \\((ocorre)\\) e \\((nÃ£o-ocorre)\\), a probabilidade de nÃ£o-ocorrÃªncia Ã©:\n\\[P(nÃ£o-ocorre) = 1 - \\frac{\\#nÃ£o-ocorre}{\\#riachos} = 1 - \\frac{4}{10} = 0.6\\]\ne, sendo eventos mutuamente exclusivos e exaustivos (nÃ£o podem ocorrer juntos e sÃ£o as Ãºnicas possibilidades), temos:\n\\[P(ocorre) + P(nÃ£o-ocorre) = 1 = P(\\Omega)\\]\nA probabilidade de nÃ£o-ocorrÃªncia tambÃ©m Ã© conhecida como complemento de \\(P(ocorre)\\), frequentemente denotado por \\(P(\\overline{ocorre})\\):\n\\[P(nÃ£o-ocorre) = P(\\overline{ocorre})\\]\n\n1.1 Estimando probabilidades\nA estimativa acima descreve o resultado para um conjunto fixo de 10 riachos. No entanto, se continuarmos a amostrar novos riachos, essa estimativa pode variar, pois eventualmente encontraremos mais (ou menos) riachos com a espÃ©cie presente. Assim, com um nÃºmero finito de observaÃ§Ãµes, nossa estimativa nÃ£o serÃ¡ exatamente igual Ã  probabilidade real.\nSuponha que repetimos o experimento em 30 riachos. A cada nova amostra coletada, calculamos a fraÃ§Ã£o acumulada de ocorrÃªncias:\n\n\n\n\n\n\n\n\nObservaÃ§Ãµes\nOcorrÃªncia acumulada\nP(ocorre)\n\n\n\n\n1\n0\n0.0000000\n\n\n2\n0\n0.0000000\n\n\n3\n1\n0.3333333\n\n\n4\n1\n0.2500000\n\n\n5\n1\n0.2000000\n\n\n6\n2\n0.3333333\n\n\n7\n2\n0.2857143\n\n\n8\n3\n0.3750000\n\n\n9\n4\n0.4444444\n\n\n10\n4\n0.4000000\n\n\n11\n4\n0.3636364\n\n\n12\n4\n0.3333333\n\n\n13\n4\n0.3076923\n\n\n14\n4\n0.2857143\n\n\n15\n4\n0.2666667\n\n\n16\n5\n0.3125000\n\n\n17\n5\n0.2941176\n\n\n18\n5\n0.2777778\n\n\n19\n5\n0.2631579\n\n\n20\n5\n0.2500000\n\n\n21\n5\n0.2380952\n\n\n22\n5\n0.2272727\n\n\n23\n5\n0.2173913\n\n\n24\n5\n0.2083333\n\n\n25\n5\n0.2000000\n\n\n26\n6\n0.2307692\n\n\n27\n6\n0.2222222\n\n\n28\n6\n0.2142857\n\n\n29\n6\n0.2068966\n\n\n30\n7\n0.2333333\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote como a estimativa de \\(P(ocorre)\\) oscila. Espera-se que este valor gradualmente aproxime-se para probabilidade real Ã  medida que o nÃºmero de observaÃ§Ãµes cresce.\n\n\n\n\n\n\nNotaLei dos Grandes NÃºmeros\n\n\n\nA Lei dos Grandes NÃºmeros afirma que, Ã  medida que o nÃºmero de repetiÃ§Ãµes de um experimento aleatÃ³rio cresce, a frequÃªncia relativa de um evento tende a se aproximar da probabilidade real desse evento. Portanto, se continuarmos amostrando mais riachos, a proporÃ§Ã£o de vezes em que a espÃ©cie ocorre deve convergir para a probabilidade verdadeira de ocorrÃªncia."
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html",
    "href": "content/visualizacao-dados/grafico-ggplot2.html",
    "title": "GrÃ¡ficos em camadas",
    "section": "",
    "text": "O pacote ggplot2 no R Ã© baseado na gramÃ¡tica de grÃ¡ficos (Grammar of Graphics), que permite a construÃ§Ã£o de visualizaÃ§Ãµes de dados de maneira declarativa. Com ele, Ã© possÃ­vel criar uma ampla variedade de grÃ¡ficos, desde simples grÃ¡ficos de barras e dispersÃ£o atÃ© complexas visualizaÃ§Ãµes com mÃºltiplas camadas e facetas. O ggplot2 facilita a personalizaÃ§Ã£o detalhada dos grÃ¡ficos, incluindo temas, cores e anotaÃ§Ãµes, tornando-o uma escolha popular entre estatÃ­sticos, cientistas de dados e analistas para comunicar informaÃ§Ãµes de maneira clara e eficiente.\nO ggplot2 gera grÃ¡ficos a partir das colunas de um data frame, o que significa que o domÃ­nio de ferramentas de transformaÃ§Ã£o de data frames Ã© fundamental para a criaÃ§Ã£o de visualizaÃ§Ãµes eficazes. Cada elemento do grÃ¡fico, como eixos, pontos, linhas e barras, Ã© mapeado a partir das variÃ¡veis presentes no data frame. Isso permite grande flexibilidade na representaÃ§Ã£o grÃ¡fica.\nA estrutura em camadas do ggplot2 fornece uma base coesa e flexÃ­vel para a codificaÃ§Ã£o de grÃ¡ficos. Por exemplo, Ã© possÃ­vel comeÃ§ar com uma camada base que define o sistema de coordenadas e os eixos, adicionar uma camada de pontos para criar um grÃ¡fico de dispersÃ£o, e entÃ£o sobrepor camadas adicionais para ajustar a estÃ©tica, adicionar linhas de tendÃªncia, ou incluir etiquetas. Essa abordagem em camadas facilita a personalizaÃ§Ã£o e a atualizaÃ§Ã£o dos grÃ¡ficos, tornando o processo de criaÃ§Ã£o de visualizaÃ§Ãµes complexas mais organizado e intuitivo. Isso nÃ£o sÃ³ melhora a clareza e a legibilidade do cÃ³digo, mas tambÃ©m promove uma maior capacidade de experimentaÃ§Ã£o e exploraÃ§Ã£o dos dados, permitindo que analistas e pesquisadores ajustem e aprimorem suas visualizaÃ§Ãµes de forma eficiente.\nAqui faremos uma introduÃ§Ã£o aos elementos princiais do ggplot2. Para saber mais verifique as referÃªncias abaixo:\nInstale o pacote gglot2 e carregue-o com os demais pacotes utilizados nessa seÃ§Ã£o. O pacote serÃ¡ adicionado para compor mÃºltiplos grÃ¡ficos em uma mesma figura.\ninstall.packages(\"ggplot2\")\ninstall.packages(\"patchwork\")\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#histogramas",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#histogramas",
    "title": "GrÃ¡ficos em camadas",
    "section": "1 Histogramas",
    "text": "1 Histogramas\nFaÃ§a um histograma dos dados de vazÃ£o da tabela HubbardBrook.csv (datasets).\n\nhbrook &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook.csv\")\nhbrook\n\n# A tibble: 62 Ã— 4\n    Year Treatment   Flow Precipitation\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n 1  1958 Deforested  645.         1168.\n 2  1959 Deforested 1012.         1483.\n 3  1960 Deforested  825.         1321.\n 4  1961 Deforested  470.          980.\n 5  1962 Deforested  777.         1232.\n 6  1963 Deforested  774.         1139.\n 7  1964 Deforested  712.         1175.\n 8  1965 Deforested  599.         1115.\n 9  1966 Deforested 1189.         1222.\n10  1967 Deforested 1132.         1315.\n# â„¹ 52 more rows\n\n\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\")\n\n\n\n\n\n\n\n\nO comando acima contÃ©m duas camadas, separadas pelo sÃ­mbolo +, que indica o fim de uma camada e o inÃ­cio de outra. No ggplot2, cada camada adiciona ou formata um elemento do grÃ¡fico. A ordem das camadas geralmente nÃ£o importa, mas organizÃ¡-las bem facilita a leitura do cÃ³digo. No exemplo, temos:\n\nFunÃ§Ã£o ggplot(): Define a estrutura bÃ¡sica do grÃ¡fico. O argumento data = especifica o data frame que contÃ©m os dados. O argumento mapping = define a estÃ©tica do grÃ¡fico definida pela funÃ§Ã£o aes(x = Flow), indicando que o eixo \\(x\\) representarÃ¡ a variÃ¡vel Flow.\nFunÃ§Ã£o geom_histogram(): Define a geometria do grÃ¡fico, aqui um histograma. A cor da borda Ã© definida por color = \"blue\" e o preenchimento por fill = \"lightblue\".\n\nFormataÃ§Ãµes adicionais:\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\") +\n  labs(title = \"Histograma de vazÃ£o\", \n       x = bquote(Vazao (m^3/s)),\n       y = \"Contagem\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nUm tÃ­tulo foi inserido, os nomes para os eixos \\(x\\) e \\(y\\) foram definidos e o tÃ­tulo foi centralizado por theme(plot.title = element_text(hjust = 0.5)).\nO histograma anterior, combina dados de vazÃ£o anual na bacia Deforested e Reference, identificadas pela variÃ¡vel Treatment. Para verificar histogramas separados de acordo com os nÃ­veis desta variÃ¡vel podemos usar a funÃ§Ã£o facet_grid()\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\") +\n  labs(title = \"Histograma de vazÃ£o\", \n       x = bquote(Vazao (m^3/s)),\n       y = \"Contagem\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_grid(rows = vars(Treatment))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotaOutras geometrias grÃ¡ficas\n\n\n\nAlÃ©m dos histogramas, existem muitas outras geometrias grÃ¡ficas do tipo geom_NOME(). Algumas das mais utilizadas sÃ£o: geom_abline(), geom_bar(), geom_boxplot(), geom_line(), geom_point(), geom_smooth(), geom_text(), entre muitas outras."
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#boxplots",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#boxplots",
    "title": "GrÃ¡ficos em camadas",
    "section": "2 Boxplots",
    "text": "2 Boxplots\nA princÃ­pio, a distribuiÃ§Ã£o das vazÃµes nÃ£o sÃ£o muito diferentes entre os tratamentos. Um boxplot pode ser utilizado para visualizar estas distribuiÃ§Ãµes.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Treatment)) +\n  geom_boxplot() +\n  labs(y = bquote(Vazao (m^3/s)),\n       x = \"\")\n\n\n\n\n\n\n\n\nO boxplot exige que sejam definidas uma variÃ¡vel contÃ­nua, neste caso Flow em \\(y\\) como funÃ§Ã£o de uma variÃ¡vel categÃ³rica, neste caso Treatment em \\(x\\)."
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#grÃ¡fico-de-dispersÃ£o",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#grÃ¡fico-de-dispersÃ£o",
    "title": "GrÃ¡ficos em camadas",
    "section": "3 GrÃ¡fico de dispersÃ£o",
    "text": "3 GrÃ¡fico de dispersÃ£o\nPara verificar a relaÃ§Ã£o entre vazÃ£o e precipitaÃ§Ã£o, pode-se plotar um grÃ¡fico de dispersÃ£o entre Flow e Precipitation.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Precipitation)) +\n  geom_point(shape = 21) +\n  labs(y = bquote(VazÃ£o (m^3/s)),\n       x = bquote(PrecipitaÃ§Ã£o (m^3/ano)))\n\n\n\n\n\n\n\n\nO Treatment pode ser adicinado a esta figura como cores diferentes.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, \n                     x = Precipitation, \n                     fill = Treatment)) +\n  geom_point(shape = 21, size = 3) +\n  labs(y = bquote(VazÃ£o (m^3/s)),\n       x = bquote(PrecipitaÃ§Ã£o (m^3/ano))) +\n  guides(fill=guide_legend(title=\"Estado da Ã¡rea\")) +\n  scale_fill_manual(values = c(\"blue\", \"green\"))"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#sÃ©ries-temporais",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#sÃ©ries-temporais",
    "title": "GrÃ¡ficos em camadas",
    "section": "4 SÃ©ries temporais",
    "text": "4 SÃ©ries temporais\nO operador pipe pode ser combinado com a funÃ§Ã£o ggplot() para filtrar as bacia Deforested e representar a vazÃ£o em uma sÃ©rie temporal.\n\nhbrook |&gt;  \n  filter(Treatment == \"Deforested\") |&gt;  \n  ggplot(mapping = aes(y = Flow, x = Year)) +\n    geom_line() +\n    labs(y = bquote(VazÃ£o (m^3/s)),\n         x = \"Ano\")\n\n\n\n\n\n\n\n\nPodem ser vistas as sÃ©ries temporais para os dois tratamentos, representando-os em figuras diferentes.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Year)) +\n  geom_line() +\n  labs(y = bquote(VazÃ£o (m^3/s)),\n       x = \"Ano\") +\n  facet_grid(rows = vars(Treatment))\n\n\n\n\n\n\n\n\nOu na mesma figura em cores diferentes.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, x = Year, color = Treatment)) +\n  geom_line() +\n  labs(y = bquote(VazÃ£o (m^3/s)),\n       x = \"Ano\") +\n  scale_color_manual(values = c(\"blue\", \"green\"))\n\n\n\n\n\n\n\n\nO desmatamento da bacia Deforested ocorreu em \\(1965\\), e intervenÃ§Ãµes para impedir o desenvolvimento da vegetaÃ§Ã£o foram realizadas atÃ© \\(1970\\). Esse intervalo pode ser representado por um retÃ¢ngulo no grÃ¡fico.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, x = Year, color = Treatment)) +\n  geom_line() +\n  labs(y = bquote(VazÃ£o (m^3/s)),\n       x = \"Ano\") +\n  scale_color_manual(values = c(\"blue\", \"green\")) +\n  scale_x_continuous(breaks = seq(1955, 1990, by = 5)) +\n  annotate(\"rect\", \n           xmin = 1965, xmax = 1970, \n           ymin = -Inf, ymax = Inf, \n           alpha = 0.2, fill = \"red\") +\n  theme_test()\n\n\n\n\n\n\n\n\nComo as vazÃµes foram mensuradas nos mesmos anos, Ã© possÃ­vel calcular a diferenÃ§a de vazÃ£o entre os tratamentos e representar essas diferenÃ§as graficamente.\n\nhbrook_largo &lt;- hbrook |&gt;\n  select(-Precipitation) |&gt;\n  pivot_wider(names_from = Treatment, values_from = Flow) |&gt; \n  mutate(diffDR = Deforested - Reference)\nhbrook_largo\n\n# A tibble: 31 Ã— 4\n    Year Deforested Reference diffDR\n   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1  1958       645.      567.   77.8\n 2  1959      1012.      918.   93.8\n 3  1960       825.      752.   73.2\n 4  1961       470.      436.   33.8\n 5  1962       777.      699.   78.0\n 6  1963       774.      663.  111. \n 7  1964       712.      630.   81.7\n 8  1965       599.      547.   52.2\n 9  1966      1189.      727.  463. \n10  1967      1132.      781.  351. \n# â„¹ 21 more rows\n\n\n\nggplot(data = hbrook_largo, \n       mapping = aes(y = diffDR, x = Year)) +\n  geom_line() +\n  geom_point(shape = 19) +\n  labs(y = bquote(DiferenÃ§a~de~VazÃ£o (m^3/s)),\n       x = \"Ano\") +\n  scale_x_continuous(breaks = seq(1955, 1990, by = 5)) +\n  annotate(\"rect\", \n           xmin = 1965, xmax = 1970, \n           ymin = -Inf, ymax = Inf, \n           alpha = 0.2, fill = \"red\") +\n  theme_test()"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#grÃ¡fico-de-barras",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#grÃ¡fico-de-barras",
    "title": "GrÃ¡ficos em camadas",
    "section": "5 GrÃ¡fico de barras",
    "text": "5 GrÃ¡fico de barras\nSerÃ¡ criada uma variÃ¡vel categÃ³rica Vazao_cat contendo os nÃ­veis Extrema (se Flow &gt;= 1000 m^3/s) e Normal caso contrÃ¡rio. Em seguida, serÃ¡ contado o nÃºmero de observaÃ§Ãµes com vazÃ£o extrema.\n\nextremo &lt;- 1000\n\nhbrook2 &lt;- hbrook  |&gt;\n  mutate(Vazao_cat = if_else(Flow &gt;= extremo, \n                             true = \"Extrema\", \n                             false = \"Normal\"))\n\nggplot(data = hbrook2, mapping = aes(x = Vazao_cat)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nSe a variÃ¡vel estiver no eixo \\(y\\), aes(y = Vazao_cat), o grÃ¡fico serÃ¡ desenhado na horizontal.\n\nggplot(data = hbrook2, mapping = aes(y = Vazao_cat)) +\n  geom_bar()"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#temas-no-ggplot2",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#temas-no-ggplot2",
    "title": "GrÃ¡ficos em camadas",
    "section": "6 Temas no ggplot2",
    "text": "6 Temas no ggplot2\nO ggplot2 oferece uma sÃ©rie de temas prÃ©-formatados para facilitar a personalizaÃ§Ã£o dos grÃ¡ficos. Para aplicar um tema, basta adicionar uma camada com o nome do tema desejado usando theme_NOME(). Veja um exemplo com o tema theme_classic():\n\nggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\n\n\n\n\n\n\n\nOs temas bÃ¡sicos disponÃ­veis no ggplot2 incluem:\n\n\nCÃ³digo\ng1 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_grey() +\n  labs(title = \"theme_grey()\")\n\ng2 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_gray() +\n  labs(title = \"theme_gray()\")\n\ng3 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_bw() +\n  labs(title = \"theme_bw()\")\n\ng4 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_linedraw() +\n  labs(title = \"theme_linedraw()\")\n\ng5 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_light() +\n  labs(title = \"theme_light()\")\n\ng6 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_dark() +\n  labs(title = \"theme_dark()\")\n\ng7 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"theme_minimal()\")\n\ng8 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic() +\n  labs(title = \"theme_classic()\")\n\ng9 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_void() +\n  labs(title = \"theme_void()\")\n\ng10 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_test() +\n  labs(title = \"theme_test()\")\n\n\n\n\nCÃ³digo\ngcol1 &lt;- g1 / g2 / g3 / g4 / g5\ngcol2 &lt;- g6 / g7 / g8 / g9 / g10\n\ngcol1 | gcol2"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#salvando-uma-figura-gerada-pelo-gglot2.",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#salvando-uma-figura-gerada-pelo-gglot2.",
    "title": "GrÃ¡ficos em camadas",
    "section": "7 Salvando uma figura gerada pelo gglot2.",
    "text": "7 Salvando uma figura gerada pelo gglot2.\nPara salvar um grÃ¡fico gerado com ggplot2, utiliza-se a funÃ§Ã£o ggsave(). Veja o exemplo abaixo:\n\nggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\nggsave(filename = \"Exemplo_ggsave.png\", \n       width = 20, height = 20, units = \"cm\")  \n\nPor padrÃ£o, a funÃ§Ã£o ggsave() salva o Ãºltimo grÃ¡fico criado. Caso seja necessÃ¡rio salvar um grÃ¡fico especÃ­fico, pode-se usar o argumento plot = objeto_grafico.\n\nobjeto_grafico &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\nggsave(filename = \"objeto_grafico_plt.png\", \n       plot = objeto_grafico,\n       device = \"png\",\n       width = 20, \n       height = 20,\n       units = \"cm\",\n       dpi = 480)"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html",
    "href": "content/regressao-linear/regressao-linear-simples.html",
    "title": "RegressÃ£o linear simples",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nlibrary(knitr)\nUm modelo de regressÃ£o linear nos permite verificar se hÃ¡ uma relaÃ§Ã£o funcional entre variÃ¡veis quantitativas. Nesta relaÃ§Ã£o, uma variÃ¡vel Ã© denominada dependente (ou variÃ¡vel resposta - \\(Y\\)) e as demais independentes (ou variÃ¡veis preditoras - \\(X\\)). Portanto, ao ajustar um modelo de regressÃ£o linear, estamos assumindo que existe uma relaÃ§Ã£o estatÃ­stica de dependencia de \\(Y\\) como funÃ§Ã£o das variÃ¡veis preditoras em \\(X\\). No modelo de regressÃ£o linear simples temos somente uma variÃ¡vel preditora e sua relaÃ§Ã£o funcional com \\(Y\\) Ã© dada por:\n\\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\]\nCÃ³digo\nst &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook_wide.csv\") |&gt;\n    rename(FlowD = WS2_Flow_Defosrested, FlowR = WS3_Flow_reference, \n           RainD = WS2_precipitation, RainR = WS3_precipitation) |&gt;\n    mutate(FlowD = FlowD / 100, FlowR = FlowR / 100,\n           RainD = RainD / 10, RainR = RainR / 10) |&gt;\n    (\\(df) df[-31, ])()\nConsidere novamente os dados sobre pluviosidade anual e vazÃ£o em uma bacia hidrogrÃ¡fica americada, medidos entre os anos de 1958 e 1987 (disponÃ­vel em: tiee.esa.org). Vamos avaliar a relaÃ§Ã£o entre a vazÃ£o na bacia e os volumes de chuva.\nYear\nFlowD\nFlowR\nDiference\nRainD\nRainR\n\n\n\n\n1958\n645.15\n567.36\n7779\n1167.5\n1161.0\n\n\n1959\n1012.05\n918.23\n9382\n1482.6\n1479.1\n\n\n1960\n825.22\n752.06\n7316\n1321.3\n1325.3\n\n\n1961\n470.05\n436.25\n3380\n979.7\n978.9\n\n\n1962\n777.31\n699.29\n7802\n1232.2\n1230.6\n\n\n1963\n773.64\n662.58\n11106\n1138.6\n1151.7\n\n\n1964\n712.15\n630.45\n8170\n1175.4\n1175.2\n\n\n1965\n598.85\n546.69\n5216\n1115.2\n1120.6\n\n\n1966\n1189.34\n726.73\n46261\n1222.3\n1223.2\n\n\n1967\n1131.85\n780.76\n35109\n1315.1\n1296.8\n\n\n1968\n1056.54\n762.84\n29370\n1268.2\n1285.2\n\n\n1969\n1347.61\n998.68\n34893\n1368.5\n1403.5\n\n\n1970\n905.47\n697.53\n20794\n1184.1\n1201.5\n\n\n1971\n800.56\n676.19\n12437\n1164.2\n1173.4\n\n\n1972\n1005.90\n885.91\n11999\n1431.3\n1424.0\n\n\n1973\n1585.73\n1396.43\n18930\n1804.0\n1792.8\n\n\n1974\n998.20\n890.45\n10775\n1406.8\n1408.9\n\n\n1975\n1086.33\n939.52\n14681\n1422.4\n1448.6\n\n\n1976\n1142.59\n1022.06\n12053\n1511.4\n1516.0\n\n\n1977\n966.25\n843.75\n12250\n1382.7\n1388.2\n\n\n1978\n722.04\n613.79\n10825\n1087.9\n1085.7\n\n\n1979\n1136.17\n1036.93\n9924\n1417.0\n1432.7\n\n\n1980\n585.22\n548.28\n3694\n1087.9\n1101.1\n\n\n1981\n1129.09\n1093.91\n3518\n1631.5\n1664.9\n\n\n1982\n802.73\n756.12\n4661\n1088.2\n1114.4\n\n\n1983\n917.13\n889.35\n2778\n1436.6\n1451.8\n\n\n1984\n1000.54\n970.65\n2989\n1396.8\n1403.5\n\n\n1985\n634.76\n627.84\n692\n1128.4\n1137.2\n\n\n1986\n987.99\n960.94\n2705\n1364.0\n1372.3\n\n\n1987\n790.47\n797.09\n-662\n1222.1\n1234.6\nÃ‰ razoÃ¡vel supor que em anos de mais chuva, seriam esperadas maiores vazÃµes e que anos mais secos resultassem menores volumes de vazÃ£o. Para verificar esta suposiÃ§Ã£o vamos fazer um grÃ¡fico de dispersÃ£o entre vazÃ£o e chuva.\nO grÃ¡fico sugere que a suposiÃ§Ã£o faz sentido. Volumes baixos de chuva estÃ£o associados a volumes baixos de vazÃ£o e vice versa. O grÃ¡fico sugrere ainda que a relaÃ§Ã£o funcional Ã© linear. Nestas condiÃ§Ãµes, faz sentido tentar modelar a relaÃ§Ã£o entre estas variÃ¡veis por meio de um modelo de regressÃ£o linear simples.\nAo ajustar um modelo de regressÃ£o, vemos que a linha em azul Ã© a que melhor descreve a relaÃ§Ã£o linear entre as variÃ¡veis.\nEsta linha nos permite obter uma estimativa sobre a vazÃ£o esperada (\\(Y\\)) para qualquer dado volume de chuva (\\(X\\)). Neste exemplo, a equaÃ§Ã£o que melhor associa vazÃ£o e chuva Ã©:\n\\[Y_i = -571.98 + 1.05 X_i\\]\nO valor de \\(\\beta_1 = 1.05\\) nos diz que para um aumento de 1 mm/area/ano de chuva, a vazÃ£o aumentarÃ¡ 1.05 mm/area/ano. \\(\\beta_1\\) Ã© conhecido como coeficiente de inclinaÃ§Ã£o da reta e nos fornece magnitude da variaÃ§Ã£o em \\(Y\\) para um aumento de 1 unidade em \\(X\\).\nEsta equaÃ§Ã£o prevÃª por exemplo, que para um volume de chuva igual a 1400 mm/area/ano a vazÃ£o na bacia serÃ¡ de 898 mm/area/ano. FaÃ§a as contas para conferir.\n\\[898.02 = -571.98 + 1.05 \\times 1400\\]\nA reta descreve portanto os valores preditos de vazÃ£o para cada nÃ­vel de chuva."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#modelo-geral-de-regressÃ£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#modelo-geral-de-regressÃ£o",
    "title": "RegressÃ£o linear simples",
    "section": "1 Modelo geral de regressÃ£o",
    "text": "1 Modelo geral de regressÃ£o\nA estrutura de um modelo de regressÃ£o Ã© dada por:\n\\[Y_i = f(X_i, \\beta) + \\epsilon_i\\]\nonde \\(f(X_i, \\beta)\\) representa a parte determinÃ­stica e \\(\\epsilon\\) a parte estocÃ¡stica. O sulfixo i nos diz que esta expressÃ£o Ã© dada para cada par de observaÃ§Ã£o \\((Y,X)\\).\n\n1.1 PorÃ§Ã£o determinÃ­stica\nA porÃ§Ã£o determinÃ­stica Ã© um modelo matemÃ¡tico que descreve a relaÃ§Ã£o funcional entre \\(X\\) e \\(Y\\). Os parÃ¢metros \\(\\beta\\)â€™s determinam a intensidade do efeito de \\(X\\) sobre \\(Y\\). Na regressÃ£o linear simples temos somente uma variÃ¡vel \\(X\\), e a relaÃ§Ã£o funcional Ã© dada pela equaÃ§Ã£o da reta. No modelo de regressÃ£o linear mÃºltipla existe mais de uma variÃ¡vel \\(X\\). Finalmente, nos modelos de regressÃ£o nÃ£o-lineares a relaÃ§Ã£o funcional pode ser representada por outros modelos matemÃ¡ticos (ex. funÃ§Ã£o potÃªncia \\(Y = \\beta_0X^{\\beta_1}\\)).\nNa regressÃ£o linear simples, o parÃ¢metro \\(\\beta_1\\) Ã© geralmente o de maior interesse. Este parÃ¢metro nos dirÃ¡ se a relaÃ§Ã£o serÃ¡ crescente (\\(\\beta_1 &gt; 0\\)), decrescente (\\(\\beta_1 &lt; 0\\)) ou nula (\\(\\beta_1 = 0\\)). \\(\\beta_0\\) Ã© o \\(\\textbf{intercepto}\\) e expressa o ponto em \\(Y\\) em que a reta cruza o eixo das ordenadas.\n\n\n\n\n\n\n\n\n\n\n\n1.2 PorÃ§Ã£o estocÃ¡stica\nA porÃ§Ã£o estocÃ¡stica, Ã© representada pelo resÃ­duo ou erro. A cada observaÃ§Ã£o \\(Y_i\\) estÃ¡ associado um valor de resÃ­duo correspondente (\\(\\epsilon_i\\)), dado pela distÃ¢ncia vertical entre \\(Y_i\\) e o valor predito \\(\\hat{Y_i}\\) sobre a reta de regressÃ£o.\n\n\n\n\n\n\n\n\n\nNo modelo de regressÃ£o linear que veremos aqui, os resÃ­dos sÃ£o uma variÃ¡vel aleatÃ³ria prevenientes de uma distribuiÃ§Ã£o normal de probabilidades com mÃ©dia \\(\\mu = 0\\) e variÃ¢ncia \\(\\sigma^2\\) constante ao longo da reta de regressÃ£o, \\(N(0, \\sigma^2)\\).\n\n\n\n\n\n\nFiguraÂ 1: ResÃ­duo normalmente distribuÃ­do ao longo da reta de regressÃ£o."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#ajuste-dos-dados-ao-modelo-de-regressÃ£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#ajuste-dos-dados-ao-modelo-de-regressÃ£o",
    "title": "RegressÃ£o linear simples",
    "section": "2 Ajuste dos dados ao modelo de regressÃ£o",
    "text": "2 Ajuste dos dados ao modelo de regressÃ£o\nO ajuste de dados observados a um modelo de regressÃ£o requer a obtenÃ§Ã£o de estimativas para \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma^2\\), denotadas respectivamente por \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\). Note que o sÃ­mbolo \\(\\hat{}\\) significa que estamos falando de estimativas obtidas a partir de dados amostrais e nÃ£o dos parÃ¢metros populacionais.\nAo obter estas estimativas, podemos encontrar valores ajustados de \\(Y\\) para um dados valor de \\(X\\). Os valores ajustados de \\(Y\\) sÃ£o denotados por \\(\\hat{Y}\\).\n\\[\\hat{Y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}X_i\\]\n\n2.1 MÃ©todo dos mÃ­nimos quadrados\nO MÃ©todo dos MÃ­nimos Quadrados (\\(MMQ\\)) Ã© uma das formas disponÃ­veis para calcularmos \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\). O \\(MMQ\\) envolve encontrar a combinaÃ§Ã£o de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimiza a Soma dos Quadrados dos ResÃ­duos (\\(SQ_{ResÃ­duo}\\)), ou seja, que minimizam a quantia:\n\\[SQ_{ResÃ­duo} = \\sum{(Y_i-\\hat{Y_ i})^2} = \\sum{(Y_i-(\\hat{\\beta_0} + \\hat{\\beta_1}X_i))^2}\\]\n\n\n\n\n\n\n\n\n\nNas figuras acima, a linha da esquerda (\\(SQ_{ResÃ­duo} = \\sum{\\epsilon_i^2} = 37\\)) estÃ¡ claramente melhor ajustada Ã  nuvem de pontos, o que se expressa em um menor somatÃ³rio dos quadrados dos resÃ­duos (\\(SQ_{ResÃ­duo} = \\sum{\\epsilon_i^2} = 37\\)) quando comparado com o ajuste da figura Ã  direita (\\(SQ_{ResÃ­duo} = \\sum{\\epsilon_i^2} = 145\\)).\n\n\n2.2 VariÃ¢ncias, covariÃ¢ncias e coeficientes da regressÃ£o\nPara estimarmos os coeficientes da regressÃ£o \\(\\beta_0\\) e \\(\\beta_1\\) devemos retomar o conceito de variÃ¢ncia amostral e introduzir o conceito de covariÃ¢ncia amostral.\nA variÃ¢ncia amostral de \\(Y\\) por exemplo, pode ser obtida subtraindo cada observaÃ§Ã£o em \\(Y\\) de sua mÃ©dia (\\(\\overline{Y}\\)) e elevando esta subtraÃ§Ã£o ao quadrado \\((Y_i - \\overline{Y})^2\\). Ao somar para todos os valores de \\(Y_i\\) teremos o somatÃ³rio dos quadrados de \\(Y\\) (\\(SQ_Y\\)).\n\\[SQ_Y = \\sum_{i-1}^{n} (Y_i - \\overline{Y})^2 = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (Y_i - \\overline{Y})\\]\nDividindo \\(SQ_Y\\) por \\(n-1\\) teremos a variÃ¢ncia amostral de \\(Y\\) (\\(s^2_Y\\)).\n\\[s^2_Y = \\frac{\\sum_{i-1}^{n} (Y_i - \\overline{Y})^2}{n-1}\\]\nAdotando o mesmo procedimento para \\(X\\), podemos calcular o somatÃ³rio dos quadrados de \\(X\\) (\\(SQ_X\\)).\n\\[SQ_X = \\sum_{i-1}^{n} (X_i - \\overline{X})^2 = \\sum_{i-1}^{n}(X_i - \\overline{X}) (X_i - \\overline{X})\\]\ne a variÃ¢ncia amostral de \\(X\\) (\\(s^2_X\\)).\n\\[s^2_X = \\frac{\\sum_{i-1}^{n} (X_i - \\overline{X})^2}{n-1}\\]\nCombinando as duas ideias, teremos o produto cruzado de \\(Y\\) e \\(X\\) (\\(SQ_{YX}\\))\n\\[SQ_{YX} = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})\\]\ne a covariÃ¢ncia amostral entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)).\n\\[s_{YX} = \\frac{\\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})}{n-1}\\]\nO estimador \\(\\hat{\\beta_1}\\) nada mais Ã© que a covariÃ¢ncia entre \\(Y\\) e \\(X\\) padronizada pela variÃ¢ncia de \\(X\\).\n\\[\\hat{\\beta_1} = \\frac{s_{YX}}{s^2_X} = \\frac{\\frac{SQ_{XY}}{n-1}}{\\frac{SQ_X}{n-1}} = \\frac{SQ_{XY}}{SQ_X} = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sum{(X_i - \\overline{X})^2}}\\]\n\\[\\hat{\\beta_1} = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sum{(X_i - \\overline{X})^2}}\\]\nApÃ³s encontrar \\(\\hat{\\beta_1}\\), podemos calcular \\(\\hat{\\beta_0}\\) sabendo que a melhor reta de regressÃ£o passarÃ¡ necessariamente pelo ponto mÃ©dio de \\(X\\) e de \\(Y\\). Deste modo temos:\n\\[\\hat{\\beta_0} = \\overline{Y} - \\hat{\\beta_1}\\overline{X}\\]\nCalculados \\(\\hat{\\beta_1}\\) e \\(\\hat{\\beta_0}\\), podemos encontrar os valores ajustados de \\(Y\\) para cada valor de \\(X\\) que serÃ£o utilizados para construir a reta de regressÃ£o. \\(\\hat{Y_i}\\) serÃ¡ dado por:\n\\[\\hat{Y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}X_i\\]\nPor fim, a variÃ¢ncia residual \\(s^2\\) Ã© dada por:\n\\[s^2 = QM_{ResÃ­duo} = \\frac{SQ_{ResÃ­duo}}{n-2} = \\frac{\\sum{(Y_i-\\hat{Y_ i})^2}}{n-2}\\]\n\n\n2.3 Exemplo de ajuste ao modelo de regressÃ£o\n\nrk = read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/RIKZ.csv')\nrks = rk |&gt; \n  (\\(df) df[seq(3,43,by = 5),])()\n\nConsidere a tabela abaixo com os dados de riqueza da macro-fauna praial (nÃºmero de espÃ©cies) e de um Ã­ndice de exposiÃ§Ã£o Ã s ondas (NAP). Os dados foram obtidos em 2002 na costa da Holanda em nove praias (Zuur et al. 2009). Valores negativos de NAP se referem a locais mais expostos e valores positivos a locais menos expostos Ã  aÃ§Ã£o das ondas.\n\nrks |&gt; \n  select(Richness, NAP) |&gt; \n  gt()\n\n\n\n\n\n\n\nRichness\nNAP\n\n\n\n\n13\n-1.336\n\n\n8\n0.635\n\n\n4\n-0.201\n\n\n3\n0.460\n\n\n6\n0.729\n\n\n1\n2.222\n\n\n1\n1.375\n\n\n7\n-1.005\n\n\n3\n-0.002\n\n\n\n\n\n\n\nO grÃ¡fico de dispersÃ£o sugere uma relaÃ§Ã£o negativa e possivelmente linear, em que a riqueza de espÃ©cies diminui com o aumento no grau de exposiÃ§Ã£o. Vamos ajustar um modelo de regressÃ£o a estes pontos calculando \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\).\n\n\n\n\n\n\n\n\n\nOs passos intermediÃ¡rios envolvem o cÃ¡lculo do somatÃ³rios dos quadrados de X:\n\\[SQ_X = \\sum{(X_i - \\overline{X})^2}\\]\nde Y:\n\\[SQ_Y = \\sum{(Y_i - \\overline{Y})^2}\\]\ne do somatÃ³rio dos produtos cruzados de X e Y:\n\\[SQ_{XY} = \\sum{(X_i - \\overline{X}) (Y_i - \\overline{Y})}\\]\nEstes passos sÃ£o descritos na tabela a seguir.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichness\nNAP\n\\((X_i - \\overline{X})\\)\n\\((Y_i - \\overline{Y})\\)\n\\((X_i - \\overline{X})^2\\)\n\\((Y_i - \\overline{Y})^2\\)\n\\((X_i - \\overline{X})(Y_i - \\overline{Y})\\)\n\n\n\n\n13\n-1.34\n-1.66\n7.89\n2.74\n62.23\n-13.06\n\n\n8\n0.64\n0.32\n2.89\n0.10\n8.35\n0.91\n\n\n4\n-0.20\n-0.52\n-1.11\n0.27\n1.23\n0.58\n\n\n3\n0.46\n0.14\n-2.11\n0.02\n4.46\n-0.30\n\n\n6\n0.73\n0.41\n0.89\n0.17\n0.79\n0.36\n\n\n1\n2.22\n1.90\n-4.11\n3.62\n16.90\n-7.82\n\n\n1\n1.38\n1.06\n-4.11\n1.11\n16.90\n-4.34\n\n\n7\n-1.00\n-1.32\n1.89\n1.75\n3.57\n-2.50\n\n\n3\n0.00\n-0.32\n-2.11\n0.10\n4.46\n0.68\n\n\n\n\n\nApÃ³s os cÃ¡lculos, os valores estimados sÃ£o:\n\\[\\hat{\\beta_1} = \\frac{\\sum{(X_i - \\overline{X})(Y_i - \\overline{Y})}}{\\sum{(X_i - \\overline{X})^2}} = \\frac{-25.49}{9.88} = -2.58\\]\n\\[\\hat{\\beta_0} = \\overline{Y} - \\hat{\\beta_1}\\overline{X} = 5.11 -2.58 \\times 0.32 = 5.94\\]\n\\[\\hat{\\sigma}^2 = QM_{ResÃ­duo} = \\frac{SQ_{ResÃ­duo}}{n-2} = \\frac{\\sum{(Y_i-\\hat{Y_ i})^2}}{n-2} = \\frac{53.11}{7} = 7.59\\]\nDe modo que a melhor reta de regressÃ£o Ã© dada por:\n\\[Richness = 5.94 -2.58 \\times NAP\\]"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#testes-de-hipÃ³teses-na-regressÃ£o-linear-simples",
    "href": "content/regressao-linear/regressao-linear-simples.html#testes-de-hipÃ³teses-na-regressÃ£o-linear-simples",
    "title": "RegressÃ£o linear simples",
    "section": "3 Testes de hipÃ³teses na regressÃ£o linear simples",
    "text": "3 Testes de hipÃ³teses na regressÃ£o linear simples\nAtÃ© o momento, apresentamos uma discussÃ£o sobre o mÃ©todo para calcular os estimadores \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}\\). Entretanto, como nossas observaÃ§Ãµes provÃªm de amostras, estas estimativas estÃ£o sujeitas Ã  variaÃ§Ã£o inerente Ã s observaÃ§Ãµes de que dispomos e certamente nÃ£o serÃ£o iguais ao valor da populaÃ§Ã£o estatÃ­stica. Devemos portanto, entender quais evidÃªncias estes estimadores nos fornecem para a existÃªncia de um efeito de \\(X\\) sobre \\(Y\\), ou seja, para rejeitarmos a hipÃ³tese nula em favor de \\(H_A\\).\n\n3.1 Teste sobre \\(\\beta_1\\)\nNa regressÃ£o linear simples, o efeito de \\(X\\) sobre \\(Y\\) depende do valor de \\(\\beta_1\\)\n\\(Y_i = \\beta + \\beta_1X_i + \\epsilon_i\\)\nA nÃ£o existÃªncia de um efeito implica em \\(\\beta_1 = 0\\) e consequentemente:\n\\(Y_i = \\beta_0 + 0 \\times X_i + \\epsilon_i\\) \\(\\rightarrow\\) \\(Y = \\beta_0 + \\epsilon_i\\)\nPortanto, as hipÃ³teses nula e alternativa seriam:\n\\(H_0: \\beta_1 = 0\\)\n\\(H_A: \\beta_1 \\ne 0\\)\nSegundo \\(H_0\\), a inclinaÃ§Ã£o da reta \\(populacional\\) nÃ£o Ã© diferente de zero e o valor estimado \\(\\hat{\\beta_1}\\) ocorreu puramente ao acaso, como efeito da variaÃ§Ã£o amostral. Para testar esta hipÃ³tese, utilizamos a distribuiÃ§Ã£o de t de modo que:\n\\[t = \\frac{\\hat{\\beta_1} - \\beta_1}{s_{\\hat{\\beta_1}}}\\]\nComo segundo \\(H_0\\), \\(\\beta_1  = 0\\) a expressÃ£o fica:\n\\[t = \\frac{\\hat{\\beta_1} - 0}{s_{\\hat{\\beta_1}}} = \\frac{\\hat{\\beta_1}}{s_{\\hat{\\beta_1}}}\\]\n\\(s_{\\hat{\\beta_1}}\\) Ã© o erro padrÃ£o de \\(\\beta_1\\) calculado por:\n\\[s_{\\hat{\\beta_1}} = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum{(X_i-\\overline{X})^2}}}\\]\nNo exemplo sobre a fauna praial estamos interessados em testar a hipÃ³tese de que a riqueza de espÃ©cies esteja associada ao grau de exposiÃ§Ã£o Ã s ondas. Em regressÃ£o linear, esta hipÃ³tese pode ser expressa por:\n\\[t = \\frac{\\hat{\\beta_1}}{s_{\\hat{\\beta_1}}} = \\frac{-2.58}{0.88} = -2.944\\]\nQue na distribuiÃ§Ã£o de t fica:\n\n\n\n\n\n\n\n\n\nSe nosso nÃ­vel de significancia \\(\\alpha = 0.05\\), entÃ£o a probabilidade \\(p = 0.011 + 0.011 = 0.022\\) indica que devemos rejeitar \\(H_0\\) e aceitar que existe uma relaÃ§Ã£o entre Riqueza de espÃ©cies e NAP.\n\n\n3.2 AnÃ¡lise de variÃ¢ncia da regressÃ£o\nComo jÃ¡ dizemos, a estrutura de um modelo de regressÃ£o Ã© dada por um componente sistemÃ¡tico expresso como funÃ§Ã£o de \\(X\\) (\\(\\beta_0 + \\beta_1X_i\\)) e um componente aleatÃ³rio expresso pelos resÃ­duos do modelo (\\(\\epsilon_i\\)). A variaÃ§Ã£o total em \\(Y\\) no modelo de regressÃ£o portanto, pode ser atribuÃ­da a ambos os efeitos de \\(X\\) e do resÃ­duo. Estas quantias de variaÃ§Ã£o podem mensuradas pelos somatÃ³rio dos quadrados abaixo.\nSoma dos quadrados totais:\n\\(SQ_Y = \\sum{(Y_i - \\overline{Y})^2}\\)\nSoma dos quadrados da regressÃ£o:\n\\(SQ_{RegressÃ£o}= \\sum{(\\hat{Y_i} - \\overline{Y})^2}\\)\nE soma dos quadrados do resÃ­duo:\n\\(SQ_{ResÃ­duo}= \\sum{(Y_i - \\hat{Y_i})^2}\\)\nPode-se mostrar ainda que vale a expressÃ£o:\n\\[SQ_Y = SQ_{RegressÃ£o} + SQ_{ResÃ­duo}\\] A decomposiÃ§Ã£o destas quantias Ã© conhecida partiÃ§Ã£o das somas dos quadrados e nos permitem comparar a influÃªncia de \\(X\\) com a influÃªncia do puro acaso sobre a variabilidade em \\(Y\\). Se todos os pontos estiverem perfeitamente sobre a reta, entÃ£o toda a variaÃ§Ã£o em \\(Y\\) seria atribuÃ­da Ã  influÃªncia de \\(X\\). Por outro lado, Ã  medida que aumenta a distÃ¢ncia mÃ©dia dos pontos acima e abaixo da curva, aumenta a parcela atribuÃ­da ao acaso.\n\n\n\n\n\n\n\n\n\nEstes componentes de variaÃ§Ã£o podem ser organizados em uma Tabela de AnÃ¡lise de VariÃ¢ncia (ANOVA). \\(n\\) se refere ao nÃºmero de amostras.\n\n\n\n\n\n\n\n\n\n\n\nFonte de variaÃ§Ã£o\nSQ\ngl\nQM\nF\np\n\n\n\n\nRegressÃ£o\n\\(SQ_{RegressÃ£o}\\)\n\\(gl_{RegressÃ£o}\\)\n\\(QM_{RegressÃ£o} = \\frac{SQ_{RegressÃ£o}}{gl_{RegressÃ£o}}\\)\n\\(\\frac{QM_{RegressÃ£o}}{QM_{ResÃ­duo}}\\)\nProbabilidade associada Ã  cauda da distribuiÃ§Ã£o F\n\n\nResÃ­duo\n\\(SQ_{ResÃ­duo}\\)\n\\(gl_{ResÃ­duo}\\)\n\\(QM_{ResÃ­duo} = \\frac{SQ_{ResÃ­duo}}{gl_{ResÃ­duo}}\\)\n\n\n\n\nTotal\n\\(SQ_{Y}\\)\n\\(gl_{Y}\\)\n\\(QM_{Y} = \\frac{SQ_{Y}}{gl_{Y}}\\)\n\n\n\n\n\nAs coluna \\(gl\\) se refer aos graus de liberdade nos modelo de regressÃ£o, a semelhanÃ§a do que discutimos para o teste t de Student. A coluna QM (Quadrado mÃ©dio) apresenta os estimadores de variÃ¢ncia da regressÃ£o (\\(QM_{RegressÃ£o}\\)), do resÃ­duo (\\(QM_{ResÃ­duo}\\)) e total (\\(QM_{Y}\\)).\n\n3.2.1 A distribuiÃ§Ã£o F\nO valor de \\(F\\) na tabela se refere a distribuiÃ§Ã£o de probabilidade F. Esta distribuiÃ§Ã£o de probabilidades Ã© esperada para a razÃ£o entre duas variÃ¢ncias amostrais. No caso da regressÃ£o linear, estas sÃ£o a variÃ¢ncia da regressÃ£o (\\(QM_{RegressÃ£o}\\) no numerador) e a variÃ¢ncia residual (\\(QM_{ResÃ­duo}\\) no denominador). Diferente da distribuiÃ§ao t, a distribuiÃ§Ã£o F tem um formato assimÃ©trico, sendo que o grau de assimetria depende dos graus de liberdade do numerador e do denominador. O valor de \\(p\\) na tabela se refere Ã  Ã¡rea sob a distribuiÃ§Ã£o F, acima do valor de \\(F\\) calculado. Na ANOVA da regressÃ£o, um valor de \\(p &lt; \\alpha\\) nos leva a rejeitar a hipÃ³tese nula e assumir que a variÃ¡vel \\(X\\) exerce algum efeito sobre \\(Y\\).\n\nO sÃ­mbolo \\(F\\) foi dado em homenagem a Ronald Aylmer Fisher o estatÃ­stico e geneticista BritÃ¢nico do inÃ­cio do sÃ©c. XX, que entre inÃºmeras outras contribuiÃ§Ãµes, desenvolveu a AnÃ¡lise de VariÃ¢ncia. Fisher Ã© descrito como â€œa genius who almost single-handedly created the foundations for modern statistical scienceâ€ (Halt 1998) e como â€œthe single most important figure in 20th century statisticsâ€ (Efron 1998). Ver Ronald Aylmer Fisher.\n\n\n\n\n\n\n\n\n\n\nOs resultados da ANOVA para os dados da fauna praial nos dÃ¡ os seguintes valores. Confira os cÃ¡lculos.\n\n\n\n\n\nFonte de variaÃ§Ã£o\nSQ\ngl\nQM\nF\np\n\n\n\n\nRegressÃ£o\n65.68\n1\n65.68\n8.64\n0.022\n\n\nResÃ­duo\n53.21\n7\n7.60\nNA\nNA\n\n\nTotal\n118.89\n8\n14.86\nNA\nNA\n\n\n\n\n\nO valor de \\(p = 0.022\\) abaixo do nÃ­vel de significÃ¢ncia \\(\\alpha = 0.05\\), nos leva a rejeitar a hipÃ³tese nula em favor da alternativa, concluindo que o Ã­ndice de exposiÃ§Ã£o Ã s ondas interfere sobre a riqueza da macro-fauna. O valor de \\(p\\) foi identico ao obtido no teste de hipÃ³teses de \\(\\beta_1\\). No modelo de regressÃ£o linear simples isto Ã© necessariamente verdadeiro, pois toda a variaÃ§Ã£o associada Ã  regressÃ£o Ã© devida ao efeito do coeficiente \\(\\beta_1\\). Por outro lado, nos modelos de regressÃ£o mÃºltipla, em que temos:\n\\[Y_i = \\beta_0 + \\beta_1X_{i1} + \\beta_1X_{i2} + \\cdots + \\beta_mX_{im} + \\epsilon_i\\]\nesta relaÃ§Ã£o nÃ£o Ã© mais observada, pois existem mÃºltiplos coeficientes agindo sobre a variaÃ§Ã£o em \\(Y\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "href": "content/regressao-linear/regressao-linear-simples.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "title": "RegressÃ£o linear simples",
    "section": "4 Coeficiente de determinaÃ§Ã£o \\(R^2\\)",
    "text": "4 Coeficiente de determinaÃ§Ã£o \\(R^2\\)\nUma vez que toda a variaÃ§Ã£o observada em Y pode ser alocada aos efeitos da reta de regressÃ£o e e do resÃ­duo podemos fazer a seguinte questÃ£o:\n\nQual parcela da variaÃ§Ã£o na Riqueza Ã© explicada exclusivamente pelo modelo de regressÃ£o?\n\nEsta pergunta pode ser respondida calculando o que denominamos de coeficiente de determinÃ§Ã£o ou simplesmente \\(R^2\\):\n\\[R^2 = \\frac{SQ_{RegressÃ£o}}{SQ_Y} = 1 - \\frac{SQ_{ResÃ­duo}}{SQ_Y}\\]\nO valor de \\(SQ_{RegressÃ£o}\\) mede a variaÃ§Ã£o explicada exclusivamente pela regressÃ£o, \\(SQ_{ResÃ­duo}\\) a variaÃ§Ã£o residual e \\(SQ_Y\\) mede a variaÃ§Ã£o total em \\(Y\\). Ao dividir \\(SQ_{ResÃ­duo}\\) por \\(SQ_Y\\), o \\(r^2\\) nos informa sobre qual a fraÃ§Ã£o da variaÃ§Ã£o total Ã© explicada somente pela reta de regressÃ£o.\nNpo exemplo da fauna praial:\n\\[R^2 = 1 - \\frac{53.11}{118.89} = 0.5533\\]\nO que significa que aproximadamente 55.33% da variaÃ§Ã£o na riqueza Ã© explicada pela variaÃ§Ã£o no grau de exposiÃ§Ã£o Ã s ondas (NAP). NÃ£o sabemos a que se deve o restante da variaÃ§Ã£o e, no contexto do modelo de regressÃ£o, assumimos ser uma variaÃ§Ã£o aleatÃ³ria inerente a cada observaÃ§Ã£o (\\(\\epsilon_i\\)). Esta variaÃ§Ã£o aleatÃ³ria, como dito, segue uma distribuiÃ§Ã£o normal com ponto central sobre a reta e variÃ¢ncia data por \\(\\sigma^2\\). Este pressuposto Ã© fundamental para a discussÃ£o do prÃ³ximo ponto a respeito do intervalo de confianÃ§a de \\(Y\\)"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#intervalo-de-confianÃ§a-de-y",
    "href": "content/regressao-linear/regressao-linear-simples.html#intervalo-de-confianÃ§a-de-y",
    "title": "RegressÃ£o linear simples",
    "section": "5 Intervalo de confianÃ§a de \\(Y\\)",
    "text": "5 Intervalo de confianÃ§a de \\(Y\\)\nComo nem todos os pontos caem perfeitamente sobre a reta, seria interessante que pudÃ©ssemos obter um intervalo de confianÃ§a de \\(Y\\) para um dado valor de \\(X\\). A amplitude deste intervalo irÃ¡ depender da variÃ¢ncia dos valores ajustados (\\(s^2_{Y|X}\\)) de \\(Y\\), calculada por:\n\\[s^2_{Y|X} = s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})\\]\ndo modo que:\n\\[s_{Y|X} = \\sqrt{s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})}\\]\nNote pela expressÃ£o acima que o \\(s_{Y|X}\\) diminui quanto:\n\na variÃ¢ncia residual \\(s^2\\) diminui;\no tamanho amostral \\(n\\) aumenta.\no dado valor de \\(X_i\\) estÃ¡ prÃ³ximo Ã  mÃ©dia, pois neste caso \\((X_i-\\overline{X})\\) diminui.\n\nEncontrado \\(s_{Y|X}\\), o intervalo de confianÃ§a de \\(Y\\) Ã© dado por:\n\\[IC_{Y} = \\hat{Y}\\pm t_{(\\alpha, n-2)} \\times s_{Y|X}\\]\nPara os dados da macrofauna, vamos exemplificar o cÃ¡lculo de \\(IC_{95\\%}\\) para a \\(4^a\\) observaÃ§Ã£o da tabela, em que Richness = 3 e NAP = 0.46.\nLembre-se que jÃ¡ estimamos anteriormente a variÃ¢ncia residual destes dados (\\(s^2 = 7.59\\)). Como temos 9 observaÃ§Ãµes, o valor de \\(t_{(\\alpha, n-2)} = 2.36\\), portanto:\n\\(s_{Y|X} = \\sqrt{s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})} = 0.93\\)\nO valor estimado de riqueza neste ponto Ã© 4.75, portanto:\n\\(IC_{Y} = \\hat{Y} \\pm t_{(\\alpha, n-2)} \\times s_{Y|X} = 4.75 \\pm 2.36 \\times 0.93\\)\n\\(IC_{Y} = 4.75 \\pm 2.19\\)\n\\(IC_{Y_{limite superior}} = 6.94\\)\n\\(IC_{Y_{limite inferior}} = 2.56\\)\nPodemos calcular intervalos destes para todos os pontos observados como expresso na tabela abaixo.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichness\nNAP\n\\(\\hat{Y}\\)\n\\(s_{Y \\mid X}\\)\n\\(IC_{inferior}\\)\n\\(IC_{superior}\\)\n\n\n\n\n13\n-1.34\n9.40\n1.72\n5.34\n13.46\n\n\n8\n0.64\n4.29\n0.96\n2.02\n6.56\n\n\n4\n-0.20\n6.46\n1.03\n4.04\n8.88\n\n\n3\n0.46\n4.75\n0.93\n2.56\n6.94\n\n\n6\n0.73\n4.06\n0.99\n1.73\n6.39\n\n\n1\n2.22\n0.21\n1.90\n-4.29\n4.71\n\n\n1\n1.38\n2.38\n1.30\n-0.70\n5.46\n\n\n7\n-1.00\n8.52\n1.48\n5.02\n12.02\n\n\n3\n0.00\n5.94\n0.96\n3.67\n8.21\n\n\n\n\n\nE representÃ¡-los graficamente, juntamente com os valores ajustados de Y.\n\n\n\n\n\n\n\n\n\nNote que na figura acima, estÃ£o representados os valores observados de riqueza de espÃ©cies (em preto), os valores ajustados (azul) e os intervalos a 95% (vermelho). Os valores ajustados sÃ£o aqueles utilizados para construir a reta de regressÃ£o. O intervalo nÃ£o costuma ser representados por pontos individuais, mas por uma banda que delimita a Ã¡rea que restringe o intervalo de confianÃ§a ao nÃ­vel \\(1 - \\alpha\\) como na figura abaixo.\n\n\n\n\n\n\n\n\n\nA banda mais estreita prÃ³xima ao ponto mÃ©dio de \\(X\\), reflete o ponto comentado anteriormente, de que quanto mais prÃ³ximo ao centro da distibuiÃ§Ã£o de pontos, mais confianÃ§a temos sobre os limites mÃ¡ximos e mÃ­nimos que um valor de \\(Y\\) pode assumir. Do mesmo modo, esta confianÃ§a diminui Ã  medida que nos aproximamos dos extremos dos valores observados em \\(X\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#pressupostos-da-regressÃ£o-linear-simples",
    "href": "content/regressao-linear/regressao-linear-simples.html#pressupostos-da-regressÃ£o-linear-simples",
    "title": "RegressÃ£o linear simples",
    "section": "6 Pressupostos da regressÃ£o linear simples",
    "text": "6 Pressupostos da regressÃ£o linear simples\nAo realizar uma regressÃ£o linear simples, devemos assumir como verdadeiros alguns pressupostos.\n\nO modelo linear descreve adequadamente a relaÃ§Ã£o funcional entre \\(X\\) e \\(Y\\);\nCada par de observaÃ§Ã£o \\((X,Y)\\) Ã© independente dos demais;\nA variÃ¡vel \\(X\\) Ã© medida sem erros;\nOs resÃ­duos tÃªm distribuiÃ§Ã£o normal, e;\nA variÃ¢ncia residual \\(\\sigma^2\\) Ã© constante ao longo dos valores de \\(X\\).\n\n\n6.1 RelaÃ§Ã£o funcional linear\nCaso a relaÃ§Ã£o funcional entre \\(X\\) e \\(Y\\) assuma uma forma diferente de \\(Y_i = \\beta_0 + \\beta_1X_i\\), o modelo de regressÃ£o nÃ£o Ã© mais vÃ¡lido, pois a estimativa de erro irÃ¡ conter, alÃ©m do componente aleatÃ³rio residual, um componente sistemÃ¡tico. Este componente terÃ¡ efeito sobre influÃªncia sobre a prediÃ§Ã£o do modelo, sobretudo nos extremos das observaÃ§Ãµes. Por modelo linear, entendemos aqueles em que os coeficientes \\(\\beta\\) aparecem de forma aditiva. Modelos em que os componentes aparecem de outro modo na equaÃ§Ã£o como potÃªncia ou no denominador de uma equaÃ§Ã£o sÃ£o exemplos de modelos nÃ£o-lineares. Abaixo estÃ£o dois exemplos de relaÃ§Ãµes nÃ£o-lineares comumente observadas em fenÃ´menos ambientais:\nEquaÃ§Ã£o potÃªncia: \\(Y_i = \\beta_0 X_i^{\\beta_1}\\)\nModelo de Michaelis-Menten: \\(Y_i = \\frac{\\beta_0 X_i}{\\beta_1 + X_i}\\)\n\n\n6.2 IndependÃªncia\nA falta de independÃªncia pode ocorrer como resultado do delineamento amostral inapropriado para a questÃ£o em teste. A falta de independÃªncia torna crÃ­tico o uso de uma distribuiÃ§Ã£o de probabilidade para o cÃ¡lculo do intervalo de confianÃ§a (distribuiÃ§Ã£o \\(t\\)) e para o teste de hipÃ³teses (distribuiÃ§Ãµes \\(t\\) e \\(F\\) ). Casos clÃ¡ssicos de falta de independÃªncia sÃ£o aqueles em que as observaÃ§Ãµes sÃ£o denominadas como pseudorÃ©plicas (Hurlbert 1984). ApÃ³s a publicaÃ§Ã£o clÃ¡ssica de Hurlbert, muito tem sido dito sobre pseudoreplicaÃ§Ã£o. Em experimentos de campo, a falta de independÃªncia ocorre geralmente como resultados da proximidade espacial entre as rÃ©plicas ou sobre sÃ©ries temporais.\n\n\n6.3 VariÃ¡vel \\(X\\) Ã© medida sem erros\nVeja que a parcela residual do modelo de regressÃ£o se refere Ã  distÃ¢ncia vertical de \\(Y_i\\), para um dados valor de \\(X\\). Isto implica que os nÃ­veis de \\(X\\) sÃ£o previamente definidos. Quando existe variabilidade aleatÃ³ria tanto em \\(Y\\) quanto em \\(X\\), o modelo correto para a estimativa dos parÃ¢metros da regressÃ£o Ã© conhecido como Modelo II de regressÃ£o. Este pressuposto Ã© frequÃªntemente ignorado em delineamentos de regressÃ£o, sobretudo em estudos observacionais, o que nÃ£o parece ser particularmente problemÃ¡tico.\n\n\n6.4 DistribuiÃ§Ã£o normal dos resÃ­duos\nAssim como no pressuposto de independÃªncia, assumir que os resÃ­duos tÃªm uma distribuiÃ§Ã£o normal permite o uso da distribuiÃ§Ã£o \\(F\\) pra o teste de hipÃ³tese e da distribuiÃ§Ã£io \\(t\\) para o cÃ¡lculo do intervalo de confianÃ§a. Uma distribuiÃ§Ã£o de erros diferente da distribuiÃ§Ã£o normal terÃ¡ influÃªncia sobre o cÃ¡lculo da amplitude do intervalo de confianÃ§a.\n\n\n6.5 VariÃ¢ncia residual constante\nCaso, a variÃ¢ncia \\(\\sigma\\) nÃ£o seja constante ao longo da reta de regressÃ£o, o cÃ¡lculo do intervalo de confianÃ§a e o resultado do teste de hipÃ³teses sÃ£o afetados. Uma vez diagnosticada uma variÃ¢ncia nÃ£o-constante existem modelos de regressÃ£o que podem ser apicados para incorporar este efeito em suas estimativas (Zuur et al. 2009)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#diagnÃ³sticos-da-regressÃ£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#diagnÃ³sticos-da-regressÃ£o",
    "title": "RegressÃ£o linear simples",
    "section": "7 DiagnÃ³sticos da regressÃ£o",
    "text": "7 DiagnÃ³sticos da regressÃ£o\nO diagnÃ³stivo da regressÃ£o Ã© composto por observaÃ§Ãµes e testes que ajudam a decidirmos se a regressÃ£o linear foi um bom modelo para ajustar a um conjunto de dados particular. Um bom modelo neste contexto significa um modelo que atendeu aos pressuostos descritos acima. Esta verificaÃ§Ã£o passa pela observaÃ§Ã£o de padrÃµes nos resÃ­duos da regressÃ£o, ou seja, pela observaÃ§Ã£o da parcela estocÃ¡stica do modelo.\n\n7.1 GrÃ¡fico de resÃ­duos\nO primeiro diagnÃ³stico da regressÃ£o Ã© conhecido como grÃ¡fico de resÃ­duos, que consiste em um grÃ¡fico de dispersÃ£o entre os resÃ­duos e o valor ajustado \\(\\hat{Y}\\). Abaixo estÃ£o os grÃ¡ficos de resÃ­duos que surge quando ajustamos uma reta a dados que apresentam uma relaÃ§Ã£o linear, uma funÃ§Ã£o potÃªncia, uma funÃ§Ã£o assintÃ³tica e uma relaÃ§Ã£o linear porÃ©m comm variÃ¢ncia heterogÃªnea.\n\n\n\n\n\n\n\n\n\nNas primeiras duas figuras, em que a relaÃ§Ã£o Ã© linear, vemos um padrÃ£o crescente de \\(Y\\) como funÃ§Ã£o de \\(X\\) (figura da esquerda), em que os pontos estÃ£o aleatÃ³riamente acima e abaixo da reta de regressÃ£o. Este padrÃ£o se reflete em um grÃ¡fico de resÃ­duos (figura da direita) em que os pontos ficam aleatÃ³riamente acima e abaixo de zero expressando resÃ­duos positivos e negativos respectivamente. Em uma situaÃ§Ã£o em que os pontos estivessem perfeitamente sobre a reta, os resÃ­duos seriam todos iguais a zero e o grÃ¡fico de resÃ­duos mostraria todos os pontos alinhados horizontalmente em zero.\nQuando a relaÃ§Ã£o Ã© potÃªncia e tentamos ajustar uma reta sobre, vemos que inicialmente os resÃ­duos sao positivos, o seja, estÃ£o acima da reta. Os resÃ­duos se tornam negativos no centro da nuvem de pontos e novamente positivos ao final do grÃ¡fico. Este padrÃ£o Ã© mais evidente no grÃ¡fico de resÃ­duos, que mostra um componente sistemÃ¡tico dos resÃ­duos como fuÃ§Ã£o do valor ajustado. Ao usar uma regressÃ£o linear neste caso, irÃ­amos subestimar consistentemente os valores de Y nos extremos da figura e superestimlÃ¡-los no trecho central. Portanto, uma reta de regressÃ£o, quando ajustada a um conjunto de dados que expressa um padrÃ£o nÃ£o-linear, nÃ£o Ã© capaz de isolar adequadamente as parcelas aleatÃ³rias e sistemÃ¡ticas da relaÃ§Ã£o entre \\(Y\\) e \\(X\\). Isto pode ser corrigido aplicando-se uma regressÃ£o nÃ£o-linear aos dados.\nQuando a relaÃ§Ã£o Ã© assintÃ³tica, o resultado do ajuste foi inverso ao anterior. De fato, resultados anÃ¡logos serÃ£o observados senpre que tentarmos ajustra uma regressÃ£o linear a dados que expressam padrÃµes nÃ£o-lineares.\nNo Ãºltimo exemplo (variÃ¢ncia heterogÃªnea) os pontos tendem a se afastar consistentemente da reta de regressÃ£o conforme aumentam os valores de \\(X\\). Isto denota que o pressuposto de variÃ¢ncia \\(\\sigma^2\\) constante nÃ£o Ã© vÃ¡lido nesta relaÃ§Ã£o. Isto pode ser corrigido aplicando-se um modelo de regressÃ£o linear com variÃ¢ncia heterogÃªnea.\n\n\n7.2 Histograma dos resÃ­duos\nOutro diagnÃ³stico da regressÃ£o consiste em fazer um histograma dos grÃ¡ficos de resÃ­duos. Um histograma, aproximadamente simÃ©trico ao redor de zero o que sugere que o pressuposto de normalidade dos resÃ­duos Ã© vÃ¡lido neste caso. Existem testes formais de normalidade cmo o teste de Kolmogorov Smirnov ou o teste de Shapiro-Wilk."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "",
    "text": "DicaObjetivos\n\n\n\nNeste tutorial, vamos implementar o MÃ©todo dos MÃ­nimos Quadrados (MMQ) em Python para ajustar um modelo de regressÃ£o polinomial de segundo grau.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\beta_2\\) da equaÃ§Ã£o \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#introduÃ§Ã£o",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#introduÃ§Ã£o",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "",
    "text": "DicaObjetivos\n\n\n\nNeste tutorial, vamos implementar o MÃ©todo dos MÃ­nimos Quadrados (MMQ) em Python para ajustar um modelo de regressÃ£o polinomial de segundo grau.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\beta_2\\) da equaÃ§Ã£o \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#importando-as-bibliotecas",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#importando-as-bibliotecas",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "2 ğŸ› ï¸ Importando as Bibliotecas",
    "text": "2 ğŸ› ï¸ Importando as Bibliotecas\nVamos comeÃ§ar importando as bibliotecas necessÃ¡rias:\n\nimport pandas as pd           # Para manipulaÃ§Ã£o de dados\nimport matplotlib.pyplot as plt  # Para criaÃ§Ã£o e manipulaÃ§Ã£o grÃ¡fica\nimport seaborn as sns        # Para criaÃ§Ã£o e manipulaÃ§Ã£o grÃ¡fica\nimport numpy as np           # Para operaÃ§Ãµes matemÃ¡ticas e matriciais"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#inserindo-os-dados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#inserindo-os-dados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "3 ğŸ“Š Inserindo os Dados",
    "text": "3 ğŸ“Š Inserindo os Dados\nVamos trabalhar com dados que apresentam uma relaÃ§Ã£o quadrÃ¡tica. Ao invÃ©s de digitarmos os dados diretamente \\(y\\) e \\(x\\) como listas, iremos ler os dados a partir de um arquivo que estÃ¡ disponÃ­vel no link regressao_polinomial_exemplo. O arquivo esta no formato .csv em que cada coluna Ã© separada por uma vÃ­rgula, um tipo de formataÃ§Ã£o muito comum.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regressao_polinomial_exemplo.csv')\n\nUtilizando a funÃ§Ã£o read_csv() da bilbioteca Pandas, os dados foram importados no formato de data frame, basicamento uma estrutura de dados em linhas e colunas, em que as colunas sÃ£o denominadas de atributos.\n\nprint(df)\n\n   x   y\n0  0   5\n1  1   2\n2  2  10\n3  3   8\n4  4  15\n5  5  35"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-os-dados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-os-dados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "4 ğŸ“ˆ Visualizando os Dados",
    "text": "4 ğŸ“ˆ Visualizando os Dados\nAntes de ajustar o modelo, vamos visualizar nossos dados:\n\n# Criando the grÃ¡fico de dispersÃ£o\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data = df, x = 'x', y = 'y', color = '#0072B2', s=120, label='Dados observados')\n\n# Configurando o grÃ¡fico\nplt.title('GrÃ¡fico de DispersÃ£o dos Dados', fontsize=14, fontweight='bold')\nplt.xlabel('VariÃ¡vel X', fontsize=12)\nplt.ylabel('VariÃ¡vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nğŸ“ ObservaÃ§Ã£o 1: Aparentemente, um modelo polinomial de segundo grau pode oferecer um ajuste melhor a estes dados do que a regressÃ£o linear simples. Nosso objetivo serÃ¡ explorar esse modelo e, ao final, comparÃ¡-lo com o modelo linear.\nğŸ“ ObservaÃ§Ã£o 2: Como importamos os dados diretamente de um arquivo .csv para o objeto df, utilizamos a funÃ§Ã£o scatterplot da biblioteca Seaborn para plotar o grÃ¡fico de dispersÃ£o entre as variÃ¡veis \\(y\\) e \\(x\\)."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#implementando-o-mmq-polinomial---passo-a-passo",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#implementando-o-mmq-polinomial---passo-a-passo",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "5 ğŸ§® Implementando o MMQ Polinomial - Passo a Passo",
    "text": "5 ğŸ§® Implementando o MMQ Polinomial - Passo a Passo\n\n5.1 Criando os Vetores Base\nPara o modelo polinomial \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\), precisamos dos vetores:\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_2 = \\begin{bmatrix} x_1^2 \\\\ x_2^2 \\\\ \\vdots \\\\ x_n^2 \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# NÃºmero de observaÃ§Ãµes\nn = len(df['x'])\n\n# Vetor f0: vetor de 1's (para o intercepto Î²â‚€)\nf0 = [1] * n\n\n# Vetor f1: valores de x (para o coeficiente linear Î²â‚)\nf1 = df['x'].copy()\n\n# Vetor f2: valores de xÂ² (para o coeficiente quadrÃ¡tico Î²â‚‚)\nf2 = np.array(df['x'])**2  # Eleva cada elemento de x ao quadrado\n\nVisualizando os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{f}_2\\).\n\nprint(\"Vetor f0 (intercepto):\", f0)\nprint(\"Vetor f1 (termo linear):\", f1)\nprint(\"Vetor f2 (termo quadrÃ¡tico):\", f2)\n\nVetor f0 (intercepto): [1, 1, 1, 1, 1, 1]\nVetor f1 (termo linear): 0    0\n1    1\n2    2\n3    3\n4    4\n5    5\nName: x, dtype: int64\nVetor f2 (termo quadrÃ¡tico): [ 0  1  4  9 16 25]\n\n\n\n\n5.2 Construindo as Matrizes X e Y\nAgora vamos montar as matrizes do sistema polinomial:\n\\[X = \\begin{bmatrix} \\vec{f}_0 & \\vec{f}_1 & \\vec{f}_2 \\end{bmatrix} = \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ 1 & x_2 & x_2^2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x_n^2 \\end{bmatrix} \\quad \\text{e} \\quad Y = \\begin{bmatrix} \\vec{y} \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# Matriz X: combinando f0, f1 e f2 em colunas\nX = np.column_stack((f0, f1, f2))\n\n# Matriz Y: transformando y em matriz com n linhas e 1 coluna\nY = np.array(df['y']).reshape(n, 1)\n\n\n\n5.3 Resolvendo o Sistema Normal\nCalculamos os coeficientes usando a mesma fÃ³rmula:\n\\[B = (X^T X)^{-1} X^T Y\\]\n\n# Calculando X transposta vezes X\nXTX = X.T @ X  # X.T Ã© a transposta de X\n# Calculando X transposta vezes Y\nXTY = X.T @ Y\n# Calculando a matriz inversa (X^T X)^(-1)\nXTX_inv = np.linalg.inv(XTX)  # Inversa de X^T X\n# Coeficientes de regressÃ£o\nB = XTX_inv @ XTY\n\n\n\n\n\n\n\nNotaInterpretaÃ§Ã£o\n\n\n\n\n\\(\\beta_0\\) (intercepto): valor de y quando x = 0\n\\(\\beta_1\\) (coeficiente linear): relacionado Ã  taxa de variaÃ§Ã£o linear\n\\(\\beta_2\\) (coeficiente quadrÃ¡tico): relacionado Ã  curvatura da parÃ¡bola\n\nSe \\(\\beta_2 &gt; 0\\): parÃ¡bola com concavidade para cima\nSe \\(\\beta_2 &lt; 0\\): parÃ¡bola com concavidade para baixo\n\n\n\n\n\n\n5.4 Obtendo os Valores Ajustados de y\nTendo obtido os coeficientes de regressÃ£o, os valores ajustados de y (\\(\\hat{y}\\)) podem ser obtido pela multiplicaÃ§Ã£o matricial:\n\\[F = XB = \\begin{bmatrix} 1 & x_1 & x^2_1 \\\\ 1 & x_2 & x^2_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x^2_n \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{bmatrix}\\]\nObs.: denominamos \\(F\\) a matriz de valores ajustados de \\(y\\).\n\n# Valores ajustados (preditos)\nF = X @ B\n\n\n\n5.5 Avaliando a Qualidade do Ajuste\n\n5.5.1 Calculando a Soma dos Quadrados dos ResÃ­duos (\\(SQ_{res}\\))\n\\(SQ_{res}\\) pode ser obtida pela multiplicaÃ§Ã£o matricial:\n\\[SQ_{res} = \\boldsymbol{e}^T \\boldsymbol{e}\\]\nEm que \\(\\boldsymbol{e}\\) Ã© a matriz coluna dos resÃ­duos obtida pela diferenÃ§a entre os valores observados e ajustados de \\(y\\):\n\\[\\boldsymbol{e} = Y - F = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\]\n\n# ResÃ­duos: diferenÃ§a entre valores observados e ajustados\ne = Y - F\n\n# Soma dos Quadrados dos ResÃ­duos\nSQres = (e.T @ e)[0, 0]\n\n\n\n5.5.2 Calculando a Soma dos Quadrados Totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser obtida pela multiplicaÃ§Ã£o matricial:\n\\[SQ_{tot} = \\boldsymbol{D}^T \\boldsymbol{D}\\]\nEm que \\(\\boldsymbol{D}\\) Ã© a matriz coluna dos desvios da mÃ©dis obtida pela diferenÃ§a entre os valores observados de \\(y\\) e a mÃ©dia de \\(\\overline{y}\\):\n\\[\\boldsymbol{D} = Y - \\overline{Y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\overline{y} \\\\ \\overline{y} \\\\ \\vdots \\\\ \\overline{y} \\end{bmatrix} = \\begin{bmatrix} d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_n \\end{bmatrix}\\]\n\n# Soma dos Quadrados Total\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\n\n\n5.5.3 Calculando o coeficiente de determinaÃ§Ã£o \\(R^2\\):\nO \\(R^2\\) Ã© dado pela expressÃ£o:\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]\n\n# Coeficiente de DeterminaÃ§Ã£o RÂ²\nR2 = 1 - (SQres / SQtot)\n\n\nVisualizando os resultados:\n\nprint(\"ğŸ“Š Medidas de Qualidade do Ajuste:\")\nprint(f\"Soma dos Quadrados dos ResÃ­duos (SQres): {SQres:.4f}\")\nprint(f\"Soma dos Quadrados Total (SQtot): {SQtot:.4f}\")\nprint(f\"Coeficiente de DeterminaÃ§Ã£o (RÂ²): {R2:.4f}\")\nprint(f\"Porcentagem da variaÃ§Ã£o explicada: {R2*100:.2f}%\")\n\nğŸ“Š Medidas de Qualidade do Ajuste:\nSoma dos Quadrados dos ResÃ­duos (SQres): 59.2643\nSoma dos Quadrados Total (SQtot): 705.5000\nCoeficiente de DeterminaÃ§Ã£o (RÂ²): 0.9160\nPorcentagem da variaÃ§Ã£o explicada: 91.60%"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-o-resultado-final",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-o-resultado-final",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "6 ğŸ“Š Visualizando o Resultado Final",
    "text": "6 ğŸ“Š Visualizando o Resultado Final\nVamos plotar os dados originais junto com a curva ajustada:\nCriando uma linha contÃ­nua para \\(\\hat{y}\\)\n\n# Criando pontos para desenhar a curva suave\nx_curva = np.linspace(min(df['x']), max(df['x']), 100)\ny_curva = B[0, 0] + B[1, 0] * x_curva + B[2, 0] * x_curva**2\n\n\n# Criando o grÃ¡fico final\nplt.figure(figsize=(8, 6))\n\n# Pontos observados\nsns.scatterplot(data = df, x = 'x', y = 'y', \n                color = '#0072B2', s=120,\n                label=f'Dados observados (n={n})')\n\n# Valores ajustados\nplt.scatter(df['x'], F[:,0], \n           color='#000000', marker='*', s=120, \n           label='Valores ajustados')\n\n# Curva ajustada\nplt.plot(x_curva, y_curva, \n         color='#D55E00', \n         label=fr'Curva ajustada: $\\hat{{y}} = {B[0,0]:.3f} {B[1,0]:.3f}x + {B[2,0]:.3f}x^2$')\n\n# ConfiguraÃ§Ãµes do grÃ¡fico\nplt.title(f'RegressÃ£o Polinomial (2Âº grau) - MMQ\\nRÂ² = {R2:.4f}', \n          fontsize=15, fontweight='bold')\nplt.xlabel('VariÃ¡vel X', fontsize=12)\nplt.ylabel('VariÃ¡vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-dos-resultados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-dos-resultados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "7 ğŸ¯ Resumo dos Resultados",
    "text": "7 ğŸ¯ Resumo dos Resultados\n\nprint(\"=\"*60)\nprint(\"         RESUMO DA REGRESSÃƒO POLINOMIAL\")\nprint(\"=\"*60)\nprint(f\"EquaÃ§Ã£o ajustada: y = {B[0,0]:.4f} {B[1,0]:.4f}x + {B[2,0]:.4f}xÂ²\")\nprint(f\"Coeficiente de determinaÃ§Ã£o (RÂ²): {R2:.4f}\")\nprint(f\"Porcentagem da variaÃ§Ã£o explicada: {R2*100:.2f}%\")\nprint(\"=\"*60)\n\n============================================================\n         RESUMO DA REGRESSÃƒO POLINOMIAL\n============================================================\nEquaÃ§Ã£o ajustada: y = 5.7500 -4.5679x + 1.9821xÂ²\nCoeficiente de determinaÃ§Ã£o (RÂ²): 0.9160\nPorcentagem da variaÃ§Ã£o explicada: 91.60%\n============================================================"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#comparaÃ§Ã£o-linear-vs-polinomial",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#comparaÃ§Ã£o-linear-vs-polinomial",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "8 ğŸ” ComparaÃ§Ã£o: Linear vs Polinomial",
    "text": "8 ğŸ” ComparaÃ§Ã£o: Linear vs Polinomial\nVamos comparar o ajuste linear e polinomial para os mesmos dados:\n\n# Ajuste LINEAR para comparaÃ§Ã£o\nX_linear = np.column_stack((f0, f1))  # Apenas f0 e f1\nB_linear = np.linalg.inv(X_linear.T @ X_linear) @ (X_linear.T @ Y)\n\n# RÂ² do modelo linear\nF_linear = X_linear @ B_linear\nresiduos_linear = Y - F_linear\nSQres_linear = (residuos_linear.T @ residuos_linear)[0, 0]\nR2_linear = 1 - (SQres_linear / SQtot)\n\nprint(\"ğŸ“Š ComparaÃ§Ã£o dos Modelos:\")\nprint(\"-\" * 40)\nprint(f\"Modelo Linear:     RÂ² = {R2_linear:.4f}\")\nprint(f\"Modelo Polinomial: RÂ² = {R2:.4f}\")\nprint(f\"Melhoria no RÂ²:    {R2 - R2_linear:.4f}\")\n\nğŸ“Š ComparaÃ§Ã£o dos Modelos:\n----------------------------------------\nModelo Linear:     RÂ² = 0.7081\nModelo Polinomial: RÂ² = 0.9160\nMelhoria no RÂ²:    0.2079\n\n\nGrÃ¡ficos de dispersÃ£o\n\nx_vals = df[\"x\"].to_numpy()\n\ny_linear = B_linear[0, 0] + B_linear[1, 0] * x_vals\n\n# GrÃ¡fico comparativo\nplt.figure(figsize=(8, 6))\n\n# plt.subplot(1, 2, 1)\nsns.scatterplot(data = df, x = 'x', y = 'y', s=100, color = '#0072B2', label='Dados observados')\nplt.plot(x_vals, y_linear, color='#D55E00', label=f'Modelo Linear\\nRÂ² = {R2_linear:.4f}')\nplt.plot(x_curva, y_curva, color='#009E73', label=f'Modelo Polinomial\\nRÂ² = {R2:.4f}')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.legend()\n\n# plt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-do-cÃ³digo-modelo-polinomial",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-do-cÃ³digo-modelo-polinomial",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "9 ğŸ§¾ Resumo do CÃ³digo (modelo polinomial)",
    "text": "9 ğŸ§¾ Resumo do CÃ³digo (modelo polinomial)\n\nInserÃ§Ã£o dos Dados\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regressao_polinomial_exemplo.csv')\n\n\nDefiniÃ§Ã£o das matrizes do sistema\n\n\nn = len(df['x'])\nf0 = [1] * n\nf1 = df['x'].copy()\nf2 = np.array(df['x'])**2\n\nX = np.column_stack((f0, f1, f2))\nY = np.array(df['y']).reshape(n, 1)\n\n\nCÃ¡lculo dos coeficientes\n\n\nXTX = X.T @ X\nXTY = X.T @ Y\nXTX_inv = np.linalg.inv(XTX)\nB = XTX_inv @ XTY\n\n\nQualidade do ajuste\n\n\nY_ajustado = X @ B\ne = Y - Y_ajustado\nSQres = (e.T @ e)[0, 0]\n\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\nR2 = 1 - (SQres / SQtot)"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#exercÃ­cio-prÃ¡tico",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#exercÃ­cio-prÃ¡tico",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "10 ğŸš€ ExercÃ­cio PrÃ¡tico",
    "text": "10 ğŸš€ ExercÃ­cio PrÃ¡tico\nTeste o cÃ³digo com novos dados:\n\n# Experimente com estes dados (padrÃ£o quadrÃ¡tico diferente):\ndf_novo = pd.DataFrame({\n  'x_novo': [1, 2, 3, 4, 5, 6, 7],\n  'y_novo': [30, 12, 18, 9, 7, 8, 6]\n})\n\nprint(df_novo)\n\n# QuestÃµes para investigar:\n# 1. Qual Ã© o RÂ² do modelo polinomial para estes dados?\n# 2. O coeficiente Î²â‚‚ Ã© positivo ou negativo? O que isso significa?\n# 3. Compare com o modelo linear - qual Ã© a diferenÃ§a no RÂ²?\n\n# Implemente todo o processo do MMQ polinomial com os novos dados\n# Dica: vocÃª pode copiar e adaptar o cÃ³digo acima!\n\n   x_novo  y_novo\n0       1      30\n1       2      12\n2       3      18\n3       4       9\n4       5       7\n5       6       8\n6       7       6"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#conceitos-importantes-revisados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#conceitos-importantes-revisados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "11 ğŸ’¡ Conceitos Importantes Revisados",
    "text": "11 ğŸ’¡ Conceitos Importantes Revisados\n\nRegressÃ£o Polinomial: ExtensÃ£o da regressÃ£o linear para relaÃ§Ãµes curvas\nMatriz de Design: Agora com trÃªs colunas: \\([1, x, x^2]\\)\nInterpretaÃ§Ã£o dos Coeficientes: Cada coeficiente tem significado especÃ­fico\nComparaÃ§Ã£o de Modelos: Uso do \\(R^2\\) para avaliar qual modelo Ã© melhor"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#prÃ³ximos-passos",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#prÃ³ximos-passos",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial",
    "section": "12 ğŸ”— PrÃ³ximos Passos",
    "text": "12 ğŸ”— PrÃ³ximos Passos\n\nExperimente com polinÃ´mios de grau maior (\\(x^3\\), \\(x^4\\), etc.)\nInvestigue o conceito de overfitting com graus muito altos"
  },
  {
    "objectID": "content/multivariada-numerica/ordination.html",
    "href": "content/multivariada-numerica/ordination.html",
    "title": "MÃ©todos de ordenaÃ§Ã£o",
    "section": "",
    "text": "1 OrdenaÃ§Ã£o\n(ConteÃºdo em construÃ§Ã£o)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#conteÃºdo-da-aula",
    "href": "content/multivariada-numerica/intro-matrizes.html#conteÃºdo-da-aula",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "ConteÃºdo da aula",
    "text": "ConteÃºdo da aula\n\n\nDefiniÃ§Ã£o de matriz\nAdiÃ§Ã£o de matrizes\nMultiplicaÃ§Ã£o por um escalar\nMultiplicaÃ§Ã£o de matrizes\nTransposta de uma matriz\nÃlgebra de matrizes\nInversa de uma matriz\nInversa de uma matriz pelo mÃ©todo de Gauss-Jordan\nMatrizes elementares\nCadeias de Markov para Recifes de Coral"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#definiÃ§Ã£o-de-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#definiÃ§Ã£o-de-matriz",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "DefiniÃ§Ã£o de matriz",
    "text": "DefiniÃ§Ã£o de matriz\n\\[A_{22} = \\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix};\nB_{33} = \\begin{bmatrix}\n5 & 6 & 7 \\\\\n8 & 9 & 10 \\\\\n11 & 12 & 13\n\\end{bmatrix}; C_{34} = \\begin{bmatrix}\n14 & 15 & 16 & 17 \\\\\n18 & 19 & 20 & 21 \\\\\n22 & 23 & 24 & 25\n\\end{bmatrix}\\]\n\nEstrutura geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\)\n\\[A_{mn} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#adiÃ§Ã£o-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#adiÃ§Ã£o-de-matrizes",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "AdiÃ§Ã£o de matrizes",
    "text": "AdiÃ§Ã£o de matrizes\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}; B = \\begin{bmatrix}\n9 & 8 & 7 \\\\\n6 & 5 & 4 \\\\\n3 & 2 & 1\n\\end{bmatrix}\\)\n\n\\(A + B = \\begin{bmatrix}\n1 + 9 & 4 + 8 & 7 + 7 \\\\\n2 + 6 & 5 + 5 & 8 + 4 \\\\\n3 + 3 & 6 + 2 & 9 + 1\n\\end{bmatrix}\n= \\begin{bmatrix}\n10 & 12 & 14 \\\\\n8 & 10 & 12 \\\\\n6 & 8 & 10\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para duas matrizes \\(m \\times n\\), \\(A = [a_{ij}]\\) e \\(B = [b_{ij}]\\):\n\\[A + B = [a_{ij} + b_{ij}] = \\begin{bmatrix}\na_{11} + b_{11} & a_{12} + b_{12} & \\cdots & a_{1n} + b_{1n} \\\\\na_{21} + b_{21} & a_{22} + b_{22} & \\cdots & a_{2n} + b_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} + b_{m1} & a_{m2} + b_{m2} & \\cdots & a_{mn} + b_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-por-um-escalar",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-por-um-escalar",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "MultiplicaÃ§Ã£o por um escalar",
    "text": "MultiplicaÃ§Ã£o por um escalar\n\n\n\nSeja \\(A\\) uma matriz \\(3 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}\\)\n\nA multiplicaÃ§Ã£o de \\(A\\) por um escalar \\(c = 3\\):\n\\(cA = 3 \\times \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}\n= \\begin{bmatrix}\n3 \\times 1 & 3 \\times 4 & 3 \\times 7 \\\\\n3 \\times 2 & 3 \\times 5 & 3 \\times 8 \\\\\n3 \\times 3 & 3 \\times 6 & 3 \\times 9\n\\end{bmatrix}\n= \\begin{bmatrix}\n3 & 12 & 21 \\\\\n6 & 15 & 24 \\\\\n9 & 18 & 27\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\) e um escalar \\(c\\):\n\\[cA = [c \\times a_{ij}] = \\begin{bmatrix}\nc \\times a_{11} & c \\times a_{12} & \\cdots & c \\times a_{1n} \\\\\nc\\times a_{21} & c \\times a_{22} & \\cdots & c \\times a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc \\times a_{m1} & c \\times a_{m2} & \\cdots & c \\times a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-de-matrizes",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "MultiplicaÃ§Ã£o de matrizes",
    "text": "MultiplicaÃ§Ã£o de matrizes\n\n\n\nSeja \\(A\\) uma matriz \\(2 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\\)\ne \\(B\\) uma matriz \\(3 \\times 2\\):\n\\(B = \\begin{bmatrix}\n7 & 8 \\\\\n9 & 10 \\\\\n11 & 12\n\\end{bmatrix}\\)\n\nA multiplicaÃ§Ã£o de \\(A\\) por \\(B\\):\n\\(AB = \\begin{bmatrix}\n1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11 & 1 \\cdot 8 + 2 \\cdot 10 + 3 \\cdot 12 \\\\\n4 \\cdot 7 + 5 \\cdot 9 + 6 \\cdot 11 & 4 \\cdot 8 + 5 \\cdot 10 + 6 \\cdot 12\n\\end{bmatrix}\n= \\begin{bmatrix}\n58 & 64 \\\\\n139 & 154\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\), e uma matriz \\(n \\times p\\), \\(B = [b_{ij}]\\):\n\\[AB = [c_{ij}] = \\begin{bmatrix}\n\\sum_{k=1}^{n} a_{1k} b_{k1} & \\sum_{k=1}^{n} a_{1k} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{1k} b_{kp} \\\\\n\\sum_{k=1}^{n} a_{2k} b_{k1} & \\sum_{k=1}^{n} a_{2k} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{2k} b_{kp} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sum_{k=1}^{n} a_{mk} b_{k1} & \\sum_{k=1}^{n} a_{mk} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{mk} b_{kp}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-de-matrizes-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplicaÃ§Ã£o-de-matrizes-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "MultiplicaÃ§Ã£o de matrizes",
    "text": "MultiplicaÃ§Ã£o de matrizes\nPropriedades AlgÃ©bricas da MultiplicaÃ§Ã£o de Matrizes\n\nSejam \\(A\\), \\(B\\) e \\(C\\) matrizes (cujas ordens possibilitem que as operaÃ§Ãµes indicadas sejam realizadas) e seja \\(k\\) um escalar. EntÃ£o:\n\n\n\n\n\n\n\n\n\nPropriedade\nDescriÃ§Ã£o\n\n\n\n\n1\n\\(A(BC) = (AB)C\\)\nAssociatividade\n\n\n2\n\\(A(B + C) = AB + AC\\)\nDistributiva Ã  esquerda\n\n\n3\n\\((A + B)C = AC + BC\\)\nDistributiva Ã  direita\n\n\n4\n\\(k(AB) = (kA)B = A(kB)\\)\n\n\n\n5\n\\(I_m A = A = A I_n\\) se \\(A\\) for \\(m \\times n\\)\nIdentidade da multiplicaÃ§Ã£o"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Transposta de uma matriz",
    "text": "Transposta de uma matriz\n\n\n\nSeja \\(A\\) uma matriz \\(2 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\\)\n\nA transposta de \\(A\\) Ã© dada por \\(A^T = [a_{ij}]^T = [a_{ji}]\\):\n\\(A^T = \\begin{bmatrix}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\):\n\n\n\\(A = [a_{ij}] = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\\)\n\n\\(A^T = [a_{ji}] = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{n1} \\\\\na_{12} & a_{22} & \\cdots & a_{n2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1m} & a_{2m} & \\cdots & a_{nm}\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Transposta de uma matriz",
    "text": "Transposta de uma matriz\nPropriedades AlgÃ©bricas da Transposta de Matrizes\n\nSejam \\(A\\) e \\(B\\) matrizes (cujas ordens sÃ£o tais que as operaÃ§Ãµes indicadas podem ser realizadas) e seja \\(k\\) um escalar. EntÃ£o:\n\n\n\n\nPropriedade\n\n\n\n\n1\n\\((A^T)^T = A\\)\n\n\n2\n\\((A + B)^T = A^T + B^T\\)\n\n\n3\n\\((kA)^T = k(A^T)\\)\n\n\n4\n\\((AB)^T = B^T A^T\\)\n\n\n5\n\\((A^r)^T = (A^T)^r\\) para todos os inteiros \\(r\\) nÃ£o negativos"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#Ã¡lgebra-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#Ã¡lgebra-de-matrizes",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Ãlgebra de matrizes",
    "text": "Ãlgebra de matrizes\nPropriedades AlgÃ©bricas da AdiÃ§Ã£o de Matrizes e da MultiplicaÃ§Ã£o por Escalar\n\nSejam \\(A\\), \\(B\\) e \\(C\\) matrizes de mesma ordem, e \\(c\\) e \\(d\\) escalares. EntÃ£o:\n\n\n\n\nPropriedade\nDescriÃ§Ã£o\n\n\n\n\n1\n\\(A + B = B + A\\)\nComutatividade\n\n\n2\n\\((A + B) + C = A + (B + C)\\)\nAssociatividade\n\n\n3\n\\(A + O = A\\)\n\n\n\n4\n\\(A + (-A) = O\\)\n\n\n\n5\n\\(c(A + B) = cA + cB\\)\nDistributividade\n\n\n6\n\\((c + d)A = cA + dA\\)\nDistributividade\n\n\n7\n\\(c(dA) = (cd)A\\)\n\n\n\n8\n\\(1A = A\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#combinaÃ§Ãµes-lineares-em-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#combinaÃ§Ãµes-lineares-em-matrizes",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "CombinaÃ§Ãµes lineares em matrizes",
    "text": "CombinaÃ§Ãµes lineares em matrizes\n\nEscrevendo a matriz \\(B = \\begin{bmatrix} 1 & 4 \\\\ 2 & 1 \\end{bmatrix}\\) como combinaÃ§Ã£o linear de \\(A_1 = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\\), \\(A_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\) e \\(A_3 = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1  \\end{bmatrix}\\)\ntemos\n\\[c_1A_1 + c_2A_2 + c_3A_3 = B\\]\n\\[c_1\\begin{bmatrix}\n0 & 1 \\\\\n-1 & 0\n\\end{bmatrix} +\nc_2\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} +\nc_3\\begin{bmatrix}\n1 & 1 \\\\\n1 & 1\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 4 \\\\\n2 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\nA combinÃ§Ã£o linear pode ser resolvida pelo sistema:\n\\[\n\\begin{cases}\nc_2 + c_3 = 1 \\\\\nc_1 + c_3 = 4 \\\\\n-c_1 + c_3 = 2 \\\\\nc_2 + c_3 = 1\n\\end{cases}\n\\]\n\nQue tem soluÃ§Ã£o:\n\\[c_1 = 1\\] \\[c_2 = -2\\] \\[c_3 = 3\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nSeja \\(A = \\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix}\\) e \\(A^{-1} = \\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix}\\)\n\nVerificamos que \\(A^{-1}\\) Ã© inversa de \\(A\\) pois:\n\\(AA^{-1} = \\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix} = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} = I\\)\ne\n\\(A^{-1}A = \\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix}\n\\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix} = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} = I\\)\n\n\n\n\n\n\n\n\n\nDefiniÃ§Ã£o\n\n\nSe \\(A\\) Ã© uma matriz \\(n \\times n\\), uma inversa de \\(A\\) Ã© uma matriz \\(n \\times n\\) \\(A^{-1}\\) que satisfaz:\n\\[AA^{-1} = I\\] e \\[A^{-1}A = I\\]\nsendo \\(I = I_n\\) a matriz identidade \\(n \\times n\\). Se existir uma matriz \\(A^{-1}\\) assim, diremos que \\(A\\) Ã© invertÃ­vel."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\nEm cada exemplo, verifique se a matriz \\(B\\) Ã© inversa de \\(A\\)\n\n\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n-2 & 1 \\\\\n1.5 & -0.5\n\\end{bmatrix}\\)\n\n\n\n\\(A = \\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n3 & -5 \\\\\n-1 & 1\n\\end{bmatrix}\\)\n\n\n\n\n\n\n\\(A = \\begin{bmatrix}\n2 & 1 & 1 \\\\\n1 & 3 & 2 \\\\\n1 & 0 & 0\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n0 & 0 & 1 \\\\\n-2 & 1 & 3 \\\\\n3 & -1 & -5\n\\end{bmatrix}\\)\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n0 & 1 & 4 \\\\\n5 & 6 & 0\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n4 & 2 & -2 \\\\\n-1 & 3 & 5 \\\\\n0 & 5 & 1\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-2",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-2",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nVerifique que \\(A = \\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\\) invertÃ­vel e pode ser escrita por:\n\\(\\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\nw & x \\\\\ny & z\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\\)\n\nQue resulta no sistema de equaÃ§Ãµes:\n\\(\\begin{cases}\n2w + 5y = 1 \\\\\n2x + 5z = 0 \\\\\nw + 3y = 0 \\\\\nx + 3z = 1\n\\end{cases}\\)\n\n\n\n\nQue pode ser resolvido por:\n\\(\\left[ \\begin{array}{cccc|c}\n2 & 0 & 5 & 0 & 1\\\\\n0 & 2 & 0 & 5 & 0\\\\\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\n\\end{array} \\right]\\) \\(\\begin{array}{c}\nL_1 \\leftrightarrow L_3\\\\\nL_2 \\leftrightarrow L_4\\\\\n\\\\\n\\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\\\\\n2 & 0 & 5 & 0 & 1\\\\\n0 & 2 & 0 & 5 & 0\n\\end{array} \\right]\\) \\(\\begin{array}{c}\n\\\\\n\\\\\nL_3 - 2L_1 \\\\\nL_4 - 2L_2 \\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\\\\\n0 & 0 & -1 & 0 & 1\\\\\n0 & 0 & 0 & -1 & -2\n\\end{array} \\right]\\) \\(\\begin{array}{c}\nL_1 + 3L_3 \\\\\nL_2 + 3L_4 \\\\\n-L_3 \\\\\n-L_4 \\\\\n\\end{array}\\)\n\\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 0 & 0 & 3\\\\\n0 & 1 & 0 & 0 & -5\\\\\n0 & 0 & 1 & 0 & -1\\\\\n0 & 0 & 0 & 1 & 2\n\\end{array} \\right]\\) \\(S = \\left[\\begin{array}{c}\n3 \\\\\n-5 \\\\\n-1 \\\\\n2 \\\\\n\\end{array} \\right]\\) Portanto: \\(A^{-1} = \\begin{bmatrix}\n3 & -5 \\\\\n-1 & 2\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-3",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-3",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nVerifique que \\(B = \\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix}\\) nÃ£o Ã© invertÃ­vel e portanto nÃ£o pode ser escrita por:\n\\(\\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix}\n\\begin{bmatrix}\nw & x \\\\\ny & z\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\\)\n\nO sistema de equaÃ§Ãµes lineares fica:\n\\(\\begin{cases}\nw + 2y = 1 \\\\\nx + 2z = 0 \\\\\n2w + 4y = 0 \\\\\n2x + 4z = 1\n\\end{cases}\\)\n\n\n\n\nQue pode ser representado por:\n\\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 2 & 0 & 1\\\\\n0 & 1 & 0 & 2 & 0\\\\\n2 & 0 & 4 & 0 & 0\\\\\n0 & 2 & 0 & 4 & 1\n\\end{array} \\right]\\) \\(\\begin{array}{c}\n\\\\\n\\\\\nL_3 - 2L_1 \\\\\nL_4 - 2L_2 \\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 2 & 0 & 1\\\\\n0 & 1 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & -2\\\\\n0 & 0 & 0 & 0 & -1\n\\end{array} \\right]\\)\n\nA matriz na forma escalonada mostra que o sistema nÃ£o tem soluÃ§Ã£o e portanto a matriz \\(B\\) nÃ£o Ã© invertÃ­vel."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-4",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-4",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\n\n\n\n\nTeorema\n\n\nSe \\(A\\) Ã© uma matriz \\(n \\times n\\) invertÃ­vel, o sistema de equaÃ§Ãµes lineares dado por \\(A\\vec{x} = \\vec{b}\\) tem uma Ãºnica soluÃ§Ã£o \\(\\vec{x} = A^{-1}\\vec{b}\\) para cada \\(\\vec{b}\\) em \\(\\mathbb{R}^n\\).\n\n\n\n\n\n\n\n\n\n\n\nPropriedades\n\n\n\nSe \\(A\\) Ã© uma matriz invertÃ­vel, entÃ£o \\(A^{-1}\\) Ã© invertÃ­vel e \\((A^{-1})^{-1} = A\\).\nSe \\(A\\) Ã© uma matriz invertÃ­vel e \\(c\\) Ã© um escalar nÃ£o nulo, entÃ£o \\(cA\\) Ã© uma matriz invertÃ­vel e \\((cA)^{-1} = \\frac{1}{c}A^{-1}\\).\nSe \\(A\\) e \\(B\\) sÃ£o matrizes invertÃ­veis de mesma ordem, entÃ£o \\(AB\\) Ã© invertÃ­vel e \\((AB)^{-1} = B^{-1}A^{-1}\\).\nSe \\(A\\) Ã© uma matriz invertÃ­vel, entÃ£o \\(A^T\\) Ã© invertÃ­vel e \\((A^T)^{-1} = (A^{-1})^T\\).\nSe \\(A\\) Ã© uma matriz invertÃ­vel, entÃ£o, para todo inteiro nÃ£o negativo \\(n\\), a matriz \\(A^n\\) Ã© invertÃ­vel e \\((A^n)^{-1} = (A^{-1})^n\\)."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-mÃ©todo-de-gauss-jordan",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-mÃ©todo-de-gauss-jordan",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz pelo mÃ©todo de Gauss-Jordan",
    "text": "Inversa de uma matriz pelo mÃ©todo de Gauss-Jordan\n\nPara encontrar a inversa de uma matriz \\(A\\) usando o mÃ©todo de Gauss-Jordan, seguimos os seguintes passos:\n\nFormaÃ§Ã£o da Matriz Aumentada:\n\n\nDada uma matriz \\(A\\) de ordem \\(n \\times n\\), formamos a matriz aumentada \\([A \\mid I]\\), onde \\(I\\) Ã© a matriz identidade de ordem \\(n \\times n\\).\n\n\nAplicaÃ§Ã£o de OperaÃ§Ãµes Elementares:\n\n\nAplicamos operaÃ§Ãµes elementares sobre as linhas da matriz aumentada \\([A \\mid I]\\) para transformar a parte esquerda (a matriz \\(A\\)) na matriz identidade \\(I\\).\n\n\nObtenÃ§Ã£o da Inversa:\n\n\nQuando a parte esquerda da matriz aumentada se transforma em \\(I\\), a parte direita serÃ¡ a matriz inversa \\(A^{-1}\\). Ou seja, \\([I \\mid A^{-1}]\\)."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-mÃ©todo-de-gauss-jordan-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-mÃ©todo-de-gauss-jordan-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Inversa de uma matriz pelo mÃ©todo de Gauss-Jordan",
    "text": "Inversa de uma matriz pelo mÃ©todo de Gauss-Jordan\n\nExemplo PrÃ¡tico\n\n\nConsidere a matriz \\(A = \\begin{bmatrix} 2 & 1 & 1 \\\\ 1 & 3 & 2 \\\\ 1 & 0 & 0 \\end{bmatrix}\\).\n\nQue tem a matriz aumentada \\([A \\mid I]\\):\n\\[\\left[\\begin{array}{ccc|ccc}\n   2 & 1 & 1 & 1 & 0 & 0 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   1 & 0 & 0 & 0 & 0 & 1\n   \\end{array}\\right]\\]\n\n\n\n\nAplique operaÃ§Ãµes elementares para transformar a parte esquerda em \\(I\\):\n\\(\\left[\\begin{array}{ccc|ccc}\n   2 & 1 & 1 & 1 & 0 & 0 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   1 & 0 & 0 & 0 & 0 & 1\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   L_1 \\leftrightarrow L_3\\\\\n   \\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   2 & 1 & 1 & 1 & 0 & 0\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 - L_1\\\\\n   L_3 - 2L_1\\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 3 & 2 & 0 & 1 & -1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 \\leftrightarrow L_3\\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 3 & 2 & 0 & 1 & -1\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   \\\\\n   L_3 - 3L_2\\\\\n   \\end{array}\\)\n\\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 0 & -1 & -3 & 1 & 5\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   \\\\\n   -L_3\\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 0 & 1 & 3 & -1 & -5\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 - L_3\\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 0 & -2 & 1 & 3 \\\\\n   0 & 0 & 1 & 3 & -1 & -5\n   \\end{array}\\right]\\)\n\n\\[A^{-1} = \\begin{bmatrix}\n   0  &  0 &  1 \\\\\n   -2 &  1 &  3 \\\\\n   3  & -1 & -5\n   \\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#matrizes-elementares",
    "href": "content/multivariada-numerica/intro-matrizes.html#matrizes-elementares",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Matrizes Elementares",
    "text": "Matrizes Elementares\n\nDefiniÃ§Ã£o:\nMatrizes elementares sÃ£o aquelas obtidas atravÃ©s de operaÃ§Ãµes elementares realizadas sobre a matriz identidade. Elas desempenham um papel fundamental na soluÃ§Ã£o de sistemas lineares e na obtenÃ§Ã£o da inversa de uma matriz.\nExemplos de OperaÃ§Ãµes Elementares:\n\nTroca de Linhas: Exemplo: Trocar a linha 1 pela linha 2.\n\\[E = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\\]\nMultiplicaÃ§Ã£o de uma Linha por um Escalar: Exemplo: Multiplicar a linha 1 por um escalar \\(k\\).\n\\[E = \\begin{bmatrix} k & 0 \\\\ 0 & 1 \\end{bmatrix}\\]\nAdiÃ§Ã£o de MÃºltiplos de Linhas: Exemplo: Adicionar a linha 2 multiplicada por um escalar \\(k\\) Ã  linha 1.\n\\[E = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de Matrizes Elementares para Calcular a Inversa",
    "text": "Exemplo de Matrizes Elementares para Calcular a Inversa\n\n\n\nConsidere a matriz \\(A = \\begin{bmatrix} 2 & 1 & 1 \\\\ 1 & 3 & 2 \\\\ 1 & 0 & 0 \\end{bmatrix}\\).\n\nQue foi resolvida no exemplo anterior pela sequÃªncia de operaÃ§Ãµes elementares:\n\n\\(L_1 \\leftrightarrow L_3\\)\n\\(L_2 \\rightarrow L_2 - L_1\\); \\(L_3 \\rightarrow L_3 - 2L_1\\)\n\\(L_2 \\leftrightarrow L_3\\)\n\\(L_3 \\rightarrow L_3 - 3L_2\\)\n\\(L_3 \\rightarrow -L_3\\)\n\\(L_2 \\rightarrow L_2 - L_3\\)\n\n\n\n\n\n\n\n\nTroca de \\(L_1\\) e \\(L_3\\):\n\\[E_1 = \\begin{bmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{bmatrix}\\]\n\\(L_2 \\rightarrow L_2 - L_1\\); \\(L_3 \\rightarrow L_3 - 2L_1\\):\n\\[E_2 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n-1 & 1 & 0 \\\\\n-2 & 0 & 1\n\\end{bmatrix}\\]\nTroca de \\(L_2\\) e \\(L_3\\):\n\\[E_3 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{bmatrix}\\]\n\n\n\n\\(L_3 \\rightarrow L_3 - 3L_2\\):\n\\[E_4 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & -3 & 1\n\\end{bmatrix}\\]\nMultiplicaÃ§Ã£o de \\(L_3\\) por \\(-1\\):\n\\[E_5 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & -1\n\\end{bmatrix}\\]\n\\(L_2 \\rightarrow L_2 - L_3\\):\n\\[E_6 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & -1 \\\\\n0 & 0 & 1\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de Matrizes Elementares para Calcular a Inversa",
    "text": "Exemplo de Matrizes Elementares para Calcular a Inversa\n\nEstabelecidas as matrizes elementares \\(E_1\\) a \\(E_6\\), tem-se a seguinte relaÃ§Ã£o:\n\\[E_6 \\times E_5 \\times E_4 \\times E_3 \\times E_2 \\times E_1 \\times A = I\\]\nE consequentemente:\n\\[E_1^{-1} \\times E_2^{-1} \\times E_3^{-1} \\times E_4^{-1} \\times E_5^{-1} \\times E_6^{-1} = A\\]\n\n\n\n\n\n\n\n\n\nO Teorema Fundamental das Matrizes InvertÃ­veis - versÃ£o 1\n\n\nSeja \\(A\\) uma matriz \\(n \\times n\\). As seguintes afirmaÃ§Ãµes sÃ£o equivalentes:\n\n\\(A\\) Ã© invertÃ­vel.\n\\(A\\vec{x} = \\vec{b}\\) tem uma Ãºnica soluÃ§Ã£o para cada \\(\\vec{b}\\) em \\(\\mathbb{R}^n\\).\n\\(A\\vec{x} = 0\\) tem apenas a soluÃ§Ã£o trivial.\nA forma escalonada reduzida de \\(A\\) Ã© \\(I_n\\).\n\\(A\\) Ã© um produto de matrizes elementares."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral\n\nProblema\nOs recifes de coral enfrentam vÃ¡rias ameaÃ§as ambientais, como branqueamento, acidificaÃ§Ã£o dos oceanos e destruiÃ§Ã£o fÃ­sica. Essas ameaÃ§as podem ser modeladas usando uma Cadeia de Markov para entender a probabilidade de um recife estar em um certo estado de saÃºde ao longo do tempo.\nEstados\nDefinimos trÃªs estados possÃ­veis para a saÃºde de um recife de coral:\n\nS1: SaudÃ¡vel\nS2: Moderadamente Degradado\nS3: Severamente Degradado\n\nMatriz de TransiÃ§Ã£o\nA matriz de transiÃ§Ã£o de estados, \\(P\\), representa as probabilidades de transiÃ§Ã£o entre os estados de saÃºde de um recife de coral de um perÃ­odo para o outro.\n\\[P = \\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix}\\]\nCada elemento \\(P_{ij}\\) na matriz representa a probabilidade de transiÃ§Ã£o do estado \\(j\\) na coluna para o estado \\(i\\) na linha. Por exemplo, \\(P_{12} = 0.2\\) indica que hÃ¡ uma probabilidade de 20% de um recife saudÃ¡vel (\\(S1\\)) passar para o estado moderadamente degradado (\\(S2\\)) no prÃ³ximo perÃ­odo."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-1",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral\n\nEstado inicial\nVamos considerar que inicialmente no tempo \\(t_0\\) 80% dos recifes estÃ£o saudÃ¡veis, 15% estÃ£o moderadamente degradados e 5% estÃ£o severamente degradados. Isso pode ser representado pelo vetor de estado inicial:\n\\[\\vec{v_0} = \\begin{bmatrix}\n0.8 \\\\\n0.15 \\\\\n0.05\n\\end{bmatrix}\\]\nEstado em \\(t + 1\\)\nPara determinar o estado dos recifes apÃ³s um perÃ­odo de tempo \\(t_1\\), multiplicamos o vetor de estado inicial pela matriz de transiÃ§Ã£o:\n\\[\n\\vec{v_1} = P \\times \\vec{v_0} = \\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix} \\times \\begin{bmatrix}\n0.8 \\\\\n0.15 \\\\\n0.05\n\\end{bmatrix} = \\begin{bmatrix}\n0.61 \\\\\n0.25 \\\\\n0.14\n\\end{bmatrix}\n\\]\nIsso significa que, apÃ³s um perÃ­odo, 61% dos recifes estarÃ£o saudÃ¡veis, 25% estarÃ£o moderadamente degradados e 14% estarÃ£o severamente degradados."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-2",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-2",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral\n\nEstado EstacionÃ¡rio\nO estado estacionÃ¡rio Ã© um vetor de probabilidades que representa a distribuiÃ§Ã£o dos estados de um sistema em equilÃ­brio, onde as probabilidades de estar em cada estado nÃ£o mudam com o tempo. Para uma cadeia de Markov, isso ocorre quando o vetor de estado nÃ£o muda apÃ³s uma multiplicaÃ§Ã£o pela matriz de transiÃ§Ã£o.\nSe \\(\\vec{v_{ss}}\\) Ã© um vetor de estado estacionÃ¡rio e \\(P\\) Ã© a matriz de transiÃ§Ã£o, entÃ£o:\n\\[\n\\vec{v_{ss}} = P \\times \\vec{v_{ss}}\n\\]\nPortanto, precisamos resolver o sistema de equaÃ§Ãµes:\n\\[\n\\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix} \\times \\begin{bmatrix}\n\\pi_1 \\\\\n\\pi_2 \\\\\n\\pi_3\n\\end{bmatrix} = \\begin{bmatrix}\n\\pi_1 \\\\\n\\pi_2 \\\\\n\\pi_3\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-3",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-3",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral\n\nResoluÃ§Ã£o do Sistema\n\n\nHÃ¡ ainda uma condiÃ§Ã£o adicional de que a soma das probabilidades em \\(\\vec{v_t}\\) seja 1:\n\\[\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\]\n\nQue gera e sistema de equaÃ§Ãµes:\n\\[\n\\begin{cases}\n0.7\\pi_1 + 0.3\\pi_2 + 0.1\\pi_3 = \\pi_1 \\\\\n0.2\\pi_1 + 0.5\\pi_2 + 0.3\\pi_3 = \\pi_2 \\\\\n0.1\\pi_1 + 0.2\\pi_2 + 0.6\\pi_3 = \\pi_3 \\\\\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\end{cases}\n\\]\n\n\n\n\n\n\nO pode ser reorganizado como:\n\\[\n\\begin{cases}\n-3\\pi_1 + 3\\pi_2 + \\pi_3 = 0 \\\\\n2\\pi_1 - 5\\pi_2 + 3\\pi_3 = 0 \\\\\n\\pi_1 + 2\\pi_2 - 4\\pi_3 = 0 \\\\\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\end{cases}\n\\]\n\nE tem soluÃ§Ã£o:\n\\[\n\\vec{v_{ss}} = \\begin{bmatrix} \\frac{7}{17} \\\\ \\frac{11}{34} \\\\ \\frac{9}{34} \\end{bmatrix} ~ \\sim \\begin{bmatrix}\n0.4117 \\\\\n0.3235 \\\\\n0.2647\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\n\nResoluÃ§ao completa\n\n\nFaÃ§a o download da RESOLUÃ‡ÃƒO COMPLETA"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-4",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplicaÃ§Ã£o-cadeias-de-markov-para-recifes-de-coral-4",
    "title": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes",
    "section": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplicaÃ§Ã£o: Cadeias de Markov para Recifes de Coral\n\nInterpretaÃ§Ã£o do vetor de Estado EstacionÃ¡rio\nNo longo prazo, a distribuiÃ§Ã£o das probabilidades entre os estados Ã©:\n\n\\(\\pi_1 = \\frac{7}{17} ~ \\sim 0.4117\\)\n\\(\\pi_2 = \\frac{11}{34} ~ \\sim 0.3235\\)\n\\(\\pi_3 = \\frac{9}{34} ~ \\sim 0.2647\\)\n\n\n\n\n\n\n\n\n\nConclusÃ£o\n\n\nA existÃªncia de um vetor estacionÃ¡rio indica que, independentemente do estado inicial, a cadeia de Markov converge para essa distribuiÃ§Ã£o de probabilidade quando o sistema estÃ¡ em equilÃ­brio.\nPortanto, mantendo as condiÃ§Ãµes atuais que resultam na matriz de transiÃ§Ã£o vigente, espera-se que, a longo prazo, aproximadamente 41,18% do recife de coral permanecerÃ¡ em condiÃ§Ãµes SaudÃ¡veis, 32,35% estarÃ¡ Moderadamente Degradado e 26,47% serÃ¡ Severamente Degradado."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html",
    "href": "content/estrutura-dados/estrutura-tipo.html",
    "title": "Estrutura e tipos de dados",
    "section": "",
    "text": "Neste tÃ³pico exploramos os conceitos fundamentais de estrutura e tipos de dados, focando na organizaÃ§Ã£o de unidades amostrais e descritores em tabelas de dados. TambÃ©m discutiremos diferentes tipos de variÃ¡veis, suas transformaÃ§Ãµes e como lidar com valores ausentes (NA) em tabelas de dados. Para ilustrar esses conceitos, usaremos a tabela penguins_raw do pacote palmerpenguins em R, fornecendo tanto explicaÃ§Ãµes teÃ³ricas quanto exemplos prÃ¡ticos de cÃ³digo em R."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#palmer-penguins-dataset",
    "href": "content/estrutura-dados/estrutura-tipo.html#palmer-penguins-dataset",
    "title": "Estrutura e tipos de dados",
    "section": "1 Palmer Penguins dataset",
    "text": "1 Palmer Penguins dataset\nA tabela penguins_raw inclui observaÃ§Ãµes de nidificaÃ§Ã£o, dados de morfometria e tamanho dos pinguins e medidas de isÃ³topos de amostras de sangue de pinguins adultos das espÃ©cies AdÃ©lie (Pygoscelis adeliae), Chinstrap (Pygoscelis antarctica) e Gentoo (Pygoscelis papua).\n\ndata(penguins_raw)\npenguins_raw |&gt; \n  head() |&gt;\n  gt()\n\n\n\nTabelaÂ 1: Primeiras linhas da tabela penguins_raw.\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n2007-11-11\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n2007-11-11\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n2007-11-16\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n2007-11-16\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n2007-11-16\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n2007-11-16\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n\n\n\nA tabela penguins_raw contÃ©m 344 linhas e 17 colunas, cada uma representando diferentes aspectos dos dados coletados sobre os pinguins. Cada linha representa uma unidade amostral (UA) e cada coluna representa uma variÃ¡vel (VAR) que descreve um atributo especÃ­fico da unidade amostral (TabelaÂ 2).\n\n\n\nTabelaÂ 2: DescriÃ§Ã£o dos atributos da tabela penguins_raw.\n\n\n\n\n\n\n\n\n\n\nVariÃ¡vel\nTipo\nDescriÃ§Ã£o\n\n\n\n\nstudyName\nCategÃ³rica\nExpediÃ§Ã£o de amostragem de onde os dados foram coletados, gerados, etc.\n\n\nSample Number\nQuantitativa Discreta\nUm nÃºmero inteiro indicando a sequÃªncia contÃ­nua de numeraÃ§Ã£o para cada amostra\n\n\nSpecies\nCategÃ³rica\nUma string de caracteres indicando a espÃ©cie de pinguim\n\n\nRegion\nCategÃ³rica\nUma string de caracteres indicando a regiÃ£o da grade de amostragem Palmer LTER\n\n\nIsland\nCategÃ³rica\nUma string de caracteres indicando a ilha perto da EstaÃ§Ã£o Palmer onde as amostras foram coletadas\n\n\nStage\nCategÃ³rica\nUma string de caracteres indicando o estÃ¡gio reprodutivo no momento da amostragem\n\n\nIndividual ID\nCategÃ³rica\nUma string de caracteres indicando o ID Ãºnico para cada indivÃ­duo no conjunto de dados\n\n\nClutch Completion\nCategÃ³rica\nUma string de caracteres indicando se o ninho estudado foi observado com uma ninhada completa, ou seja, 2 ovos\n\n\nDate Egg\nCategÃ³rica Ordinal\nUma data indicando a data em que o ninho estudado foi observado com 1 ovo (amostrado)\n\n\nCulmen Length\nQuantitativa ContÃ­nua\nUm nÃºmero indicando o comprimento da crista dorsal do bico de um pÃ¡ssaro (milÃ­metros)\n\n\nCulmen Depth\nQuantitativa ContÃ­nua\nUm nÃºmero indicando a profundidade da crista dorsal do bico de um pÃ¡ssaro (milÃ­metros)\n\n\nFlipper Length\nQuantitativa Discreta\nUm nÃºmero inteiro indicando o comprimento da nadadeira do pinguim (milÃ­metros)\n\n\nBody Mass\nQuantitativa Discreta\nUm nÃºmero inteiro indicando a massa corporal do pinguim (gramas)\n\n\nSex\nCategÃ³rica\nUma string de caracteres indicando o sexo do animal\n\n\nDelta 15 N\nQuantitativa ContÃ­nua\nUm nÃºmero indicando a medida da razÃ£o dos isÃ³topos estÃ¡veis 15N:14N\n\n\nDelta 13 C\nQuantitativa ContÃ­nua\nUm nÃºmero indicando a medida da razÃ£o dos isÃ³topos estÃ¡veis 13C:12C\n\n\nComments\nCategÃ³rica\nUma string de caracteres com texto fornecendo informaÃ§Ãµes adicionais relevantes para os dados"
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#unidades-amostrais-e-descritores-formato-geral",
    "href": "content/estrutura-dados/estrutura-tipo.html#unidades-amostrais-e-descritores-formato-geral",
    "title": "Estrutura e tipos de dados",
    "section": "2 Unidades amostrais e descritores: formato geral",
    "text": "2 Unidades amostrais e descritores: formato geral\nA tabela TabelaÂ 1 estÃ¡ organizada no formato em que cada linha representa uma unidade amostral (UA) e cada coluna representa uma variÃ¡vel (VA). As variÃ¡veis sÃ£o os descritores ou atributos que descrevem as caracterÃ­sticas de cada unidade amostral.\n\n\n\n\nTabelaÂ 3: Estrutura geral de uma base de dados. As linhas representam as unidades amostrais (ou observaÃ§Ãµes) e as colunas representam as variÃ¡veis (ou atributos).\n\n\n\n\n\n\n\n\n\nID\nVA 1\nVA 2\nVA 3\nVA 4\nVA 5\nVA 6\nVA 7\n\n\n\n\nUA 1\n\n\n\n\n\n\n\n\n\nUA 2\n\n\n\n\n\n\n\n\n\nUA 3\n\n\n\n\n\n\n\n\n\nUA 4\n\n\n\n\n\n\n\n\n\nUA 5\n\n\n\n\n\n\n\n\n\nUA 6\n\n\n\n\n\n\n\n\n\nUA 7\n\n\n\n\n\n\n\n\n\nUA 8\n\n\n\n\n\n\n\n\n\nUA 9\n\n\n\n\n\n\n\n\n\nUA 10"
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#dados-ausentes",
    "href": "content/estrutura-dados/estrutura-tipo.html#dados-ausentes",
    "title": "Estrutura e tipos de dados",
    "section": "3 Dados ausentes",
    "text": "3 Dados ausentes\nValores nÃ£o preenchidos sÃ£o comuns em conjuntos de dados. Na tabela penguins_raw, diversas colunas apresentam dados ausentes, indicados como NA. A seguir, sÃ£o apresentadas algumas estratÃ©gias para lidar com esses dados faltantes:\n\nRemover valores faltantes: Exclua linhas com dados ausentes usando a funÃ§Ã£o drop_na().\n\n\npenguins_limpo &lt;- drop_na(penguins_raw)\n\nnrow(penguins_limpo)\n\n[1] 34\n\n\nRestaram apenas 344 linhas na tabela, o que indica a necessidade de avaliar cuidadosamente quais colunas terÃ£o seus valores NA removidos. Para isso, Ã© Ãºtil verificar a quantidade de dados ausentes em cada coluna. Observando a tabela TabelaÂ 1, nota-se que a maioria dos dados ausentes estÃ¡ na variÃ¡vel Comments. Como essa coluna nÃ£o serÃ¡ incluÃ­da nas anÃ¡lises, os valores ausentes nela nÃ£o precisam ser removidos. Podemos, portanto, excluir as linhas que contÃªm NA em outras colunas, preservando apenas a coluna Comments.\n\npenguins_limpo &lt;- penguins_raw |&gt; \n  drop_na(-Comments)\n\nnrow(penguins_limpo)\n\n[1] 324\n\n\nAgora, restaram 344 linhas na tabela. A remoÃ§Ã£o de linhas deve ser feita com cautela, avaliando caso a caso. Como alternativa, pode-se considerar a imputaÃ§Ã£o de valores para as cÃ©lulas ausentes, o que pode permitir a preservaÃ§Ã£o de mais dados para anÃ¡lise.\n\nInserir valores faltantes: Preencha valores faltantes usando mÃ©todos estatÃ­sticos, como substituiÃ§Ã£o pela mÃ©dia.\n\n\npenguins_lpch &lt;- penguins_raw |&gt; \n  mutate(`Culmen Length (mm)` = if_else(\n    is.na(`Culmen Length (mm)`),\n    mean(`Culmen Length (mm)`, na.rm = TRUE),\n    `Culmen Length (mm)`\n  ))\n\nNeste caso, os valores ausentes foram substituÃ­dos pela mÃ©dia aritmÃ©tica da variÃ¡vel Culmen Length (mm).\n\n\n\n\n\n\nDicaTÃ©cnicas AvanÃ§adas de ImputaÃ§Ã£o\n\n\n\nUma alternativa Ã  substituiÃ§Ã£o pela mÃ©dia simples Ã© a imputaÃ§Ã£o mÃºltipla, que pode utilizar agrupamentos mais detalhados (por exemplo, por espÃ©cie e ilha) e considerar a associaÃ§Ã£o com outras variÃ¡veis da tabela. Outra opÃ§Ã£o Ã© empregar mÃ©todos mais sofisticados, como o k-Nearest Neighbors (kNN)."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#tipos-de-dados",
    "href": "content/estrutura-dados/estrutura-tipo.html#tipos-de-dados",
    "title": "Estrutura e tipos de dados",
    "section": "4 Tipos de dados",
    "text": "4 Tipos de dados\nUma tabela de dados pode ser composta por variÃ¡veis quantitativas ou qualitativas.\n\nVariÃ¡veis qualitativas\nSÃ£o variÃ¡veis nÃ£o-numÃ©ricas como categorias ou rÃ³tulos. Dentre as variÃ¡veis qualitativas temos aquelas do tipo categÃ³ricas nÃ£o-ordenadas e do tipo categÃ³ricas ordenadas.\nVariÃ¡vel categÃ³rica nÃ£o-ordenada: a variÃ¡vel Island classifica cada penguim de acordo com a ilha em que foi registrado. Os nÃ­veis da variÃ¡vel Island sÃ£o: Torgersen, Biscoe, Dream. A variÃ¡vel Ã© do tipo categÃ³rica nÃ£o-ordenada, pois os nÃ­veis nÃ£o possuem qualquer relaÃ§Ã£o de ordenaÃ§Ã£o natural entre si.\n\n\nVariÃ¡veis quantitativas\nSÃ£o variÃ¡veis numÃ©ricas que tambÃ©m podem ser sub-divididas em dois grupos: discretas e contÃ­nuas.\n\nVariÃ¡veis quantitativas discretas: envolvem quantias enumerÃ¡veis. Na tabela penguins_raw nÃ£o hÃ¡ nenhum exemplo deste tipo de variÃ¡vel, mas exemplos podem ser a contagem de barcos que saem para pescar em um determinado dia, o nÃºmero de peixes de um cardume o nÃºmero de ovos no ninho de ave.\nVariÃ¡veis quantitativas contÃ­nuas: envolvem quantias nÃ£o-enumerÃ¡veis como a vazÃ£o em \\(m^3/seg\\) que verte de uma cachoeira, o volume de chuva em um determinado dia, altura da marÃ© ou a velocidade do vento. O limite de precisÃ£o que utilizamos para representÃ¡-las depende basicamente da capacidade de mensuraÃ§Ã£o dos aparelhos disponÃ­veis. Na tabela penguins_raw existem diversos exemplos deste tipo de variÃ¡vel como\n\nEm nosso exemplo, temos diversas variÃ¡veis deste tipo como Culmen Length, Culmen Depth, Flipper Length, Body Mass, Delta 15 N e Delta 13 C.\n\n\n\n\n\n\nNotaTransformando variÃ¡veis\n\n\n\nSempre Ã© possÃ­vel transformar variÃ¡veis quantitativas em qualitativas. Se temos uma variÃ¡vel medindo o comprimento de peixes desembarcados em centÃ­metros (variÃ¡vel quantitativa), Ã© possÃ­vel expressÃ¡-la de forma categÃ³rica em peixes grandes e peixes pequenos (variÃ¡vel qualitativa). Por outro lado, se tivermos somente a informaÃ§Ã£o de que um peixe Ã© grande ou pequeno, nÃ£o podemos recuperar as quantias numÃ©ricas originais. Ao transformar uma variÃ¡vel de quantitativa em qualitativa, algumas propriedades sÃ£o perdidas."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#nÃ­veis-de-mensuraÃ§Ã£o",
    "href": "content/estrutura-dados/estrutura-tipo.html#nÃ­veis-de-mensuraÃ§Ã£o",
    "title": "Estrutura e tipos de dados",
    "section": "5 NÃ­veis de mensuraÃ§Ã£o",
    "text": "5 NÃ­veis de mensuraÃ§Ã£o\nPodemos organizar uma variÃ¡vel a partir de seu nÃ­vel de mensuraÃ§Ã£o (FiguraÂ 1), dado em: nominal, ordinal, intervalar e razÃ£o.\nNÃ­vel nominal: Ã© caracterÃ­stico de variÃ¡veis que possuem nÃ­veis nÃ£o ordenaveis. Ex. cor, grupo taxonÃ´mico, nomes de cidades, etc.\n\nNÃ­vel ordinal: Ã© aquele em que os nÃ­veis podem ser ordenados, embora nÃ£o seja possÃ­vel quantificar as diferenÃ§as entre dois nÃ­veis. Ex. i - Ordem de chegada de maratonistas em uma competiÃ§Ã£o (\\(1^o\\),\\(2^o\\),\\(3^o\\),\\(\\cdots\\)). ii - CondiÃ§Ã£o de saneamento das cidades (Ã³timo, bom, ruim, pÃ©ssimo). iii - CondiÃ§Ã£o de saneamento das praias da baixada santista (prÃ³prio, imprÃ³rpio). No nÃ­vel ordinal podemos ordenar os elementos porÃ©m nÃ£o podemos quantificar as diferenÃ§as entre eles.\nNÃ­vel intervalar: Ã© aquele em que alÃ©m ser possÃ­vel ordenar, Ã© possÃ­vel quantificar as diferenÃ§as entre duas observaÃ§Ãµes. No entanto, nÃ£o hÃ¡ um ponto inicial natural, ou seja, um ponto zero que indique ausÃªncia da quantia. Ex. i â€“ Temperatura: \\(0^oC\\) nÃ£o indica ausÃªncia de temperatura, assim como \\(10^oC\\) nÃ£o Ã© duas vezes mais quente que \\(5^oC\\). Essas caracterÃ­sticas sÃ£o somente uma convenÃ§Ã£o relacionada Ã  escala de mensuraÃ§Ã£o da temperatura. ii - Ano do calendÃ¡rio: o ano zero Ã© uma convenÃ§Ã£o do calendÃ¡rio, nÃ£o significa ausÃªncia de tempo.\nNÃ­vel de razÃ£o: Ã© como o intervalar, porÃ©m existe um ponto zero natural. Peso igual a \\(0\\) kg indica ausÃªncia de peso e dez quilogramas Ã© duas vezes mais pesado que \\(5\\) kg. O mesmo vale para comprimento, distÃ¢ncia, velocidade, nÃºmero de ovos.\n\n\n\n\n\n\n\n\nFiguraÂ 1: Tipos de variÃ¡veis e nÃ­veis de mensuraÃ§Ã£o.\n\n\n\n\nA depender do nÃ­vel de mensuraÃ§Ã£o, algumas operaÃ§Ãµes matemÃ¡ticas podem ou nÃ£o fazer sentido. Por exemplo, se uma espÃ©cie tem \\(N_A = 100\\) indivÃ­duos na regiÃ£o A e \\(N_B = 200\\) na regiÃ£o B, a segunda regiÃ£o Ã© duas vezes mais populosa pois \\(\\frac{N_B}{N_A} = 2\\). Por outro lado, se a temperatura na regiÃ£o A Ã© de \\(T_A = 10^oC\\) enquanto na B Ã© de \\(T_B = 20^oC\\) nÃ£o faz sentido fazer \\(\\frac{T_B}{T_A} = 2\\) e dizer que B seja duas vezes mais quente que A. Ainda que matematicamente a operaÃ§Ã£o seja possÃ­vel nos dois exemplos, no Ãºltimo sua interpretaÃ§Ã£o fÃ­sica nÃ£o tem sentido.\n\n\n\n\n\n\nNotaTipos de dados vs nÃ­veis de mensuraÃ§Ã£o\n\n\n\nExiste uma relaÃ§Ã£o entre tipo de dados e nÃ­vel de mensuraÃ§Ã£o. Os nÃ­veis nominal e ordinal de mensuraÃ§Ã£o se referem a variÃ¡veis qualitativas nÃ£o-ordenadas e qualitativas ordenadas respectivamente. JÃ¡ os nÃ­veis intervalar e razÃ£o se referem a variÃ¡veis quantitativas, podendo ser discretas ou contÃ­nuas."
  },
  {
    "objectID": "topics/anova.html",
    "href": "topics/anova.html",
    "title": "AnÃ¡lise de variÃ¢ncia",
    "section": "",
    "text": "AnÃ¡lise de variÃ¢ncia de um fator\n\n\nAvaliaÃ§Ã£o de uma Ãºnica fonte de variaÃ§Ã£o, partiÃ§Ã£o da soma de quadrados e aplicaÃ§Ã£o do teste F.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/distribuicao-normal.html",
    "href": "topics/distribuicao-normal.html",
    "title": "A DistribuiÃ§Ã£o Normal",
    "section": "",
    "text": "O modelo de distribuiÃ§Ã£o normal\n\n\nIntroduÃ§Ã£o Ã  distribuiÃ§Ã£o normal, suas caracterÃ­sticas e aplicaÃ§Ãµes no contexto da inferÃªncia estatÃ­stica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO modelo da distribuiÃ§Ã£o normal\n\n\nApresenta o modelo matemÃ¡tico da distribuiÃ§Ã£o normal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO modelo da distribuiÃ§Ã£o normal\n\n\nExplora a distribuiÃ§Ã£o normal para extrair probabilidades\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/introducao-r.html",
    "href": "topics/introducao-r.html",
    "title": "IntroduÃ§Ã£o ao R",
    "section": "",
    "text": "Estrutura da linguagem\n\n\n\nR\n\nProgramaÃ§Ã£o\n\n\n\nEstrutura da linguagem R, incluindo operaÃ§Ãµes bÃ¡sicas, tipos de objetos (vetores, data frames, matrizes, listas) e sintaxe principal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(BÃ¡sico da) ManipulaÃ§Ã£o de data frames\n\n\n\nR\n\nProgramaÃ§Ã£o\n\nManipulaÃ§Ã£o de dados\n\nData frames\n\n\n\nPrincÃ­pios de manipulaÃ§Ã£o de data frames no R: importaÃ§Ã£o, seleÃ§Ã£o de linhas e colunas e criaÃ§Ã£o de variÃ¡veis.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/multivariada-numerica.html",
    "href": "topics/multivariada-numerica.html",
    "title": "TÃ³picos AvanÃ§ados em CiÃªncia de Dados e AnÃ¡lise Multivariada",
    "section": "",
    "text": "IntroduÃ§Ã£o Ã  Ãlgebra de Matrizes\n\n\nOperaÃ§Ãµes bÃ¡sicas e Ã¡lgebra matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEcologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial\n\n\n\nProduto escalar\n\nÃ‚ngulo entre vetores\n\nMultiplicaÃ§Ã£o matricial\n\nMatriz transposta\n\nMatriz simÃ©trica\n\n\n\nCÃ¡lculo da similaridade funcional entre espÃ©cies de peixes usando Ã¡lgebra matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgrupamento (Clustering)\n\n\n\nDendrograma\n\nK-means\n\nÃrvore de RegressÃ£o Multivariada\n\n\n\nIntroduÃ§Ã£o aos mÃ©todos de agrupamento hierÃ¡rquico e nÃ£o hierÃ¡rquico.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMÃ©todos de ordenaÃ§Ã£o\n\n\n\nOrdenaÃ§Ã£o\n\n\n\nIntroduÃ§Ã£o aos mÃ©todos de ordenaÃ§Ã£o: PCA, PCoA, CA, NMDS.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/estatistica-descritiva.html",
    "href": "topics/estatistica-descritiva.html",
    "title": "EstatÃ­stica Descritiva",
    "section": "",
    "text": "Descrevendo variÃ¡veis qualitativas\n\n\n\nR\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nVariÃ¡veis qualitativas\n\nVisualizaÃ§Ã£o de dados\n\n\n\nDescriÃ§Ã£o de variÃ¡veis qualitativas, incluindo tabelas de frequÃªncia, grÃ¡ficos de barras e consideraÃ§Ãµes sobre variÃ¡veis ordinais.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescrevendo variÃ¡veis quantitativas\n\n\n\nR\n\nCiÃªncia de dados\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nVariÃ¡veis quantitativas\n\nDistribuiÃ§Ã£o de frequÃªncia\n\n\n\nExploraÃ§Ã£o de variÃ¡veis quantitativas por meio de tabelas de frequÃªncia, histogramas e grÃ¡ficos de frequÃªncia acumulada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de tendÃªncia central\n\n\n\nR\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nTendÃªncia central\n\nDistribuiÃ§Ã£o de dados\n\n\n\nDiscussÃ£o das principais medidas de tendÃªncia central (mÃ©dia, mediana, moda) e sua interpretaÃ§Ã£o em diferentes distribuiÃ§Ãµes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de variaÃ§Ã£o\n\n\n\nR\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nVariabilidade de dados\n\nAnÃ¡lise de dispersÃ£o\n\n\n\nApresentaÃ§Ã£o das medidas de variaÃ§Ã£o, como variÃ¢ncia, desvio padrÃ£o, coeficiente de variaÃ§Ã£o e amplitude, com exemplos prÃ¡ticos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de posiÃ§Ã£o: quartis\n\n\n\nR\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nVariabilidade de dados\n\nAnÃ¡lise de dispersÃ£o\n\n\n\nCÃ¡lculo e interpretaÃ§Ã£o de quartis para anÃ¡lise de distribuiÃ§Ã£o, ressaltando faixas de variaÃ§Ã£o e valores atÃ­picos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de posiÃ§Ã£o: transformaÃ§Ã£o Z\n\n\n\nR\n\nAnÃ¡lise de dados\n\nEstatÃ­stica descritiva\n\nPadronizaÃ§Ã£o de dados\n\nÃndice Z\n\n\n\nTransformaÃ§Ã£o Z para padronizar distribuiÃ§Ãµes, facilitando comparaÃ§Ãµes entre diferentes escalas de medida.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/manipulacao-dados-python.html",
    "href": "topics/manipulacao-dados-python.html",
    "title": "IntroduÃ§Ã£o e ManipulaÃ§Ã£o de Dados em Python",
    "section": "",
    "text": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem\n\n\nEstrutura da linguagem Python, incluindo operaÃ§Ãµes bÃ¡sicas, tipos de objetos (listas, arrays, strings, dicionÃ¡rios) e sintaxe principal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstrutura e Tipos de Dados em Python\n\n\nManipulaÃ§Ã£o de DataFrames em Python usando Pandas, incluindo seleÃ§Ã£o de linhas e colunas, filtragem de dados e tratamento de valores ausentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstatÃ­stica Descritiva e VisualizaÃ§Ã£o com Python\n\n\nAnÃ¡lise descritiva de dados usando Python com Pandas e Matplotlib, incluindo medidas de tendÃªncia central, dispersÃ£o e visualizaÃ§Ãµes bÃ¡sicas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python\n\n\nAnÃ¡lise de associaÃ§Ãµes entre variÃ¡veis usando Python com Pandas, Matplotlib e Seaborn, incluindo tabelas de contingÃªncia, correlaÃ§Ã£o e visualizaÃ§Ãµes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportando data frames a partir de arquivos CSV\n\n\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/estrutura-dados.html",
    "href": "topics/estrutura-dados.html",
    "title": "Estrutura de Dados",
    "section": "",
    "text": "Estrutura e tipos de dados\n\n\n\nR\n\nEstrutura de dados\n\nTipos de dados\n\nAnÃ¡lise de dados\n\n\n\nDescriÃ§Ã£o de diferentes estruturas de dados e tipos de variÃ¡veis, com foco em nÃ­veis de mensuraÃ§Ã£o e tratamento de valores ausentes em tabelas.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/intro-bayes.html",
    "href": "topics/intro-bayes.html",
    "title": "IntroduÃ§Ã£o Ã  InferÃªncia Bayesiana",
    "section": "",
    "text": "Contando possibilidades\n\n\nIntroduÃ§Ã£o Ã  contagem de possibilidades na abordagem bayesiana. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe contagens a probabilidades\n\n\nTransiÃ§Ã£o de contagens para probabilidades sob uma perspectiva bayesiana. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstruindo um modelo bayesiano\n\n\nConstruÃ§Ã£o de um modelo bayesiano, enfatizando a formulaÃ§Ã£o de distribuiÃ§Ãµes a priori e posterior. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInferÃªncia Bayesiana Binomial\n\n\nIntroduÃ§Ã£o ao conceito de aproximaÃ§Ã£o por grid na abordagem bayesiana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInferÃªncia Bayesiana Binomial com PyMC\n\n\nIntroduÃ§Ã£o Ã  modelagem probabilÃ­stica na abordagem bayesiana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo Normal Bayesiano\n\n\nIntroduÃ§Ã£o Ã  modelagem Bayesiana de dados contÃ­nuos, incluindo escolha das priores e checagens preditivas.\n\n\n\n\n\n\n\n\nNenhum item correspondente\nReferÃªncias\n\nMcElreath, Richard. 2018. Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman; Hall/CRC."
  },
  {
    "objectID": "topics/fundamentos-probabilidade.html",
    "href": "topics/fundamentos-probabilidade.html",
    "title": "Fundamentos de Probabilidades",
    "section": "",
    "text": "EspaÃ§o de possibilidades de um experimento\n\n\n\nProbabilidade\n\nEspaÃ§o amostral\n\nEventos\n\nExperimento aleatÃ³rio\n\n\n\nEspaÃ§o de possibilidades de um experimento aleatÃ³rio, abordando a definiÃ§Ã£o de evento e probabilidade.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombinando as probabilidades de eventos\n\n\n\nProbabilidade\n\nEventos complexos\n\nDiagrama de Venn\n\nDiagrama de Ã¡rvore\n\n\n\nCombinaÃ§Ã£o de probabilidades de eventos, utilizando diagramas de Venn e Ã¡rvores para representar uniÃµes e interseÃ§Ãµes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilidade condicional e independÃªncia\n\n\n\nProbabilidade condicional\n\nEventos dependentes\n\nTeorema de Bayes\n\nDiagrama de Ã¡rvore\n\n\n\nExploraÃ§Ã£o da probabilidade condicional e independÃªncia, com aplicaÃ§Ãµes do Teorema de Bayes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeorema de Bayes\n\n\n\nTeorema de Bayes\n\nProbabilidade condicional\n\nEventos dependentes\n\n\n\nApresentaÃ§Ã£o do Teorema de Bayes e sua aplicaÃ§Ã£o no cÃ¡lculo de probabilidades condicionais.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "",
    "text": "Nenhum item correspondente"
  },
  {
    "objectID": "index.html#fundamentos-computacionais",
    "href": "index.html#fundamentos-computacionais",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "",
    "text": "Nenhum item correspondente"
  },
  {
    "objectID": "index.html#estatÃ­stica-descritiva-e-anÃ¡lise-exploratÃ³ria",
    "href": "index.html#estatÃ­stica-descritiva-e-anÃ¡lise-exploratÃ³ria",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "EstatÃ­stica Descritiva e AnÃ¡lise ExploratÃ³ria",
    "text": "EstatÃ­stica Descritiva e AnÃ¡lise ExploratÃ³ria\n\n\n\n\n\n\n\n\n\n\nEstrutura de Dados\n\n\n\n\n\n\n\n\n\n\n\n\nEstatÃ­stica Descritiva\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de AssociaÃ§Ã£o\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#fundamentos-teÃ³ricos",
    "href": "index.html#fundamentos-teÃ³ricos",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "Fundamentos TeÃ³ricos",
    "text": "Fundamentos TeÃ³ricos\n\n\n\n\n\n\n\n\n\n\nFundamentos de Probabilidades\n\n\n\n\n\n\n\n\n\n\n\n\nA DistribuiÃ§Ã£o Normal\n\n\n\n\n\n\n\n\n\n\n\n\nAmostragem\n\n\n\n\n\n\n\n\n\n\n\n\nInferÃªncia EstatÃ­stica\n\n\n\n\n\n\n\n\n\n\n\n\nTeste de HipÃ³teses\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#modelos-lineares",
    "href": "index.html#modelos-lineares",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "Modelos Lineares",
    "text": "Modelos Lineares\n\n\n\n\n\n\n\n\n\n\nAnÃ¡lise de variÃ¢ncia\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de RegressÃ£o\n\n\n\n\n\n\n\n\n\n\n\n\nModelos Lineares Generalizados\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#inferÃªncia-bayesiana",
    "href": "index.html#inferÃªncia-bayesiana",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "InferÃªncia Bayesiana",
    "text": "InferÃªncia Bayesiana\n\n\n\n\n\n\n\n\n\n\nIntroduÃ§Ã£o Ã  InferÃªncia Bayesiana\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de RegressÃ£o Bayesianos\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#anÃ¡lise-multivariada-e-ecologia-numÃ©rica",
    "href": "index.html#anÃ¡lise-multivariada-e-ecologia-numÃ©rica",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "AnÃ¡lise Multivariada e Ecologia NumÃ©rica",
    "text": "AnÃ¡lise Multivariada e Ecologia NumÃ©rica\n\n\n\n\n\n\n\n\n\n\nTÃ³picos AvanÃ§ados em CiÃªncia de Dados e AnÃ¡lise Multivariada\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#funÃ§Ãµes-e-modelos",
    "href": "index.html#funÃ§Ãµes-e-modelos",
    "title": "Modelagem EstatÃ­stica e AnÃ¡lise de Dados",
    "section": "FunÃ§Ãµes e Modelos",
    "text": "FunÃ§Ãµes e Modelos\n\n\n\n\n\n\n\n\n\n\nFunÃ§Ãµes e modelos\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/glms.html",
    "href": "topics/glms.html",
    "title": "Modelos Lineares Generalizados",
    "section": "",
    "text": "Modelos Lineares Generalizados (GLMs)\n\n\n\nModelagem\n\nGLM\n\nRegressÃ£o\n\n\n\nIntroduÃ§Ã£o aos GLMs, incluindo RegressÃ£o LogÃ­stica e Poisson.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/medidas-associacao.html",
    "href": "topics/medidas-associacao.html",
    "title": "Medidas de AssociaÃ§Ã£o",
    "section": "",
    "text": "AssociaÃ§Ã£o entre duas variÃ¡veis qualitativas\n\n\n\nEstatÃ­stica\n\nAnÃ¡lise qualitativa\n\nTabelas de contingÃªncia\n\nMedidas de associaÃ§Ã£o\n\n\n\nAnÃ¡lise da associaÃ§Ã£o entre variÃ¡veis qualitativas, uso de tabelas de contingÃªncia e estatÃ­sticas de associaÃ§Ã£o.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssociaÃ§Ã£o entre duas variÃ¡veis quantitativas\n\n\n\nEstatÃ­stica\n\nAnÃ¡lise quantitativa\n\nCovariÃ¢ncia\n\nCorrelaÃ§Ã£o\n\nMedidas de associaÃ§Ã£o\n\n\n\nAnÃ¡lise da associaÃ§Ã£o entre variÃ¡veis quantitativas, com destaque para covariÃ¢ncia e correlaÃ§Ã£o de Pearson.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas\n\n\n\nEstatÃ­stica\n\nANOVA\n\nAnÃ¡lise quantitativa\n\nAnÃ¡lise qualitativa\n\nMedidas de associaÃ§Ã£o\n\n\n\nAnÃ¡lise da relaÃ§Ã£o entre variÃ¡veis quantitativas e categÃ³ricas, considerando partiÃ§Ã£o da soma de quadrados e coeficientes de determinaÃ§Ã£o.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/inferencia-estatistica.html",
    "href": "topics/inferencia-estatistica.html",
    "title": "InferÃªncia EstatÃ­stica",
    "section": "",
    "text": "DistribuiÃ§Ã£o das mÃ©dias amostrais\n\n\nExposiÃ§Ã£o do teorema central do limite, enfatizando a distribuiÃ§Ã£o das mÃ©dias amostrais e sua importÃ¢ncia em inferÃªncia estatÃ­stica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimando a mÃ©dia populacional\n\n\nConstruÃ§Ã£o e interpretaÃ§Ã£o de intervalos de confianÃ§a para estimar a mÃ©dia populacional, incluindo a distribuiÃ§Ã£o t de Student.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/amostragem.html",
    "href": "topics/amostragem.html",
    "title": "Amostragem",
    "section": "",
    "text": "Descrevendo populaÃ§Ãµes e amostras\n\n\nDescreve populaÃ§Ãµes e amostras, abordando a distinÃ§Ã£o entre parÃ¢metros populacionais e estimadores amostrais.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmostrando uma populaÃ§Ã£o estatÃ­stica\n\n\nMÃ©todos de amostragem aleatÃ³ria simples, estratificada e sistemÃ¡tica, destacando o erro amostral e a acurÃ¡cia das estimativas.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/modelos-regressao-bayes.html",
    "href": "topics/modelos-regressao-bayes.html",
    "title": "Modelos de RegressÃ£o Bayesianos",
    "section": "",
    "text": "RegressÃ£o Linear Bayesiana\n\n\nRegressÃ£o linear bayesiana â€” altura em adultos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFluxo de Trabalho na Modelagem Bayesiana\n\n\n\nInferÃªncia bayesiana\n\nModelagem estatÃ­stica\n\nBambi\n\nPyMC\n\nFluxo de trabalho\n\nDistribuiÃ§Ãµes a priori\n\nInferÃªncia a posteriori\n\n\n\nExplorando o fluxo de trabalho bayesiano em modelos de regressÃ£o linear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplorando Modelos de RegressÃ£o Bayesiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelos EstatÃ­sticos e Modelos CientÃ­ficos\n\n\nTrÃªs estratÃ©gias para modelar a relaÃ§Ã£o entre tamanho populacional e nÃºmero de ferramentas\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/manipulacao-dados-R.html",
    "href": "topics/manipulacao-dados-R.html",
    "title": "ManipulaÃ§Ã£o de Dados em R",
    "section": "",
    "text": "Os pacotes em tidyverse\n\n\n\nCiÃªncia de dados\n\nR\n\nTidyverse\n\n\n\nPacotes do tidyverse para importaÃ§Ã£o, organizaÃ§Ã£o, transformaÃ§Ã£o e visualizaÃ§Ã£o de dados em R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportando/Exportando dados\n\n\n\nCiÃªncia de dados\n\nR\n\nTidyverse\n\nImportaÃ§Ã£o e exportaÃ§Ã£o de dados\n\n\n\nTÃ©cnicas de importaÃ§Ã£o e exportaÃ§Ã£o de dados com o pacote readr do Tidyverse, para diversos formatos de arquivo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperadores pipe\n\n\n\nCiÃªncia de dados\n\nR\n\nTidyverse\n\nTransformaÃ§Ã£o de dados\n\n\n\nUso de operadores pipe para encadear funÃ§Ãµes e simplificar fluxos de dados em R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransformaÃ§Ã£o de Dados\n\n\n\nCiÃªncia de dados\n\nR\n\nTidyverse\n\nTransformaÃ§Ã£o de dados\n\n\n\nManipulaÃ§Ã£o e transformaÃ§Ã£o de dados com as funÃ§Ãµes principais do Tidyverse, incluindo dplyr e tidyr.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/regressao-linear.html",
    "href": "topics/regressao-linear.html",
    "title": "Modelos de RegressÃ£o",
    "section": "",
    "text": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples\n\n\nMÃ©todo dos mÃ­nimos quadrados na RegressÃ£o linear simples por meio da representaÃ§Ã£o vetorial e matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples\n\n\nTutorial prÃ¡tico para implementar o mÃ©todo dos mÃ­nimos quadrados em Python, aplicando os conceitos de Ã¡lgebra linear e estatÃ­stica bÃ¡sica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Polinomial\n\n\nTutorial prÃ¡tico para implementar o mÃ©todo dos mÃ­nimos quadrados em Python para modelos polinomiais, aplicando os conceitos de Ã¡lgebra linear e estatÃ­stica bÃ¡sica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegressÃ£o linear simples\n\n\nIntroduÃ§Ã£o Ã  regressÃ£o linear simples, incluindo ANOVA da regressÃ£o, coeficiente de determinaÃ§Ã£o e diagnÃ³sticos bÃ¡sicos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegressÃ£o linear mÃºltipla\n\n\nRegressÃ£o linear mÃºltipla, discutindo seleÃ§Ã£o de variÃ¡veis, pressupostos e diagnÃ³sticos de adequaÃ§Ã£o do modelo.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/teste-hipoteses.html",
    "href": "topics/teste-hipoteses.html",
    "title": "Teste de HipÃ³teses",
    "section": "",
    "text": "IntroduÃ§Ã£o ao teste de hipÃ³teses\n\n\nApresentaÃ§Ã£o do teste de hipÃ³teses, definiÃ§Ãµes de hipÃ³teses nula e alternativa, erros do tipo I/II e valor de p.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparando variÃ¢ncias\n\n\nMÃ©todos de comparaÃ§Ã£o de variÃ¢ncias, incluindo o teste F e o teste de Levene.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparando mÃ©dias: teste t de Student\n\n\nTeste t de Student para comparaÃ§Ã£o de mÃ©dias, abrangendo uma amostra, grupos independentes e medidas pareadas.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/visualizacao-dados.html",
    "href": "topics/visualizacao-dados.html",
    "title": "VisualizaÃ§Ã£o de Dados",
    "section": "",
    "text": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica\n\n\n\nR\n\nProgramaÃ§Ã£o\n\nGrÃ¡ficos em R\n\nVisualizaÃ§Ã£o de dados\n\n\n\nIntroduÃ§Ã£o Ã  criaÃ§Ã£o de grÃ¡ficos em R: grÃ¡ficos de barras, histogramas, boxplots, dispersÃ£o e exportaÃ§Ã£o de figuras.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrÃ¡ficos em camadas\n\n\n\nCiÃªncia de dados\n\nR\n\nTidyverse\n\nVisualizaÃ§Ã£o grÃ¡fica\n\n\n\nCriaÃ§Ã£o de grÃ¡ficos em camadas com ggplot2, incluindo histogramas, boxplots e grÃ¡ficos de dispersÃ£o.\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/funcoes-modelos.html",
    "href": "topics/funcoes-modelos.html",
    "title": "FunÃ§Ãµes e modelos",
    "section": "",
    "text": "Explorando FunÃ§Ãµes PotÃªncias com Python\n\n\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html",
    "href": "content/multivariada-numerica/cossine-similarity.html",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "",
    "text": "Considere a situaÃ§Ã£o em que temos 8 espÃ©cies de peixes nas descritas por 6 traÃ§os funcionais (TabelaÂ 1). TraÃ§os funcionais sÃ£o caracterÃ­sticas morfolÃ³gicas, fisiolÃ³gicas ou comportamentais mensurÃ¡veis que influenciam diretamente o desempenho ecolÃ³gico das espÃ©cies, determinando como elas interagem com o ambiente e utilizam recursos (como habitats, alimento e abrigo). Espera-se, por exemplo, que espÃ©cies similares em seus traÃ§os funcionais ocupem um espaÃ§o de nicho e respondam de forma similar a pressÃµes ambientais. Nosso objetivo serÃ¡ quantificar o grau de similaridade entre os pares de espÃ©cies por meio do Ã­ndice de similaridade por cossenos.\n\n\n\nTabelaÂ 1: TraÃ§os funcionais entre 8 espÃ©cies de peixes de riachos. CI: Ãndice de compressÃ£o; RD: Altura relativa; IVF: Ãndice de achatamento ventral; RAC: Ãrea relativa da nadadeira caudal; REP: PosiÃ§Ã£o relativa do olho; MO: orientaÃ§Ã£o da boca. Bstr: Bryconamericus stramineus; Bsp: Bryconamericus sp.; Cfasc: Characidium fasciatum; Czeb: Characidium zebra; Cih: Cetopsorhamdia iheringi; Imin: Imparfinis minutus; Hsp: Hisonotus sp.; Hypsp: Hypostomus sp.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraÃ§o\nBstr\nBsp\nCfasc\nCzeb\nCih\nImin\nHsp\nHypsp\n\n\n\n\nCI\n1.67\n1.71\n1.41\n1.47\n0.97\n0.69\n0.73\n0.66\n\n\nRD\n0.21\n0.26\n0.21\n0.22\n0.17\n0.12\n0.16\n0.19\n\n\nIVF\n0.57\n0.53\n0.51\n0.49\n0.59\n0.55\n0.39\n0.35\n\n\nRAC\n0.14\n0.13\n0.14\n0.11\n0.22\n0.26\n0.19\n0.3\n\n\nREP\n0.7\n0.68\n0.79\n0.8\n0.91\n0.76\n0.71\n0.85\n\n\nMO\n1.26\n1.74\n3.03\n1.98\n2.06\n2.24\n3.14\n3.14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBryconamericus stramineus\n\n\n\n\n\n\n\nBryconamericus sp\n\n\n\n\n\n\n\n\n\nCharacidium fasciatum\n\n\n\n\n\n\n\nCharacidium zebra\n\n\n\n\n\n\n\n\n\nCetopsorhamdia iheringi\n\n\n\n\n\n\n\nImparfinis minutus\n\n\n\n\n\n\n\n\n\nHisonotus sp\n\n\n\n\n\n\n\nHypostomus sp\n\n\n\n\n\n\nFiguraÂ 1: EspÃ©cies da TabelaÂ 1.\n\n\n\nCada espÃ©cie estÃ¡ representada em uma coluna, e as linhas correspondem Ã s medidas morfolÃ³gicas que podem ser associadas aos traÃ§os funcionais das espÃ©cies. Em notaÃ§Ã£o matricial, podemos representar a TabelaÂ 1 como:\n\\[\\mathbf{T} =\n\\begin{bmatrix}\n1.67 & 1.71 & \\dots & 0.66\\\\\n0.21 & 0.26 & \\dots & 0.19\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n1.26 & 1.74 & \\dots & 3.14\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#matriz-de-traÃ§os-morfolÃ³gicos",
    "href": "content/multivariada-numerica/cossine-similarity.html#matriz-de-traÃ§os-morfolÃ³gicos",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "",
    "text": "Considere a situaÃ§Ã£o em que temos 8 espÃ©cies de peixes nas descritas por 6 traÃ§os funcionais (TabelaÂ 1). TraÃ§os funcionais sÃ£o caracterÃ­sticas morfolÃ³gicas, fisiolÃ³gicas ou comportamentais mensurÃ¡veis que influenciam diretamente o desempenho ecolÃ³gico das espÃ©cies, determinando como elas interagem com o ambiente e utilizam recursos (como habitats, alimento e abrigo). Espera-se, por exemplo, que espÃ©cies similares em seus traÃ§os funcionais ocupem um espaÃ§o de nicho e respondam de forma similar a pressÃµes ambientais. Nosso objetivo serÃ¡ quantificar o grau de similaridade entre os pares de espÃ©cies por meio do Ã­ndice de similaridade por cossenos.\n\n\n\nTabelaÂ 1: TraÃ§os funcionais entre 8 espÃ©cies de peixes de riachos. CI: Ãndice de compressÃ£o; RD: Altura relativa; IVF: Ãndice de achatamento ventral; RAC: Ãrea relativa da nadadeira caudal; REP: PosiÃ§Ã£o relativa do olho; MO: orientaÃ§Ã£o da boca. Bstr: Bryconamericus stramineus; Bsp: Bryconamericus sp.; Cfasc: Characidium fasciatum; Czeb: Characidium zebra; Cih: Cetopsorhamdia iheringi; Imin: Imparfinis minutus; Hsp: Hisonotus sp.; Hypsp: Hypostomus sp.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraÃ§o\nBstr\nBsp\nCfasc\nCzeb\nCih\nImin\nHsp\nHypsp\n\n\n\n\nCI\n1.67\n1.71\n1.41\n1.47\n0.97\n0.69\n0.73\n0.66\n\n\nRD\n0.21\n0.26\n0.21\n0.22\n0.17\n0.12\n0.16\n0.19\n\n\nIVF\n0.57\n0.53\n0.51\n0.49\n0.59\n0.55\n0.39\n0.35\n\n\nRAC\n0.14\n0.13\n0.14\n0.11\n0.22\n0.26\n0.19\n0.3\n\n\nREP\n0.7\n0.68\n0.79\n0.8\n0.91\n0.76\n0.71\n0.85\n\n\nMO\n1.26\n1.74\n3.03\n1.98\n2.06\n2.24\n3.14\n3.14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBryconamericus stramineus\n\n\n\n\n\n\n\nBryconamericus sp\n\n\n\n\n\n\n\n\n\nCharacidium fasciatum\n\n\n\n\n\n\n\nCharacidium zebra\n\n\n\n\n\n\n\n\n\nCetopsorhamdia iheringi\n\n\n\n\n\n\n\nImparfinis minutus\n\n\n\n\n\n\n\n\n\nHisonotus sp\n\n\n\n\n\n\n\nHypostomus sp\n\n\n\n\n\n\nFiguraÂ 1: EspÃ©cies da TabelaÂ 1.\n\n\n\nCada espÃ©cie estÃ¡ representada em uma coluna, e as linhas correspondem Ã s medidas morfolÃ³gicas que podem ser associadas aos traÃ§os funcionais das espÃ©cies. Em notaÃ§Ã£o matricial, podemos representar a TabelaÂ 1 como:\n\\[\\mathbf{T} =\n\\begin{bmatrix}\n1.67 & 1.71 & \\dots & 0.66\\\\\n0.21 & 0.26 & \\dots & 0.19\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n1.26 & 1.74 & \\dots & 3.14\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#calculando-similaridade-por-cossenos",
    "href": "content/multivariada-numerica/cossine-similarity.html#calculando-similaridade-por-cossenos",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "2 Calculando Similaridade por cossenos",
    "text": "2 Calculando Similaridade por cossenos\nCada espÃ©cie na TabelaÂ 1 pode ser vista como um vetor \\(\\vec{v}\\) ou \\(\\vec{u}\\) com 6 entradas, uma para cada traÃ§o funcional. Assim, o cosseno do Ã¢ngulo \\(\\theta\\) entre os vetores pode ser calculado por:\n\\[\\cos(\\theta) = \\frac{\\vec{v} \\cdot \\vec{u}}{\\|\\vec{v}\\| \\|\\vec{u}\\|}\n\\tag{1}\\]\nOnde:\n\n\\(\\vec{v} \\cdot \\vec{u}\\) Ã© o produto escalar entre os vetores \\(\\vec{v}\\) e \\(\\vec{u}\\).\n\\(\\|\\vec{v}\\|\\) e \\(\\|\\vec{u}\\|\\) sÃ£o as normas (comprimentos) dos vetores.\n\\(\\theta\\) Ã© o Ã¢ngulo entre os vetores no espaÃ§o multidimensional de 6 dimensÃµes.\n\nO valor do \\(\\cos(\\theta)\\) funciona como um Ã­ndice de similaridade cuja interpretaÃ§Ã£o ecolÃ³gica Ã© direta:\n\n\\(\\cos(\\theta) \\approx 1\\) (Ã¢ngulo prÃ³ximo a 0Â°), indica espÃ©cies com alta similaridade funcional, compartilhando estratÃ©gias ecolÃ³gicas semelhantes;\n\\(\\cos(\\theta) \\approx 0\\) (Ã¢ngulo prÃ³ximo a 90Â°) revela espÃ©cies ecologicamente distintas, com traÃ§os funcionais divergentes."
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#exemplo-prÃ¡tico-similaridade-entre-bstr-e-bsp",
    "href": "content/multivariada-numerica/cossine-similarity.html#exemplo-prÃ¡tico-similaridade-entre-bstr-e-bsp",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "3 Exemplo PrÃ¡tico: Similaridade entre Bstr e Bsp",
    "text": "3 Exemplo PrÃ¡tico: Similaridade entre Bstr e Bsp\n\nVetores das espÃ©cies:\n\n\\[\n\\vec{v}_{\\text{Bstr}} = \\begin{bmatrix}\n1.67 \\\\ 0.21 \\\\ 0.57 \\\\ 0.14 \\\\ 0.7 \\\\ 1.26\n\\end{bmatrix}, \\quad\n\\vec{u}_{\\text{Bsp}} = \\begin{bmatrix}\n1.71 \\\\ 0.26 \\\\ 0.53 \\\\ 0.13 \\\\ 0.68 \\\\ 1.74\n\\end{bmatrix}\n\\]\n\nProduto Escalar:\n\n\\[\\vec{v} \\cdot \\vec{u} = (1.67 \\times 1.71) + (0.21 \\times 0.26) + \\dots + (1.26 \\times 1.74) = 5.899\\]\n\nNormas dos Vetores: \\[\\|\\vec{v}\\| = \\sqrt{1.67^2 + 0.21^2 + \\dots + 1.26^2} \\approx 2.2924\\] \\[\\|\\vec{u}\\| = \\sqrt{1.71^2 + 0.26^2 + \\dots + 1.74^2} \\approx 2.6037\\]\nCosseno do Ã‚ngulo: \\[\\cos(\\theta) = \\frac{5.899}{2.2924 \\times 2.6037} \\approx 0.988\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#similaridade-por-cossenos-a-partir-de-operaÃ§Ãµes-matriciais",
    "href": "content/multivariada-numerica/cossine-similarity.html#similaridade-por-cossenos-a-partir-de-operaÃ§Ãµes-matriciais",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "4 Similaridade por Cossenos a partir de operaÃ§Ãµes matriciais",
    "text": "4 Similaridade por Cossenos a partir de operaÃ§Ãµes matriciais\nOs passos do item dois podem ser generalizados para todos os pares de espÃ©cies utilizando uma sÃ©rie de operaÃ§Ãµes matriciais.\n\nObtenÃ§Ã£o da Matriz de Produtos Escalares (\\(\\mathbf{E}\\)): \\[\\mathbf{E} = \\mathbf{T}^\\top \\mathbf{T}\\]\n\n\\[\\mathbf{T^\\top} =\n\\begin{bmatrix}\n1.67 & 0.21 & \\dots & 1.26\\\\\n1.71 & 0.26 & \\dots & 1.74\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n0.66 & 0.19 & \\dots & 3.14\n\\end{bmatrix}, \\quad\n\\mathbf{E} =\n\\begin{bmatrix}\ne_{11} & e_{12} & \\dots & e_{18}\\\\\ne_{21} & e_{22} & \\dots & e_{28}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\ne_{81} & e_{82} & \\dots & e_{88}\n\\end{bmatrix}\n\\]\n\n\n\nObtenÃ§Ã£o da Matriz \\(\\mathbf{D}\\):\n\nAs normas dos vetores de espÃ©cies da matriz \\(\\mathbf{T}\\) podem ser obtidas a partir dos elementos da diagonal da matriz \\(\\mathbf{E}\\), em que:\n\\[\\text{norma}_i = \\sqrt{e_{ii}}\\]\nSabendo disso, obtenha a Matriz \\(\\mathbf{D}\\):\n\\[\\mathbf{D} =\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{e_{11}}} & 0 & \\dots & 0\\\\\n0 & \\frac{1}{\\sqrt{e_{22}}} & \\dots & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n0 & 0 & \\dots & \\frac{1}{\\sqrt{e_{88}}}\n\\end{bmatrix}\n\\]\n\n\nMatriz Final de similaridade por cossenos (\\(\\mathbf{C}\\)):\n\n\\[\\mathbf{C} = \\mathbf{D} \\mathbf{E} \\mathbf{D}\n\\tag{2}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#roteiro-matriz-de-similaridade-no-google-planilhas",
    "href": "content/multivariada-numerica/cossine-similarity.html#roteiro-matriz-de-similaridade-no-google-planilhas",
    "title": "Ecologia Funcional: aplicaÃ§Ã£o da Ã¡lgebra matricial",
    "section": "5 Roteiro: Matriz de Similaridade no Google Planilhas",
    "text": "5 Roteiro: Matriz de Similaridade no Google Planilhas\n\nAcesse sheets.google.com.\nInsira os dados da tabela \\(\\mathbf{T}\\) (TabelaÂ 1). Se necessÃ¡rio modifique o decimal de ponto (.) para vÃ­rgula (,).\nCalcule \\(\\mathbf{T}^\\top\\).\n\nDica - utilize a fÃ³rmula:\n=TRANSPOR()\n\nCalcule a matriz \\(\\mathbf{E}\\).\n\nDica - utilize a fÃ³rmula:\n=MATRIZ.MULT()\n\nCalcule as normas das colunas da matriz \\(\\mathbf{E}\\) e monte a matriz diagonal \\(\\mathbf{D}\\).\n\nDica: A matriz diagonal \\(\\mathbf{D}\\) terÃ¡ as mesmas dimensÃµes de \\(\\mathbf{E}\\), mas serÃ¡ preenchida com zeros exceto na diagonal principal. Nela, os valores serÃ£o \\(\\frac{1}{\\sqrt{e_{ii}}}\\), onde \\(e_{ii}\\) sÃ£o os elementos da diagonal principal de \\(\\mathbf{E}\\).\n\nCalcule a matriz \\(\\mathbf{C}\\) conforme a EquaÃ§Ã£oÂ 2.\n\nDica - utilize a fÃ³rmula:\n=MATRIZ.MULT()\n\nVerificaÃ§Ã£o: calcule o cosseno de \\(\\theta\\) entre algumas espÃ©cies utilizando a EquaÃ§Ã£oÂ 1 e verifique se os resultados coincidem com os observados na matriz de similaridade \\(\\mathbf{C}\\).\nVerificaÃ§Ã£o: Considerando as imagens apresentadas na FiguraÂ 1, avalie criticamente se a matriz de similaridade representa de maneira fidedigna a semelhanÃ§a morfomÃ©trica entre as espÃ©cies."
  },
  {
    "objectID": "content/multivariada-numerica/clustering.html",
    "href": "content/multivariada-numerica/clustering.html",
    "title": "Agrupamento (Clustering)",
    "section": "",
    "text": "1 Agrupamento (Clustering)\n(ConteÃºdo em construÃ§Ã£o)"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#conteÃºdo-da-aula",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#conteÃºdo-da-aula",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "ConteÃºdo da Aula",
    "text": "ConteÃºdo da Aula\n\n\nIntroduÃ§Ã£o Ã  RegressÃ£o Linear Simples\nDefiniÃ§Ã£o dos ResÃ­duos\nMÃ©todo dos MÃ­nimos Quadrados\nRepresentaÃ§Ã£o Vetorial dos ResÃ­duos\nGeometria da SoluÃ§Ã£o de MÃ­nimos Quadrados\nSoluÃ§Ã£o Matricial do MÃ©todo dos MÃ­nimos Quadrados\nValores preditos\nSoma dos quadrados dos resÃ­duos\nSoma dos quadrados dos totais\nCoeficiente de determinaÃ§Ã£o"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#introduÃ§Ã£o-Ã -regressÃ£o-linear-simples",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#introduÃ§Ã£o-Ã -regressÃ£o-linear-simples",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "IntroduÃ§Ã£o Ã  RegressÃ£o Linear Simples",
    "text": "IntroduÃ§Ã£o Ã  RegressÃ£o Linear Simples\nA regressÃ£o linear simples Ã© um mÃ©todo para modelar a relaÃ§Ã£o entre uma variÃ¡vel dependente \\(y\\) e uma variÃ¡vel independente \\(x\\). A equaÃ§Ã£o da reta ajustada Ã© dada por:\n\\[ \\hat{y} = \\beta_0 + \\beta_1 x \\]\n\n\n\n\n\n\nObservaÃ§Ã£o\n\\(x_i\\)\n\\(y_i\\)\n\n\n\n\n\\(1\\)\n\\(x_1\\)\n\\(y_1\\)\n\n\n\\(2\\)\n\\(x_2\\)\n\\(y_2\\)\n\n\n\\(3\\)\n\\(x_3\\)\n\\(y_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#definiÃ§Ã£o-dos-resÃ­duos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#definiÃ§Ã£o-dos-resÃ­duos",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "DefiniÃ§Ã£o dos ResÃ­duos",
    "text": "DefiniÃ§Ã£o dos ResÃ­duos\nNa figura abaixo, os resÃ­duos \\(e_i\\) representam as diferenÃ§as entre os valores observados \\(y_i\\) e os valores ajustados \\(\\hat{y}_i\\) pela reta de regressÃ£o:\n\\[ e_i = y_i - (\\beta_0 + \\beta_1 x_i) \\]\nPortando na regressÃ£o linear, assume-se que o valor observado em \\(y_i\\) Ã© dado por:\n\\[ y_i = \\beta_0 + \\beta_1 x_i + e_i\\]\n\n\n\n\n\n\nDica\n\n\n\n\nAcesse o link RegresÃ£o linear Geogebra\n\n\n\n\n\nObservaÃ§Ã£o\n\\(x_i\\)\n\\(y_i\\)\n\n\n\n\n\\(1\\)\n\\(x_1\\)\n\\(y_1\\)\n\n\n\\(2\\)\n\\(x_2\\)\n\\(y_2\\)\n\n\n\\(3\\)\n\\(x_3\\)\n\\(y_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#mÃ©todo-dos-mÃ­nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#mÃ©todo-dos-mÃ­nimos-quadrados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "MÃ©todo dos MÃ­nimos Quadrados",
    "text": "MÃ©todo dos MÃ­nimos Quadrados\nO MÃ©todo dos MÃ­nimos Quadrados busca minimizar a soma dos quadrados dos resÃ­duos:\n\\[ SQ_{res} = \\sum_{i=1}^{n} e_i^2 = e_1^2 + e_2^2 + \\cdots + e_n^2 \\]\nQue pode ser representada como:\n\\[\n\\begin{cases}\ne_1 = y_1 - (\\beta_0 + \\beta_1 x_1) \\\\\ne_2 = y_2 - (\\beta_0 + \\beta_1 x_2) \\\\\n\\vdots \\\\\ne_n = y_n - (\\beta_0 + \\beta_1 x_n) \\\\\n\\end{cases}\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#representaÃ§Ã£o-vetorial-dos-resÃ­duos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#representaÃ§Ã£o-vetorial-dos-resÃ­duos",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "RepresentaÃ§Ã£o Vetorial dos ResÃ­duos",
    "text": "RepresentaÃ§Ã£o Vetorial dos ResÃ­duos\nPodemos portanto representar os resÃ­duos como vetor em que o vetor \\(\\vec{e}\\) Ã© igual ao vetor \\(y\\) menos uma combinaÃ§Ã£o linear dos vetores \\(\\vec{f}_0\\) e \\(\\vec{f}_0\\) com constantes \\(\\beta_0\\) e \\(\\beta_1\\).\n\n\\[ \\vec{e} = \\vec{y} - (\\beta_0 \\vec{f}_0 + \\beta_1 \\vec{f}_1) \\]\n\n\n\\[\n\\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\ny_1 - (\\beta_0 + \\beta_1 x_1) \\\\\ny_2 - (\\beta_0 + \\beta_1 x_2) \\\\\n\\vdots \\\\\ny_n - (\\beta_0 + \\beta_1 x_n) \\\\\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{array} \\right]\n-\n\\left(\n\\beta_0\n\\left[ \\begin{array}{c}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{array} \\right]\n+\n\\beta_1\n\\left[ \\begin{array}{c}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{array} \\right]\n\\right)\n\\]\nOnde:\n\\[\\vec{e} =\n\\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right];\n\\vec{y} =\n\\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\n\\vec{f}_0 =\n\\left[ \\begin{array}{c}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{array} \\right];\n\\vec{f}_1 =\n\\left[ \\begin{array}{c}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{array} \\right]\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-soluÃ§Ã£o-de-mÃ­nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-soluÃ§Ã£o-de-mÃ­nimos-quadrados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Geometria da SoluÃ§Ã£o de MÃ­nimos Quadrados",
    "text": "Geometria da SoluÃ§Ã£o de MÃ­nimos Quadrados\nA Soma dos quadrados dos resÃ­duos (\\(SQ_{res}\\)) pode ser obtida pela norma ao quadrado do vetor \\(\\vec{e}\\):\n\\[SQ_{res} = \\Vert\\vec{e}\\Vert^{2}=\\vec{e}\\cdot\\vec{e}=e_{1}^{2}+e_{2}^{2}+\\cdots+e_{n}^{2}\\]\n\n\n\n\n\n\n\n\nRepresentaÃ§Ã£o da SoluÃ§Ã£o do MMQ no GeoGebra\n\n\nO MÃ©todo dos MÃ­nimos Quadrados determina \\(\\beta_0\\) e \\(\\beta_1\\) de modo a minimizar o comprimento (a norma) do vetor \\(\\vec{e}\\) que pode ser obtida impondo que o vetor \\(\\vec{e}\\) seja ortogonal aos vetores \\(\\vec{f_0}\\) e \\(\\vec{f_1}\\), ou seja:\n\\[ \\vec{f_0} \\cdot \\vec{e} = 0 \\] \\[ \\vec{f_1} \\cdot \\vec{e} = 0 \\]\nLink para soluÃ§Ã£o vetorial do MMQ"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-soluÃ§Ã£o-de-mÃ­nimos-quadrados-1",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-soluÃ§Ã£o-de-mÃ­nimos-quadrados-1",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Geometria da SoluÃ§Ã£o de MÃ­nimos Quadrados",
    "text": "Geometria da SoluÃ§Ã£o de MÃ­nimos Quadrados\n\\[\n\\left\\{\\begin{array} {c}\n\\vec{f_0} \\cdot \\vec{e} = 0 \\Leftrightarrow \\vec{f_0}\\cdot(\\vec{y}-\\beta_0\\vec{f_0}-\\beta_1\\vec{f_1})=0\\\\\n\\vec{f_1} \\cdot \\vec{e} = 0 \\Leftrightarrow \\vec{f_1}\\cdot(\\vec{y}-\\beta_0\\vec{f_0}-\\beta_1\\vec{f_1})=0\n\\end{array} \\right.\n\\] que Ã© equivalente a: \\[\n\\left\\{\\begin{array} {c}\n\\beta_0\\vec{f_0}\\cdot\\vec{f_0}+\\beta_1\\vec{f_0}\\cdot\\vec{f_1}=\\vec{f_0}\\cdot\\vec{y}\\\\\n\\beta_0\\vec{f_1}\\cdot\\vec{f_0}+\\beta_1\\vec{f_1}\\cdot\\vec{f_1}=\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right.\n,\n\\] que ainda pode ser escrito na forma matricial: \\[\n\\left[ \\begin{array}{cc}\n\\vec{f_0}\\cdot\\vec{f_0} & \\vec{f_0}\\cdot\\vec{f_1}\\\\\n\\vec{f_1}\\cdot\\vec{f_0} & \\vec{f_1}\\cdot\\vec{f_1}\n\\end{array} \\right]\n\\left[ \\begin{array}{c}\n\\beta_0\\\\\n\\beta_1\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\n\\vec{f_0}\\cdot\\vec{y}\\\\\n\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right]\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soluÃ§Ã£o-matricial-do-mÃ©todo-dos-mÃ­nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soluÃ§Ã£o-matricial-do-mÃ©todo-dos-mÃ­nimos-quadrados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "SoluÃ§Ã£o Matricial do MÃ©todo dos MÃ­nimos Quadrados",
    "text": "SoluÃ§Ã£o Matricial do MÃ©todo dos MÃ­nimos Quadrados\nA combinaÃ§Ã£o linear:\n\\[\n\\left[ \\begin{array}{cc}\n\\vec{f_0}\\cdot\\vec{f_0} & \\vec{f_0}\\cdot\\vec{f_1}\\\\\n\\vec{f_1}\\cdot\\vec{f_0} & \\vec{f_1}\\cdot\\vec{f_1}\n\\end{array} \\right]\n\\left[ \\begin{array}{c}\n\\beta_0\\\\\n\\beta_1\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\n\\vec{f_0}\\cdot\\vec{y}\\\\\n\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right]\n\\]\npor ser expressa pelas matrizes:\n\\[X = \\left[ \\begin{array}{ccc}\n\\vec{f_0} & \\vdots & \\vec{f_1}\n\\end{array} \\right] =\n\\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right];\nY = \\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\nB = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]\nE finalmente:\n\\[B = (X^{T} X)^{-1}(X^{T}Y)\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#calculando-os-valores-preditos-haty",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#calculando-os-valores-preditos-haty",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Calculando os valores preditos (\\(\\hat{y}\\))",
    "text": "Calculando os valores preditos (\\(\\hat{y}\\))\nDefinimos \\(\\mathbf{F}\\) como a matriz coluna que contÃ©m os valores preditos de \\(y\\) (denominados \\(\\hat{y}\\)), isto Ã©, aquela que contÃ©m os pontos em \\(y\\) que se sobrepÃµem Ã  reta da regressÃ£o linear. Podemos obter \\(\\mathbf{F}\\) por meio da operaÃ§Ã£o matricial abaixo:\n\n\\[\\mathbf{F} = \\mathbf{X}\\mathbf{B}\\]\n\n\\[\\mathbf{F} = \\left[ \\begin{array}{c}\n\\hat{y}_1 \\\\\n\\hat{y}_2 \\\\\n\\vdots & \\vdots \\\\\n\\hat{y}_n \\\\\n\\end{array} \\right]; \\mathbf{X} = \\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right]; \\mathbf{B} = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#vetor-de-resÃ­duos-e",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#vetor-de-resÃ­duos-e",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Vetor de resÃ­duos (\\(e\\))",
    "text": "Vetor de resÃ­duos (\\(e\\))\nFinalmente, o vetor de resÃ­duos Ã© obtido por:\n\n\\[e = \\mathbf{Y} - \\mathbf{F}\\]\n\nAgora temos todos os componentes da regressÃ£o linear estabelecida inicialmente:\n\\[ \\hat{y_i} = \\beta_0 + \\beta_1 x_i \\]\ne\n\\[ y_i = \\hat{y_i} + e_i \\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-dos-resÃ­duos-sq_res",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-dos-resÃ­duos-sq_res",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Soma dos quadrados dos resÃ­duos (\\(SQ_{res}\\))",
    "text": "Soma dos quadrados dos resÃ­duos (\\(SQ_{res}\\))\nA Soma dos quadrados dos resÃ­duos foi definida pela expressÃ£o abaixo:\n\\[SQ_{res} = \\Vert\\vec{e}\\Vert^{2}=\\vec{e}\\cdot\\vec{e}=e_{1}^{2}+e_{2}^{2}+\\cdots+e_{n}^{2}\\]\nConsiderando \\(\\vec{e}\\) como a matriz coluna \\(\\mathbf{e}\\):\n\\[\\mathbf{e} = \\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right]\n\\]\nPodemos fazer:\n\n\\[SQ_{res} = \\mathbf{e}^\\top \\mathbf{e}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-totais-sq_tot",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-totais-sq_tot",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Soma dos quadrados totais (\\(SQ_{tot}\\))",
    "text": "Soma dos quadrados totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser definido como:\n\n\\[SQ_{tot} = \\sum_{i}^{n}{(y_i - \\overline{y})^{2}} = (y_1 - \\overline{y})^{2} + (y_2 - \\overline{y})^{2} + \\cdots + (y_n - \\overline{y})^{2}\\]\nem que \\(\\overline{y}\\) Ã© a mÃ©dia aritmÃ©tica de \\(y\\)\n\n\n\nPodemos definir a matrix coluna \\(\\mathbf{D}\\)\n\\[\\mathbf{D} = \\left[ \\begin{array}{c}\n(y_1 - \\overline{y})^{2} \\\\\n(y_2 - \\overline{y})^{2} \\\\\n\\vdots\\\\\n(y_n - \\overline{y})^{2} \\\\\n\\end{array} \\right]\n\\]\n\nE obter \\(SQ_{tot}\\) por:\n\\[SQ_{tot} = \\mathbf{D}^\\top \\mathbf{D}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Coeficiente de determinaÃ§Ã£o (\\(R^2\\))",
    "text": "Coeficiente de determinaÃ§Ã£o (\\(R^2\\))\nA qualidade do ajuste pode ser determinada pelo coeficiente de determinaÃ§Ã£o (\\(R^2\\)), um Ã­ndice que varia entre 0 e 1.\n\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determinaÃ§Ã£o-r2-1",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determinaÃ§Ã£o-r2-1",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "Coeficiente de determinaÃ§Ã£o (\\(R^2\\))",
    "text": "Coeficiente de determinaÃ§Ã£o (\\(R^2\\))"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#mÃ©todo-dos-mÃ­nimos-quadrados-resumo-dos-passos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#mÃ©todo-dos-mÃ­nimos-quadrados-resumo-dos-passos",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "MÃ©todo dos mÃ­nimos quadrados: Resumo dos passos",
    "text": "MÃ©todo dos mÃ­nimos quadrados: Resumo dos passos\n\n\n\n\n\n\n\n\n\nResoluÃ§Ã£o do MMQ\n\n\n\nDefiniÃ§Ã£o das matrizes do sistema\n\n\\[X = \\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right];\nY = \\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\nB = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]\n\nCÃ¡lculo dos coeficientes\n\n\\[B = (X^{T} X)^{-1}(X^{T}Y)\\]\n\nValores preditos\n\n\\[\\mathbf{F} = \\mathbf{X}\\mathbf{B}\\]\n\nMatriz coluna de ResÃ­duos\n\n\\[\\mathbf{e} = \\mathbf{Y} - \\mathbf{F}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nQualidade do ajuste\n\n\n\nSoma dos quadrados dos resÃ­duos\n\n\\[SQ_{res} = \\mathbf{e}^\\top \\mathbf{e}\\]\n\nSoma dos quadrados totais\n\n\\[SQ_{tot} = \\mathbf{D}^\\top \\mathbf{D}\\]\n\nCoeficiente de determinaÃ§Ã£o\n\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html",
    "href": "content/regressao-linear/regressao-linear-multipla.html",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(patchwork)\nlibrary(gt)"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#abundÃ¢ncia-de-aves-em-fragmentos-de-floresta",
    "href": "content/regressao-linear/regressao-linear-multipla.html#abundÃ¢ncia-de-aves-em-fragmentos-de-floresta",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "1 AbundÃ¢ncia de aves em fragmentos de floresta",
    "text": "1 AbundÃ¢ncia de aves em fragmentos de floresta\nLoyn (1987) conduziu um estudo para entender quais caracterÃ­sticas do habitat estavam relacionadas Ã  abundÃ¢ncia de aves da floresta (acesse o artigo aqui). Para isso, ele selecionou 56 fragmentos de floresta no sudeste de Victoria, AustrÃ¡lia, e registrou a abundÃ¢ncia de aves da floresta (ABUND) em cada fragmento como variÃ¡vel de resposta.\nAs variÃ¡veis preditoras registradas para cada fragmento incluÃ­ram:\n\nÃrea do fragmento (ha): AREA\nDistÃ¢ncia ao fragmento mais prÃ³ximo (km): DIST\nDistÃ¢ncia ao fragmento maior mais prÃ³ximo (km):LDIST\nNÃºmero de anos desde que o fragmento foi isolado por desmatamento (anos):YR.ISOL\nÃndice de histÃ³rico de pastagem, de 1 (leve) a 5 (pesado):GRAZE\nAltitude mÃ©dia (m):ALT\n\nInicialmente, vamos nos concentrar nas variÃ¡veis YR.ISOL, GRAZE e ALT.\nImporte a base de dados loyn.csv\n\nloyn = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/loyn.csv\")\n\nhead(loyn) |&gt; gt()\n\n\n\n\n\n\n\nABUND\nAREA\nYR.ISOL\nDIST\nLDIST\nGRAZE\nALT\n\n\n\n\n5.3\n0.1\n1968\n39\n39\n2\n160\n\n\n2.0\n0.5\n1920\n234\n234\n5\n60\n\n\n1.5\n0.5\n1900\n104\n311\n5\n140\n\n\n17.1\n1.0\n1966\n66\n66\n3\n160\n\n\n13.8\n1.0\n1918\n246\n246\n5\n140\n\n\n14.1\n1.0\n1965\n234\n285\n3\n130"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#grÃ¡ficos-de-dispersÃ£o-entre-abund-e-cada-uma-das-demais-variÃ¡veis-preditoras",
    "href": "content/regressao-linear/regressao-linear-multipla.html#grÃ¡ficos-de-dispersÃ£o-entre-abund-e-cada-uma-das-demais-variÃ¡veis-preditoras",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "2 GrÃ¡ficos de dispersÃ£o entre ABUND e cada uma das demais variÃ¡veis preditoras",
    "text": "2 GrÃ¡ficos de dispersÃ£o entre ABUND e cada uma das demais variÃ¡veis preditoras\n\nplt_gr &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = GRAZE) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\nplt_al &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = ALT) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\nplt_yr &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = YR.ISOL) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\n\nplt_gr + plt_al + plt_yr"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#multicolinearidade-as-variÃ¡veis-preditoras-sÃ£o-correlacionadas-entre-si",
    "href": "content/regressao-linear/regressao-linear-multipla.html#multicolinearidade-as-variÃ¡veis-preditoras-sÃ£o-correlacionadas-entre-si",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "3 Multicolinearidade: as variÃ¡veis preditoras sÃ£o correlacionadas entre si?",
    "text": "3 Multicolinearidade: as variÃ¡veis preditoras sÃ£o correlacionadas entre si?\n\nggpairs(loyn |&gt; select(GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nAs variÃ¡veis ALT versus GRAZE e GRAZE versus YR.ISOL parecem ter um grau de correlaÃ§Ã£o moderado entre si."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#o-modelo-de-regressÃ£o-mÃºltipla",
    "href": "content/regressao-linear/regressao-linear-multipla.html#o-modelo-de-regressÃ£o-mÃºltipla",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "4 O modelo de regressÃ£o mÃºltipla",
    "text": "4 O modelo de regressÃ£o mÃºltipla\nO modelo de regressÃ£o linear mÃºltipla Ã© dado por:\n\\[ABUND_i = \\beta_0 + \\beta_1 ALT_i + \\beta_2 YR.ISIOL_i + \\epsilon_i\\]\nNo R pode ser ajustado por:\n\nmfull &lt;- lm(ABUND ~ ALT + YR.ISOL, data  = loyn)\nmfull\n\n\nCall:\nlm(formula = ABUND ~ ALT + YR.ISOL, data = loyn)\n\nCoefficients:\n(Intercept)          ALT      YR.ISOL  \n -348.47698      0.07006      0.18348  \n\n\nO resumo do modelo pode ser visto com a funÃ§Ã£o summary\n\nsummary(mfull)\n\n\nCall:\nlm(formula = ABUND ~ ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.9745  -6.4690   0.6168   7.4408  24.0155 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -348.47698   93.73407  -3.718 0.000486 ***\nALT            0.07006    0.02852   2.457 0.017329 *  \nYR.ISOL        0.18348    0.04852   3.781 0.000398 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.953 on 53 degrees of freedom\nMultiple R-squared:  0.3297,    Adjusted R-squared:  0.3044 \nF-statistic: 13.03 on 2 and 53 DF,  p-value: 2.49e-05"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#hipÃ³tese-nula-e-comparaÃ§Ã£o-de-modelos",
    "href": "content/regressao-linear/regressao-linear-multipla.html#hipÃ³tese-nula-e-comparaÃ§Ã£o-de-modelos",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "5 HipÃ³tese nula e comparaÃ§Ã£o de modelos",
    "text": "5 HipÃ³tese nula e comparaÃ§Ã£o de modelos\nA hipÃ³tese nula (\\(H_0\\)) bÃ¡sica que podemos testar ao ajustar um modelo de regressÃ£o linear mÃºltipla Ã© que todas as inclinaÃ§Ãµes de regressÃ£o parciais sÃ£o iguais a zero, ou seja, \\(H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_j = 0\\). Neste exemplo, \\(H_0\\) Ã© que o coeficiente de inclinaÃ§Ã£o dos nÃ­veis de pastagem e os anos de isolamento do fragmento sejam ambos iguais a zero e, consequentemente, nÃ£o tÃªm influÃªncia sobre a abundÃ¢ncia.\nTestamos a hipÃ³tese nula com a ANOVA na regressÃ£o mÃºltipla, que divide a variaÃ§Ã£o total de \\(Y\\) em dois componentes: a variaÃ§Ã£o explicada pela regressÃ£o linear com \\(X_1\\), \\(X_2\\), \\(\\cdots\\), \\(X_j\\) e a variaÃ§Ã£o residual.\nSe \\(H_0\\) for verdadeira, tanto o quadrado mÃ©dio da regressÃ£o \\(QM_{RegressÃ£o}\\) quanto o quadrado mÃ©dio do resÃ­duo (\\(QM_{ResÃ­duo}\\)) estimarÃ£o \\(\\sigma^2\\), e a razÃ£o \\(F\\) entre eles serÃ¡ igual a 1. Se \\(H_0\\) for falsa, pelo menos uma das inclinaÃ§Ãµes de regressÃ£o parciais nÃ£o serÃ¡ igual a zero e \\(QM_{RegressÃ£o}\\) estimarÃ¡ \\(\\sigma^2\\) mais um termo \\(QM_{RegressÃ£o}\\) o que representa essas inclinaÃ§Ãµes de regressÃ£o parciais. Portanto, a razÃ£o \\(F = \\frac{QM_{RegressÃ£o}}{QM_{RegressÃ£o}} &gt; 1\\). Neste caso, a decisÃ£o de aceitar \\(H_0\\) Ã© feita pela comparaÃ§Ã£o do \\(F\\) calculado com a distribuiÃ§Ã£o \\(F\\) apropriada, da mesma forma que fazemos com a regressÃ£o linear simples ou com a AnÃ¡lise de VariÃ¢ncia.\nO resultado da razÃ£o \\(F\\) aparece no comando summary, que no exemplo acima Ã© F = 13.035, com valor de p = 2.5^{-5}.\nTambÃ©m podemos testar as hipÃ³teses nulas sobre cada coeficiente de regressÃ£o parcial, ou seja, de que qualquer \\(\\beta_1\\) seja igual a zero. Para isto, podemos usar a estratÃ©gia de comparaÃ§Ã£o de modelos em que o modelo completo (aquele com todas as variÃ¡veis) Ã© comparado com o modelo reduzido (aquele sem a variÃ¡vel \\(X_1\\) de interesse).\nPara testar o efeito da altitude, por exemplo, o modelo reduzido Ã©:\n\\(ABUND_i = \\beta_0 + \\beta_2 YR.ISIOL_i + \\epsilon_i\\)\nO modelo completo tem soma dos quadrados (\\(SQ\\)) maior que o modelo reduzido. Para comparar o ganho extra que o modelo completo tem sobre o modelo reduzido podemos fazer:\n\\(SS_{extra} = SS_{RegressÃ£o_{completo}} - SS_{RegressÃ£o_{reduzido}}\\)\nEm seguida, calculamos o quadrado mÃ©dio extra como \\(QM_{extra} = \\frac{SS_{extra}}{gl}\\) e usamos o teste \\(F\\) como:\n\\(F = \\frac{QM_{extra}}{QM_{ResÃ­duo_{completo}}}\\)\nO mesmo pode ser feito para a variÃ¡vel \\(YR.ISOL\\).\nNo R, podemos testar os efeitos dos coeficientes parciais de regressÃ£o com o comando drop1.\n\ndrop1(mfull, test = 'F')\n\nSingle term deletions\n\nModel:\nABUND ~ ALT + YR.ISOL\n        Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;               4248.3 248.42                      \nALT      1    483.79 4732.1 252.46  6.0355 0.0173292 *  \nYR.ISOL  1   1146.10 5394.4 259.80 14.2982 0.0003979 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVemos aqui que os dois componentes (ALT e YR.ISOL) adicionam uma variaÃ§Ã£o explicada significativa, isto Ã©, para os dois coeficientes \\(p \\le 0,005\\).\nNote que o teste o teste F de comparaÃ§Ã£o de modelos foi equivalente ao teste \\(t\\) aplicado a cada coeficiente e que pode ser visto no resultado da funÃ§Ã£o summary, sendo \\(F = t^2\\). No entanto, a estratÃ©gia de comparaÃ§Ã£o de modelos apresentada aqui permite a comparaÃ§Ã£o nÃ£o somente de coeficientes isolados, mas de qualquer combinaÃ§Ã£o especÃ­fica dos coeficientes em comparaÃ§Ã£o com o modelo completo."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "href": "content/regressao-linear/regressao-linear-multipla.html#coeficiente-de-determinaÃ§Ã£o-r2",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "6 Coeficiente de determinaÃ§Ã£o (\\(R^2\\))",
    "text": "6 Coeficiente de determinaÃ§Ã£o (\\(R^2\\))\nNa regressÃ£o mÃºltipla, o coeficiente de determinaÃ§Ã£o \\(R^2\\) mede a proporÃ§Ã£o da variabilidade total da variÃ¡vel resposta que Ã© explicada pelas variÃ¡veis preditoras. No entanto, \\(R^2\\) tende a aumentar Ã  medida que mais preditores sÃ£o adicionados ao modelo, mesmo que nÃ£o sejam significativos. Para corrigir essa inflaÃ§Ã£o, utilizamos o coeficiente de determinaÃ§Ã£o ajustado (\\(R^2_{ajustado}\\)), que ajusta o \\(R^2\\) considerando o nÃºmero de preditores no modelo e o tamanho da amostra. O \\(R^2_{ajustado}\\) penaliza a adiÃ§Ã£o de preditores irrelevantes, proporcionando uma avaliaÃ§Ã£o mais precisa da qualidade do ajuste do modelo e pode ser obtido pela expressÃ£o:\n\\(R^2_{ajustado} = 1 - \\frac{(1-R^2)(n-1)}{n-k-1}\\)\nNo resultado da funÃ§Ã£o summary vemos que o \\(R^2 = 0.33\\) e o \\(R^2_{ajustado} = 0.304\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#pressupostos-da-regressÃ£o-linear-mÃºltipla",
    "href": "content/regressao-linear/regressao-linear-multipla.html#pressupostos-da-regressÃ£o-linear-mÃºltipla",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "7 Pressupostos da regressÃ£o linear mÃºltipla",
    "text": "7 Pressupostos da regressÃ£o linear mÃºltipla\n\n7.1 Normalidade dos resÃ­duos\n\nloyn &lt;- loyn |&gt; \n  mutate(rst = rstudent(mfull),\n         yaj = fitted(mfull))\n\n\nggplot(loyn) +\n  aes(x = rst, y = after_stat(density)) +\n  geom_histogram(bins = 10, density = TRUE, color = 'white') +\n  geom_density(color = 'darkblue', linewidth = 2)\n\n\n\n\n\n\n\n\n\nshapiro.test(loyn$rst)\n\n\n    Shapiro-Wilk normality test\n\ndata:  loyn$rst\nW = 0.97409, p-value = 0.2687\n\n\n\n\n7.2 GrÃ¡fico de resÃ­duos\n\nggplot(loyn) +\n  aes(x = yaj, y = rst) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\")\n\n\n\n\n\n\n\n\n\n\n7.3 Ãndice de Alavancagem (Leverage)\n\ninfl &lt;- influence.measures(mfull)$infmat |&gt; \n  as.data.frame()\n\nggplot(infl) +\n  aes(y = hat, x = 1:nrow(infl)) +\n  geom_point() +\n  ylab('Leverage')\n\n\n\n\n\n\n\n\n\n\n7.4 Ãndice de Alavancagem de Cook (Dcook)\nO Ã­ndice de alavancagem de Cook Ã© uma medida que combina a magnitude do efeito de alavancagem de uma observaÃ§Ã£o com o quanto essa observaÃ§Ã£o influencia a estimativa dos coeficientes de regressÃ£o. Uma observaÃ§Ã£o com \\(D_{Cook} &gt; 1\\) Ã© frequentemente considerada influente e devem ser examinada para avaliar seu impacto no modelo.\nPara obter o Ã­ndice de alavancagem de Cook em R:\n\nggplot(infl) +\n  aes(y = cook.d, x = 1:nrow(infl)) +\n  geom_point() +\n  ylab('DistÃ¢ncia de Cook')"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#outros-dignÃ³sticos",
    "href": "content/regressao-linear/regressao-linear-multipla.html#outros-dignÃ³sticos",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "8 Outros dignÃ³sticos",
    "text": "8 Outros dignÃ³sticos\n\n8.1 ResÃ­duos versus variÃ¡veis preditoras\n\nggplot(loyn) +\n  aes(x = ALT, y = rst) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(loyn) +\n  aes(x = YR.ISOL, y = rst) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n8.2 ResÃ­duos dos modelos reduzidos versus variÃ¡veis preditoras\nNeste grÃ¡ficos, ajustamos os modelos reduzidos excluindo uma variÃ¡vel preditora por vez e plotamos os resÃ­duos deste modelo com a variÃ¡vel preditora excluÃ­da. Uma tendÃªncia neste grÃ¡fico indica que a inclusÃ£o da variÃ¡vel no modelo ajudaria a reduzir a variaÃ§Ã£o residual.\n\nmpalt &lt;- lm(ABUND ~ YR.ISOL, data  = loyn) # Modelo reduzido sem ALT\nplot(rstudent(mpalt) ~ loyn$ALT)\nabline(lm(rstudent(mpalt) ~ loyn$ALT))\n\n\n\n\n\n\n\n\n\nmpisol &lt;- lm(ABUND ~ ALT, data  = loyn) # Modelo reduzido sem YR.ISOL\nplot(rstudent(mpisol) ~ loyn$YR.ISOL)\nabline(lm(rstudent(mpisol) ~ loyn$YR.ISOL))"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#mais-sobre-multicolinearidade",
    "href": "content/regressao-linear/regressao-linear-multipla.html#mais-sobre-multicolinearidade",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "9 Mais sobre multicolinearidade",
    "text": "9 Mais sobre multicolinearidade\nVariÃ¡veis preditoras correlacionadas entre si caracteriza a multicolinearidade. Quando severa, a multicolinearidade pode afetar a estimativa dos parÃ¢metros da regressÃ£o, pois pequenas alteraÃ§Ãµes nos dados ou inclusÃ£o/remoÃ§Ã£o de variÃ¡veis podem causar grandes mudanÃ§as nos coeficientes estimados da regressÃ£o. AlÃ©m disso, a presenÃ§a de multicolinearidade pode inflar os erros padrÃµes dos coeficientes de regressÃ£o, resultando em um modelo globalmente significativo, mas com coeficientes individuais que nÃ£o sÃ£o estatisticamente diferentes de zero.\nAvaliar uma matriz de correlaÃ§Ã£o entre pares de variÃ¡veis preditoras pode ser a primeira e mais simples forma de explorar a presenÃ§a de colinearidade. Outra forma Ã© avaliar a tolerÃ¢ncia de cada variÃ¡vel preditora \\(X_j\\) por meio de \\(1 - R^2_j\\), em que \\(R^2_j\\) Ã© o coeficiente de determinaÃ§Ã£o do modelo em que \\(X_j\\) Ã© relacionada Ã s demais \\(1 - p\\) variÃ¡veis preditoras. Geralmente, esta tolerÃ¢ncia Ã© expressa na forma do Ã­ndice de inflaÃ§Ã£o da variaÃ§Ã£o (variance inflation factor - \\(VIF\\)) para cada variÃ¡vel preditora, em que:\n\\[VIF_j =\\frac{1}{1 - R^2_j}\\]\nValores elevados indicam que a presenÃ§a de colinearidade devido a variÃ¡vel \\(X_j\\). Diferente nÃ­veis de corte sÃ£o propostos como indicadores da presenÃ§a de multicolinearidade \\(VIF &gt; 5\\), \\(VIF &gt; 10\\) ou \\(VIF &gt; 20\\)\nTodos os coeficientes \\(VIF_j\\) podem ser encontrados em uma Ãºnica operaÃ§Ã£o calculando a inversa da matriz de correlaÃ§Ã£o, \\(\\mathbb{R^{1}}\\) entre as variÃ¡veis de interesse. Os elementos diagonais dessa matriz inversa sÃ£o os coeficientes \\(VIF_j\\). Vimos que GRAZE era correlacionada com ALT e com YR.ISOL. Os ceoficientes \\(VIF\\) para estas variÃ¡veis podem ser obtidos por:\n\nvif &lt;- loyn |&gt; \n  select(GRAZE, ALT, YR.ISOL) |&gt; \n  cor() |&gt; \n  solve() |&gt; \n  diag()\n\nvif\n\n   GRAZE      ALT  YR.ISOL \n1.904799 1.200372 1.679995 \n\n\nO \\(VIF\\) para GRAZE Ã© maior que os demais, porÃ©m longe do limite \\(VIF &gt; 5\\). Vejamos entretanto o que ocorre com o modelo para abundÃ¢ncia se inserimos estas trÃªs variÃ¡veis:\n\nmfull2 &lt;- lm(ABUND ~ GRAZE + ALT + YR.ISOL, data = loyn)\nsummary(mfull2)\n\n\nCall:\nlm(formula = ABUND ~ GRAZE + ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\nALT           0.03285    0.02679   1.226 0.225618    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\n\nNote que agora, somente GRAZE aparece com coeficiente estatÃ­sticamente diferente de \\(0\\) e \\(R^2_{ajustado}\\) aumenta de 0.304 para 0.459"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#tranformaÃ§Ãµes",
    "href": "content/regressao-linear/regressao-linear-multipla.html#tranformaÃ§Ãµes",
    "title": "RegressÃ£o linear mÃºltipla",
    "section": "10 TranformaÃ§Ãµes",
    "text": "10 TranformaÃ§Ãµes\nTransformaÃ§Ãµes podem frequentemente ser eficazes se a distribuiÃ§Ã£o em situaÃ§Ãµes em que as variÃ¡veis preditoras apresentem distribuiÃ§Ãµes assimÃ©tricas. Vamos incluir a AREA no modelo de regressÃ£o. Vejamos os graficos de disperÃ§Ã£o entre as variÃ¡veis preditoras.\n\nggpairs(loyn |&gt; select(AREA, GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nHÃ¡ uma relaÃ§Ã£o fortemente assimÃ©trica da variÃ¡vel Ã¡rea, em que poucos framentos sÃ£o muito maiores. Vejamos as associaÃ§Ãµes par a par utilizando a transfomaÃ§Ã£o \\(log(AREA)\\)\n\nloyn$lAREA &lt;- log(loyn$AREA)\nggpairs(loyn |&gt; select(lAREA, GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nA transformaÃ§Ã£o resolveu o problema da assimetria.\nVamos ajustar agora o modelo de regressÃ£o:\n\nmfull3 &lt;- lm(ABUND ~ lAREA + GRAZE + ALT + YR.ISOL, data = loyn)\nsummary(mfull3)\n\n\nCall:\nlm(formula = ABUND ~ lAREA + GRAZE + ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.4245  -3.3341   0.6227   2.6759  15.3290 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -141.88574   86.23728  -1.645   0.1061    \nlAREA          3.07303    0.55118   5.575 9.41e-07 ***\nGRAZE         -1.60127    0.90538  -1.769   0.0829 .  \nALT            0.02586    0.02136   1.210   0.2317    \nYR.ISOL        0.07991    0.04323   1.848   0.0703 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.283 on 51 degrees of freedom\nMultiple R-squared:  0.6823,    Adjusted R-squared:  0.6574 \nF-statistic: 27.39 on 4 and 51 DF,  p-value: 3.671e-12\n\n\nO resultado indica que somente o \\(log(AREA)\\) seja importante para predizer a abundÃ¢ncia. Entretanto, lembre-se que havia uma certo padrÃ£o de colinearidade entre GRAZE, ALT a YR.ISOL. Teste retirar uma a uma estas variÃ¡veis do modelo e avalie os resultados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "",
    "text": "DicaObjetivos\n\n\n\nNeste tutorial, vamos implementar o MÃ©todo dos MÃ­nimos Quadrados (MMQ) em Python para ajustar um modelo de regressÃ£o linear simples.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\) e \\(\\beta_1\\) da equaÃ§Ã£o \\(\\hat{y} = \\beta_0 + \\beta_1 x\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#introduÃ§Ã£o",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#introduÃ§Ã£o",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "",
    "text": "DicaObjetivos\n\n\n\nNeste tutorial, vamos implementar o MÃ©todo dos MÃ­nimos Quadrados (MMQ) em Python para ajustar um modelo de regressÃ£o linear simples.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\) e \\(\\beta_1\\) da equaÃ§Ã£o \\(\\hat{y} = \\beta_0 + \\beta_1 x\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#importando-as-bibliotecas",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#importando-as-bibliotecas",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "2 ğŸ› ï¸ Importando as Bibliotecas",
    "text": "2 ğŸ› ï¸ Importando as Bibliotecas\nPrimeiro, vamos importar as bibliotecas que usaremos:\n\nimport matplotlib.pyplot as plt  # Para criaÃ§Ã£o e manipulaÃ§Ã£o grÃ¡fica\nimport numpy as np           # Para operaÃ§Ãµes matemÃ¡ticas e matriciais\n\nğŸ’¡ Dica: No Google Colab, essas bibliotecas jÃ¡ vÃªm instaladas!"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#inserindo-os-dados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#inserindo-os-dados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "3 ğŸ“Š Inserindo os Dados",
    "text": "3 ğŸ“Š Inserindo os Dados\nVamos trabalhar um exemplo simples em que \\(x\\) e \\(y\\) sÃ£o inseridos como listas em Python:\n\n# Nossos dados de exemplo\nx = [0, 1, 2, 3, 4]  # VariÃ¡vel independente (preditora)\ny = [0, 1, 1, 4, 4]  # VariÃ¡vel dependente (resposta)\n\nCaso deseje visualizar se os objetos x e y foram criados corretamente podemos utilizar a funÃ§Ã£o print().\n\nprint(\"Valores de x:\", x)\nprint(\"Valores de y:\", y)\n\nValores de x: [0, 1, 2, 3, 4]\nValores de y: [0, 1, 1, 4, 4]"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-os-dados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-os-dados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "4 ğŸ“ˆ Visualizando os Dados",
    "text": "4 ğŸ“ˆ Visualizando os Dados\nAntes de ajustar o modelo, vamos visualizar nossos dados em um grÃ¡figo de dispersÃ£o utilizando a funÃ§Ã£o scatter() da biblioteca Matplotlib:\n\n# Criando o grÃ¡fico de dispersÃ£o\nplt.figure(figsize=(8, 6))\nplt.scatter(x, y, color = '#0072B2', s=120, label='Dados observados')\n\n# Configurando o layout grÃ¡fico\nplt.title('GrÃ¡fico de DispersÃ£o dos Dados', fontsize=14, fontweight='bold')\nplt.xlabel('VariÃ¡vel X', fontsize=12)\nplt.ylabel('VariÃ¡vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nğŸ“ ObservaÃ§Ã£o: O grÃ¡fico sugere uma relaÃ§Ã£o linear entre as variÃ¡veis, o que justifica o uso da regressÃ£o linear simples, que iremos ajustra por meio do MMQ."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#implementando-o-mmq---passo-a-passo",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#implementando-o-mmq---passo-a-passo",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "5 ğŸ§® Implementando o MMQ - Passo a Passo",
    "text": "5 ğŸ§® Implementando o MMQ - Passo a Passo\n\n5.1 Criando os Vetores Base\nLembre-se da teoria: inicialmente precisamos caracterizar os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{y}\\):\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# NÃºmero de observaÃ§Ãµes\nn = len(x)\n\n# Vetor f0: vetor de 1's (para o intercepto Î²â‚€)\nf0 = [1] * n  # Cria uma lista com n elementos iguais a 1\n\n# Vetor f1: nossos valores de x (para o coeficiente Î²â‚)\nf1 = x.copy()  # Copia os valores de x para um novo objeto denominado f1\n\nVisualizando os vetores \\(\\vec{f}_0\\) e \\(\\vec{f}_1\\).\n\nprint(\"Vetor f0 (intercepto):\", f0)\nprint(\"Vetor f1 (coeficiente):\", f1)\n\nVetor f0 (intercepto): [1, 1, 1, 1, 1]\nVetor f1 (coeficiente): [0, 1, 2, 3, 4]\n\n\n\n\n5.2 Construindo as Matrizes X e Y\nAgora vamos montar as matrizes do sistema:\n\\[X = \\begin{bmatrix} \\vec{f}_0 & \\vec{f}_1 \\end{bmatrix} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\quad \\text{e} \\quad Y = \\begin{bmatrix} \\vec{y} \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# Matriz X: combinando f0 e f1 em colunas\nX = np.column_stack((f0, f1))\n\n# Matriz Y: transformando y em matriz com n linhas e 1 coluna \nY = np.array(y).reshape(n, 1)\n\nVisualizando as matrizes \\(X\\) e \\(Y\\).\n\nprint(\"Matriz X:\")\nprint(X)\nprint(\"\\nMatriz Y:\")\nprint(Y)\nprint(f\"\\nDimensÃµes - X: {X.shape}, Y: {Y.shape}\")\n\nMatriz X:\n[[1 0]\n [1 1]\n [1 2]\n [1 3]\n [1 4]]\n\nMatriz Y:\n[[0]\n [1]\n [1]\n [4]\n [4]]\n\nDimensÃµes - X: (5, 2), Y: (5, 1)\n\n\nNote agora que a matriz \\(X\\) tem 5 linhas e 2 colunas, enquanto a matriz \\(Y\\) tem 5 linhas e 1 colunas.\n\n\n5.3 Resolvendo o Sistema Normal\nAgora vamos calcular os coeficientes usando as operaÃ§Ãµes matriciais: \\[B = (X^T X)^{-1} X^T Y\\]\n\n# Calculando X transposta vezes X\nXTX = np.dot(X.T, X)  # X.T Ã© a transposta de X\n# Calculando X transposta vezes Y\nXTY = np.dot(X.T, Y)\n# Calculando a matriz inversa (X^T X)^(-1)\nXTX_inv = np.linalg.inv(XTX)  # Inversa de X^T X\n# Coeficientes de regressÃ£o\nB = np.dot(XTX_inv, XTY)\n\nVisualizando os objetos\n\n# Calculando X transposta vezes X\nprint(\"X^T X:\")\nprint(XTX)\n\nprint(\"\\nX^T Y:\")\nprint(XTY)\n\nprint(\"\\nB:\")\nprint(B)\n\nX^T X:\n[[ 5 10]\n [10 30]]\n\nX^T Y:\n[[10]\n [31]]\n\nB:\n[[-0.2]\n [ 1.1]]\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nA funÃ§Ã£o Â´np.dot()Â´ em Python pode ser substituÃ­da pelo sÃ­mbolo @. Teste os cÃ³digos abaixo e verifique que os resultados coincidem:\n\n\nprint(\"Usando np.dot()\")\nprint(np.dot(X.T, X))\n\nUsando np.dot()\n[[ 5 10]\n [10 30]]\n\n\n\nprint(\"Usando '@'\")\nprint(X.T @ X)\n\nUsando '@'\n[[ 5 10]\n [10 30]]\n\n\n\nOs elementos internos de uma matriz podem ser acessados destacando suas posiÃ§Ãµes na linha e coluna. Considere a matrtiz B. O coeficiente \\(\\beta_0\\) pode ser acessado na linha 1 e coluna 1, enquanto \\(\\beta_1\\) pode ser acessado na linha 2 e coluna 1.\n\n\nprint(B[0,0]) # Beta 0\n\n-0.1999999999999993\n\n\n\nprint(B[1,0]) # Beta 1\n\n1.1\n\n\n\n\n\n\n5.4 Obtendo os Valores Ajustados de y\nTendo obtido os coeficientes de regressÃ£o, os valores ajustados de y (\\(\\hat{y}\\)) podem ser obtido pela multiplicaÃ§Ã£o matricial:\n\\[F = X B = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\begin{bmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{bmatrix}\\]\nObs.: denominamos \\(F\\) a matriz de valores ajustados de \\(y\\).\n\n# Valores ajustados (preditos)\nF = np.dot(X, B)\n\n\n# Valores ajustados (preditos)\nprint(F)\n\n[[-0.2]\n [ 0.9]\n [ 2. ]\n [ 3.1]\n [ 4.2]]\n\n\n\n\n5.5 Avaliando a Qualidade do Ajuste\n\n5.5.1 Calculando a Soma dos Quadrados dos ResÃ­duos (\\(SQ_{res}\\))\n\\(SQ_{res}\\) pode ser obtida pela multiplicaÃ§Ã£o matricial:\n\\[SQ_{res} = \\boldsymbol{e}^T \\boldsymbol{e}\\]\nEm que \\(\\boldsymbol{e}\\) Ã© a matriz coluna dos resÃ­duos obtida pela diferenÃ§a entre os valores observados e ajustados de \\(y\\):\n\\[\\boldsymbol{e} = Y - F = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\]\n\n# ResÃ­duos: diferenÃ§a entre valores observados e ajustados\ne = Y - F\n\n# Soma dos Quadrados dos ResÃ­duos\nSQres = np.dot(e.T, e)[0, 0]\n\n\n\n5.5.2 Calculando a Soma dos Quadrados Totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser obtida pela multiplicaÃ§Ã£o matricial:\n\\[SQ_{tot} = \\boldsymbol{D}^T \\boldsymbol{D}\\]\nEm que \\(\\boldsymbol{D}\\) Ã© a matriz coluna dos desvios da mÃ©dis obtida pela diferenÃ§a entre os valores observados de \\(y\\) e a mÃ©dia de \\(\\overline{y}\\):\n\\[\\boldsymbol{D} = Y - \\overline{Y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\overline{y} \\\\ \\overline{y} \\\\ \\vdots \\\\ \\overline{y} \\end{bmatrix} = \\begin{bmatrix} d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_n \\end{bmatrix}\\]\n\n# Soma dos Quadrados Total\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = np.dot(D.T, D)[0, 0]\n\n\n\n5.5.3 Calculando o coeficiente de determinaÃ§Ã£o \\(R^2\\):\nO \\(R^2\\) Ã© dado pela expressÃ£o:\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]\n\n# Coeficiente de DeterminaÃ§Ã£o RÂ²\nR2 = 1 - (SQres / SQtot)\n\n\nVisualizando os resultados:\n\nprint(\"ğŸ“Š Medidas de Qualidade do Ajuste:\")\nprint(f\"Soma dos Quadrados dos ResÃ­duos (SQres): {SQres:.4f}\")\nprint(f\"Soma dos Quadrados Total (SQtot): {SQtot:.4f}\")\nprint(f\"Coeficiente de DeterminaÃ§Ã£o (RÂ²): {R2:.4f}\")\nprint(f\"Porcentagem da variaÃ§Ã£o explicada: {R2*100:.2f}%\")\n\nğŸ“Š Medidas de Qualidade do Ajuste:\nSoma dos Quadrados dos ResÃ­duos (SQres): 1.9000\nSoma dos Quadrados Total (SQtot): 14.0000\nCoeficiente de DeterminaÃ§Ã£o (RÂ²): 0.8643\nPorcentagem da variaÃ§Ã£o explicada: 86.43%\n\n\nğŸ“ InterpretaÃ§Ã£o do \\(R^2\\):\n\nVaria de 0 a 1\nQuanto mais prÃ³ximo de 1, melhor o ajuste\nRepresenta a proporÃ§Ã£o da variaÃ§Ã£o em \\(y\\) explicada pelo modelo"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-o-resultado-final",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-o-resultado-final",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "6 ğŸ“Š Visualizando o Resultado Final",
    "text": "6 ğŸ“Š Visualizando o Resultado Final\nVamos plotar os dados originais junto com a reta ajustada:\n\n# Criando o grÃ¡fico final\nplt.figure(figsize=(8, 6))\n\n# Pontos observados\nplt.scatter(x, y, \n            color = '#0072B2', s=120,\n            label=f'Dados observados (n={n})')\n\n# Valores ajustados\nplt.scatter(x, F[:,0],\n            color='#000000', marker='*', s=120, \n            label='Valores ajustados')\n\n# Reta ajustada\nplt.plot(x, F[:,0], color='#D55E00', \n         label=fr'Reta de regressÃ£o: $\\hat{{y}} = {B[0,0]:.3f} + {B[1,0]:.3f}x$')\n\n# ConfiguraÃ§Ãµes do grÃ¡fico\nplt.title(f'RegressÃ£o Linear Simples - MMQ\\nRÂ² = {R2:.4f}', \n          fontsize=14, fontweight='bold')\nplt.xlabel('VariÃ¡vel X', fontsize=12)\nplt.ylabel('VariÃ¡vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-dos-resultados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-dos-resultados",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "7 ğŸ¯ Resumo dos Resultados",
    "text": "7 ğŸ¯ Resumo dos Resultados\n\nprint(\"=\"*50)\nprint(\"         RESUMO DA REGRESSÃƒO LINEAR\")\nprint(\"=\"*50)\nprint(f\"EquaÃ§Ã£o ajustada: y = {B[0,0]:.4f} + {B[1,0]:.4f}x\")\nprint(f\"Coeficiente de determinaÃ§Ã£o (RÂ²): {R2:.4f}\")\nprint(f\"Porcentagem da variaÃ§Ã£o explicada: {R2*100:.2f}%\")\nprint(\"=\"*50)\n\n==================================================\n         RESUMO DA REGRESSÃƒO LINEAR\n==================================================\nEquaÃ§Ã£o ajustada: y = -0.2000 + 1.1000x\nCoeficiente de determinaÃ§Ã£o (RÂ²): 0.8643\nPorcentagem da variaÃ§Ã£o explicada: 86.43%\n=================================================="
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-do-cÃ³digo",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-do-cÃ³digo",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "8 ğŸ§¾ Resumo do CÃ³digo",
    "text": "8 ğŸ§¾ Resumo do CÃ³digo\n\nInserÃ§Ã£o dos Dados\n\n\nx = [0, 1, 2, 3, 4]\ny = [0, 1, 1, 4, 4]\n\n\nDefiniÃ§Ã£o das matrizes do sistema\n\n\nn = len(x)\nf0 = [1] * n\nf1 = x.copy()\n\nX = np.column_stack((f0, f1))\nY = np.array(y).reshape(n, 1)\n\n\nCÃ¡lculo dos coeficientes\n\n\nXTX = X.T @ X\nXTY = X.T @ Y\nXTX_inv = np.linalg.inv(XTX)\nB = XTX_inv @ XTY\n\n\nQualidade do ajuste\n\n\nF = X @ B\ne = Y - F\nSQres = (e.T @ e)[0, 0]\n\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\nR2 = 1 - (SQres / SQtot)"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#exercÃ­cio-prÃ¡tico",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#exercÃ­cio-prÃ¡tico",
    "title": "MÃ©todo dos MÃ­nimos Quadrados na RegressÃ£o Linear Simples",
    "section": "9 ğŸš€ ExercÃ­cio PrÃ¡tico",
    "text": "9 ğŸš€ ExercÃ­cio PrÃ¡tico\nImplemente o MMQ com novos dados:\n\n# Experimente com estes dados:\nx_novo = [1, 2, 3, 4, 5, 6]\ny_novo = [2, 4, 5, 4, 5, 7]\n\n# Dica: vocÃª pode copiar e adaptar o cÃ³digo acima!"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html",
    "href": "content/visualizacao-dados/graficos-r.html",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "",
    "text": "A visualizaÃ§Ã£o grÃ¡fica consiste em representar visualmente os padrÃµes de distribuiÃ§Ã£o de uma variÃ¡vel ou a associaÃ§Ã£o entre duas ou mais variÃ¡veis. Os tipos de grÃ¡ficos utilizados dependem do tipo de variÃ¡vel (categÃ³rica ou numÃ©rica) e do nÃºmero de variÃ¡veis envolvidas. Temos grÃ¡ficos univariados para uma Ãºnica variÃ¡vel, grÃ¡ficos bivariados para associaÃ§Ã£o entre duas variÃ¡veis e grÃ¡ficos multivariados para mais de duas variÃ¡veis.\nAs funÃ§Ãµes grÃ¡ficas discutidas nesta seÃ§Ã£o estÃ£o disponÃ­veis no pacote graphics, que vem instalado por padrÃ£o no R, nÃ£o sendo necessÃ¡rio instalar pacotes adicionais. Essas funÃ§Ãµes oferecem elevado controle sobre elementos grÃ¡ficos (fontes, tamanhos, cores), mas podem ser complexas para criar figuras elaboradas. Apesar de muitas nomenclaturas serem compatÃ­veis para o controle de eixos, tÃ­tulos e tamanhos de fonte, os argumentos nem sempre sÃ£o coesos entre os diferentes tipos de grÃ¡ficos, o que pode dificultar o aprendizado. No entanto, essas funÃ§Ãµes fornecem uma base sÃ³lida sobre a estrutura grÃ¡fica no R, permitindo resolver rapidamente muitas situaÃ§Ãµes do dia a dia da anÃ¡lise exploratÃ³ria."
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#doubs-river-dataset",
    "href": "content/visualizacao-dados/graficos-r.html#doubs-river-dataset",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "1 Doubs river dataset",
    "text": "1 Doubs river dataset\nPara demonstrar algumas ferramentas grÃ¡ficas, serÃ¡ utilizado o conjunto de dados Doubs River data, disponÃ­vel no pacote ade4 (Dray, Dufour, e Thioulouse 2015). Esse conjunto de dados foi apresentado na seÃ§Ã£o anterior sobre manipulaÃ§Ã£o de data frames, onde foi importado o arquivo dbenv.csv. Agora, serÃ¡ usado o conjunto de dados completo.\nO conjunto de dados do Rio Doubs (Verneaux 1973) consiste de amostras sequenciais da cabeceira Ã  foz do rio, em condiÃ§Ãµes que variam de Ã¡guas bem oxigenadas e oligotrÃ³ficas a Ã¡guas eutrÃ³ficas e desprovidas de oxigÃªnio. O conjunto de dados Ã© uma lista com quatro data frames:\n\n$env: data frame com variÃ¡veis ambientais relacionadas Ã  hidrologia, geomorfologia e quÃ­mica do\n$fish: data frame com abundÃ¢ncias das espÃ©cies de peixes capturadas nos locais de amostragem.\n$xy: data frame com coordenadas geogrÃ¡ficas de cada ponto de amostragem.\n$species: data frame com os nomes cientÃ­ficos, populares em francÃªs e inglÃªs, e cÃ³digos abreviados das espÃ©cies capturadas.\n\n\n1.1 Instalando o pacote ade4 e carregando os dados\n\nInstale o pacote ade4:\n\n\ninstall.packages(\"ade4\")\n\n\nCarregue o pacote:\n\n\nlibrary(ade4)\n\n\nHabilite o conjunto de dados doubs\n\n\ndata(doubs)\n\n\nConfira se consiste de uma lista:\n\n\nclass(doubs)\nstr(doubs)\n\n\nLeia a descriÃ§Ã£o do conjunto de dados para conchecÃª-lo melhor.\n\n\n?doubs\n\n\nExtraia os dados ambientais para um novo data.frame:\n\n\nambiente &lt;- doubs$env\n\n\nAdicione a este data frame uma nova variÃ¡vel categÃ³rica denominada secao com quatro nÃ­veis (Borcard, Gillet, e Legendre 2018).\n\n\nambiente$secao &lt;- c(rep(\"SeÃ§Ã£o 1\", 16), rep(\"SeÃ§Ã£o 4\", 14))\nambiente$secao[c(5,9,17)] &lt;- \"SeÃ§Ã£o 2\"\nambiente$secao[23:25] &lt;- \"SeÃ§Ã£o 3\"\nambiente$secao &lt;- factor(ambiente$secao)\n\n\nAdicione outra variÃ¡vel categÃ³rica, indicando trÃªs nÃ­veis de saturaÃ§Ã£o de oxigÃªnio em cada ponto.\n\n\nambiente$saturacao &lt;- cut(ambiente$oxy, breaks = c(0, 80, 109, 124), \n           labels = c(\"Pobre\", \"MÃ©dio\", \"Saturado\"))\nhead(ambiente, 10)\n\n   dfs alt   slo  flo pH har pho nit amm oxy bdo   secao saturacao\n1    3 934 6.176   84 79  45   1  20   0 122  27 SeÃ§Ã£o 1  Saturado\n2   22 932 3.434  100 80  40   2  20  10 103  19 SeÃ§Ã£o 1     MÃ©dio\n3  102 914 3.638  180 83  52   5  22   5 105  35 SeÃ§Ã£o 1     MÃ©dio\n4  185 854 3.497  253 80  72  10  21   0 110  13 SeÃ§Ã£o 1  Saturado\n5  215 849 3.178  264 81  84  38  52  20  80  62 SeÃ§Ã£o 2     Pobre\n6  324 846 3.497  286 79  60  20  15   0 102  53 SeÃ§Ã£o 1     MÃ©dio\n7  268 841 4.205  400 81  88   7  15   0 111  22 SeÃ§Ã£o 1  Saturado\n8  491 792 3.258  130 81  94  20  41  12  70  81 SeÃ§Ã£o 1     Pobre\n9  705 752 2.565  480 80  90  30  82  12  72  52 SeÃ§Ã£o 2     Pobre\n10 990 617 4.605 1000 77  82   6  75   1 100  43 SeÃ§Ã£o 1     MÃ©dio"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#descrevendo-os-padrÃµes-de-uma-variÃ¡vel",
    "href": "content/visualizacao-dados/graficos-r.html#descrevendo-os-padrÃµes-de-uma-variÃ¡vel",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "2 Descrevendo os padrÃµes de uma variÃ¡vel",
    "text": "2 Descrevendo os padrÃµes de uma variÃ¡vel\n\n2.1 GrÃ¡fico de barras\nUm grÃ¡fico de barras Ã© utilizado para verificar a contagem de cada nÃ­vel de uma variÃ¡vel categÃ³rica. FaÃ§a um grÃ¡fico de barras para a variÃ¡vel saturacao.\nInicialmente, monte uma tabela de frequencia:\n\ntab1 &lt;- table(ambiente$saturacao)\ntab1\n\n\n   Pobre    MÃ©dio Saturado \n       8       14        8 \n\n\nEm seguida represente-a em um grÃ¡fico de barras:\n\nbarplot(tab1)\n\n\n\n\n\n\n\n\nAdicionando elementos de formataÃ§Ã£o grÃ¡fica:\n\nbarplot(tab1,\n        main = \"ConcentraÃ§Ã£o de oxigÃªnio\",\n        ylab = \"FrequÃªncia\",\n        ylim = c(0, 18), col = \"black\")\nbox()\n\n\n\n\n\n\n\n\n\n\n2.2 Histograma\nUm histograma descreve o padrÃ£o de distribuiÃ§Ã£o de uma variÃ¡vel quantitativa a partir da divisÃ£o desta variÃ¡vel em intervalos de classe.\nO histograma abaixo para a coluna oxy expressa a saturaÃ§Ã£o de oxigÃªnio (mg/l \\(\\times\\) 10).\n\nhist(ambiente$oxy)\n\n\n\n\n\n\n\n\n\n\nNo histograma, o intervalo de classes determina o formato exato do grÃ¡fico. No exemplo acima, a escolha foi feita automaticamente. No entanto, Ã© possÃ­vel definir o intervalo desejado com o argumento breaks:\n\nclasses &lt;- seq(40, 140, by = 20)\nhist(ambiente$oxy, breaks = classes)\n\n\n\n\n\n\n\n\nA divisÃ£o foi feita em intervalos de tamanho 20, iniciando em 40 e terminando em 140. A escolha deve ser a que evidencie da melhor forma possÃ­vel o padrÃ£o de distribuiÃ§Ã£o da variÃ¡vel.\n\n\n2.3 Boxplot\nBoxplots oferecem um resumo grÃ¡fico da distribuiÃ§Ã£o de uma variÃ¡vel quantitativa. Abaixo estÃ¡ representada a variÃ¡vel oxy.\n\nboxplot(ambiente$oxy)\n\n\n\n\n\n\n\n\nA linha do meio representa a mediana da variÃ¡vel, enquanto os limites das caixas representam o \\(1^o\\) e \\(3^o\\) quartis e as linhas externas representam os pontos mÃ­nimo e mÃ¡ximo. Estes limites podem ser obtidos com o comando:\n\nquantile(ambiente$oxy, probs = c(0, 0.25, 0.5, 0.75, 1))\n\n    0%    25%    50%    75%   100% \n 41.00  80.25 102.00 109.00 124.00"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#associaÃ§Ã£o-entre-duas-variÃ¡veis",
    "href": "content/visualizacao-dados/graficos-r.html#associaÃ§Ã£o-entre-duas-variÃ¡veis",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "3 AssociaÃ§Ã£o entre duas variÃ¡veis",
    "text": "3 AssociaÃ§Ã£o entre duas variÃ¡veis\n\n3.1 GrÃ¡fico de barras\nUm grÃ¡fico de barras pode combinar duas variÃ¡veis categÃ³ricas como secao e saturacao. Inicialmente, monta-se uma tabela de frequÃªncia, combinandos as contagens para cada nÃ­vel das variÃ¡veis.\n\ntab2 &lt;- table(ambiente[,c(\"secao\", \"saturacao\")])\ntab2\n\n         saturacao\nsecao     Pobre MÃ©dio Saturado\n  SeÃ§Ã£o 1     1     5        8\n  SeÃ§Ã£o 2     2     1        0\n  SeÃ§Ã£o 3     3     0        0\n  SeÃ§Ã£o 4     2     8        0\n\n\nNeste caso, Ã© possÃ­vel representar estas contagens de diferentes formas:\n\nlayout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE))\nbarplot(tab2, legend = TRUE)\nbarplot(tab2, legend = TRUE, beside = TRUE)\nbarplot(t(tab2), legend = TRUE)\nbarplot(t(tab2), legend = TRUE, beside = TRUE)\n\n\n\n\n\n\n\n\n\nA funÃ§Ã£o layout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE)) organiza o espaÃ§o grÃ¡fico em um formato matricial com 2 linhas por 2 colunas, permitindo a inserÃ§Ã£o de 4 figuras. O argumento byrow = TRUE define que as figuras serÃ£o adicionais linha-a-linha.\nA funÃ§Ã£o t() transpÃµe a tabela, o que consequentemente altera a referÃªncia da figura. No primeiro caso, a concentraÃ§Ã£o de oxigÃªnio Ã© a variÃ¡vel principal e, no segundo caso, sÃ£o as seÃ§Ãµes.\nO argumento beside = TRUE faz com que as barras apareÃ§am lado-a-lado e beside = FALSE resulta em cada barra representa a variÃ¡vel principal subdividida nos nÃ­veis da variÃ¡vel secubdÃ¡ria.\nEm todos os grÃ¡ficos foi adicionada uma legenda.\n\nAdiocionando elementos de formataÃ§Ã£o:\n\ncores &lt;- 1:4\nlimy1 &lt;- c(0, 17)\nlimy2 &lt;- c(0, 16)\nlegenda &lt;- list(cex = 0.8)\n\nlayout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE))\nbarplot(tab2, legend = TRUE, col = cores, ylim = limy1, \n        args.legend = legenda)\nbox()\nbarplot(tab2, legend = TRUE, beside = TRUE, col = cores, \n        ylim = limy1, args.legend = legenda)\nbox()\nbarplot(t(tab2), legend = TRUE, col = cores, ylim = limy2, \n        args.legend = legenda)\nbox()\nbarplot(t(tab2), legend = TRUE, beside = TRUE, col = cores, \n        ylim = limy2, args.legend = legenda)\nbox()\n\n\n\n\n\n\n\n\n\n\n3.2 Boxplot\nO boxplot tambÃ©m pode ser utilizado para representar uma variÃ¡vel \\(X_1\\) para diferentes nÃ­veis de uma variÃ¡vel categÃ³rica \\(X_2\\), por exemplo oxy para cada nÃ­vel de secao.\n\nboxplot(oxy ~ secao, data = ambiente)\n\n\n\n\n\n\n\n\nOs pontos associados Ã  SeÃ§Ã£o 1 tÃªm maiores concentraÃ§Ãµes de oxigÃªnio (mediana = 110.5) e que os pontos associados Ã  SeÃ§Ã£o 3 (mediana = 52).\nNa funÃ§Ã£o boxplot foi utilizada a representaÃ§Ã£o de fÃ³rmula no R (y ~ x) em que a variÃ¡vel no eixo y depende de x. Esta notaÃ§Ã£o Ã© amplamente utilizada em modelos estatÃ­sticos (ex. regressÃ£o linear, e anÃ¡lise de variÃ¢ncia, etc.).\n\nAo invÃ©s de acessar a variÃ¡vel por ambiente$oxy, utilizou-se o nome da coluna (oxy) e adicionou-se o argumento data = ambiente para indicar em qual data frame a funÃ§Ã£o irÃ¡ buscar as variÃ¡veis.\n\n\n\n3.3 GrÃ¡fico de dispersÃ£o\nUm grÃ¡fico de dispersÃ£o mostra a associaÃ§Ã£o entre duas variÃ¡veis quantitativas, por exemplo, concentraÃ§Ã£o de nitrato (mg/l \\(\\times\\) 100) e distÃ¢ncia da foz (km \\(\\times\\) 10). Neste caso a concentraÃ§Ã£o de nitrato serÃ¡ representada como dependente da distÃ¢ncia da foz.\n\nplot(nit ~ dfs, data = ambiente)\n\n\n\n\n\n\n\n\nOs resultados expressam uma relaÃ§Ã£o em que a concentraÃ§Ã£o de nutrientes aumenta Ã  medida que distancia-se da foz.\nAdicionando formataÃ§Ã£o grÃ¡fica: nomes dos eixos (argumentos xlab e ylab) e tipo de ponto (argumento pch).\n\nplot(nit ~ dfs, data = ambiente,\n     xlab = bquote(\"VazÃ£o mÃ©dia mÃ­nima (m\" ^3/\"seg x 100)\"),\n     ylab = bquote(\"ConcentraÃ§Ã£o de Nitrato (mg\"/\"l x 100)\"),\n     pch = 19\n)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#compreendendo-o-ambiente-por-meio-de-suas-variÃ¡veis",
    "href": "content/visualizacao-dados/graficos-r.html#compreendendo-o-ambiente-por-meio-de-suas-variÃ¡veis",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "4 Compreendendo o ambiente por meio de suas variÃ¡veis",
    "text": "4 Compreendendo o ambiente por meio de suas variÃ¡veis\nUm dos objetivo da descriÃ§Ã£o grÃ¡fica Ã© representar o sistema por meio das variÃ¡veis escolhidas para quantificÃ¡-lo. AlÃ©m dos grÃ¡ficos apresentados anteriormente, hÃ¡ outras formas de incorporar essas variÃ¡veis em uma figura, utilizando cores, sÃ­mbolos e textos no ambiente grÃ¡fico. Nesta seÃ§Ã£o, serÃ£o exploradas algumas possibilidades.\nOs pontos de amostragem foram obtidos ao longo do gradiente cabeceira-foz. As informaÃ§Ãµes incluem as coordenadas geogrÃ¡ficas desses pontos (no data frame $xy). A sequÃªncia dos pontos segue uma ordem crescente de distÃ¢ncia da foz. Inicialmente, serÃ£o plotadas as coordenadas geogrÃ¡ficas de todos os pontos utilizando um grÃ¡fico de linhas.\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\n\n\n\n\n\n\n\n\nCompare a figura com o desenho do rio Doubs.\n\n\n\n\n\n\nNota\n\n\n\nUtilizamos a definiÃ§Ã£o de cores em HEXADECIMAL. VocÃª pode fazer o mesmo, escolhendo a cor desejada aqui: hex color picker.\n\n\nRepresentando os pontos de amostragem.\n\npontos_extremos &lt;- doubs$xy[which(doubs$env$dfs == min(doubs$env$dfs) | \n                                      doubs$env$dfs == max(doubs$env$dfs)),]\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\ntext(x = pontos_extremos$x, \n       y = pontos_extremos$y,\n       labels = c(\"Cabeceira\", \"Foz\"))\n\n\n\n\n\n\n\n\nRepresentando as \\(4\\) seÃ§Ãµes do rio.\n\nsecao_cor &lt;- as.numeric(ambiente$secao)\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\npoints(x = doubs$xy$x, y = doubs$xy$y, pch = 21, \n       bg = secao_cor, cex = 3)\nlegend(x = \"bottomright\", col = 1:4, \n       legend = levels(ambiente$secao), bty = \"n\", pch = 19)\n\n\n\n\n\n\n\n\nRepresentando a concentraÃ§Ã£o de amÃ´nia (amm).\n\nsecao_cor &lt;- as.numeric(ambiente$secao) + 1\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\npoints(x = doubs$xy$x, y = doubs$xy$y, pch = 21, \n       bg = secao_cor, cex = 4)\nlegend(x = \"bottomright\", col = 1:4, \n       legend = levels(ambiente$secao), bty = \"n\", pch = 19)\ntext(x = doubs$xy$x, y = doubs$xy$y, labels = doubs$env$amm, \n     cex = 0.8, font = 2)\ntext(x = 55, y = 220, labels = \"ConcentraÃ§Ã£o de amÃ´nia\")\ntext(x = 25, y = 120, label = \"Foz\")\ntext(x = 60, y = 20, label = \"Cabeceira\")\n\n\n\n\n\n\n\n\nA figura nos informa sobre a distribuiÃ§Ã£o espacial da concentraÃ§Ã£o de amÃ´nia entre as seÃ§Ãµes. Verifica-se que a concentraÃ§Ã£o de amÃ´nia Ã© mais nas seÃ§Ãµes \\(4\\) e \\(3\\).\n\n\n\n\n\n\nNota\n\n\n\nUtilizamos uma sÃ©rie de funÃ§Ãµes novas: text, points, legend. Para entender como elas funcionam, rode os comandos acima linha por linha e veja como cada funÃ§Ã£o adiciona uma informaÃ§Ã£o adicional Ã  figura."
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#outros-argumentos-de-formataÃ§Ã£o-grÃ¡fica",
    "href": "content/visualizacao-dados/graficos-r.html#outros-argumentos-de-formataÃ§Ã£o-grÃ¡fica",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "5 Outros argumentos de formataÃ§Ã£o grÃ¡fica",
    "text": "5 Outros argumentos de formataÃ§Ã£o grÃ¡fica\nA capacidade de formataÃ§Ã£o grÃ¡fica no R Ã© extensa e qualquer tentativa de resumÃ­-las seria incompleta. Abaixo exemplificam alguns argumentos comuns de formataÃ§Ã£o grÃ¡fica.\n\nplot(nit ~ dfs, data = ambiente)\nplot(nit ~ dfs, data = ambiente, pch = 2)\nplot(nit ~ dfs, data = ambiente, pch = 19)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\")\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\",\n     xlab = \"Nitrato\", ylab = \"VazÃ£o\")\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\", \n     xlab = \"Nitrato\", ylab = \"VazÃ£o\", font.lab = 3)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2, lwd = 3)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2, lwd = 3, col = 2)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#figuras-compostas",
    "href": "content/visualizacao-dados/graficos-r.html#figuras-compostas",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "6 Figuras compostas",
    "text": "6 Figuras compostas\nUma das formas mais simples para inserir mÃºltiplas figuras no mesmo espaÃ§o grÃ¡fico Ã© por meio da funÃ§Ã£o layout. Abaixo, serÃµ inseridos \\(6\\) grÃ¡ficos em uma espaÃ§o de \\(3\\) colunas por \\(2\\) linhas.\n\nlayout(mat = matrix(1:6, nrow = 3, ncol = 2))\nplot(alt ~ dfs, data = ambiente)\nplot(amm ~ alt, data = ambiente)\nplot(nit ~ alt, data = ambiente)\nplot(pH ~ alt, data = ambiente)\nplot(bdo ~ alt, data = ambiente)\nplot(oxy ~ alt, data = ambiente)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#exportando-figuras-funÃ§Ãµes-png-tiff-jpeg-e-bmp",
    "href": "content/visualizacao-dados/graficos-r.html#exportando-figuras-funÃ§Ãµes-png-tiff-jpeg-e-bmp",
    "title": "(BÃ¡sico da) VisualizaÃ§Ã£o grÃ¡fica",
    "section": "7 Exportando figuras: funÃ§Ãµes png, tiff, jpeg e bmp",
    "text": "7 Exportando figuras: funÃ§Ãµes png, tiff, jpeg e bmp\nÃ‰ possÃ­vel exportar figuras em diversos formatos e resoluÃ§Ãµes. A funÃ§Ã£o png Ã© exemplificada abaixo. As funÃ§Ãµes para exportar em outros formatos sÃ£o similares.\n\npng(filename = \"Exemplo_figura.png\",\n    width = 15, height = 15, units = \"cm\", \n    pointsize = 10, bg = \"white\", res = 800)\n\nplot(alt ~ dfs, data = ambiente, pch = 19, type = \"b\", \n     xlab = \"VazÃ£o\", ylab = \"ElevaÃ§Ã£o\")\n\ndev.off()\n\nA figura foi salva do diretÃ³rio atual de sua seÃ§Ã£o de trabalho. VocÃª pode conferir este diretÃ³rio com o comando:\n\ngetwd()\n\nExperimente alterar os argumentos width, height, pointsize, units (com \"px\", \"in\", \"cm\" ou \"mm\") e res.\nAs capacidades grÃ¡ficas no R incluem ainda muitos outros argumentos. Alguns deles sÃ£o: cores (col), tipos da fonte (font), tamanhos de sÃ­mbolos (cex), dos labels (cex.lab), dos rÃ³tulos dos eixos (cex.axis), tÃ­tulo (main), etc. Pode-se ainda inserir legendas (funÃ§Ã£o legend) e textos (funÃ§Ã£o text). Veja o help de cada uma destas funÃ§Ãµes e a lista de argumentos possÃ­veis para o ambiente grÃ¡fico do R em ?par. Veja tambÃ©m uma demonstraÃ§Ã£o com demo(graphics), demo(image), demo(persp) e demo(plotmath).\nExistem diversos outros pacotes grÃ¡ficos alÃ©m do graphics:\n\nggplot2\nggvis\nLattice\nhighcharter\nLeaflet\nRColorBrewer\nPlotly\nsunburstR\nRGL\ndygraphs"
  },
  {
    "objectID": "content/fundamentos-probabilidade/combina-probabilidades.html",
    "href": "content/fundamentos-probabilidade/combina-probabilidades.html",
    "title": "Combinando as probabilidades de eventos",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(ggVennDiagram)"
  },
  {
    "objectID": "content/fundamentos-probabilidade/combina-probabilidades.html#eventos-complexos",
    "href": "content/fundamentos-probabilidade/combina-probabilidades.html#eventos-complexos",
    "title": "Combinando as probabilidades de eventos",
    "section": "1 Eventos complexos",
    "text": "1 Eventos complexos\nConsideremos a seguinte situaÃ§Ã£o: hÃ¡ dois tipos principais de estruturas nas quais um animal aquÃ¡tico pode procurar suas presas: folhas e galhos. As folhas podem conter entre 0 e 6 itens, enquanto os galhos podem conter entre 0 e 4 itens. Ao virar qualquer uma dessas estruturas, o predador consome todos os itens encontrados. Embora seja um exemplo altamente hipotÃ©tico, ele serve para ilustrar nossa discussÃ£o. A pergunta que nos interessa Ã©: ao virar uma dessas estruturas, de quantos itens o predador poderÃ¡ se alimentar?\nVejamos as possibilidades. Denotemos por \\(F\\) ou \\(G\\) o evento de encontrar, respectivamente, uma folha ou um galho, e por \\(0\\) a \\(n\\) o nÃºmero de itens presentes. O espaÃ§o amostral do experimento â€” virar uma estrutura e contar quantos itens hÃ¡ â€” Ã© dado por:\n\\[\\Omega = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6), (G0), (G1), (G2), (G3), (G4)}\\}.\\]\nNote que hÃ¡ \\(\\text{12}\\) eventos simples e mutuamente exclusivos.\nConsidere agora o evento \\(A\\): â€œvirar uma folhaâ€, que ocorre quando observamos F0 ou F1 ou F2 ou F3 ou F4 ou F5 ou F6. Em notaÃ§Ã£o de conjunto:\n\\[A = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6)}\\}.\\]\nO evento \\(A\\) Ã© um evento complexo, pois consiste na uniÃ£o de vÃ¡rios eventos simples. Ou seja, podemos dizer que \\(A\\) acontece se a estrutura virada for uma folha com \\(0\\) OU \\(1\\) OU \\(2\\) OU \\(3\\) OU \\(4\\) OU \\(5\\) OU \\(6\\) itens. A palavra OU indica que basta qualquer uma dessas possibilidades para o evento ser considerado realizado, o que significa que \\(A\\) pode ocorrer de 7 maneiras diferentes.\nAssim, podemos representar \\(A\\) pela expressÃ£o:\n\\[A = F0 \\cup F1 \\cup F2 \\cup F3 \\cup F4 \\cup F5 \\cup F6,\\]\nonde, o sÃ­mbolo \\(\\cap\\) Ã© sendo lido como OU.\n\n1.1 RepresentaÃ§Ã£o de eventos: diagrama de Venn\nUma forma de visualizar o espaÃ§o amostral e seus eventos Ã© por meio de diagramas de Venn. Para isso, vamos considerar tambÃ©m o evento \\(B\\): â€œencontrar mais de 3 itensâ€, que consiste em:\n\\[B = \\{\\text{(F3), (F4), (F5), (F6), (G3), (G4)}\\}.\\]\nObservando \\(A\\) e \\(B\\) em um Diagrama de Venn, temos:\n\n\n\n\n\n\n\n\n\nO evento \\(B\\) tambÃ©m Ã© um evento complexo que ocorre quando se encontra uma folha OU um galho que tenham 3 ou mais itens.\nObserve que as ocorrÃªncias \\((G0)\\), \\((G1)\\) e \\((G2)\\) nÃ£o pertencem a \\(A\\) nem a \\(B\\), embora faÃ§am parte do espaÃ§o amostral \\(\\Omega\\).\nConsidere agora o evento \\(C\\): â€œvirar uma folha com mais de 3 itensâ€. Ele pode ocorrer ao observar F3 ou F4 ou F5 ou F6. No diagrama de Venn, vemos que essas possibilidades constituem a intersecÃ§Ã£o de \\(A\\) e \\(B\\) representada por \\(\\cap\\). Portanto, podemos escrever \\(C\\) como:\n\\[C = A \\cap B.\\]\n\n\n1.2 Probabilidade de eventos complexos\nConsiderando o experimento virar uma estrutura e contar o nÃºmero de itens, qual seria a probabilidade de cada observaÃ§Ã£o? Para isso, lembremos que:\n\nO espaÃ§o amostral consiste em \\(N = \\text{12}\\) observaÃ§Ãµes.\nDefiniremos um modelo de probabilidade para cada uma dessas observaÃ§Ãµes.\n\nNeste tÃ³pico, vamos assumir um modelo de probabilidade uniforme, ou seja, cada observaÃ§Ã£o tem a mesma probabilidade \\(\\frac{1}{N}\\).\nDessa forma, a probabilidade do evento \\(A\\) ocorrer Ã© dada pelo nÃºmero de resultados favorÃ¡veis a \\(A\\) dividido pelo nÃºmero total de resultados no espaÃ§o amostral. Como \\(A\\) consiste de 7 observaÃ§Ãµes:\n\\[P(A) = \\frac{7}{12} = 0.58\\]\nNaturalmente, a probabilidade de \\(A\\) nÃ£o ocorrer Ã©:\n\\[P(\\overline{A}) = 1 - \\frac{7}{12} = 1 - 0.58 = 0.42\\]\nO sÃ­mbolo \\(\\overline{A}\\) representa todas as observaÃ§Ãµes que nÃ£o pertencem a \\(A\\).\nConsidere tambÃ©m a probabilidade de \\(B\\) que consiste de 6 observaÃ§Ãµes:\n\\[P(B) = \\frac{6}{12} = 0.5\\]\nVemos tambÃ©m que o evento \\(C = A \\cap B\\), consiste de 4 observaÃ§Ãµes e portanto:\n\\[P(C) = P(A \\cap B) = \\frac{4}{12} = 0.33\\]\n\n\n1.3 Probabilidade da uniÃ£o de eventos\nO evento \\(A \\cup B\\) consiste em todas as observaÃ§Ãµes que estejam em \\(A\\) ou \\(B\\):\n\\(A \\cup B = \\{(F0),(F1),(F2),(F3),(F4),(F5),(F6),(G3),(G4) \\}\\)\nHÃ¡ 9 ocorrÃªncias em \\(A \\cup B\\), de modo que:\n\\[P(A \\cup B) = \\frac{9}{12} = 0.75\\]\nDo diagrama de Venn, fica fÃ¡cil verificar que o nÃºmero de eventos em \\(A \\cup B\\) pode ser obtido pelo nÃºmero de eventos em \\(A\\) somados ao nÃºmero de eventos em \\(B\\) e subtraÃ­do pelo nÃºmero de evendos que ocorrem em ambos (\\(A \\cap B\\)).\nAssim:\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\\[P(A \\cup B) = 0.58 + 0.5 - 0.33 = 0.75\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html",
    "title": "Teorema de Bayes",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas\n\n\n\n\n\n\nsource(\"scripts/conditional-tree.r\")\nO Teorema de Bayes provÃ©m da definiÃ§Ã£o de probabilidade condicional:\n\\[P(B|A) = \\frac{P(A \\cap B)}{P(A)},\\]\no que implica:\n\\[P(A \\cap B) = P(A)\\,P(B|A).\\]\nPodemos tambÃ©m escrever:\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\quad P(A \\cap B) = P(B)\\,P(A|B).\\]\nComo \\(P(A \\cap B) = P(B \\cap A)\\), segue:\n\\[P(A)\\,P(B|A) = P(B)\\,P(A|B),\\]\nresultando na forma geral do Teorema de Bayes:\n\\[P(B|A) = \\frac{P(B)\\,P(A|B)}{P(A)}.\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html#teorema-da-probabilidade-total",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html#teorema-da-probabilidade-total",
    "title": "Teorema de Bayes",
    "section": "1 Teorema da probabilidade total",
    "text": "1 Teorema da probabilidade total\nConsidere o esquema de um diagrama de Ã¡rvore:\n\n\n\n\n\n\n\n\n\nDois caminhos podem levar Ã  ocorrÃªncia de \\(A\\): um em que \\(B\\) ocorre \\(\\bigl[P(A \\cap B)\\bigr]\\) e outro em que \\(B\\) nÃ£o ocorre \\(\\bigl[P(A \\cap \\overline{B})\\bigr]\\). Por serem mutuamente exclusivos:\n\\[P(A) = P(A \\cap B) + P(A \\cap \\overline{B}),\\]\nque pode ser reescrito como:\n\\[P(A) = P(B)\\,P(A|B) + P(\\overline{B})\\,P(A|\\overline{B}).\\]\nEste resultado Ã© conhecido como Teorema da probabilidade total. Assim, o Teorema de Bayes pode ser expresso por:\n\\[\nP(B|A) = \\frac{P(B)\\,P(A|B)}{P(B)\\,P(A|B) + P(\\overline{B})\\,P(A|\\overline{B})}.\n\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html#o-problema-da-detecÃ§Ã£o-de-espÃ©cies",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html#o-problema-da-detecÃ§Ã£o-de-espÃ©cies",
    "title": "Teorema de Bayes",
    "section": "2 O problema da detecÃ§Ã£o de espÃ©cies",
    "text": "2 O problema da detecÃ§Ã£o de espÃ©cies\nSuponha um estudo sobre a presenÃ§a de uma espÃ©cie de peixe em riachos costeiros da Mata AtlÃ¢ntica. Ela ocorre em 5% dos riachos \\(\\bigl[P(O) = 0,05\\bigr]\\), sendo, portanto, rara. A detecÃ§Ã£o se dÃ¡ por captura e identificaÃ§Ã£o taxonÃ´mica. Se a espÃ©cie estÃ¡ presente, a probabilidade de captura Ã© \\(0,99\\), havendo \\(0,01\\) de falso negativo (quando a espÃ©cie nÃ£o Ã© detectada mesmo presente).\nHÃ¡ tambÃ©m a possibilidade de falso positivo: mesmo quando ausente, existe uma chance de 0,10 de a espÃ©cie ser registrada erroneamente, devido Ã  semelhanÃ§a com outra espÃ©cie presente na regiÃ£o.\nPodemos organizar essas probabilidades em um diagrama de Ã¡rvore:\n\n\n\nDiagrama de Ã¡rvore representando as probabilidades de ocorrÃªncia P(O) e detecÃ§Ã£o P(D) de uma espÃ©cie.\n\n\nAs ramificaÃ§Ãµes mostram as bifurcaÃ§Ãµes do evento â€œespÃ©cie presente ou ausenteâ€ e, em seguida, â€œdetecÃ§Ã£o ou nÃ£o-detecÃ§Ã£oâ€. Assim, sÃ£o possÃ­veis:\n\n\\(P(O \\cap D) = 0,0495\\)\n\\(P(O \\cap \\overline{D}) = 0,0005\\)\n\\(P(\\overline{O} \\cap D) = 0,095\\)\n\\(P(\\overline{O} \\cap \\overline{D}) = 0,855\\)\n\nA probabilidade total de detecÃ§Ã£o \\(P(D)\\) Ã©:\n\\[P(D) = P(O \\cap D) + P(\\overline{O} \\cap D) = 0,0495 + 0,095 = 0,1445.\\]\n\n2.1 RazÃ£o de verossimilhanÃ§a, inferÃªncia bayesiana e teste de hipÃ³teses\nUma pergunta relevante Ã©:\n\nAo sabermos de uma possÃ­vel detecÃ§Ã£o, podemos ter certeza da presenÃ§a dessa espÃ©cie?\n\nEm inferÃªncia estatÃ­stica, buscamos tomar decisÃµes a respeito de um fenÃ´meno desconhecido com base em dados observados. Aqui, exploramos duas abordagens: verossimilhanÃ§a e inferÃªncia bayesiana.\n\n2.1.1 VerossimilhanÃ§a: uma medida indireta para \\(P(O|D)\\)\nSe \\(P(D|O)\\) for alta, a presenÃ§a da espÃ©cie se torna mais plausÃ­vel, pois a chance de detectÃ¡-la quando estÃ¡ presente Ã© elevada. JÃ¡ \\(P(D|\\overline{O})\\) alto indicaria que a nÃ£o-ocorrÃªncia Ã© mais provÃ¡vel, pois hÃ¡ muitos falsos positivos.\nEm estatÃ­stica, \\(P(D|O)\\) Ã© anÃ¡logo Ã  verossimilhanÃ§a de \\(O\\) dado \\(D\\). De modo simplificado, contrastamos duas hipÃ³teses:\n\nEspÃ©cie ocorre e Ã© detectada;\nEspÃ©cie nÃ£o ocorre, mas hÃ¡ detecÃ§Ã£o falsa.\n\nA razÃ£o de verossimilhanÃ§a (\\(RV\\)) Ã©:\n\\[RV = \\frac{P(D|O)}{P(D|\\overline{O})} = \\frac{0,99}{0,10} = 9,9.\\]\nInterpretamos como sendo cerca de 10 vezes mais provÃ¡vel a hipÃ³tese â€œespÃ©cie ocorreâ€ do que â€œespÃ©cie nÃ£o ocorreâ€ quando hÃ¡ detecÃ§Ã£o.\n\n\n2.1.2 InferÃªncia bayesiana: o conhecimento a priori importa?\nNa abordagem bayesiana, incluÃ­mos a probabilidade a priori de ocorrÃªncia, \\(P(O)\\). Quando recebemos a informaÃ§Ã£o de detecÃ§Ã£o, atualizamos essa probabilidade, tornando-a \\(P(O|D)\\).\nNo exemplo, conhecemos:\n\n\\(P(O) = 0,05\\) e \\(P(\\overline{O}) = 0,95\\);\n\\(P(D|O) = 0,99\\) e \\(P(D|\\overline{O}) = 0,10\\).\n\nPelo Teorema de Bayes:\n\\[P(O|D) = \\frac{P(O)\\,P(D|O)}{P(O)\\,P(D|O) + P(\\overline{O})\\,P(D|\\overline{O})}.\\]\nSubstituindo valores:\n\\[P(O|D) = \\frac{0,02 \\times 0,99}{0,02 \\times 0,99 + 0,98 \\times 0,10} \\approx 0.17.\\]\nE:\n\\[P(\\overline{O}|D) = \\frac{0,98 \\times 0,10}{0,02 \\times 0,99 + 0,98 \\times 0,10} \\approx 0.83.\\]\nMesmo com a detecÃ§Ã£o, a chance de nÃ£o-ocorrÃªncia ainda Ã© maior, favorecendo a hipÃ³tese de falso positivo.\n\n\n2.1.3 DiferenÃ§as entre as abordagens\nA verossimilhanÃ§a foca em \\(P(D|O)\\), enquanto a inferÃªncia bayesiana calcula \\(P(O|D)\\) diretamente, ponderada por \\(P(O)\\). Se \\(P(O) = 0,5\\), entÃ£o:\n\\[P(O|D) = \\frac{0,5 \\times 0,99}{0,5 \\times 0,99 + 0,5 \\times 0,10} \\approx 0,91,\\] \\[P(\\overline{O}|D) \\approx 0,09,\\]\ne a razÃ£o \\(\\frac{P(O|D)}{P(\\overline{O}|D)}\\) serÃ¡ igual a \\(RV = 9,9\\), tal como na verossimilhanÃ§a. PorÃ©m, quando \\(P(O)\\) indica uma espÃ©cie muito rara, esse valor a priori altera o resultado final de \\(P(O|D)\\). Por isso, as duas abordagens sÃ³ coincidem quando usamos uma priori nÃ£o-informativa (probabilidades iniciais iguais para presenÃ§a e ausÃªncia)."
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html",
    "href": "content/estatistica-descritiva/quartis.html",
    "title": "Medidas de posiÃ§Ã£o: quartis",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/assimetria-ggplot.r')\nA mÃ©dia, mediana, moda e ponto mÃ©dio sÃ£o um tipo de medidas de posiÃ§Ã£o que indicam uma posiÃ§Ã£o particular, isto Ã©, a posiÃ§Ã£o central ao redor da qual os dados estÃ£o dispersos. Existem, no entanto, outras medidas de posiÃ§Ã£o como quartis, comumente utilizadas na descriÃ§Ã£o, anÃ¡lise e interpretaÃ§Ã£o de dados.\nOs quartis de uma distribuiÃ§Ã£o de valores sÃ£o obtidos apÃ³s ordenarmos os dados em ordem crescente e, em seguida, agrupÃ¡-los em partes iguais, contendo cada uma 25% do nÃºmero total de observaÃ§Ãµes. Se temos 20 observaÃ§Ãµes, cada parte conterÃ¡, portanto, cinco observaÃ§Ãµes, \\(20 \\times 0.25 = 5\\). Os quartis sÃ£o as posiÃ§Ãµes numÃ©ricas que dividem estas partes.\nOs quartis podem ser indicados por \\(Q_1\\), \\(Q_2\\) e \\(Q_3\\), conforme a figura abaixo.\nOs quartis que veremos aqui sÃ£o medidas empÃ­ricas dos limites indicados na figura acima. Calculamos estes limites a partir de uma amostra de tamanho \\(n\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#cÃ¡lculo-dos-quartis-na-posiÃ§Ã£o-j",
    "href": "content/estatistica-descritiva/quartis.html#cÃ¡lculo-dos-quartis-na-posiÃ§Ã£o-j",
    "title": "Medidas de posiÃ§Ã£o: quartis",
    "section": "1 CÃ¡lculo dos quartis na posiÃ§Ã£o \\(j\\)",
    "text": "1 CÃ¡lculo dos quartis na posiÃ§Ã£o \\(j\\)\nExistem diferentes algoritmos possÃ­veis para o cÃ¡lculo dos quartis. Veremos um deles. Para isso, siga os passos abaixo:\n\nReorganize \\(X\\) em ordem crescente de \\(k = 1\\) a \\(k = n\\). Seja \\(n\\) o nÃºmero de observaÃ§Ãµes em \\(X\\), teremos, portanto, \\(X_k\\) como o valor observado na posiÃ§Ã£o \\(k\\) em ordem crescente. Deste modo, para \\(k = 1\\), teremos \\(X_1\\) como o menor valor, e para \\(k = n\\), teremos \\(X_n\\) como o maior valor.\nCalcule\n\n\\[L = \\frac{j \\times (n+1)}{4};\\]\n\nDefina \\(k\\) como o maior nÃºmero inteiro abaixo de \\(L\\);\nCalcule\n\n\\[Q_j = X_k + (L - k) \\times (X_{k+1}-X_k);\\]\n\n\\(Q_j\\) serÃ¡ um elemento entre \\(X_k\\) e \\(X_{k+1}\\). Se \\(X_k\\) for um nÃºmero inteiro, \\(Q_j = X_k\\).\n\nExemplo para o cÃ¡lculo de \\(Q_1\\)\n\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\nnX &lt;- length(X)\n\nConsidere a variÃ¡vel \\(X\\) com \\(n =\\) 20 observaÃ§Ãµes.\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\n\nsX &lt;- sort(X)\n\nj1 &lt;- 1\nL1 &lt;- j1 * (nX + 1) / 4\nk1 &lt;- floor(L1)\nQ1 &lt;- sX[k1] + (L1 - k1) * (sX[k1+1] - sX[k1])\n\nj2 &lt;- 2\nL2 &lt;- j2 * (nX + 1) / 4\nk2 &lt;- floor(L2)\nQ2 &lt;- sX[k2] + (L2 - k2) * (sX[k2+1] - sX[k2])\n\nj3 &lt;- 3\nL3 &lt;- j3 * (nX + 1) / 4\nk3 &lt;- floor(L3)\nQ3 &lt;- sX[k3] + (L3 - k3) * (sX[k3+1] - sX[k3])\n\n\nOrganize em ordem crescente para determinar os valores de \\(X\\) nas posiÃ§Ãµes \\(k\\).\n\n\nPosicao_k &lt;- paste(1:length(X), \"a PosiÃ§Ã£o\", sep = \"\")\ndf &lt;- tibble(`PosiÃ§Ã£o k` = Posicao_k, `X ordenado` = sX)\n\ndf |&gt; \n  gt()\n\n\n\n\n\n\n\nPosiÃ§Ã£o k\nX ordenado\n\n\n\n\n1a PosiÃ§Ã£o\n5.6\n\n\n2a PosiÃ§Ã£o\n8.3\n\n\n3a PosiÃ§Ã£o\n8.4\n\n\n4a PosiÃ§Ã£o\n8.7\n\n\n5a PosiÃ§Ã£o\n8.8\n\n\n6a PosiÃ§Ã£o\n9.4\n\n\n7a PosiÃ§Ã£o\n9.9\n\n\n8a PosiÃ§Ã£o\n10.0\n\n\n9a PosiÃ§Ã£o\n10.4\n\n\n10a PosiÃ§Ã£o\n10.7\n\n\n11a PosiÃ§Ã£o\n10.8\n\n\n12a PosiÃ§Ã£o\n11.0\n\n\n13a PosiÃ§Ã£o\n11.2\n\n\n14a PosiÃ§Ã£o\n11.2\n\n\n15a PosiÃ§Ã£o\n11.5\n\n\n16a PosiÃ§Ã£o\n11.6\n\n\n17a PosiÃ§Ã£o\n11.9\n\n\n18a PosiÃ§Ã£o\n12.2\n\n\n19a PosiÃ§Ã£o\n13.0\n\n\n20a PosiÃ§Ã£o\n13.2\n\n\n\n\n\n\n\n\nPara \\(j = 1\\) (\\(Q_1\\)), calcule:\n\n\\(L = \\frac{1 \\times (20+1)}{4} = 5.25\\);\n\nDefina \\(k\\) como o maior nÃºmero inteiro abaixo de \\(L\\). Portanto, se \\(L = 5.25\\), \\(k = 5\\).\nNote que a observaÃ§Ã£o correspondente Ã  \\(k = 5\\) (5\\(^a\\) posiÃ§Ã£o) Ã© 8.8, enquanto a observaÃ§Ã£o correspondente Ã  \\(k = 6\\) (6\\(^a\\) posiÃ§Ã£o) Ã© 9.4. Deste modo, calcule\n\n\\(Q_1 = 8.8 + (5.25 - 5) \\times (9.4 - 8.8) = 8.95\\).\nVemos entÃ£o que, para a variÃ¡vel \\(X\\) em questÃ£o, o primeiro quartil Ã©:\n\\(Q_1 = 8.95\\)\nExercÃ­cio: Calcule agora os valores correspondentes a \\(Q_2\\) e \\(Q_3\\) e verifique que os resultados sÃ£o: \\(Q_2 = 10.75\\) e \\(Q_3 = 11.575\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#cÃ¡lculo-dos-quartis-no-r",
    "href": "content/estatistica-descritiva/quartis.html#cÃ¡lculo-dos-quartis-no-r",
    "title": "Medidas de posiÃ§Ã£o: quartis",
    "section": "2 CÃ¡lculo dos quartis no R",
    "text": "2 CÃ¡lculo dos quartis no R\nPodemos programar a sequÃªncia de funÃ§Ãµes acima utilizando o R:\n\nX &lt;- c(8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, \n       13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2)\n\n# Ordenando X em ordem crescente\nsX &lt;- sort(X, decreasing = FALSE)\n# Encontrando o nÃºmero de observaÃ§Ãµes em X\nn &lt;- length(X) \n# Encontrando os quartis (Q1, Q2 e Q3)\nj &lt;- c(1, 2, 3)\nL &lt;- j * (n + 1) / 4\nk &lt;- floor(L)\nQ &lt;- sX[k] + (L - k) * (sX[k+1] - sX[k])\nnames(Q) &lt;- c('Q1', 'Q2', 'Q3')\n\n# Visualizando os quartis\nQ\n\n    Q1     Q2     Q3 \n 8.950 10.750 11.575 \n\n\nEntretanto, existe uma funÃ§Ã£o no R denominada quantile, que pode ser utilizada da seguinte forma:\n\nquantile(X, probs = c(0.25, 0.50, 0.75))\n\n   25%    50%    75% \n 9.250 10.750 11.525 \n\n\n\n\n\n\n\n\nNotaObservaÃ§Ãµes\n\n\n\n\nLembre que o quartil \\(Q_1\\) delimita a posiÃ§Ã£o \\(25\\%\\), \\(Q_2\\) delimita a posiÃ§Ã£o \\(50\\%\\) (\\(=\\) mediana) e \\(Q_3\\) delimita a posiÃ§Ã£o \\(75\\%\\). Por este motivo, utilizamos o argumento probs = c(0.25, 0.50, 0.75). Assim, a funÃ§Ã£o quantile Ã© mais geral que a rotina passada anteriormente, pois permite o cÃ¡lculo para qualquer posiÃ§Ã£o entre os quantis \\(0\\%\\) e \\(100\\%\\).\nNote tambÃ©m que os resultados foram ligeiramente diferentes, uma vez que existem diferentes algoritmos para o cÃ¡lculo dos quartis. A funÃ§Ã£o quantile permite a escolha entre \\(9\\) algoritmos diferentes e, por padrÃ£o, utiliza o type = 7. O passo-a-passo que mostramos corresponde ao type = 6. VocÃª pode verificar que, ao digitar o comando abaixo, os resultados serÃ£o os mesmos que calculamos manualmente.\n\n\nquantile(X, probs = c(0.25, 0.50, 0.75), type = 6)\n\n   25%    50%    75% \n 8.950 10.750 11.575 \n\n\n\nEssas diferenÃ§as diminuem Ã  medida que o tamanho amostral aumenta.\nFinalmente, os quartis discutidos aqui sÃ£o casos particulares de limites mais gerais denominados quantis, que indicam uma posiÃ§Ã£o especÃ­fica na distribuiÃ§Ã£o. Por exemplo, o limite \\(Q_1\\) poderia ser chamado de Quantil \\(0,25\\). Assim, podemos encontrar qualquer posiÃ§Ã£o, como o quantil \\(0,10\\) que delimita os \\(10\\%\\) menores valores.\nNo cÃ¡lculo dos quantis para um limite \\(p\\) qualquer (\\(0 \\le p \\le 1\\)), a Ãºnica mudanÃ§a no algoritmo apresentado estÃ¡ na obtenÃ§Ã£o de \\(L\\) (passo 2), que Ã© feita como:\n\n\\[L = p \\times (n+1)\\]"
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#obtendo-os-quartis-a-partir-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/quartis.html#obtendo-os-quartis-a-partir-de-uma-tabela-de-dados",
    "title": "Medidas de posiÃ§Ã£o: quartis",
    "section": "3 Obtendo os quartis a partir de uma tabela de dados",
    "text": "3 Obtendo os quartis a partir de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUsaremos a funÃ§Ã£o summarise para obter os quartis para a variÃ¡vel CPUE.\n\nres |&gt; \n  reframe(Quartis = quantile(CPUE, probs = c(0.25, 0.50, 0.75)),\n          Limites = c('25%', '50%', '75%')) |&gt; \n  gt()\n\n\n\n\n\n\n\nQuartis\nLimites\n\n\n\n\n7.43\n25%\n\n\n11.74\n50%\n\n\n16.30\n75%"
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#boxplots-uma-representaÃ§Ã£o-grÃ¡fica-dos-quartis",
    "href": "content/estatistica-descritiva/quartis.html#boxplots-uma-representaÃ§Ã£o-grÃ¡fica-dos-quartis",
    "title": "Medidas de posiÃ§Ã£o: quartis",
    "section": "4 Boxplots: uma representaÃ§Ã£o grÃ¡fica dos quartis",
    "text": "4 Boxplots: uma representaÃ§Ã£o grÃ¡fica dos quartis\nOs quartis de uma distribuiÃ§Ã£o nos ajudam a entender o formato de uma distribuiÃ§Ã£o. Uma das formas amplamente estabelecidas de representÃ¡-los graficamente Ã© por meio de um boxplot. Para a variÃ¡vel acima, o boxplot serÃ¡:\n\n\nCÃ³digo\ndf &lt;- data.frame(X)\nPX &lt;- quantile(X, probs = c(0, 0.25, 0.50, 0.75, 1))\nLegX &lt;- c(\"MÃ­nimo\", \"Q1\", \"Q2 = Mediana\", \"Q3\", \"MÃ¡ximo\")\nggplot(df, aes(y = X)) +\n  geom_boxplot(fill = 'lightblue', coef = 10) +\n  annotate(geom = 'text', x = .8, y = PX - 0.3,\n           label = LegX) +\n  annotate(geom = 'segment', \n           x = 0.5, xend = 1.23,\n           y = PX, yend = PX,\n           arrow = arrow(ends = 'first')) +\n  scale_y_continuous(breaks = 5:14) +\n  theme_classic() +\n  theme(axis.title = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n\n\n\n\n\n\n\nFiguraÂ 2: DivisÃ£o em quartis de um boxplot\n\n\n\n\n\nEm um boxplot, a linha central representa a Mediana ou \\(2^o\\) quartil (\\(Q_2\\)), e os limites da caixa sÃ£o o \\(1^o\\) e \\(3^o\\) quartis, respectivamente \\(Q_1\\) e \\(Q_3\\). As extremidades geralmente sÃ£o os pontos mÃ¡ximo e mÃ­nimo da distribuiÃ§Ã£o.\nExiste uma relaÃ§Ã£o entre os histogramas e os boxplots. Ambos podem ser utilizados para avaliar o grau de assimetria de uma distribuiÃ§Ã£o, como apresentado abaixo. Em uma distribuiÃ§Ã£o simÃ©trica, a caixa do boxplot tende a se concentrar no meio da distribuiÃ§Ã£o. JÃ¡ em distribuiÃ§Ãµes assimÃ©tricas, a caixa tende a ficar deslocada Ã  esquerda ou Ã  direita (FiguraÂ 3).\n\n\nCÃ³digo\n# Ver funÃ§Ã£o completa no arquivo 'scripts/assimetria-ggplot.r'\nassimetria_ggplot(fig = 'bh')\n\n\n\n\n\n\n\n\nFiguraÂ 3: PadrÃ£o de assimetria representado por meio de histogramas e boxplots."
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html",
    "href": "content/estatistica-descritiva/variacao.html",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nAs medidas de variaÃ§Ã£o indicam o grau de dispersÃ£o das observaÃ§Ãµes. DistribuiÃ§Ãµes com observaÃ§Ãµes muito prÃ³ximas Ã  mÃ©dia tÃªm baixo grau de dispersÃ£o, enquanto aquelas com observaÃ§Ãµes muito distantes da mÃ©dia tÃªm alto grau de dispersÃ£o. Vamos apresentar quatro Ã­ndices que medem o grau de dispersÃ£o: a variÃ¢ncia, o desvio padrÃ£o, o coeficiente de variaÃ§Ã£o e a amplitude de variaÃ§Ã£o."
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#variÃ¢ncia-amostral",
    "href": "content/estatistica-descritiva/variacao.html#variÃ¢ncia-amostral",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "1 VariÃ¢ncia amostral",
    "text": "1 VariÃ¢ncia amostral\nA variÃ¢ncia amostral, descrita pelo sÃ­mbolo \\(s^2\\), mede quÃ£o distantes as observaÃ§Ãµes em uma variÃ¡vel estÃ£o de sua mÃ©dia aritmÃ©tica.\nPara um conjunto de observaÃ§Ãµes, \\(s^2\\) Ã© dada por:\n\\[s^2=\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}\\]\nSeja a variÃ¡vel \\(X\\) abaixo:\n\n\nCÃ³digo\nn &lt;- 5\nset.seed(1)\nX &lt;- sample(x = 1:10, size = n, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2}\n\\(X\\) tem 5 observaÃ§Ãµes:\nPara calcularmos \\(s^2\\), devemos inicialmente obter a mÃ©dia de \\(X\\), que neste caso Ã©:\n\\(\\overline{X} = 4.6\\)\nE subtrair cada observaÃ§Ã£o da mÃ©dia:\n\n\nCÃ³digo\ndf &lt;- data.frame(X) |&gt; \n  mutate(dif = X - mean(X)) |&gt; \n  as.data.frame() # Garantir que Ã© um data frame simples\n\ndf |&gt; \n  knitr::kable(col.names = c('$X$', '$X - \\\\overline{X}$'))\n\n\n\n\n\n\\(X\\)\n\\(X - \\overline{X}\\)\n\n\n\n\n9\n4.4\n\n\n4\n-0.6\n\n\n7\n2.4\n\n\n1\n-3.6\n\n\n2\n-2.6\n\n\n\n\n\nEm seguida, elevamos cada diferenÃ§a ao quadrado:\n\n\nCÃ³digo\ndf &lt;- df |&gt; \n  mutate(dif = X - mean(X)) |&gt; \n  mutate(dif2 = dif^2)\n\ndf |&gt; \n  knitr::kable(col.names = c('$X$',\n                             '$X - \\\\overline{X}$',\n                             '${(X - \\\\overline{X})}^{2}$'))\n\n\n\n\n\n\\(X\\)\n\\(X - \\overline{X}\\)\n\\({(X - \\overline{X})}^{2}\\)\n\n\n\n\n9\n4.4\n19.36\n\n\n4\n-0.6\n0.36\n\n\n7\n2.4\n5.76\n\n\n1\n-3.6\n12.96\n\n\n2\n-2.6\n6.76\n\n\n\n\n\nSe somarmos essas quantias e dividirmos por \\(n-1\\), teremos a variÃ¢ncia amostral como:\n\\(s^2 = \\frac{19.36 + 0.36 + 5.76 + 12.96 + 6.76}{5 - 1} = \\frac{45.2}{4} = 11.3\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#desvio-padrÃ£o-amostral",
    "href": "content/estatistica-descritiva/variacao.html#desvio-padrÃ£o-amostral",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "2 Desvio padrÃ£o amostral",
    "text": "2 Desvio padrÃ£o amostral\nO desvio padrÃ£o amostral (\\(s\\)) Ã© a raiz quadrada da variÃ¢ncia amostral.\n\\[s=\\sqrt{\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}}\\]\nE em nosso exemplo:\n\\(s = \\sqrt{11.3} = 3.36\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#coeficiente-de-variaÃ§Ã£o",
    "href": "content/estatistica-descritiva/variacao.html#coeficiente-de-variaÃ§Ã£o",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "3 Coeficiente de variaÃ§Ã£o",
    "text": "3 Coeficiente de variaÃ§Ã£o\nO coeficiente de variaÃ§Ã£o (cv) relaciona o desvio padrÃ£o Ã  mÃ©dia, sendo definido por:\n\\[cv = s/\\overline{X}\\] ou \\[cv_{\\%}  = s/\\overline{X}\\cdot 100\\]\nEm nosso exemplo:\n\\(cv = \\frac{3.36}{4.6} \\cdot 100 = 73.08\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#amplitude-de-variaÃ§Ã£o",
    "href": "content/estatistica-descritiva/variacao.html#amplitude-de-variaÃ§Ã£o",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "4 Amplitude de variaÃ§Ã£o",
    "text": "4 Amplitude de variaÃ§Ã£o\nÃ‰ a diferenÃ§a entre os pontos mÃ¡ximo e mÃ­nimo de um grupo de observaÃ§Ãµes.\nAmplitude de variaÃ§Ã£o = \\(X_{maximo} - X_{minimo}\\)\nque em nosso exemplo Ã©:\nAmplitude de variaÃ§Ã£o = \\(9 - 1 = 8\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#obtendo-medidas-de-variaÃ§Ã£o-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/variacao.html#obtendo-medidas-de-variaÃ§Ã£o-de-uma-tabela-de-dados",
    "title": "Medidas de variaÃ§Ã£o",
    "section": "5 Obtendo medidas de variaÃ§Ã£o de uma tabela de dados",
    "text": "5 Obtendo medidas de variaÃ§Ã£o de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUsaremos a funÃ§Ã£o summarise para obter descritores de variaÃ§Ã£o para a variÃ¡vel CPUE.\n\nres |&gt; \n  summarise(CPUE_var = var(CPUE),\n            CPUE_dp = sd(CPUE),\n            CPUE_cv = sd(CPUE) / mean(CPUE) * 100,\n            CPUE_amplitude = max(CPUE) - min(CPUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_var\nCPUE_dp\nCPUE_cv\nCPUE_amplitude\n\n\n\n\n54.31838\n7.3701\n58.02786\n28.71"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html",
    "href": "content/estatistica-descritiva/tendcentral.html",
    "title": "Medidas de tendÃªncia central",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/getmode.r')\nsource('scripts/assimetria-ggplot.r')\nTabelas de frequÃªncia e histogramas permitem a visualizaÃ§Ã£o dos padrÃµes de distribuiÃ§Ã£o de uma variÃ¡vel quantitativa, evidenciando limites inferiores e superiores, faixas de valores mais ou menos frequentes etc. Neste capÃ­tulo, veremos medidas-resumo que possibilitam descrever a tendÃªncia central de um conjunto de dados. Algumas dessas medidas sÃ£o a mÃ©dia aritmÃ©tica, a mediana, a moda e o ponto mÃ©dio."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#mÃ©dia-aritmÃ©tica",
    "href": "content/estatistica-descritiva/tendcentral.html#mÃ©dia-aritmÃ©tica",
    "title": "Medidas de tendÃªncia central",
    "section": "1 MÃ©dia aritmÃ©tica",
    "text": "1 MÃ©dia aritmÃ©tica\nConsidere a variÃ¡vel \\(X\\) com \\(n\\) elementos \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(\\cdots, X_n\\). A mÃ©dia aritmÃ©tica (\\(\\overline{X}\\)) Ã© dada por:\n\\[\\overline{X}=\\frac{X_1+X_2+X_3+\\cdots+X_n}{n}=\\frac{\\sum_{i=1}^n{X_i}}{n}\\]\nExemplo\nSeja a variÃ¡vel \\(X\\) abaixo:\n\n\nCÃ³digo\nn &lt;- 5\nset.seed(1)\nX &lt;- sample(x = 1:10, size = n, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2}\n\\(X\\) possui 5 observaÃ§Ãµes e tem mÃ©dia:\n\\(\\overline{X}=\\frac{9 + 4 + 7 + 1 + 2}{5}\\)\n\\(\\overline{X}=\\frac{23}{5} = 4.6\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#mediana",
    "href": "content/estatistica-descritiva/tendcentral.html#mediana",
    "title": "Medidas de tendÃªncia central",
    "section": "2 Mediana",
    "text": "2 Mediana\nÃ‰ definida como o valor do meio de uma distribuiÃ§Ã£o, de modo que metade dos valores estÃ¡ abaixo e metade acima da mediana. Se organizarmos a variÃ¡vel \\(X\\) em ordem crescente teremos:\n\n\nCÃ³digo\nX &lt;- sort(X)\nXmed &lt;- median(X)\n\n\n\\(X =\\) {1,2 , 4 , 7,9}\nsendo a mediana igual a \\(4\\).\nNeste exemplo, temos \\(n = 5\\) observaÃ§Ãµes. Se tivermos um nÃºmero par de observaÃ§Ãµes, teremos duas na posiÃ§Ã£o central. Por exemplo, se:\n\n\nCÃ³digo\nset.seed(1)\nX &lt;- sample(x = 1:10, size = 6, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2, 7}\nvemos que apÃ³s ordenarmos \\(X\\):\n\\(X =\\) {1, 2, 4, 7, 7, 9}\nteremos o \\(4\\) e o \\(7\\) como valores do meio.\nNeste caso, a mediana fica como sendo:\n\\(\\frac{4 + 7}{2} = 5.5\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#moda",
    "href": "content/estatistica-descritiva/tendcentral.html#moda",
    "title": "Medidas de tendÃªncia central",
    "section": "3 Moda",
    "text": "3 Moda\nÃ‰ definida como o valor mais frequente de uma distribuiÃ§Ã£o.\n\n\nCÃ³digo\nset.seed(1)\nX &lt;- sample(x = 1:10, size = 6, rep = TRUE)\n\n\nPara \\(X =\\) {9, 4, 7, 1, 2, 7}, a moda Ã© 7, o valor que mais se repete na distribuiÃ§Ã£o.\n\n\n\n\n\n\nNota\n\n\n\nA moda nem sempre Ã© Ãºnica. Se vÃ¡rios valores repetem-se igualmente, teremos mais de uma moda na distribuiÃ§Ã£o."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#ponto-mÃ©dio",
    "href": "content/estatistica-descritiva/tendcentral.html#ponto-mÃ©dio",
    "title": "Medidas de tendÃªncia central",
    "section": "4 Ponto mÃ©dio",
    "text": "4 Ponto mÃ©dio\nÃ‰ calculado com base nos dois valores extremos da distribuiÃ§Ã£o (mÃ­nimo e mÃ¡ximo), sendo obtido por:\n\\[P_{medio}=\\frac{X_{minimo} + X_{maximo}}{2}\\]\nPara \\(X =\\) {9, 4, 7, 1, 2, 7}, o ponto mÃ©dio Ã©:\n\\(PM = \\frac{1 + 9}{2} = \\frac{10}{2} = 5\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#efeito-da-assimetria-sobre-os-descritores-de-tendÃªncia-central",
    "href": "content/estatistica-descritiva/tendcentral.html#efeito-da-assimetria-sobre-os-descritores-de-tendÃªncia-central",
    "title": "Medidas de tendÃªncia central",
    "section": "5 Efeito da assimetria sobre os descritores de tendÃªncia central",
    "text": "5 Efeito da assimetria sobre os descritores de tendÃªncia central\nCada um dos descritores de tendÃªncia central descritos acima Ã© mais ou menos sensÃ­vel ao grau de assimetria de uma distribuiÃ§Ã£o. Em uma distribuiÃ§Ã£o perfeitamente simÃ©trica, onde as observaÃ§Ãµes estÃ£o igualmente dispersas acima e abaixo do ponto central, os valores da mÃ©dia, mediana, moda e ponto mÃ©dio coincidem. Por outro lado, pode ocorrer da distribuiÃ§Ã£o ser assimÃ©trica. Neste caso, a posiÃ§Ã£o relativa dos descritores irÃ¡ depender se a assimetria Ã© Ã  direita ou Ã  esquerda. Esta discrepÃ¢ncia ocorre devido Ã  sensibilidade destes descritores a valores extremos na distribuiÃ§Ã£o. O ponto mÃ©dio Ã© o mais sensÃ­vel Ã  presenÃ§a de pontos extremos, seguido da mÃ©dia, mediana e moda.\n\n\nCÃ³digo\n# Ver funÃ§Ã£o completa no arquivo 'scripts/assimetria-ggplot.r'\nassimetria_ggplot()\n\n\n\n\n\n\n\n\nFiguraÂ 1: Efeito da assimetria de uma distribuiÃ§Ã£o sobre o ponto mÃ©dio, a mÃ©dia aritmÃ©tica, a mediana e a moda.\n\n\n\n\n\n\n\n\n\n\n\nNotaMedidas de tendÃªncia central\n\n\n\nMÃ©dia aritmÃ©tica: utiliza todo o conjunto de dados. Relativamente sensÃ­vel a valores extremos;\nMediana: o valor do meio. Metade dos pontos estÃ¡ acima e metade abaixo da mediana. A mediana Ã© uma medida resistente a valores extremos;\nModa: valor mais frequente. Se mais de um valor aparece com a mesma frequÃªncia, os dados tÃªm uma distribuiÃ§Ã£o multimodal;\nPonto mÃ©dio: considera somente o valor mÃ­nimo e mÃ¡ximo. O ponto mÃ©dio Ã© fÃ¡cil de calcular, porÃ©m nÃ£o utiliza a maioria do conjunto de dados e Ã© muito sensÃ­vel a valores extremos."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#obtendo-medidas-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/tendcentral.html#obtendo-medidas-de-uma-tabela-de-dados",
    "title": "Medidas de tendÃªncia central",
    "section": "6 Obtendo medidas de uma tabela de dados",
    "text": "6 Obtendo medidas de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nMedidas-resumo podem ser obtidas com a funÃ§Ã£o summarise.\nVamos encontrar a mÃ©dia aritmÃ©tica e a mediana da variÃ¡vel CPUE.\n\nres |&gt; \n  summarise(CPUE_medio = mean(CPUE),\n            CPUE_mediana = median(CPUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\n\n\n\n\n12.70097\n11.74\n\n\n\n\n\n\n\nOs valores sÃ£o parecidos, porÃ©m a mÃ©dia Ã© um pouco superior. Provavelmente a distribuiÃ§Ã£o deve ser ligeiramente assimÃ©trica Ã  direita. Podemos verificar isto por meio de um histograma.\n\ncl_cpue &lt;- seq(0, 35, by = 5)\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue',\n                 color = 'white') +\n  theme_classic()\n\n\n\n\n\n\n\n\nAlguns valores de captura prÃ³ximos a \\(30\\) kg estÃ£o fazendo com que a mÃ©dia esteja um pouco acima da mediana.\nVamos verificar agora a mÃ©dia da variÃ¡vel Area dos reservatÃ³rios:\n\nres |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\n\n\n\n\n64.7369\n12\n\n\n\n\n\n\n\nPara esta variÃ¡vel, a discrepÃ¢ncia Ã© muito maior.\n\n\nobs: tivemos que utilizar o argumento na.rm = TRUE para excluir do cÃ¡lculo reservatÃ³rios com dados faltantes para Area.\n\n\n\ncl_area &lt;- seq(0, 500, by = 50)\n\nggplot(res, aes(x = Area)) +\n  geom_histogram(breaks = cl_area, \n                 fill = 'darkblue',\n                 color = 'white') +\n  theme_classic()\n\n\n\n\n\n\n\n\nAo verificar o histograma, vemos que existe uma grande concentraÃ§Ã£o de reservatÃ³rios com Ã¡reas atÃ© \\(50\\) \\(km^2\\), porÃ©m poucos reservatÃ³rios muito grandes com mais de \\(200\\) \\(km^2\\). Estes grandes reservatÃ³rios deslocam a mÃ©dia aritmÃ©tica Ã  direita.\nPodemos ver quais sÃ£o estes reservatÃ³rios utilizando a funÃ§Ã£o filter.\n\nr_grandes &lt;- res |&gt; \n  filter(Area &gt;= 200) |&gt; \n  select(Reservatorio, Area)\n\nr_grandes |&gt; \n  gt()\n\n\n\n\n\n\n\nReservatorio\nArea\n\n\n\n\nSalto Santiago\n208.0\n\n\nCapivara\n419.3\n\n\nChavantes\n400.0\n\n\nRosana\n220.0\n\n\n\n\n\n\n\nEntre os 31 reservatÃ³rios, temos 4 com Ã¡reas acima de \\(200\\) \\(km^2\\) (Salto Santiago, Capivara, Chavantes, Rosana). A influÃªncia destes reservatÃ³rios Ã© maior para a mÃ©dia aritmÃ©tica, pois esta Ã© mais sensÃ­vel a valores extremos do que a mediana. Se calcularmos o ponto mÃ©dio, veremos que esta influÃªncia Ã© ainda maior.\n\nres |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE),\n            P_medio = sum(range(Area, na.rm = TRUE)) / 2) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\nP_medio\n\n\n\n\n64.7369\n12\n209.685\n\n\n\n\n\n\n\nSe calcularmos os descritores de tendÃªncia central sem estes reservatÃ³rios, vemos que a diferenÃ§a entre os descritores diminui, mas nÃ£o desaparece, o que ocorre devido Ã  elevada assimetria nesta variÃ¡vel.\n\nres |&gt; \n  filter(Area &lt; 200) |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE),\n            P_medio = sum(range(Area, na.rm = TRUE)) / 2) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\nP_medio\n\n\n\n\n25.2028\n7.2\n69.535"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html",
    "href": "content/introducao-r/estrutura-linguagem.html",
    "title": "Estrutura da linguagem",
    "section": "",
    "text": "R Ã© um ambiente de software livre para computaÃ§Ã£o estatÃ­stica e grÃ¡fica que roda em uma variedade de plataformas UNIX, Windows e MacOS (R Project). A instalaÃ§Ã£o pode ser feita a partir do site oficial CRAN, seguindo as instruÃ§Ãµes para cada plataforma. O RStudio Ã© uma Interface de Desenvolvimento Integrado (IDE) dedicada ao ambiente R, embora existam outras opÃ§Ãµes como Jupyter Notebook, Jupyter Lab, Visual Studio Code e Google Colab."
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#o-r-para-cÃ¡lculos-aritmÃ©ticos",
    "href": "content/introducao-r/estrutura-linguagem.html#o-r-para-cÃ¡lculos-aritmÃ©ticos",
    "title": "Estrutura da linguagem",
    "section": "1 O R para cÃ¡lculos aritmÃ©ticos",
    "text": "1 O R para cÃ¡lculos aritmÃ©ticos\nVamos iniciar nossa introduÃ§Ã£o ao R com seu uso mais simples, um ambiente para cÃ¡lculos aritmÃ©ticos. Como vocÃª verÃ¡, o R usa os operadores matemÃ¡ticos de subtraÃ§Ã£o (-), adiÃ§Ã£o (+), multiplicaÃ§Ã£o (*), divisÃ£o (/) e potenciaÃ§Ã£o (^) do modo anÃ¡logo a outros softwares.\n\n2 + 4\n\n[1] 6\n\n2 * 4\n\n[1] 8\n\n2 - 4\n\n[1] -2\n\n2^4\n\n[1] 16\n\n\nAlÃ©m destes, temos operadores para extrairmos a parte inteira (%%) e o resto (%/%) de uma divisÃ£o.\n\n13%/%2\n\n[1] 6\n\n13%%2\n\n[1] 1\n\n\nO uso de parÃªnteses tambÃ©m permite o controle das operaÃ§Ãµes matemÃ¡ticas seguindo as prioridades conhecidas nestas operaÃ§Ãµes. Por exemplo, a expressÃ£o:\n\n5 * (9 + 2)\n\n[1] 55\n\n\nÃ© diferente de:\n\n5 * 9 + 2\n\n[1] 47\n\n\nAssim como a expressÃ£o:\n\n(3 + 4)^2\n\n[1] 49\n\n\nÃ© diferente de:\n\n3 + 4^2\n\n[1] 19\n\n\nExistem tambÃ©m funÃ§Ãµes aritmÃ©ticas comuns como \\(log(x)\\), \\(\\sqrt(x)\\), \\(\\sin(x)\\), o nÃºmero \\(\\pi\\), etc.\n\nlog(100)\n\n[1] 4.60517\n\nlog10(100)\n\n[1] 2\n\nlog(100, base = 2)\n\n[1] 6.643856\n\nsqrt(36)\n\n[1] 6\n\npi\n\n[1] 3.141593\n\nsin(0.5 * pi)\n\n[1] 1"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#atribuiÃ§Ã£o-de-valores",
    "href": "content/introducao-r/estrutura-linguagem.html#atribuiÃ§Ã£o-de-valores",
    "title": "Estrutura da linguagem",
    "section": "2 AtribuiÃ§Ã£o de valores",
    "text": "2 AtribuiÃ§Ã£o de valores\nO R se estrutura por meio de objetos. Ao atribuir um valor a uma variÃ¡vel, esta se torna um objeto que fica disponÃ­vel na memÃ³ria. Para atribuir valor \\(2\\) Ã  variÃ¡vel x fazemos:\n\nx &lt;- 2\nx\n\n[1] 2\n\n\nApÃ³s atribuir um valor Ã  variÃ¡vel, esta fica disponÃ­vel na memÃ³ria da seÃ§Ã£o atual e pode ser utilizada em operaÃ§Ãµes subsequentes.\n\ny &lt;- x + 10\ny\n\n[1] 12\n\n\nAo atribuir outro valor Ã  mesma variÃ¡vel, o valor inicial Ã© substituÃ­do:\n\nx &lt;- 5\ny &lt;- x + 10\ny\n\n[1] 15\n\n\nO R diferencia caracteres minÃºsculos de MAIÃšSCULOS. Portanto:\n\na &lt;- sqrt(49)\nA &lt;- sqrt(81)\na\n\n[1] 7\n\nA\n\n[1] 9"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#estruturas-de-dados",
    "href": "content/introducao-r/estrutura-linguagem.html#estruturas-de-dados",
    "title": "Estrutura da linguagem",
    "section": "3 Estruturas de dados",
    "text": "3 Estruturas de dados\nOs objetos em R podem ser vetores (numÃ©ricos, alfanumÃ©ricos ou fatores), matrizes (numÃ©ricas ou alfanumÃ©tricas), data frames (estrutura bidimensional que pode combinar colunas de diferentes tipos como vetores numÃ©ricos, alfanumÃ©ricos ou fatores) ou listas (que pode combinar em sua estrutura, todos os objetos descritos acima). As funÃ§Ãµes em R sÃ£o sequÃªncias de comandos que podem transformar objetos.\n\n3.1 Vetores numÃ©ricos\nOs objetos podem guardar mais de um Ãºnico valor. A funÃ§Ã£o concatenar c() pode ser utilizada para criar um vetor com mÃºltiplos valores. Dizemos que cada valor individual Ã© uma entrada.\n\nx &lt;- c(4, 3.0, 5, 9, 10)\nx\n\n[1]  4  3  5  9 10\n\n\nPodemos utilizar estes vetores em nossas operaÃ§Ãµes.\n\ny &lt;- x * 2\ny\n\n[1]  8  6 10 18 20\n\n\nNote que na operaÃ§Ã£o acima, cada entrada foi multiplicada por \\(2\\).\nPodemos ainda acessar e modificar entradas individuais. Por exemplo, o objeto y criado acima tem 5 elementos. O segundo elemento pode ser acessado com o comando:\n\ny[2]\n\n[1] 6\n\n\nE alterado com o comando:\n\ny[2] &lt;- 300\ny\n\n[1]   8 300  10  18  20\n\n\nSe quisermos excluir o quarto elemento de y e gravar o resultado em um novo objeto z fazemos:\n\nz &lt;- y[-4]\nz\n\n[1]   8 300  10  20\n\n\nObs: Veja que o quarto elemento, 18, foi excluÃ­do.\nPodemos obter a informaÃ§Ã£o sobre o nÃºmero de elementro do vetor. O vetor y tem tamanho igual a 5, enquanto o vetor z tem 4 elementos.\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 4\n\n\n\nSequÃªncias regulares e repetiÃ§Ãµes\nPodemos criar sequencias regulares.\n\n2:10\n\n[1]  2  3  4  5  6  7  8  9 10\n\nseq(2, 10, by = 2)\n\n[1]  2  4  6  8 10\n\nseq(2, 10, length = 4)\n\n[1]  2.000000  4.666667  7.333333 10.000000\n\nseq(2, 10, length = 10)\n\n [1]  2.000000  2.888889  3.777778  4.666667  5.555556  6.444444  7.333333\n [8]  8.222222  9.111111 10.000000\n\n\nE repetiÃ§Ãµes de valores e vetores.\n\nrep(4, times = 6)\n\n[1] 4 4 4 4 4 4\n\nrep(c(2, 5), times = 3)\n\n[1] 2 5 2 5 2 5\n\nrep(c(2, 5), each = 3)\n\n[1] 2 2 2 5 5 5\n\n\nOs resultados destas sequÃªncias podem ser guardadas em um objeto para utilizaÃ§Ã£o subsequente.\n\na &lt;- seq(2, 10, by = 2)\na\n\n[1]  2  4  6  8 10\n\nb &lt;- seq(10, 2, by = -2)\nb\n\n[1] 10  8  6  4  2\n\nc &lt;- a + b\nc\n\n[1] 12 12 12 12 12\n\n\n\n\n\n3.2 Vetores alfanumÃ©ricos\nSÃ£o vetores em que cada entrada Ã© um caracter alfanumerico.\n\nespecie = c(\"Deuterodon iguape\", \n            \"Characidium japuhybense\", \n            \"Trichomycterus zonatus\")\nespecie\n\n[1] \"Deuterodon iguape\"       \"Characidium japuhybense\"\n[3] \"Trichomycterus zonatus\" \n\n\nExiste uma variedade de funÃ§Ãµes para manipulaÃ§Ã£o de vetores alfanumÃ©ricos.\nA funÃ§Ã£o sort() por exemplo, aplicada a um vetor numÃ©rico Ã© utilizada para ordenÃ¡-lo de forma crescente:\n\na = c(5,2,15,12)\na\n\n[1]  5  2 15 12\n\nsort(a)\n\n[1]  2  5 12 15\n\n\nou decrescente:\n\nsort(a, decreasing = T)\n\n[1] 15 12  5  2\n\n\nSe aplicada a um vetor alfanumerico esta funÃ§Ã£o ordena o vetor em ordem alfabÃ©tica:\n\nsort(especie, decreasing = FALSE)\n\n[1] \"Characidium japuhybense\" \"Deuterodon iguape\"      \n[3] \"Trichomycterus zonatus\" \n\nsort(especie, decreasing = TRUE)\n\n[1] \"Trichomycterus zonatus\"  \"Deuterodon iguape\"      \n[3] \"Characidium japuhybense\"\n\n\n\n\n3.3 Unindo vetores: comando paste\nSuponha que desejamos unir dois vetores alfanumÃ©ricos\n\nx1 &lt;- c(\"Experimento\")\nx2 &lt;- c(\"A\", \"B\", \"C\")\nx3 &lt;- paste(x1, x2, sep = \"_\")\n\nO mesmo resultado pode ser obtido de forma mais concisa com o comando:\n\nx4 &lt;- paste(\"Experimento\", LETTERS[1:3], sep = \"_\")\nx4\n\n[1] \"Experimento_A\" \"Experimento_B\" \"Experimento_C\"\n\n\n\n\n3.4 Fatores\nFatores sÃ£o como vetores alfanumÃ©ricos, porÃ©m com um atributo adicional. Fatores sÃ£o compostos por diferentes nÃ­veis. Por exemplo, podemos criar o objeto dosagem com o comando:\n\ndosagem &lt;- c(\"Alta\", \"Alta\", \"Alta\", \n            \"Media\", \"Media\", \"Media\", \n            \"Baixa\", \"Baixa\", \"Baixa\")\ndosagem\n\n[1] \"Alta\"  \"Alta\"  \"Alta\"  \"Media\" \"Media\" \"Media\" \"Baixa\" \"Baixa\" \"Baixa\"\n\n\nNo exemplo acima, o R nÃ£o reconhece as palavras Alta, Media e Baixa como diferentes nÃ­veis. Para isto devemos transformÃ¡-lo em um fator:\n\ndosagem &lt;- factor(dosagem)\ndosagem\n\n[1] Alta  Alta  Alta  Media Media Media Baixa Baixa Baixa\nLevels: Alta Baixa Media\n\n\nO objeto dosagem agora Ã© um fator com 3 nÃ­veis.\n\nlevels(dosagem)\n\n[1] \"Alta\"  \"Baixa\" \"Media\"\n\nnlevels(dosagem)\n\n[1] 3\n\nlevels(dosagem)[2]\n\n[1] \"Baixa\"\n\n\nNote entretanto que os nÃ­veis foram reconhecidos em ordem alfabÃ©tica. Se quisermos ordenar este nÃ­veis de outro modo fazemos:\n\ndosagem &lt;- factor(dosagem, ordered = TRUE, \n                 levels = c(\"Baixa\", \"Media\", \"Alta\"))\ndosagem\n\n[1] Alta  Alta  Alta  Media Media Media Baixa Baixa Baixa\nLevels: Baixa &lt; Media &lt; Alta\n\n\nComo veremos a frente, esta operaÃ§Ã£o facilita a visualizaÃ§Ã£o grÃ¡fica de fatores ordenados.\n\n\n3.5 Matrizes\nMatrizes sÃ£o objetos compostos por linhas e colunas. No R, uma matriz pode ser construÃ­da inicialmente criando um vetor numÃ©rico:\n\na &lt;- c(21,26,5,18,17,28,20,15,13,14,27,22)\na\n\n [1] 21 26  5 18 17 28 20 15 13 14 27 22\n\n\nEm seguida o vetor pode ser organizado em uma matriz definindo-se o nÃºmero de linhas e de colunas que sejam compatÃ­veis com o tamanho do vetor. No exemplo acima o vetor tem comprimento 12 e pode ser organizado em uma matriz de \\(3\\) linhas e \\(4\\) colunas:\n\nx &lt;- matrix(a, nrow = 3, ncol = 4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   18   20   14\n[2,]   26   17   15   27\n[3,]    5   28   13   22\n\n\nNote que os elementos foram adicionados um por vez de coluna em coluna. Se quisermos preencher a matriz por linhas adicionamos ao comando, o argumento byrow = TRUE.\n\nx &lt;- matrix(a, nrow = 3, ncol = 4, byrow = TRUE)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28   20   15\n[3,]   13   14   27   22\n\n\nOs elementos de uma matriz podem ser acessados indicando sua posiÃ§Ã£o na linha e na coluna. Por exemplo, o elemento da \\(2^a\\) linha e \\(3^a\\) coluna de x pode ser acessados pelo comando:\n\nx[2, 3]\n\n[1] 20\n\n\nDe modo anÃ¡logo, a \\(2^a\\) linha pode ser acessada por:\n\nx[2, ]\n\n[1] 17 28 20 15\n\n\nE a \\(4^a\\) coluna por:\n\nx[, 4]\n\n[1] 18 15 22\n\n\nValores individuais em matrizes podem ser alterados de forma similar ao que Ã© realizasdo em vetores. Por exemplo, para alterar o elemento da \\(2^a\\) linha e \\(3^a\\) coluna de x por \\(1000\\) fazemos:\n\nx[2, 3] &lt;- 1000\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28 1000   15\n[3,]   13   14   27   22\n\n\nTambÃ©m podemos excluir linhas e colunas de uma matriz.\n\nx[-2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   13   14   27   22\n\nx[,-3]\n\n     [,1] [,2] [,3]\n[1,]   21   26   18\n[2,]   17   28   15\n[3,]   13   14   22\n\n\nNote que, acima, nÃ£o salvamos os resultados da exclusÃ£o das linhas e colunas de x em nenhum objeto, de modo que x continua inalterado.\n\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28 1000   15\n[3,]   13   14   27   22\n\n\nPodemos criar matrizes unindo vetores de tamanho iguais em linhas ou colunas.\n\nx &lt;- 3:12\ny &lt;- 12:3\nrbind(x, y)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\nx    3    4    5    6    7    8    9   10   11    12\ny   12   11   10    9    8    7    6    5    4     3\n\ncbind(x, y)\n\n       x  y\n [1,]  3 12\n [2,]  4 11\n [3,]  5 10\n [4,]  6  9\n [5,]  7  8\n [6,]  8  7\n [7,]  9  6\n [8,] 10  5\n [9,] 11  4\n[10,] 12  3\n\n\nEventualmente, se desejarmos atribuir nomes Ã s linhas e Ã s colunas de uma matriz, podemos fazÃª-lo por meio das funÃ§Ãµes rownames() e colnames() respectivamente:\n\nx_mat &lt;- matrix(1:12, nrow = 3, ncol = 4)\nx_mat\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nrownames(x_mat) &lt;- paste(\"Linha\", 1:3, sep = \"\")\nx_mat\n\n       [,1] [,2] [,3] [,4]\nLinha1    1    4    7   10\nLinha2    2    5    8   11\nLinha3    3    6    9   12\n\ncolnames(x_mat) &lt;- paste(\"Coluna\", 1:4, sep = \"\")\nx_mat\n\n       Coluna1 Coluna2 Coluna3 Coluna4\nLinha1       1       4       7      10\nLinha2       2       5       8      11\nLinha3       3       6       9      12\n\n\n\n\n3.6 Data frames\nAssim como Matrizes, Data frames sÃ£o estruturas que permitem organizar dados em formato de linhas e colunas. No R entanto, as Matrizes nÃ£o podem guardar objetos de diferentes caracterÃ­sticas. Por exemplo, uma matriz pode ser composta inteiramente numÃ©rica:\n\nmatrix(1:12, nrow = 4, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\nOu alfanumÃ©rica:\n\nmatrix(letters[1:12], nrow = 4, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"e\"  \"i\" \n[2,] \"b\"  \"f\"  \"j\" \n[3,] \"c\"  \"g\"  \"k\" \n[4,] \"d\"  \"h\"  \"l\" \n\n\nPorÃ©m, se tentarmos unir um vetor numÃ©rico a um vetor alfanumÃ©rico, toda a matriz serÃ¡ convertida no formato alfanumÃ©rico.\n\nz &lt;- LETTERS[3:12]\nz\n\n [1] \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\"\n\ncbind(x, z)\n\n      x    z  \n [1,] \"3\"  \"C\"\n [2,] \"4\"  \"D\"\n [3,] \"5\"  \"E\"\n [4,] \"6\"  \"F\"\n [5,] \"7\"  \"G\"\n [6,] \"8\"  \"H\"\n [7,] \"9\"  \"I\"\n [8,] \"10\" \"J\"\n [9,] \"11\" \"K\"\n[10,] \"12\" \"L\"\n\n\nPara unir diferentes tipos de vetores devemos usar transformar a matriaz para um objeto do tipo data.frame que cria uma estrutura com colunas independentes, permitindo que estas tenham diferentes formatos. Podemos unir os objetos x e z acima em um data frame como segue:\n\ndata.frame(x, z)\n\n    x z\n1   3 C\n2   4 D\n3   5 E\n4   6 F\n5   7 G\n6   8 H\n7   9 I\n8  10 J\n9  11 K\n10 12 L\n\n\nNote que automaticamente, a funÃ§Ã£o atribui nomes as colunas (x e z) e Ã s linhas (\\(1\\) a 10). Estes nomes podem ser alterados com as funÃ§Ãµes rownames() e colnames().\nNeste caso, a coluna x continua sendo numÃ©rica e a coluna z continua alfanumÃ©rica.\nPodemos acessar os elementos de um data frame do mesmo modo que fizemos para matrizes.\nPodemos criar um data frame diretamente:\n\nDados &lt;- data.frame(Regiao = factor(c(\"Santos\", \"Santos\", \n                                     \"Bertioga\", \"Bertioga\", \n                                     \"Peruibe\", \"Peruibe\")),\n                   Especie_A = c(12,43,80,91,75,115), \n                   Especie_B = c(0, 59, 300, 350, 154, 200))\n\nE acessÃ¡-lo de diferentes formas:\n\nDados\n\n    Regiao Especie_A Especie_B\n1   Santos        12         0\n2   Santos        43        59\n3 Bertioga        80       300\n4 Bertioga        91       350\n5  Peruibe        75       154\n6  Peruibe       115       200\n\nDados$Regiao\n\n[1] Santos   Santos   Bertioga Bertioga Peruibe  Peruibe \nLevels: Bertioga Peruibe Santos\n\nDados[\"Regiao\"]\n\n    Regiao\n1   Santos\n2   Santos\n3 Bertioga\n4 Bertioga\n5  Peruibe\n6  Peruibe\n\nDados[,\"Regiao\"]\n\n[1] Santos   Santos   Bertioga Bertioga Peruibe  Peruibe \nLevels: Bertioga Peruibe Santos\n\nDados[,c(\"Especie_A\",\"Especie_B\")]\n\n  Especie_A Especie_B\n1        12         0\n2        43        59\n3        80       300\n4        91       350\n5        75       154\n6       115       200\n\n\n\n\n3.7 Listas\nCombinam em um Ãºnico objeto todas as estruturas anteriores. Veja o exemplo em que combinamos um vetor alfanumÃ©rico, um vetor nominal e um data frame dentro da mesma lista.\n\nnossalista &lt;- list(Ilha = c(\"Ilhabela\", \"Anchieta\", \"Cardoso\"), \n                  Areaskm2 = c(347.5, 8.3, 131), \n                  Localizacao = data.frame(\n                    Bioma = rep(\"Mata Atlantica\", 3),\n                  Lat = c(23, 25, 23),\n                  Long = c(45, 47, 45)))\nnossalista\n\n$Ilha\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\n$Areaskm2\n[1] 347.5   8.3 131.0\n\n$Localizacao\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45\n\n\nPodemos ainda inserir listas dentro de outras listas, criando estruturas altamente complexas.\nPara acessar os elementos de uma lista podemos identificar seu nome apÃ³s o operador $ ou sua posiÃ§Ã£o das formas que se seguem:\n\nnossalista$Ilha\n\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\nnossalista[[1]]\n\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\nnossalista$Localizacao\n\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45\n\nnossalista[[3]]\n\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#operadores-relacionais",
    "href": "content/introducao-r/estrutura-linguagem.html#operadores-relacionais",
    "title": "Estrutura da linguagem",
    "section": "4 Operadores relacionais",
    "text": "4 Operadores relacionais\nOperadores relacionais sÃ£o aqueles de verificam as relaÃ§Ãµes de menor que (&lt;), maior que (&gt;), menor ou igual (&lt;=), maior ou igual (&gt;=), igual a (==) ou diferente de (!=). O resultado de uma comparaÃ§Ã£o retorna um objeto com o argumento verdadeiro (TRUE) ou falso (FALSE). Veja por exemplo:\n\n3 &gt; 5\n\n[1] FALSE\n\n\n\n3 &gt; 3\n\n[1] FALSE\n\n\n\n3 &gt;= 3\n\n[1] TRUE\n\n\n\na &lt;- 5\nb &lt;- 7\na == b\n\n[1] FALSE\n\na != b\n\n[1] TRUE\n\n\nSe os objetos tÃªm mais de um elemento, no caso de vetores, matrizes ou data frames, a comparaÃ§Ã£o Ã© feita elemento-a-elemento, comparando aqueles que estÃ£o na mesma posiÃ§Ã£o, ou seja, os que tÃªm o mesmo Ã­ndice de posiÃ§Ã£o.\n\na &lt;- c(3,5,5,7,1)\nb &lt;- c(3,6,1,9,-3)\na &lt; b\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n\nOs operadores TRUE e FALSE, quanto utilizados em operaÃ§Ãµes aritmÃ©ticas se comportam respectivamente como valores 1 e 0.\n\na &lt;- 5\nb &lt;- c(3,6,1,9,-3)\ny &lt;- b &gt; a\ny\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n\nSomando os elementos de y temos o nÃºmero de elementos que atendendem Ã  condiÃ§Ã£o acima:\n\nsum(y)\n\n[1] 2\n\n\nE se tirarmos a mÃ©dia aritmÃ©tica, teremos a proporÃ§Ã£o de 1â€™s no vetor y.\n\nmean(y)\n\n[1] 0.4\n\n\n\n\n\n\n\n\nNota\n\n\n\nLembre-se que ao compararmos vetores de tamanhos distintos, o R nÃ£o retorna um erro, mas recicla os elementos do vetor menor para compensar elementos faltantes."
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#operadores-lÃ³gicos",
    "href": "content/introducao-r/estrutura-linguagem.html#operadores-lÃ³gicos",
    "title": "Estrutura da linguagem",
    "section": "5 Operadores lÃ³gicos",
    "text": "5 Operadores lÃ³gicos\nOperadores lÃ³gicos sÃ£o os de NEGAÃ‡ÃƒO (!), E lÃ³gico, OU lÃ³gico versÃ£o vetorizada (|) e OU exclusivo (xor()). Exemplos destes operadores sÃ£o:\n\nx &lt;- 3:5\ny &lt;- 5:3\n\n\n(x &lt; 4)\n\n[1]  TRUE FALSE FALSE\n\n!(x &lt; 4)\n\n[1] FALSE  TRUE  TRUE\n\n\n\n(x &lt; 4) & (y &gt; 4)\n\n[1]  TRUE FALSE FALSE\n\n\n\n(x &lt; 4) | (y &gt; 4)\n\n[1]  TRUE FALSE FALSE\n\n\n\nxor(x,y)\n\n[1] FALSE FALSE FALSE"
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html",
    "href": "content/inferencia-estatistica/int-conf.html",
    "title": "Estimando a mÃ©dia populacional",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizados\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')"
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html#estimaÃ§Ã£o-pontual-e-estimaÃ§Ã£o-intervalar",
    "href": "content/inferencia-estatistica/int-conf.html#estimaÃ§Ã£o-pontual-e-estimaÃ§Ã£o-intervalar",
    "title": "Estimando a mÃ©dia populacional",
    "section": "1 EstimaÃ§Ã£o pontual e estimaÃ§Ã£o intervalar",
    "text": "1 EstimaÃ§Ã£o pontual e estimaÃ§Ã£o intervalar\nA mÃ©dia \\(\\overline{X}\\) obtida a partir de uma determinada amostra varia em funÃ§Ã£o das caracterÃ­sticas das unidades amostrais que foram selecionadas. Portanto, \\(\\overline{X}\\) nÃ£o serÃ¡ igual Ã  mÃ©dia \\(\\mu\\). No entanto, o TLC nos garante que a distribuiÃ§Ã£o esperada das mÃ©dias amostrais terÃ¡ uma distribuiÃ§Ã£o normal e que a mÃ©dia das mÃ©dias (\\(\\mu_{\\overline{X}}\\)) serÃ¡ igual a \\(\\mu\\). Vimos ainda que o desvio padrÃ£o da distribuiÃ§Ã£o das mÃ©dias amostrais (conhecido como erro padrÃ£o - \\(\\sigma_{\\overline{X}}\\)) dependerÃ¡ do tamanho da amostra \\(n\\), de acordo com a expressÃ£o:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nUma vez que nÃ£o conhecemos \\(\\mu\\), temos que estimÃ¡-lo a partir da amostra. Neste caso, \\(\\overline{X}\\) serÃ¡ nossa melhor estimativa da mÃ©dia populacional. Dizemos que \\(\\overline{X}\\) Ã© o estimador pontual de \\(\\mu\\).\nComo \\(\\overline{X}\\) varia em funÃ§Ã£o de nossa amostra particular, devemos obter alÃ©m da estimativa pontual, uma estimativa intervalar que nos Ã© fornecida pelo intervalo de confianÃ§a.\n\n1.1 Intervalo de confianÃ§a\n\n\n\n\n\n\nNotaIntervalo de confianÃ§a: definiÃ§Ã£o\n\n\n\nÃ‰ o intervalo de valores associado a um determinado nÃ­vel de significÃ¢ncia (\\(\\alpha\\)). Quando dizemos que um intervalo foi calculado a um nÃ­vel de confianÃ§a de \\(95\\%\\) (\\(1 - \\alpha\\)), estamos dizendo que a probabilidade do IC conter o valor da mÃ©dia populacional \\(\\mu\\) Ã© de \\(95\\%\\).\n\n\nO IC Ã© calculado por:\n\\[IC_{1-\\alpha} = \\mu \\pm z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO valor de \\(z_{\\alpha/2}\\) Ã© o valor do Ã­ndice \\(z\\) associado ao nÃ­vel de confianÃ§a desejado.\nSe desejamos definir o intervalo de confianÃ§a a 95% precisamos garantir que haja uma probabilidade de 95% de que a mÃ©dia amostral esteja ao redor da mÃ©dia populacional. Deste modo, o limite deve excluir 2.5% da porÃ§Ã£o superior e 2.5% da porÃ§Ã£o inferior da curva. Para isto, definimos \\(z_{\\alpha/2} = 1.96\\), sendo \\(\\alpha\\) fixado em 0.05.\n\nO valor \\(z_{\\alpha/2} = 1.96\\) foi retirado da Tabela \\(Z\\) como o mÃ³dulo do valor de \\(z\\) que delimida uma Ã¡rea inferior igual a \\(0.025\\).\n\nSe queremos um nÃ­vel de confianÃ§a diferente, basta ajustar o valor de \\(\\alpha\\). Por exemplo, se queremos um nÃ­vel de significÃ¢ncia a 99%, fixamos \\(\\alpha\\) em \\(0.01\\) e portanto \\(z = 2.58\\). Da mesma forma, o \\(IC_{90\\%}\\) poderÃ¡ ser obtido com \\(\\alpha = 0.10\\) e consequentemente \\(z = 1.64\\). Estes e outros limites descrevem as probabilidades em uma distribuiÃ§Ã£o normal padronizada, que podem ser obtidos com o uso da maioria dos softwares estatÃ­sticos, alÃ©m de estarem incluso na Tabela Z, encontrada na grande maioria dos livros de estatÃ­stica bÃ¡sica.\n\n\nCÃ³digo\n# Ver funÃ§Ã£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\n\n\n\nFiguraÂ 1: Ãreas de probabilidade em uma distribuiÃ§Ã£o Normal Padronizada (DistribuiÃ§Ã£o Z).\n\n\n\n\n\nPara o cÃ¡lculo do intervalo de confianÃ§a, assumimos que as mÃ©dias amostrais seguem uma distribuiÃ§Ã£o normal com mÃ©dia \\(\\mu\\) e desvio padrÃ£o \\(\\frac{\\sigma}{\\sqrt{n}}\\). Ao fazer isso, estamos aplicando o Teorema Central do Limite (TCL). Geralmente, nÃ£o temos os valores de \\(\\mu\\) e \\(\\sigma\\), por isso utilizamos os valores de \\(\\overline{X}\\) e \\(s\\), calculados a partir de nossa amostra. Quando o tamanho das amostras Ã© grande (\\(n \\geq 30\\)), Ã© aceitÃ¡vel utilizar o valor de \\(z_{\\alpha/2}\\). Assim::\n\\[IC_{1-\\alpha} = \\overline{X} \\pm z_{\\alpha/2} \\times \\frac{s}{\\sqrt{n}}\\]\n\n1.1.1 DistribuiÃ§ao \\(t\\) de Student: \\(\\mu\\) e \\(\\sigma\\) desconhecidos\nQuando nÃ£o conhecemos \\(\\mu\\) e \\(\\sigma\\) e as amostras sÃ£o pequenas (ex. \\(n&lt;30\\)), a dsitribuiÃ§Ã£o normal nÃ£o Ã© a melhor aproximaÃ§Ã£o para o comportamento das mÃ©dias amostrais. Nestes casos, substituÃ­mos a distribuiÃ§Ã£o de \\(z\\) pela DistribuiÃ§Ã£o \\(t\\) de Student, sendo o intervalo de confianÃ§a obtido por:\n\\[IC_{1-\\alpha} = \\overline{X} \\pm t_{\\alpha/2, gl} \\times \\frac{s}{\\sqrt{n}}\\]\nEm que \\(\\alpha\\) continua sendo o nÃ­vel de significÃ¢ncia e \\(gl\\) Ã© definido como os graus de liberdade. Neste caso, os graus de liberdade sÃ£o dados por:\n\\[gl = n-1\\]\nO formato da distribuiÃ§Ã£o \\(t\\) de student nÃ£o Ã© constante. Ã€ medida que o tamanho amostral aumenta, o formado da distribuiÃ§Ã£o \\(t\\) converge para a distribuiÃ§Ã£o normal. Isto faz com que na prÃ¡tica raremente se utiliza a distribuiÃ§Ã£o \\(Z\\), substituindo-a pela distribuiÃ§Ã£o \\(t\\) de Student.\n\n\n\n\n\n\n\n\nFiguraÂ 2: FunÃ§Ã£o de densidade de t para diferentes graus de liberdade.\n\n\n\n\n\nPara amostras pequenas (\\(n = 2\\)) o formato da distribuiÃ§Ã£o de \\(t\\) Ã© distinto da distribuiÃ§Ã£o normal. No entanto, para tamanhos amostrais maiores (\\(n = 30\\)) as o formato da distribuiÃ§Ã£o \\(t\\) tende a a convergir para o mesmo formato a distribuiÃ§Ã£o normal. Esta caracterÃ­stica implica que a Ã¡rea a partir de um determinado limite \\(t_i\\) nÃ£o Ã© constante como na distribuiÃ§Ã£o normal, mas depende do tamanho da amostra, como pode ser visto abaixo.\n\n\n\n\n\n\n\n\nFiguraÂ 3: FunÃ§Ã£o de densidade de t para diferentes graus de liberdade."
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html#introduÃ§Ã£o-Ã -suficiÃªncia-amostral",
    "href": "content/inferencia-estatistica/int-conf.html#introduÃ§Ã£o-Ã -suficiÃªncia-amostral",
    "title": "Estimando a mÃ©dia populacional",
    "section": "2 IntroduÃ§Ã£o Ã  suficiÃªncia amostral",
    "text": "2 IntroduÃ§Ã£o Ã  suficiÃªncia amostral\nUma decisÃ£o central ao planejamento de um experimento Ã© quanto recurso (ex. tempo, dinheiro, mÃ£o de obra) devem ser investidos para se obter boas estimativas dos parÃ¢metros populacionais. Por boas estimativas, entendemos amostras precisas, ou seja, que podem ser definida por amostras com baixo erro padrÃ£o e acuradas, que em mÃ©dia apontem para o verdadeiro valor do parÃ¢metro. Neste caso, uma das primeiras questÃµes a ser feita Ã© â€œQual tamanho amostral aplicar em meu estudo?â€.\nVimos que aumentar o tamanho amostral resulta em estimativas mais precisas, isto Ã© com menor erro padrÃ£o. Portanto, um bom delineamento amostral Ã© aquele que permita, a um custo mÃ­nimo, obter estimativas com a precisÃ£o desejada. Uma pesquisa que resulte em estimativas demasiadamente imprecisas pode se mostrar inÃºtil. O que dizer por exemplo, se um estudo conclui que o comprimento mÃ©dios de uma espÃ©cie de pescado Ã© de \\(35\\) cm com uma incerteza a \\(95\\%\\) entre \\(15\\) e \\(55\\) cm? Uma estimativa com tal nÃ­vel de imprecisÃ£o nÃ£o terÃ¡ qualquer implicaÃ§Ã£o prÃ¡tica.\nPor outro lado, partir de um determinado tamanho amostral o ganho em precisÃ£o torna-se mÃ­nimo. Isto significa que amostras demasiadamente grandes podem ter um custo muto alto porÃ©m nÃ£o serem capazes aumentar de forma relevante a precisÃ£o do experimento.\nVeja o que ocorre com o erro padrÃ£o de uma amostra Ã  medida que aumenta o tamanho \\(n\\).\n\n\n\n\n\n\n\n\nFiguraÂ 4: Efeito do aumento do tamanho amostral n sobre o erro padrÃ£o da mÃ©dia.\n\n\n\n\n\nNeste exemplo, para amostras de tamanho 1, \\(\\sigma_{\\overline{X}} = 4\\). Se tivermos agora amostras de tamanho 10, \\(\\sigma_{\\overline{X}} = 1.2\\), uma reduÃ§Ã£o de mais de 50%. No entanto aumentarmos o tamanho amostral para 50 o erro padrÃ£o cai somente de \\(1,2\\) para \\(0,56\\). Isto significa que a partir de determinado ponto (neste exemplo a partir de \\(10\\) ou \\(20\\) amostras), a reduÃ§Ã£o no erro padrÃ£o torna-se mÃ­nima. Neste momento podemos podemos refletir sobre o custo de continuar aumentando o tamanho amostral para obter um ganho cada vez menor em precisÃ£o.\nPara encontrarmos o tamanho amostral desejado, devemos decidir sobre dois pontos: i - que nÃ­vel de acurÃ¡cia desejado, ou seja, quÃ£o distante do valor real (mÃ©dia populacional) queremos que nossa esimativa esteja; e ii - qual o nÃ­vel de confianÃ§a do resultado, ou seja, com que precisÃ£o queremos fazer esta estimativa.\n\n2.1 NÃ­vel de acurÃ¡cia desejado (margem de erro) e nÃ­vel de confianÃ§a na estimativa\nO nÃ­vel de acurÃ¡cia desejado Ã© comumente conhecido com margem de Erro (E), definida como diferenÃ§a mÃ¡xima provÃ¡vel (com probabilidade \\(1-\\alpha\\)) entre a mÃ©dia amostral e a mÃ©dia populacional.\nA margem de erro para a mÃ©dia amostral pode ser obtida por (compare esta expressÃ£o com a do intervalo de confianÃ§a):\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO nÃ­vel de confianÃ§a na estimativa nos garante que nossa estimativa estarÃ¡ dentro da margem de erro assumida com probabilidade \\(1-\\alpha\\). Como vimos acima, valores tÃ­picos para o nÃ­vel de confianÃ§a sÃ£o \\(99\\%\\), \\(95\\%\\) e \\(90\\%\\).\nUma representaÃ§Ã£o esquemÃ¡tica do erro amostral e do nÃ­vel de confianÃ§a na distribuiÃ§Ã£o de \\(z\\) pode ser vista abaixo:\n\n\n\n\n\n\n\n\nFiguraÂ 5: Erro amostra e nÃ­vel de confianÃ§a na distribuiÃ§Ã£o Z.\n\n\n\n\n\nA definiÃ§Ã£o da margem de erro e do nÃ­vel de confianÃ§a depende de estimativas prÃ©vias dos parÃ¢metros populacionais \\(\\mu\\) e \\(\\sigma\\). Estas estimativas podem ser obtidas na literatura, buscando estudos similares, ou por meio de um projeto piloto. Em um experimento piloto, o pesquisador irÃ¡ conduzir seu plano de amostragem com um tamanho mÃ­nimo, justamente para avaliar a eficiÃªncia metodolÃ³gica, adequabilidade dos resultados e prever o esforÃ§o amostral adequado. As informaÃ§Ãµes de um pequeno estudo piloto, se bem aproveitadas, podem evitar erros simples de delineamento, alÃ©m de invariavelmente, permitir economia de recusros e consequentemente ganho em qualidade.\n\n\n2.2 Determinando o tamanho de uma amostra\nPodemos voltar a nossa questÃ£o anterior sobre Qual tamanho amostral aplicar em meu estudo?. Esta questÃ£o pode ser reformulada como:\n\nQual tamanho amostral aplicar para obter uma estimativa de \\(\\mu\\) que possua uma margem de erro \\(E\\) e nivel de confianÃ§a \\(1-\\alpha\\) prÃ©-determinados.\n\nIniciando com a fÃ³rmula da margem de erro:\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nisolamos a variÃ¡vel \\(n\\) para obter:\n\\[n = (\\frac{ z_{\\alpha/2} \\times \\sigma}{E})^2\\]\nNovamente, uma vez que nÃ£o conhecemos o desvio padrÃ£o populacional \\(\\sigma\\) podemos substituÃ­-lo pelo desvio padrÃ£o (\\(s\\)) de um experimento piloto ou estimÃ¡-lo a partir da literatura.\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/amostragem/pop-amostra.html",
    "href": "content/amostragem/pop-amostra.html",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas no capÃ­tulo\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(knitr)"
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#populaÃ§Ã£o-amostra-e-unidade-amostral",
    "href": "content/amostragem/pop-amostra.html#populaÃ§Ã£o-amostra-e-unidade-amostral",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "1 PopulaÃ§Ã£o, amostra e unidade amostral",
    "text": "1 PopulaÃ§Ã£o, amostra e unidade amostral\nUma populaÃ§Ã£o estatÃ­stica sÃ£o todos os elementos sobre os quais queremos tirar conclusÃµes. Refere-se ao conjunto de medidas que podem ser mensuradas como resultado de um experimento. As medidas que compÃµem a populaÃ§Ã£o estatÃ­stica podem ser pesos, temperaturas, velocidades, tempos de reaÃ§Ã£o, entre outras, a depender das caracterÃ­sticas de um estudo particular. Uma populaÃ§Ã£o estatÃ­stica pode ser finita ou infinita. Quando Ã© finita, o nÃºmero de elementos Ã© dado por \\(N\\). O termo populaÃ§Ã£o nÃ£o pode ser confundido com seu uso do dia-a-dia, quando refere-se a conjuntos de pessoas ou de organismos, nem mesmo com os elementos fÃ­sicos nos quais as variÃ¡veis foram mensuradas.\nA abrangÃªncia da populaÃ§Ã£o estatÃ­stica depende do contexto e do escopo da pergunta que se pretende responder.\n\nExemplo 1: Suponha um estudo para descrever o comprimento do lambari Deuterodon iguape em riachos do litoral de SÃ£o Paulo. A populaÃ§Ã£o estatÃ­stica nÃ£o sÃ£o os peixes em si, mas o comprimento de cada indivÃ­duo que habita os riachos destas bacias. Dado o escopo do estudo (bacias do litoral de SÃ£o Paulo), a populaÃ§Ã£o estatÃ­stica abrange somente comprimentos dos organismos existem nesta regiÃ£o.\nExemplo 2: Suponha agora que desejamos estudar a diversidade de espÃ©cies de peixes em bacias costeiras do litoral de SÃ£o Paulo. Neste caso, a populaÃ§Ã£o estatÃ­stica seria constituida de um Ã­ndice de diversidade calculado para cada uma das bacias costeiras do litoral. Fica claro que, neste caso, populaÃ§Ã£o estatÃ­stica nÃ£o se refere a populaÃ§Ã£o biolÃ³gica, mas sim a variÃ¡vel que foi mensurada a partir do conjunto de espÃ©cies que habitam cada bacia.\n\nNestes dois exemplos Ã© inviÃ¡vel obter informaÃ§Ãµes de todos os elementos que compÃµem a populaÃ§Ã£o estaÃ­stica. No caso dos comprimentos, nÃ£o temos como capturar todos os animais presentes em uma bacia hidrogrÃ¡fica, mas ainda que tivÃ©ssemos seria inviÃ¡vel medir todos, pois existem provavelmente alguns milhares de peixes somente em um pequeno trecho de riacho. JÃ¡ o nÃºmero de Bacias costeiras no litoral do Estado de SÃ£o Paulo Ã© bem menor, porÃ©m ainda seria inviÃ¡vel mensurar a diversidade de espÃ©cies em todas elas.\nUm censo ocorre nos raros exemplos em que Ã© possÃ­vel mensurar todos os elementos da populaÃ§Ã£o estatÃ­stica. Entretanto, a prÃ¡tica cientÃ­fica lida com a maioria dos casos em que mensuramos um subconjunto da populaÃ§Ã£o estatÃ­stica, definido como uma amostra. O tamanho da amostra Ã© denominado de \\(n\\).\nFinalmente, unidade amostral Ã© definida como um Ãºnico elemento da populaÃ§Ã£o estatÃ­stica. A unidade amostral Ã© uma determinada observaÃ§Ã£o da variÃ¡vel de interesse. No exemplo dos lambaris, unidade amostral Ã© o comprimento mensurado em um indivÃ­duo da espÃ©cie de interesse, enquanto no exemplo das bacias costeiras, as unidades amostrais sÃ£o cada um dos valores de diversidade calculados para cada bacia costeira.\n\n\n\n\n\n\nNotaDEFINIÃ‡Ã•ES\n\n\n\nPopulaÃ§Ã£o estatÃ­stica: todos os elementos que podem compor uma amostra. Podem ser medidas como comprimentos, temperaturas, velocidades, etc.\nUnidade amostral: um Ãºnico elemento da populaÃ§Ã£o.\nCenso: o levantamento de todos os elementos da populaÃ§Ã£o.\nAmostra: um subconjunto extraÃ­do da populaÃ§Ã£o.\nTamanho populacional (N): o nÃºmero de elementos da populaÃ§Ã£o.\nTamanho amostral (n): o nÃºmero de elementos da amostra."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribuiÃ§Ã£o-de-frequÃªncias-na-populaÃ§Ã£o-estatÃ­stica",
    "href": "content/amostragem/pop-amostra.html#distribuiÃ§Ã£o-de-frequÃªncias-na-populaÃ§Ã£o-estatÃ­stica",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "2 DistribuiÃ§Ã£o de frequÃªncias na populaÃ§Ã£o estatÃ­stica",
    "text": "2 DistribuiÃ§Ã£o de frequÃªncias na populaÃ§Ã£o estatÃ­stica\nOs valores em uma populaÃ§Ã£o estatÃ­stica nÃ£o sÃ£o idÃªnticos, de modo que poderÃ­amos descrevÃª-los por meio de uma distribuiÃ§Ã£o de frequÃªncia, em que algumas faixas de valores sÃ£o mais frequentes que outras. Os comprimentos de Deuterodon iguape por exemplo devem variar de alguns milÃ­metros (pÃ³s-larva) a cerca de 20 cm (adulto), em que nem todos os comprimentos sÃ£o igualmente representados. Certamente, existem mais lambaris pequenos e mÃ©dios do que lambaris grandes. De fato, animais muito grandes sÃ£o os mais raros, de modo que se tivÃ©ssemos informaÃ§Ã£o da populaÃ§Ã£o estatÃ­stica, verÃ­amos que faixas de valores muito elevados se tornariam cada vez menos frequentes.\nSe fosse possÃ­vel observar todos os elementos da populaÃ§Ã£o estatÃ­stica, saberÃ­amos exatamente qual o formato de sua distribuiÃ§Ã£o de frequÃªncias. Suponha por exemplo, a altura de adultos acima de 18 anos. Seria razoÃ¡vel supor que a maioria das alturas consiste de valores intermediÃ¡rios ao redor de, por exemplo, 170 centÃ­metros. Ã‰ razoÃ¡vel supor tambÃ©m que a frequÃªncia de pessoas muito altas ou muito baixas vai diminuindo gradativamente, de modo que Ã© muito raro encontrarmos adultos muito altos (ex. acima de \\(200\\) centÃ­metros) ou muito baixos (ex. menores que \\(150\\) centÃ­metros). A figura abaixo, descreve uma distribuiÃ§Ã£o de frequÃªncia de uma populaÃ§Ã£o fictÃ­cia de exatamente \\(N = 1000\\) alturas.\n\n\nCÃ³digo\nmu = 170\nsd = 10\nN = 1000\nset.seed(1)\nadultos = data.frame(\n  CP = round(rnorm(n = N, mean = mu, sd = sd),2)\n  )\n\nplt_pop = ggplot(adultos, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', \n                 color = 'black', bins = 20) +\n   labs(x = \"Alturas em centÃ­metros\",\n        y = \"FrequÃªncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 200, by = 20)) +\n  coord_cartesian(ylim = c(0, 200), xlim = c(130, 220)) +\n  theme_classic(base_size = 15)\n\n\n\n\nCÃ³digo\nplt_pop +\n  annotate(geom = 'text', x = 130, y = 175, \n           label = deparse(bquote('N' == .(N))), parse = TRUE, hjust = 0, size = 7) +\n  annotate(geom = 'text', x = 130, y = 155, \n           label = deparse(bquote(mu == .(mu) ~ 'm')), parse = TRUE, hjust = 0, size = 7)\n\n\n\n\n\n\n\n\nFiguraÂ 1: DistribuiÃ§Ã£o de uma populaÃ§Ã£o estatÃ­stica representando as alturas (em centÃ­metros) de adultos acima de 18 anos.\n\n\n\n\n\nVemos que existem mais valores entre \\(160\\) e \\(180\\) e poucas observaÃ§Ãµes extremas. Por exemplo, das \\(1000\\) observaÃ§Ãµes, apenas 27 mais extremas que \\(190\\) cm, o que Ã© condizente com nossa expectativa para a distribuiÃ§Ã£o de frequÃªncias das alturas de indivÃ­duos adultos."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribuiÃ§Ã£o-de-probabilidade-da-populaÃ§Ã£o-estatÃ­stica",
    "href": "content/amostragem/pop-amostra.html#distribuiÃ§Ã£o-de-probabilidade-da-populaÃ§Ã£o-estatÃ­stica",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "3 DistribuiÃ§Ã£o de probabilidade da populaÃ§Ã£o estatÃ­stica",
    "text": "3 DistribuiÃ§Ã£o de probabilidade da populaÃ§Ã£o estatÃ­stica\nNa prÃ¡tica, como nÃ£o temos acesso a toda a populaÃ§Ã£o estatÃ­stica, nÃ£o temos como visualizar toda a sua distribuiÃ§Ã£o de frequÃªncia. Dizemos portanto, que conhecemos a populaÃ§Ã£o estatÃ­stica quando conhecemos a funÃ§Ã£o de probabilidades associada a variÃ¡vel que estÃ¡ sendo mensurada. No exemplo da FiguraÂ 1, dirÃ­amos que a variÃ¡vel altura segue uma distribuiÃ§Ã£o normal de probabilidades. Quando descrevemos uma distribuiÃ§Ã£o de probabilidades, precisamos caracterizÃ¡-la por meio de certas quantidades, ou parÃ¢metros da distribuiÃ§Ã£o. Na distribuiÃ§Ã£o normal, os parÃ¢metros de interesse sÃ£o a mÃ©dia \\(\\mu\\) e o desvio padrÃ£o \\(\\sigma\\). No exemplo das alturas, \\(\\mu = 170\\) e \\(\\sigma = 10\\)."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribuiÃ§Ãµes-de-frequÃªncias-na-amostra",
    "href": "content/amostragem/pop-amostra.html#distribuiÃ§Ãµes-de-frequÃªncias-na-amostra",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "4 DistribuiÃ§Ãµes de frequÃªncias na amostra",
    "text": "4 DistribuiÃ§Ãµes de frequÃªncias na amostra\n\n\nCÃ³digo\nn = 50\nset.seed(2)\nselecao = sample(N, size = n)\nAm1 = sort(adultos$CP[selecao], decreasing = FALSE)\n\n\nAinda que nÃ£o tenhamos acesso a toda populaÃ§Ã£o estatÃ­stica, gostarÃ­amos de ter informaÃ§Ãµes sobre a variÃ¡vel de interesse. Utilizamos o processo de amostragem para obter estas informaÃ§Ãµes.\nSuponha, uma amostra de \\(n = 50\\) adultos. Se organizarmos esta amostra em valores crescentes terÃ­amos:\n140.03, 151.5, 152.13, 152.91, 154.07, 158.14, 158.32, 159.59, 159.69, 160.14, 160.42, 160.46, 161.48, 161.89, 162.05, 163.11, 163.59, 163.77, 165.36, 166.11, 166.38, 166.69, 166.76, 167.03, 168.55, 169.72, 170.56, 172.17, 172.94, 173.8, 173.92, 174.34, 174.5, 175.24, 175.76, 175.95, 176.16, 177.13, 177.63, 177.66, 178.03, 178.48, 180.96, 180.97, 183.94, 184.17, 187.54, 187.64, 188.87, 191.69\nOs valores estÃ£o entre \\(140.03\\) e \\(191.69\\), o que certamente nÃ£o Ã© igual aos valores mÃ¡ximos e mÃ­nimos da populaÃ§Ã£o. Vamos representar esta amostra por meio de um histograma.\n\n\nCÃ³digo\namostra_df = data.frame(CP = adultos$CP[selecao]) \nggplot(amostra_df, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 15) +\n   labs(x = \"Alturas em centÃ­metros\",\n        y = \"FrequÃªncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 10, by = 1)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 10)) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nFiguraÂ 2: Amostra de tamanho n = 50 da populaÃ§Ã£o estatÃ­stica de alturas.\n\n\n\n\n\nAinda que a distribuiÃ§Ã£o da amostra nÃ£o seja igual Ã  da populaÃ§Ã£o estatÃ­stica, podemos perceber que hÃ¡ uma concentraÃ§Ã£o de valores justamente entre \\(160\\) cm e \\(180\\) cm, assim como na populaÃ§Ã£o estatÃ­stica.\nA diferenÃ§a entre a distribuiÃ§Ã£o da populaÃ§Ã£o e a distribuiÃ§Ã£o da amostra Ã© esperada e ocorre porque estamos observando um subconjunto particular de elementos. Deste modo, sempre que amostrarmos uma populaÃ§Ã£o estatÃ­stica, teremos uma amostra ligeiramente diferente.\nVamos verificar por exemplo, as distribuiÃ§Ãµes de frequÃªncia de seis amostras possÃ­ves de tamanho \\(n = 50\\) desta mesma populaÃ§Ã£o.\n\n\nCÃ³digo\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em centÃ­metros\",\n         y = \"FrequÃªncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n  scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\n\n\n\nFiguraÂ 3: Seis diferentes amostra de tamanho n = 50 da populaÃ§Ã£o estatÃ­stica de alturas.\n\n\n\n\n\nCada amostra resulta em distribuiÃ§Ãµes diferentes, mas em todas a frequÃªncia de observaÃ§Ãµes na faixa intermediÃ¡ria Ã© maior. O processo de amostragem nos forneceu portanto amostras representativas da populaÃ§Ã£o estatÃ­stica, isto Ã©, amostras em que a distribuiÃ§Ã£o de frequÃªncias se aproximou da distribuiÃ§Ã£o de frequÃªncias da populaÃ§Ã£o.\nNeste exemplo fictÃ­cio, como conhecemos a populaÃ§Ã£o estatÃ­stica Ã© fÃ¡cil verificar que as amostras foram representativas. Na prÃ¡tica cientÃ­fica nÃ£o conhecemos a populaÃ§Ã£o estatÃ­stica e, consequentemente, nÃ£o temos como saber se a nossa amostra em particular foi ou nÃ£o representativa.\nDevemos portanto conduzir o processo de tal forma que a teoria da amostragem nos garanta que a amostra resultante de um determinado experimento seja, em mÃ©dia, representativa da populaÃ§Ã£o. O modo mais simples de garantir este comportamento Ã© realizarmos uma amostra aleatÃ³ria dos elementos da populaÃ§Ã£o estatÃ­stica."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#parÃ¢metros-e-estimadores",
    "href": "content/amostragem/pop-amostra.html#parÃ¢metros-e-estimadores",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "5 ParÃ¢metros e estimadores",
    "text": "5 ParÃ¢metros e estimadores\nA populaÃ§Ã£o estatÃ­stica tem determinadas quantias de interesse que definimos como parÃ¢metros da populaÃ§Ã£o. Se fosse possÃ­vel medir as alturas dos \\(N = 1000\\) adultos, poderÃ­amos calcular a mÃ©dia da populaÃ§Ã£o. Seja uma variÃ¡vel \\(X\\) composta por \\(X_1, X_2, X_3, \\cdots , X_N,\\), a mÃ©dia da populaÃ§Ã£o estatÃ­stica Ã© denominada de \\(\\mu\\) e definida por:\n\\[\\mu=\\frac{X_1+X_2+X_3+\\cdots+X_N}{N}=\\frac{\\sum_{i=1}^N{X_i}}{N}\\] Como nÃ£o temos acesso a toda a populaÃ§Ã£o nÃ£o podemos obter \\(\\mu\\), mas podemos estimÃ¡-lo por meio de uma amostra. Neste caso, seja uma amostra de tamanho \\(n\\) composta por \\(X_1, X_2, X_3, \\cdots, X_n\\), a mÃ©dia da amosta Ã© denominada de \\(\\overline{X}\\) e definida por:\n\\[\\overline{X}=\\frac{X_1+X_2+X_3+\\cdots+X_n}{n}=\\frac{\\sum_{i=1}^n{X_i}}{n}\\]\nDizemos que \\(\\overline{X}\\) Ã© um estimador nÃ£o viciado de \\(\\mu\\).\nComo os valores da populaÃ§Ã£o estatÃ­stica nÃ£o sÃ£o idÃªnticos, podemos obter uma medida de dispersÃ£o como a variÃ¢ncia populacional (\\(\\sigma^2\\)) definida por:\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N}\\]\nNovamente, como nÃ£o temos acesso a todos os \\(N\\) elementos, podemos apenas calcular a variÃ¢ncia amostral (\\(s^2\\)) definida por:\n\\[s^2=\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}\\]\nNote que na expressÃ£o acima, substituimos \\(\\mu\\) por \\(\\overline{X}\\) pois estamos nos referindo Ã  variÃ¢ncia da amostra. No denominador fizemos a divisÃ£o por \\(n-1\\) nÃ£o por \\(N\\). Estas mudanÃ§as sÃ£o necessÃ¡rias para que \\(s^2\\) seja um estimador nÃ£o-viciado de \\(\\sigma^2\\).\nDenominamos de parÃ¢metro ao descritor obtido a partir da mensuraÃ§Ã£o de todos os elementos da populaÃ§Ã£o estatÃ­stica e de estimador (ou estatÃ­stica), a quantia obtida a partir da amostra. Os parÃ¢metros sÃ£o comumente representados por letras gregas. O sÃ­mbolo \\(\\mu\\) e \\(\\sigma^2\\) representam, respectivamente, a mÃ©dia e variÃ¢ncia populacionais, enquanto \\(\\overline{X}\\) e \\(s^2\\) sÃ£o a mÃ©dia e variÃ¢ncia amostrais.\n\n\n\n\n\n\nNotaDEFINIÃ‡Ã•ES\n\n\n\nParÃ¢metro: a medida que descreve uma caracterÃ­stica da populaÃ§Ã£o estatÃ­stica. Ex.: a mÃ©dia (\\(\\mu\\)) ou a variÃ¢ncia (\\(\\sigma^2\\)) populacional.\nEstimador ou EstatÃ­stica: Uma medida que descreve uma caracterÃ­stica da amostra. Ex.: a mÃ©dia amostral (\\(\\overline{X}\\)) ou a variÃ¢ncia amostral (\\(s^2\\)). Os estimadores tÃ¡mbem podem ser representados por letras gregas com o sÃ­mbolo \\(\\hat{}\\). A variÃ¢ncia amostral, por exemplo, pode ser representada por \\(\\hat{\\sigma}^2\\).\nEstimativa: Ã© o valor numÃ©rico assumido pelo estimador. Ex. o valor numÃ©rico calculado para a mÃ©dia ou variÃ¢ncia de uma amostra em particular.\n\n\n\n5.1 Verificando as propriedades de \\(\\overline{X}\\) e \\(s^2\\)\n\n\nCÃ³digo\nNsmall = 5\nnsmall = 2\nset.seed(5)\npop_small = sample(20, size = Nsmall, replace = F)\nmu = mean(pop_small)\nsigma2 = sum((pop_small - mu)^2)/Nsmall\n\nm = matrix(NA, ncol = Nsmall, nrow = Nsmall)\nrownames(m) = colnames(m) = as.character(pop_small)\nfor (i in 1:Nsmall){\n  for (j in 1:Nsmall){\n    m[i,j] = paste('(', pop_small[i], ' ; ', pop_small[j], ')', sep = '')\n  }\n}\n\n\nPor meio de um exmplo, vamos verificar empiricamente que \\(\\overline{X}\\) e \\(s^2\\) sÃ£o estimadores nÃ£o viciados de \\(\\mu\\) e \\(\\sigma^2\\) respectivamente. Suponha uma populaÃ§Ã£o de somente \\(5\\) elementos.\n\\[2 - 11 - 15 - 19 - 9\\]\n1. Calculando \\(\\mu\\) e \\(\\sigma^2\\).\nComo conhecemos a populaÃ§Ã£o vamos obter:\n\\[\\mu = \\frac{\\sum_{i=1}^N{X_i}}{N} = \\frac{2 + 11 + 15 + 19 + 9}{5}= \\frac{5}{5} = 11.2\\]\ne\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N} = \\frac{164.8}{5} = 32.96\\]\n2. Amostrando a populaÃ§Ã£o estatÃ­stica\nA TabelaÂ 1 mostra todas as \\(25\\) amostras com reposiÃ§Ã£o de tamanho \\(n = 2\\) que podem ser obtidas desta populaÃ§Ã£o.\nA tabela abaixo mostra todas as \\(25\\) amostras com reposiÃ§Ã£o de tamanho \\(n = 2\\) que podem ser obtidas desta populaÃ§Ã£o.\n\n\nCÃ³digo\nknitr::kable(m)\n\n\n\n\nTabelaÂ 1: Todas as amostras possÃ­veis de tamanho n = 2 da populaÃ§Ã£o estatÃ­stica com N = 5\n\n\n\n\n\n\n\n2\n11\n15\n19\n9\n\n\n\n\n2\n(2 ; 2)\n(2 ; 11)\n(2 ; 15)\n(2 ; 19)\n(2 ; 9)\n\n\n11\n(11 ; 2)\n(11 ; 11)\n(11 ; 15)\n(11 ; 19)\n(11 ; 9)\n\n\n15\n(15 ; 2)\n(15 ; 11)\n(15 ; 15)\n(15 ; 19)\n(15 ; 9)\n\n\n19\n(19 ; 2)\n(19 ; 11)\n(19 ; 15)\n(19 ; 19)\n(19 ; 9)\n\n\n9\n(9 ; 2)\n(9 ; 11)\n(9 ; 15)\n(9 ; 19)\n(9 ; 9)\n\n\n\n\n\n\n\n\n3. Calculando \\(\\overline{X}\\) e \\(s^2\\).\nEm seguida, organizamos as amostras em uma outra tabela, de modo que possamos calcular, para cada uma, os estimadores \\(\\overline{X}\\) e \\(s^2\\)\n\n\nCÃ³digo\ntab_df = data.frame(expand_grid(pop_small, pop_small))\ncolnames(tab_df) = c('X1', 'X2')\ntab_df = tab_df |&gt; \n  rowwise() |&gt; \n  mutate(Xm = mean(c(X1,X2)),\n         s2 = var(c(X1,X2)))\nEx = mean(tab_df$Xm)\nEs2 = mean(tab_df$s2)\n\n\n\n\nCÃ³digo\ntab_df |&gt; \n  knitr::kable(col.names = c('$x_1$', '$x_2$', '$\\\\overline{X}$', '$s^2$'))\n\n\n\n\nTabelaÂ 2: MÃ©dia e variÃ¢ncia amostrais para todas as amostras possÃ­veis de tamanho n = 2 da populaÃ§Ã£o estatÃ­stica com N = 5\n\n\n\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(\\overline{X}\\)\n\\(s^2\\)\n\n\n\n\n2\n2\n2.0\n0.0\n\n\n2\n11\n6.5\n40.5\n\n\n2\n15\n8.5\n84.5\n\n\n2\n19\n10.5\n144.5\n\n\n2\n9\n5.5\n24.5\n\n\n11\n2\n6.5\n40.5\n\n\n11\n11\n11.0\n0.0\n\n\n11\n15\n13.0\n8.0\n\n\n11\n19\n15.0\n32.0\n\n\n11\n9\n10.0\n2.0\n\n\n15\n2\n8.5\n84.5\n\n\n15\n11\n13.0\n8.0\n\n\n15\n15\n15.0\n0.0\n\n\n15\n19\n17.0\n8.0\n\n\n15\n9\n12.0\n18.0\n\n\n19\n2\n10.5\n144.5\n\n\n19\n11\n15.0\n32.0\n\n\n19\n15\n17.0\n8.0\n\n\n19\n19\n19.0\n0.0\n\n\n19\n9\n14.0\n50.0\n\n\n9\n2\n5.5\n24.5\n\n\n9\n11\n10.0\n2.0\n\n\n9\n15\n12.0\n18.0\n\n\n9\n19\n14.0\n50.0\n\n\n9\n9\n9.0\n0.0\n\n\n\n\n\n\n\n\nVemos que a mÃ©dia amostral pode variar entre 2, quando amostramos o menor valor da populaÃ§Ã£o duas vezes (isto Ã©, o nÃºmero 2) e 19, quando a amostra contÃ©m o maior valor da populaÃ§Ã£o (isto Ã©, 19). Vemos ainda que existe uma maior concentraÃ§Ã£o de valores entre \\(8\\) e \\(14\\) e que a distribuiÃ§Ã£o das mÃ©dias Ã© aproximadamente simÃ©trica.\nPara a variÃ¢ncia amostral \\(s^2\\) tambÃ©m verificamos uma grande diferenÃ§a entre as amostras particulares, com resultados que varia entre 0 e 144.5, alÃ©m de uma distribuiÃ§Ã£o altamente assimÃ©trica.\n\n\nCÃ³digo\nplt_Xm = ggplot(tab_df, aes(x = Xm)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n   labs(x = bquote('DistribuiÃ§Ã£o de ' ~ bar(X)),\n        y = \"FrequÃªncia\") +\n  scale_x_continuous(breaks = seq(0, 20, by = 2)) +\n  theme_classic(base_size = 15)\n\nplt_s2 = ggplot(tab_df, aes(x = s2)) +\n  geom_histogram(fill = 'red4', color = 'black', bins = 12) +\n   labs(x = bquote('DistribuiÃ§Ã£o de ' ~ s^2),\n        y = \"FrequÃªncia\") +\n  scale_x_continuous(breaks = seq(0, 200, by = 20)) +\n  theme_classic(base_size = 15)\n\n\n\n\nCÃ³digo\nplt_Xm | plt_s2\n\n\n\n\n\n\n\n\nFiguraÂ 4: DistribuiÃ§Ã£o das mÃ©dias e variÃ¢ncias amostrais com n = 2\n\n\n\n\n\n3. Verificando os valores esperados de \\(\\overline{X}\\) e \\(s^2\\).\nPara verificar empiricamente os valores esperados de \\(\\overline{X}\\) e \\(s^2\\) podemos encontrar sua mÃ©dias. Vemos que:\n\\[\\overline{\\overline{X}} = \\frac{\\sum_{i=1}^{25}{280}}{25} = 11.2 = \\mu\\]\ne que\n\\[\\overline{s^2} = \\frac{\\sum_{i=1}^{25}{824}}{25} = 32.96 = \\sigma^2\\]\nEstes resultados mostram que, em mÃ©dia, espera-se que as estimativas de \\(\\overline{X}\\) e \\(s^2\\) coincidem exatamente com os parÃ¢metros \\(\\mu\\) e \\(\\sigma^2\\). Quando isto ocorre dizemos que o estimador Ã© nÃ£o viciado.\n\n\n\n\n\n\nNotaAmostragem com e sem reposiÃ§Ã£o\n\n\n\nA discussÃ£o acima Ã© vÃ¡lida para a amostragem de uma populaÃ§Ã£o infinita ou para a amostragem com reposiÃ§Ã£o de uma populaÃ§Ã£o finita de tamanho \\(N\\). Se a amostragem for feita sem reposiÃ§Ã£o de uma populaÃ§Ã£o finita, \\(\\overline{X}\\) continua sendo o estimador nÃ£o viciado de \\(\\mu\\), porÃ©m o estimador nÃ£o viciado da variÃ¢ncia fica:\n\\(s^2 = \\left( \\frac{N-1}{N} \\right) \\left( \\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1} \\right)\\)\nNa prÃ¡tica, raramente conduzimos uma amostragem com reposiÃ§Ã£o. No entanto, ou a populaÃ§Ã£o Ã© infinita como nos casos de estudos experimentais, ou a populaÃ§Ã£o Ã© finita porÃ©m muito grande, como na maioria dos estudos observacionais. Neste segundo caso, para populaÃ§Ãµes finitas com \\(N\\) grande, o termo \\(\\left( \\frac{N-1}{N}  \\right)\\sim 1\\)."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#amostragem-e-inferÃªncia",
    "href": "content/amostragem/pop-amostra.html#amostragem-e-inferÃªncia",
    "title": "Descrevendo populaÃ§Ãµes e amostras",
    "section": "6 Amostragem e inferÃªncia",
    "text": "6 Amostragem e inferÃªncia\nO problema central que comeÃ§amos e discutir neste capÃ­tulo e com o qual iremos lidar em estatÃ­stica Ã© que:\n\nEstamos interessados nas caracterÃ­sticas da populaÃ§Ã£o estatÃ­stica, porÃ©m sÃ³ temos informaÃ§Ã£o sobre a amostra.\nA estimativa obtida a partir de uma amostra particular Ã© sujeita Ã  variaÃ§Ã£o decorrente do processo de amostragem.\n\nConsidere por exemplo, as diferentes amostras que podem ser obtidas a partir da populaÃ§Ã£o estatÃ­stica de alturas para um \\(n = 50\\) amostras:\n\n\nCÃ³digo\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  x_bar = mean(df$CP)\n  s2_bar = var(df$CP)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em centÃ­metros\",\n         y = \"FrequÃªncia\") +\n    scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n    scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n    coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    annotate(geom = 'text', x = 130, y = 15, label = deparse(bquote('n' == .(n))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 14, label = deparse(bquote(bar(X) == .(round(x_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 13, label = deparse(bquote(s^2 == .(round(s2_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\n\n\n\nFiguraÂ 5: Seis diferentes amostras de tamanho n = 50 da populaÃ§Ã£o de alturas.\n\n\n\n\n\nVemos que a cada nova amostra, \\(\\overline{X}\\) e \\(s^2\\) sÃ£o numericamente diferentes e nÃ£o coicidem com os parÃ¢metros da populaÃ§Ã£o estatÃ­stica (\\(\\mu = 11.2\\), \\(\\sigma^2 = 100\\)). Vemos entretanto, que mesmo sendo diferentes, estÃ£o ao redor dos parÃ¢metros populacionais. Se pudermos conhecer algumas propriedades destes estimadores, seremos capazes de estabelecer limites de confianÃ§a sobre as conclusÃµes que podemos tirar as respeito da populaÃ§Ã£o estatÃ­stica.\nNeste sentido, o processo de amostragem e inferÃªncia consiste em:\n\nObter uma amostra representativa da populaÃ§Ã£o estatÃ­stica;\nCalcular estimativas a partir das caracterÃ­sticas da amostra (ex. \\(\\overline{X}\\) e \\(s^2\\));\nAssumir distribuiÃ§Ãµes de probabilidade apropriadas para os estimadores;\nUtilizar para estas distribuiÃ§Ãµes para calcular intervalos de confianÃ§a ou testar hipÃ³teses estatÃ­sticas.\n\nEste processo pode ser resumido na figura abaixo e serÃ¡ discutido nos prÃ³ximos capÃ­tulos.\n\n\n\n\n\n\nFiguraÂ 6: Processo de amostragem e inferÃªncia estatÃ­stica.\n\n\n\n\n\n\n\n\n\n\nNotaVÃ­deo-aulas"
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html",
    "href": "content/medidas-associacao/biquantquali.html",
    "title": "AssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas no capÃ­tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(gridExtra)\nsource('scripts/anova-sim.r')\nNeste capÃ­tulo vamos descrever a associaÃ§Ã£o entre uma variÃ¡vel \\(Y\\) contÃ­nua e uma variÃ¡vel \\(X\\) categÃ³rica denominadas respectivamente de variÃ¡vel dependente (ou resposta) e variÃ¡vel independente (ou preditora)\nAssumimos explicitamente que \\(Y\\) Ã© funÃ§Ã£o (depende) de \\(X\\) e nÃ£o o contrÃ¡rio. O nome variÃ¡vel preditora vem do fato que, se \\(Y\\) e \\(X\\) estÃ£o associadas, ao conhecemos \\(X\\) somos capazer de predizer a resposta mÃ©dia em \\(Y\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#visualizando-a-distribuiÃ§Ã£o-de-y-em-diferentes-grupos",
    "href": "content/medidas-associacao/biquantquali.html#visualizando-a-distribuiÃ§Ã£o-de-y-em-diferentes-grupos",
    "title": "AssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas",
    "section": "1 Visualizando a distribuiÃ§Ã£o de \\(Y\\) em diferentes grupos",
    "text": "1 Visualizando a distribuiÃ§Ã£o de \\(Y\\) em diferentes grupos\nImporte a base de dados medley.csv (disponÃ­vel tambÃ©m em Chapter 10 - Single factor classification (ANOVA)) que avalia o impacto da presenÃ§a de metais pesados na diversidade de espÃ©cies de diatomÃ¡cias em riachos (Medley e Clements (1998); Queen, Quinn, e Keough (2002); Logan (2011)).\n\nmedley = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/medley.csv\") |&gt; \n  mutate(STREAM = factor(STREAM),\n         ZINC = factor(ZINC, ordered = TRUE,\n                       levels = c(\"BACK\", \"LOW\", \"MED\", \"HIGH\")))\nvar_medley = colnames(medley)\nstream_levels = levels(medley$STREAM)\nn_stream = nlevels(medley$STREAM)\nzinc_levels = levels(medley$ZINC)\nn_zinc = nlevels(medley$ZINC)\n\n\nmedley |&gt; gt()\n\n\n\n\n\n\n\nSTREAM\nZINC\nDIVERSITY\n\n\n\n\nEagle\nBACK\n2.27\n\n\nEagle\nHIGH\n1.25\n\n\nEagle\nHIGH\n1.15\n\n\nEagle\nMED\n1.62\n\n\nBlue\nBACK\n1.70\n\n\nBlue\nHIGH\n0.63\n\n\nBlue\nBACK\n2.05\n\n\nBlue\nBACK\n1.98\n\n\nBlue\nHIGH\n1.04\n\n\nBlue\nMED\n2.19\n\n\nBlue\nMED\n2.10\n\n\nSnake\nBACK\n2.20\n\n\nSnake\nMED\n2.06\n\n\nSnake\nHIGH\n1.90\n\n\nSnake\nHIGH\n1.88\n\n\nSnake\nHIGH\n0.85\n\n\nArkan\nLOW\n1.40\n\n\nArkan\nLOW\n2.18\n\n\nArkan\nLOW\n1.83\n\n\nArkan\nLOW\n1.88\n\n\nArkan\nMED\n2.02\n\n\nArkan\nMED\n1.94\n\n\nArkan\nLOW\n2.10\n\n\nChalk\nLOW\n2.38\n\n\nChalk\nHIGH\n1.43\n\n\nChalk\nHIGH\n1.37\n\n\nChalk\nMED\n1.75\n\n\nChalk\nLOW\n2.83\n\n\nSplat\nBACK\n1.53\n\n\nSplat\nBACK\n0.76\n\n\nSplat\nMED\n0.80\n\n\nSplat\nLOW\n1.66\n\n\nSplat\nMED\n0.98\n\n\nSplat\nBACK\n1.89\n\n\n\n\n\n\n\nA coluna STREAM Ã© uma variÃ¡vel categÃ³rica contendo o nome dos \\(6\\) riachos amostrados (Arkan, Blue, Chalk, Eagle, Snake, Splat). A coluna ZINC Ã© uma variÃ¡vel categÃ³rica ordinal com \\(4\\) nÃ­veis de concentraÃ§Ã£o de zinco na Ã¡gua (BACK &lt; LOW &lt; MED &lt; HIGH). O primeiro nÃ­vel (BACK) Ã© o nÃ­vel de referÃªncia (BACKGROUND). Finalmente, a coluna DIVERSITY Ã© uma variÃ¡vel contÃ­nua que contÃ©m a diversidade de diatomÃ¡cieas (medida pelo Ã­ndice de diversidade de Shannon medida de cada uma das 34 amostras.\nVamos nos concentrar nas variÃ¡veis DIVERSITY e ZINC. DIVERSITY serÃ¡ a variÃ¡vel resposta. Em delineamento experimental, dizemos que ZINC Ã© um tratamento, isto Ã©, uma condiÃ§Ã£o experimental sob a qual nossa variÃ¡vel dependente \\(Y\\) foi mensurada.\nPara verificarmos a distribuiÃ§Ã£o de diversidade para cada concentraÃ§Ã£o de zinco poderÃ­amos fazer um grÃ¡fico de dispersÃ£o. A diferenÃ§a agora Ã© que \\(X\\) trata-se de uma variÃ¡vel categÃ³rica ordinal com \\(4\\) nÃ­veis.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_point() +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\n1.1 Boxplots para os nÃ­veis do tratamento\nNÃ£o hÃ¡ problema em apresentarmos um grÃ¡fico de dispersÃ£o. No entanto, em situaÃ§Ãµes deste tipo estamos comumente interessados em representar medidas-resumo que nos permitam comparar os diferentes nÃ­veis do tratamento. A forma mais comum de representar esta situaÃ§Ã£o Ã© por meio de um boxplot para cada nÃ­vel do tratamento.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot() +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nNa figura acima estÃ£o representadas a mediana, os quartis (\\(1^o\\) e \\(3^o\\)) e os pontos mÃ¡ximo e mÃ­nimo para cada nÃ­vel do tratamento. Alguns pontos extremos podem aparecer isoladamente para indicar que estÃ£o muito distantes dos demais. Podemos controlar esta representaÃ§Ã£o com o argumento coef na funÃ§Ã£o geom_boxplot.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nVemos que o boxplot referente ao nÃ­vel HIGH estÃ¡ em uma posiÃ§Ã£o inferior aos demais, sugerindo que a diversidade de diatomÃ¡ceas tende a ser mais baixa para nÃ­veis elevados de zinco.\nExitem outras variaÃ§Ãµes que podem nos ajudar a entender melhor os padrÃµes. Podemos sobrepor os pontos individuais sobre os boxplots:\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  geom_point(size = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\n\n1.2 O grÃ¡fico de erros\nNas figuras acima representamos os quartis das distribuiÃ§Ãµes. Podemos estar interessados em apresentar somente os pontos mÃ©dios (mÃ©dia aritimÃ©tica) juntamente com barras de erro que representem alguma medida de dispersÃ£o (ex. desvio padrÃ£o). Para isto Ã© necessÃ¡rio inicialmente criar um data.frame com estas medidas.\n\nmedley_barras = medley |&gt; \n  group_by(ZINC) |&gt; \n  summarise(Media = mean(DIVERSITY),\n            Desvio = sd(DIVERSITY))\nmedley_barras |&gt; \n  gt()\n\n\n\n\n\n\n\nZINC\nMedia\nDesvio\n\n\n\n\nBACK\n1.797500\n0.4852613\n\n\nLOW\n2.032500\n0.4449960\n\n\nMED\n1.717778\n0.5030104\n\n\nHIGH\n1.277778\n0.4268717\n\n\n\n\n\n\n\nE em seguida plotar a figura.\n\nggplot(medley_barras, aes(x = ZINC)) +\n  geom_point(aes(y = Media), size = 3) +\n  geom_errorbar(aes(ymin = Media - Desvio,\n                    ymax = Media + Desvio), width = 0.4) +\n  labs(y = 'DIVERSITY') +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nAqui vemos somente os pontos mÃ©dios e as barras de erro, que estÃ£o Ã  distÃ¢ncia de \\(1\\) desvio padrÃ£o acima e abaixo da mÃ©dia (\\(\\overline{Y} \\pm 1s\\)). Embora tenhamos expressado as distÃ¢ncias utilizado o desvio padrÃ£o como medida de variaÃ§Ã£o, poderÃ­amos ter utilizado outras medidas como o erro padrÃ£o ou o intervalo de confianÃ§a O importante Ã© sempre deixar claro qual medida de variaÃ§Ã£o estÃ¡ semdo representada no grÃ¡fico de erros (Veja: Krzywinski & Altman, 2013 - Error bars - Points of Significance)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#partiÃ§Ã£o-das-soma-dos-quadrados",
    "href": "content/medidas-associacao/biquantquali.html#partiÃ§Ã£o-das-soma-dos-quadrados",
    "title": "AssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas",
    "section": "2 PartiÃ§Ã£o das Soma dos Quadrados",
    "text": "2 PartiÃ§Ã£o das Soma dos Quadrados\nAo representarmos a distribuiÃ§Ã£o de uma variÃ¡vel \\(Y\\) contÃ­nua em funÃ§Ã£o de uma variÃ¡vel \\(X\\) categÃ³rica, geralmente estamos interessados em determinar se os diferentes nÃ­veis de \\(X\\) (diferentes grupos) tÃªm mÃ©dias similares ou se ao menos um dos nÃ­veis tÃªm mÃ©dia diferente dos demais. Queremos uma medida que nos permita diferenciar situaÃ§Ãµes como as apresentadas abaixo.\n\n\n\n\n\n\n\n\n\nNa figura \\(A\\) todos os grupos sÃ£o provenientes da mesma distribuiÃ§Ã£o e tÃªm mÃ©dias aproximadamente iguais (\\(\\overline{Y}_A \\approx  \\overline{Y}_B \\approx \\overline{Y}_C \\approx \\overline{Y}_D\\)). Na figura \\(B\\) o segundo grupo tem mÃ©dia mais elevada que os demais, e na da figura \\(C\\), todas as mÃ©dias parecem ser diferentes entre si (\\(\\overline{Y}_A \\ne  \\overline{Y}_B \\ne \\overline{Y}_C \\ne \\overline{Y}_D\\)).\nPara mensurar o grau de associaÃ§Ã£o entre \\(Y\\) e \\(X\\) e entender como podemos diferenciar as situaÃ§Ãµes acima, vamos introduzir o processo de PartiÃ§Ã£o da Soma dos Quadrados.\nSuponha a situÃ§Ã£o abaixo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotaNotaÃ§Ãµes\n\n\n\n\nTemos \\(k = 3\\) grupos (A, B ou C) e para cada grupo \\(n =  5\\) observaÃ§Ãµes. Denotamos por \\(n_{ij}\\) o nÃºmero de observaÃ§Ãµes dentro de cada grupo, em que \\(i\\) Ã© a i-Ã©sima observaÃ§Ã£o (\\(i = 1\\) a \\(5\\)) do j-Ã©simo grupo (\\(j = 1\\) a \\(3\\) - grupos A ao C). Neste exemplo, o nÃºmero de observaÃ§Ãµes em cada grupo Ã© o mesmo (\\(n_1 = n_2 = n_3 = n\\)), de modo que o total de observaÃ§Ãµes Ã© dado por:\n\n\\(N = k \\times n = n_1 + n_2 + n_3 = 15\\)\n\nA mÃ©dia de cada grupo serÃ¡ denotada por \\(\\overline{Y}_j\\), que neste exemplo sÃ£o: \\(Y_1 = 20.64\\) (grupo A), \\(Y_2 = 28.68\\) (grupo B) e \\(Y_3 = 12.18\\) (grupo C).\nVamos denotar por \\(\\overline{\\overline{Y}}\\) a Grande MÃ©dia, isto Ã©, a mÃ©dia geral de todas as observaÃ§Ãµes independente do grupo de origem.\n\n\\[\\overline{\\overline{Y}} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}\\frac{Y_{ij}}{N} = \\frac{\\overline{Y_1} + \\overline{Y_2} + \\overline{Y_3}}{3} = 20.5\\]\n\n\nPodemos agora observar estes elementos no grÃ¡fico de dispersÃ£o.\n\n\n\n\n\n\n\n\n\nEm seguida, precisamos calcular \\(3\\) quantias, a Soma dos Quadrados Totais (\\(SQ_{Total}\\)), a Soma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\) e a Soma dos Quadrados dos ResÃ­duos \\(SQ_{Res}\\).\n\nSoma dos Quadrados Totais \\(SQ_{Total}\\): mede as diferenÃ§as entre \\(Y_{ij}\\) e \\(\\overline{\\overline{Y}}\\). Temos nesta expressÃ£o o somatÃ³rio dos desvios ao quadrado de todas as observaÃ§Ãµes com relaÃ§Ã£o Ã  grand, fig.align=â€˜centerâ€™, fig.width=8, fig.height=4e mÃ©dia independente do grupo de origem de cada observaÃ§Ã£o.\n\n\\[SQ_{Total} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\): mede as diferenÃ§as entre as mÃ©dias dos tratamentos \\(\\overline{Y}_j\\) e \\(\\overline{\\overline{Y}}\\), sendo portanto os desvios ao quadrado da mÃ©dia de cada tratamento subtraÃ­da da grande mÃ©dia. \\(SQ_{Trat}\\) tambÃ©m Ã© chamada de soma dos quadrados entre grupos ou entre tratamentos\n\n\\[SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos ResÃ­duos \\(SQ_{Res}\\): mede as diferenÃ§as entre cada observaÃ§Ã£o \\(Y_{ij}\\) e a mÃ©dia de seu prÃ³prio grupo \\(\\overline{Y}_{j}\\). \\(SQ_{Res}\\) tambÃ©m Ã© chamada de soma dos quadrados dentro dos grupos ou dentro dos tratamentos\n\n\\[SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2\\]\n\n\n\n\n\n\nNotaA caracterÃ­stica aditiva das somas dos quadrados\n\n\n\nA partiÃ§Ã£o da soma dos quadrados consiste em decompor a variaÃ§Ã£o total do experimento em uma parcela atribuÃ­da Ã  variaÃ§Ã£o entre tratamentos e outra parcela da variaÃ§Ã£o dentro dos tratamentos. Isto Ã© possÃ­vel pois as somas dos quadrados definidas acima podem ser expressas de forma aditiva como:\n\\[SQ_{Total} = SQ_{Trat} + SQ_{Res}\\]\nDeste modo, Ã© possÃ­vel demostrar que:\n\\(\\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(Y_{j} - \\overline{\\overline{Y}})^2 + \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{Y}_{j})^2\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#medindo-a-associaÃ§Ã£o-entre-y-e-x",
    "href": "content/medidas-associacao/biquantquali.html#medindo-a-associaÃ§Ã£o-entre-y-e-x",
    "title": "AssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas",
    "section": "3 Medindo a associaÃ§Ã£o entre \\(Y\\) e \\(X\\)",
    "text": "3 Medindo a associaÃ§Ã£o entre \\(Y\\) e \\(X\\)\nA caracterÃ­stica aditiva das somas dos quadrados pode ser utilizada para mensurar o grau de dependÃªncia de \\(Y_{ij}\\) com respeito aos diferentes tratamentos. Compare as duas figuras abaixo:\n\n\n\n\n\n\n\n\n\nA soma dos quadrados dentro dos grupos Ã© a mesma nas duas figuras (\\(SQ_{Res} = 362.6\\)). No entanto, na figura da esquerda, em que as mÃ©dias dos tratamentos sÃ£o similares (e consequentemente prÃ³ximas Ã  grande mÃ©dia), a soma dos quadrados entre os tratamentos Ã© muito menor (\\(SQ_{Trat}^{esquerda} = 15.8\\)) que na figura da direita, em que as mÃ©dias dos tratamentos estÃ£o distantes entre si (\\(SQ_{Trat}^{direita} = 680.8\\)). Ã‰ desta forma que a partiÃ§Ã£o das somas dos quadrados nos permite diferenciar situaÃ§Ãµes em que: i - a mÃ©dia dos grupos depende dos nÃ­veis do tratamento (figura da direita); de situaÃ§Ãµes em que ii - a mÃ©dia nÃ£o depende dos nÃ­veis do tratamento (figura da esquerda).\n\n3.1 O coeficiente de determinaÃ§Ã£o (\\(R^2\\))\nPodemos expressar a relaÃ§Ã£o entre \\(SQ_{Trat}\\) e \\(SQ_{Total}\\) pela expressÃ£o:\n\n\\[R^2 = \\frac{SQ_{Trat}}{SQ_{Trat} + SQ_{Res}} = \\frac{SQ_{Trat}}{SQ_{Total}}\\]\n\n\\(R^2\\) Ã© chamado de coeficiente de determinaÃ§Ã£o e varia entre \\(0\\) e \\(1\\). Se \\(R^2 = 0\\) toda a variaÃ§Ã£o em \\(Y\\) Ã© causada por \\(SQ_{Res}\\) (\\(\\overline{\\overline{Y}} = \\overline{Y}_1 = \\overline{Y}_2 = \\cdots = \\overline{Y}_k\\)). Ã€ medida que as mÃ©dias dos tratamentos se distanciam umas das outras, \\(R^2\\) se aproxima de \\(1\\) pois a maior parte da variaÃ§Ã£o em \\(Y\\) Ã© causada por \\(SQ_{Trat}\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#partiÃ§Ã£o-das-soma-dos-quadrados-no-ambiente-r",
    "href": "content/medidas-associacao/biquantquali.html#partiÃ§Ã£o-das-soma-dos-quadrados-no-ambiente-r",
    "title": "AssociaÃ§Ã£o entre variÃ¡veis quantitativas e qualitativas",
    "section": "4 PartiÃ§Ã£o das Soma dos Quadrados no ambiente R",
    "text": "4 PartiÃ§Ã£o das Soma dos Quadrados no ambiente R\nVoltando ao conjundo de dados medley.csv, uma forma de obter os somatÃ³rios dos quadrados no R Ã© utilizando a funÃ§Ã£o aov (mas veja tambÃ©m a funÃ§Ã£o lm).\n\naov(DIVERSITY ~ ZINC, data = medley)\n\nCall:\n   aov(formula = DIVERSITY ~ ZINC, data = medley)\n\nTerms:\n                    ZINC Residuals\nSum of Squares  2.566612  6.516411\nDeg. of Freedom        3        30\n\nResidual standard error: 0.4660619\nEstimated effects may be unbalanced\n\n\nO resultado retorna a soma dos quadrados dos tratamentos (neste caso a coluna ZINC) e dos resÃ­duos (coluna Residuals). Como o \\(SQ_{Total}\\) Ã© simplesmente a soma dos dois anteriores, podemos obtÃª-lo facilmente:\n\nsq = aov(DIVERSITY ~ ZINC, data = medley)\nSQTrat = anova(sq)$`Sum Sq`[1]\nSQRes = anova(sq)$`Sum Sq`[2]\nSQTotal = SQTrat + SQRes\n\nSQTotal\n\n[1] 9.083024\n\n\nPor fim, o \\(R^2\\) pode ser calculado por:\n\nR2 = SQTrat / SQTotal\nR2\n\n[1] 0.2825725"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html",
    "href": "content/medidas-associacao/biquanti.html",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis quantitativas",
    "section": "",
    "text": "DicaPacotes e funÃ§Ãµes utilizadas no capÃ­tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(mvtnorm)\nIremos medir o grau de associaÃ§Ã£o entre duas variÃ¡veis quantitativas \\(X\\) e \\(Y\\) por meio dos coeficientes de covariÃ¢ncia e correlaÃ§Ã£o linear. NÃ£o estamos interessados em verificar se \\(Y\\) depende funcionalmente de \\(X\\) ou vice-versa. Estamos interessados somente em medir a intensidade de associaÃ§Ã£o linear entre as duas variÃ¡veis. Ao calcularmos a covariÃ¢ncia entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)), por exemplo, poderÃ­amos inverter a ordem fazendo \\(s_{XY}\\) e terÃ­amos exatamente os mesmo resultados. O mesmo vale para o coeficiente de correlaÃ§Ã£o (\\(r_{YX} = r_{XY}\\)). Dizemos que existe uma simetria ao calcular estes coeficientes.\nEstamos interessados em diferenciar trÃªs situaÃ§Ãµes que podem ser visualizadas nos grÃ¡ficos de dispersÃ£o abaixo:"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#covariÃ¢ncia-entre-y-e-x",
    "href": "content/medidas-associacao/biquanti.html#covariÃ¢ncia-entre-y-e-x",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis quantitativas",
    "section": "1 CovariÃ¢ncia entre \\(Y\\) e \\(X\\)",
    "text": "1 CovariÃ¢ncia entre \\(Y\\) e \\(X\\)\nA variÃ¢ncia amostral de \\(Y\\) pode ser obtida subtraindo cada observaÃ§Ã£o em \\(Y\\) de sua mÃ©dia (\\(\\overline{Y}\\)) e elevando esta subtraÃ§Ã£o ao quadrado \\((Y_i - \\overline{Y})^2\\). Ao somar para todos os valores de \\(Y_i\\) teremos o somatÃ³rio dos quadrados de \\(Y\\) (\\(SQ_Y\\)).\n\\[SQ_Y = \\sum_{i-1}^{n} (Y_i - \\overline{Y})^2 = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (Y_i - \\overline{Y})\\]\nDividindo \\(SQ_Y\\) por \\(n-1\\) teremos a variÃ¢ncia amostral de \\(Y\\) (\\(s^2_Y\\)).\n\\[s^2_Y = \\frac{\\sum_{i-1}^{n} (Y_i - \\overline{Y})^2}{n-1}\\]\nA variÃ¢ncia amostral Ã© representada por \\(s^2\\). Aqui vamos usar a notaÃ§Ã£o (\\(s^2_Y\\)), pois haverÃ¡ outros estimadores de variÃ¢ncia envolvidos, de modo que deveremos ser mais claros a respeito de qual estimador estaremos nos referindo.\nAdotando o mesmo procedimento para \\(X\\), podemos calcular o somatÃ³rio dos quadrados de \\(X\\) (\\(SQ_X\\)).\n\\[SQ_X = \\sum_{i-1}^{n} (X_i - \\overline{X})^2 = \\sum_{i-1}^{n}(X_i - \\overline{X}) (X_i - \\overline{X})\\]\ne a variÃ¢ncia amostral de \\(X\\) (\\(s^2_X\\)).\n\\[s^2_X = \\frac{\\sum_{i-1}^{n} (X_i - \\overline{X})^2}{n-1}\\]\nCombinando as duas ideias, teremos o produto cruzado de \\(Y\\) e \\(X\\) (\\(SQ_{YX}\\))\n\\[SQ_{YX} = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})\\]\ne finalmente a covariÃ¢ncia amostral entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)).\n\n\n\n\n\n\nNotaCovariÃ¢ncia amostral\n\n\n\n\\[s_{YX} = \\frac{\\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})}{n-1}\\]"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#coeficiente-de-correlaÃ§Ã£o-linear-de-pearson-r",
    "href": "content/medidas-associacao/biquanti.html#coeficiente-de-correlaÃ§Ã£o-linear-de-pearson-r",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis quantitativas",
    "section": "2 Coeficiente de correlaÃ§Ã£o linear de Pearson \\(r\\)",
    "text": "2 Coeficiente de correlaÃ§Ã£o linear de Pearson \\(r\\)\nAssim como a covariÃ¢ncia, o coeficiente de correlaÃ§Ã£o de Pearson (\\(r\\)) mede a intensidade da associaÃ§Ã£o linear entre \\(Y\\) e \\(X\\). A covariÃ¢ncia entretanto, nÃ£o tem limite superior ou inferior, pois sua magnitude depende da ordem de grandeza das variÃ¡veis envolvidas. O coeficiente de correlaÃ§Ã£o \\(r\\) Ã© calculado como a covariÃ¢ncia entre \\(Y\\) e \\(X\\) padronizada pelo produto dos desvios padrÃµes de \\(Y\\) e de \\(X\\).\n\\[r = \\frac{s_{YX}}{s_Y s_X} = \\frac{\\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{n-1}} {\\sqrt{\\frac{\\sum{(Y_i - \\overline{Y})^2}}{n-1}}  \\times \\sqrt{\\frac{\\sum{(X_i - \\overline{X})^2}}{n-1}}}\\]\n\n\n\n\n\n\nNotaCoeficiente de correlaÃ§Ã£o\n\n\n\n\\[r = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sqrt{\\sum{(Y_i - \\overline{Y})^2 \\sum{(X_i - \\overline{X})^2}}}}\\]\n\n\nEsta padronizaÃ§Ã£o garante que \\(r\\) pode variar entre \\(-1\\) (correlaÃ§Ã£o perfeitamente linear e negativa) e \\(+1\\) (correlaÃ§Ã£o perfeitamente linear e positiva), se aproximando de zero quando nÃ£o existe correlaÃ§Ã£o."
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#exemplo",
    "href": "content/medidas-associacao/biquanti.html#exemplo",
    "title": "AssociaÃ§Ã£o entre duas variÃ¡veis quantitativas",
    "section": "3 Exemplo",
    "text": "3 Exemplo\nA TabelaÂ 1 apresenta dados da pesca do camarÃ£o tigre e do camarÃ£o rei entre nos anos de 1976 a 1987 (Haddon 2010). O camarÃ£o tigre constitui a espÃ©cie alvo da pesca, enquanto o camarÃ£o rei aparece como uma espÃ©cie acidental.\nImporte a base de dados ctigre_haddon.csv\n\ntigre = read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/ctigre_haddon.csv')\nrtk = cor(tigre$Tiger, tigre$King)\nstk = cov(tigre$Tiger, tigre$King)\n\n\n\n\n\nTabelaÂ 1: Captura do camarÃ£o tigre e do camarÃ£o rei (ton) entre 1976 e 1987.\n\n\n\n\n\n\n\n\n\nAno\nCamarÃ£o tigre\nCamarÃ£o rei\n\n\n\n\n1976\n566\n10\n\n\n1977\n1437\n22\n\n\n1978\n1646\n42\n\n\n1979\n2056\n33\n\n\n1980\n3171\n64\n\n\n1981\n2743\n34\n\n\n1982\n2838\n59\n\n\n1983\n4434\n146\n\n\n1984\n4149\n78\n\n\n1985\n3480\n75\n\n\n1986\n2375\n81\n\n\n1987\n3355\n52\n\n\n\n\n\n\n\n\n\n\nNas figuras abaixo temos as abundÃ¢ncias das espÃ©cies ao longo dos anos e o grÃ¡fico de dispersÃ£o.\n\n\nCÃ³digo\nc1 = ggplot(tigre, aes(x = Year)) +\n  geom_line(aes(y = Tiger), color = 'red') +\n  geom_point(aes(y = Tiger), color = 'red', \n             shape = 19, size = 4) +\n  geom_line(aes(y = King), color = 'blue') +\n  geom_point(aes(y = King), color = 'blue', \n             shape = 19, size = 4) +\n  geom_segment(x = 1976, xend = 1976.3, \n               y = 4000, yend = 4000, \n               color = 'red') +\n  geom_segment(x = 1976, xend = 1976.3, \n               y = 3700, yend = 3700, \n               color = 'blue') +\n  geom_text(x = 1976.4, y = 4000, \n            label = 'CamarÃ£o tigre', hjust = 0) +\n  geom_text(x = 1976.4, y = 3700, \n            label = 'CamarÃ£o rei', hjust = 0) +\n  scale_x_continuous(breaks = tigre$Year) +\n  labs(title = 'A', \n       y = 'AbundÃ¢ncia (Ton)') +\n  theme_classic(base_size = 12)\n\nc2 = ggplot(tigre, aes(y = King, x = Tiger)) +\n  geom_point(shape = 19, size = 4) +\n  scale_y_continuous(breaks = seq(0, 150, by = 20)) +\n  scale_x_continuous(breaks = seq(500, 5000, by = 500)) +\n  labs(title = 'B',\n       x = 'CamarÃ£o tigre (Ton)', \n       y = 'CamarÃ£o rei  (Ton)') +\n  theme_classic(base_size = 12)\n\nc1 | c2\n\n\n\n\n\n\n\n\nFiguraÂ 1: A - Captura do camarÃ£o tigre e do camarÃ£o-rei (ton) entre 1976 e 1987. B - AssociaÃ§Ã£o positiva nas capturas anuais entre 1976 e 1987.\n\n\n\n\n\nA captura em toneladas do camarÃ£o tigre Ã© sempre mais elevada. Entretanto, a figura da direita sugere haver uma associaÃ§Ã£o linear entre as capturas. Nos anos em que houve maiores capturas do camarÃ£o tigre parece ter havido tambÃ©m um aumento nas capturas do camarÃ£o rei. Dizemos as capturas covariam positivamente. Portanto existe uma correlaÃ§Ã£o positiva entre a captura das duas espÃ©cies.\nEm nenhum momento estamos dizendo que a captura de uma espÃ©cie resulta no aumento na captura da outra. Muito provavelmente, as abundÃ¢ncias das duas espÃ©cies estÃ£o relacionadas a um terceiro fator que gera um comportamento similar na variaÃ§Ã£o das capturas ano a ano. Estamos interessados em mensurar o grau de associaÃ§Ã£o seja pela covariÃ¢ncia ou pelo coeficiente de correlaÃ§Ã£o de Pearson.\na covariÃ¢ncia entre as abundÃ¢ncias dos camarÃµes tigre e rei Ã© positiva (\\(s_{tigre-rei} = 3.3293\\times 10^{4}\\)) e consequentemente a correlaÃ§Ã£o de Pearson tambÃ©m Ã© positiva (\\(r = 0.82\\)). Confira os cÃ¡lculos utilizando as expressÃµes apresentadas no capÃ­tulo.\nNo R, a covariÃ¢ncia entre \\(Y\\) e \\(X\\) pode ser obtida pela funÃ§Ã£o cov:\n\ncov(tigre$Tiger, tigre$King)\n\n[1] 33293\n\n\nE a correlaÃ§Ã£o pela funÃ§Ã£o cor:\n\ncor(tigre$Tiger, tigre$King)\n\n[1] 0.8196913"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "",
    "text": "DicaBibliotecas utilizadas nesta seÃ§Ã£o\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as st"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#simulando-uma-distribuiÃ§Ã£o-de-probabilidade-normal",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#simulando-uma-distribuiÃ§Ã£o-de-probabilidade-normal",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "1 Simulando uma distribuiÃ§Ã£o de probabilidade normal",
    "text": "1 Simulando uma distribuiÃ§Ã£o de probabilidade normal\nVamos utilizar nosso modelo teÃ³rico de probabilidades (a distribuiÃ§Ã£o normal) para prever o que seria esperado para as frequÃªncias relativas de alunos de diferentes alturas. Para isso precisamos calcular a probabilidade abaixo da curva para diferentes faixas de altura.\nEstritamente falando a equaÃ§Ã£o da distribuiÃ§Ã£o normal abaixo:\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma} \\right)^2}, \\quad x \\in \\mathbb{R} \\mid -\\infty \\leq x \\leq +\\infty\n\\]\nÃ© a FunÃ§Ã£o de Densidade de Probabilidade (PDF) da distribuiÃ§Ã£o normal. Com base nesta equaÃ§Ã£o, as probabilidades para intervalos de \\(X\\) sÃ£o obtidas por meio da FunÃ§Ã£o de Probabilidade Acumulada (CDF).\n\nmi = 170.94\nsigma = 6.86\n\nx = np.linspace(130, 210, 1000)\npdf = st.norm.pdf(x = x, loc = mi, scale = sigma)\n\ncdf = st.norm.cdf(x = x, loc = mi, scale = sigma)\n\nA distribuiÃ§Ã£o normal com mÃ©dia \\(X = 170.94\\) e \\(\\sigma = 6.86\\) estÃ£o representadas abaixo (PDF - FiguraÂ 2 (a); CDF - FiguraÂ 2 (b)).\nplt.plot(x, pdf)\nplt.xlabel('Alturas (cm)')\nplt.ylabel('PDF')\nplt.show()\n\nplt.plot(x, cdf)\nplt.xlabel('Alturas (cm)')\nplt.ylabel('CDF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) FunÃ§Ã£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) FunÃ§Ã£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFiguraÂ 2: DistribuiÃ§Ã£o normal de probabilidade"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#obtendo-probabilidades-de-uma-distribuiÃ§Ã£o-normal",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#obtendo-probabilidades-de-uma-distribuiÃ§Ã£o-normal",
    "title": "O modelo da distribuiÃ§Ã£o normal",
    "section": "2 Obtendo probabilidades de uma distribuiÃ§Ã£o normal",
    "text": "2 Obtendo probabilidades de uma distribuiÃ§Ã£o normal\n\n2.1 A probabilidade de \\(X\\) ser menor ou igual a \\(x_1\\): \\(P(X \\le x_1)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 160\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np = st.norm.cdf(x = x1, loc=mi, scale=sigma)\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = (x &lt;= x1), color='lightblue')\nplt.title(f'$P(X \\leq {x1})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p, p], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) FunÃ§Ã£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) FunÃ§Ã£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFiguraÂ 3: DistribuiÃ§Ã£o Normal de Probabilidades.\n\n\n\n\n\n2.2 A probabilidade de \\(X\\) ser maior ou igual a \\(x_1\\): \\(P(X \\ge x_1)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 180\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np = st.norm.cdf(x = x1, loc=mi, scale=sigma)\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = (x &gt;= x1), color='lightblue')\nplt.title(f'$P(X \\geq {x1})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p, p], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) FunÃ§Ã£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) FunÃ§Ã£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFiguraÂ 4: DistribuiÃ§Ã£o Normal de Probabilidades.\n\n\n\n\n\n2.3 A probabilidade de \\(X\\) estar entre \\(x_1\\) e \\(x_2\\): \\(P(x_1 \\le X \\le x_2)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 160\nx2 = 180\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np1 = st.norm.cdf(x = x1, loc=mi, scale=sigma)\np2 = st.norm.cdf(x = x2, loc=mi, scale=sigma)\np = p2 - p1\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = ((x &gt;= x1) & (x &lt;= x2)), color='lightblue')\nplt.title(f'$P({x1} \\leq X \\leq {x2})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.title(f'$F(X = {x2}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p1], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p1, p1], color = 'red', linewidth = 3)\nplt.plot([x2, x2], [0, p2], color = 'red', linewidth = 3)\nplt.plot([130, x2], [p2, p2], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) FunÃ§Ã£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) FunÃ§Ã£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFiguraÂ 5: DistribuiÃ§Ã£o Normal de Probabilidades.\n\n\n\n\n\n2.4 Representando \\(x_1\\) e \\(x_2\\) por \\(\\mu \\pm z\\sigma\\): \\(P(\\mu - z\\sigma \\le X \\le \\mu + z\\sigma)\\)\nObs.: \\(z\\) representa o nÃºmero de desvios padrÃµes acima ou abaixo de \\(\\mu\\).\n\nmi = 170.94\nsigma = 6.86\nz = 1.96\nx1 = mi - z * sigma\nx2 = mi + z * sigma\n\nx = np.arange(130, 210, 0.001)\ny = st.norm.pdf(x = x, loc = mi, scale = sigma)\n\np1 = st.norm.cdf(x = x1, loc=mi, scale=sigma)\np2 = st.norm.cdf(x = x2, loc=mi, scale=sigma)\np = p2 - p1\n\nplt.plot(x, y)\nplt.fill_between(x, y, where = ((x &gt;= x1) & (x &lt;= x2)), color='lightblue')\nplt.title(f'P($\\mu - {z}\\sigma \\leq X \\leq \\mu + {z}\\sigma$) = {np.round(p, 3)}')\nplt.show()\n\n\n\n\n\n\n\nFiguraÂ 6: DistribuiÃ§Ã£o Normal de Probabilidades."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html",
    "href": "content/manipulacao-dados-R/pipe.html",
    "title": "Operadores pipe",
    "section": "",
    "text": "Em R, operadores pipe sÃ£o usados para passar a saÃ­da de uma funÃ§Ã£o para a entrada de outra, tornando o cÃ³digo mais legÃ­vel e conciso. Este tutorial compara o operador pipe nativo |&gt; introduzido no R 4.1.0 e o operador %&gt;% do pacote magrittr."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#operador-pipe-nativo",
    "href": "content/manipulacao-dados-R/pipe.html#operador-pipe-nativo",
    "title": "Operadores pipe",
    "section": "1 Operador Pipe nativo |>",
    "text": "1 Operador Pipe nativo |&gt;\nO operador pipe nativo |&gt; Ã© uma nova adiÃ§Ã£o ao R base. Ele permite escrever cÃ³digo mais limpo e legÃ­vel ao encadear funÃ§Ãµes.\n\n# Exemplo usando o operador pipe nativo |&gt;\nresultado &lt;- 1:10 |&gt; \n  sum() |&gt;\n  sqrt()\n\nresultado\n\n[1] 7.416198\n\n\nNeste exemplo, a sequÃªncia de 1 a 10 Ã© passada para a funÃ§Ã£o sum(), e o resultado Ã© entÃ£o passado para a funÃ§Ã£o `sqrt()```.\nO mesmo resultado Ã© obtido sem o operador pipe por:\n\nresultado &lt;- sqrt(sum(1:10))\n\nresultado\n\n[1] 7.416198"
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#operador-pipe-do-pacote-magrittr",
    "href": "content/manipulacao-dados-R/pipe.html#operador-pipe-do-pacote-magrittr",
    "title": "Operadores pipe",
    "section": "2 Operador Pipe do pacote magrittr %>%",
    "text": "2 Operador Pipe do pacote magrittr %&gt;%\nO operador %&gt;% do pacote `magrittr``` tem sido amplamente usado na comunidade R hÃ¡ vÃ¡rios anos. Ele serve ao mesmo propÃ³sito que o operador pipe nativo, mas possui alguns recursos adicionais.\n\nlibrary(magrittr)\n\n# Exemplo usando o operador pipe do magrittr %&gt;%\nresultado &lt;- 1:10 %&gt;%\n  sum() %&gt;%\n  sqrt()\n\nresultado\n\n[1] 7.416198\n\n\nEste exemplo alcanÃ§a o mesmo resultado que o anterior, mas usa o operador %&gt;% do pacote magrittr."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#diferenÃ§as-e-consideraÃ§Ãµes",
    "href": "content/manipulacao-dados-R/pipe.html#diferenÃ§as-e-consideraÃ§Ãµes",
    "title": "Operadores pipe",
    "section": "3 DiferenÃ§as e ConsideraÃ§Ãµes",
    "text": "3 DiferenÃ§as e ConsideraÃ§Ãµes\n\n3.1 Suporte a Placeholder\nUma diferenÃ§a chave Ã© que %&gt;% suporta placeholders (.), que podem ser Ãºteis para pipelines mais complexos.\n\n# Usando placeholder com %&gt;%\nresultado &lt;- 1:10 %&gt;%\n  sum() %&gt;%\n  { . / 2 } %&gt;%\n  sqrt()\n\nresultado\n\n[1] 5.244044\n\n\nO operador pipe nativo |&gt; nÃ£o suporta placeholders diretamente.\nUsando o pipe nativo, a mesma expressÃ£o ficaria:\n\nresultado &lt;- 1:10 |&gt;\n  sum() |&gt;\n  (\\(x) x / 2)() |&gt;  # Esta linha Ã© similar Ã : `(function(x) x / 2)()`\n  sqrt()\n\nPortanto, torna-se necessÃ¡rio declarar uma funÃ§Ã£o dentro da sequÃªncia se comandos."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#tratamento-de-erros-e-depuraÃ§Ã£o",
    "href": "content/manipulacao-dados-R/pipe.html#tratamento-de-erros-e-depuraÃ§Ã£o",
    "title": "Operadores pipe",
    "section": "4 Tratamento de Erros e DepuraÃ§Ã£o",
    "text": "4 Tratamento de Erros e DepuraÃ§Ã£o\nO operador %&gt;% do magrittr fornece mensagens de erro mais detalhadas e melhores capacidades de depuraÃ§Ã£o. Se vocÃª encontrar um erro em um pipeline usando |&gt;, a mensagem de erro pode ser menos informativa em comparaÃ§Ã£o com o uso de %&gt;%."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#desempenho",
    "href": "content/manipulacao-dados-R/pipe.html#desempenho",
    "title": "Operadores pipe",
    "section": "5 Desempenho",
    "text": "5 Desempenho\nAmbos os operadores pipe tÃªm desempenho semelhante na maioria dos casos. No entanto, |&gt; por ser parte do R base, pode ter ligeiras vantagens de desempenho em alguns cenÃ¡rios devido Ã  sua integraÃ§Ã£o com a linguagem principal."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#quando-usar-operadores-pipe",
    "href": "content/manipulacao-dados-R/pipe.html#quando-usar-operadores-pipe",
    "title": "Operadores pipe",
    "section": "6 Quando usar operadores pipe",
    "text": "6 Quando usar operadores pipe\nTanto o operador pipe nativo |&gt; quanto o operador %&gt;% do magrittr sÃ£o ferramentas poderosas para escrever cÃ³digo R limpo e legÃ­vel. A escolha entre eles depende de suas necessidades especÃ­ficas e preferÃªncias. Se vocÃª precisa de suporte a placeholders e depuraÃ§Ã£o aprimorada, %&gt;% Ã© uma boa escolha. Para uma dependÃªncia mais leve e potencialmente melhor desempenho, |&gt; Ã© uma opÃ§Ã£o sÃ³lida. A seguir algumas sugestÃµes para a escolha entre os operadores.\n\nLeitura e Legibilidade: Use operadores pipe quando vocÃª deseja aumentar a legibilidade do cÃ³digo. Eles ajudam a encadear operaÃ§Ãµes de forma linear, tornando o fluxo de dados claro e fÃ¡cil de seguir.\n\n\nresultado &lt;- dados %&gt;%\n  filter(variavel1 &gt; 10) %&gt;%  # Filtra os dados\n  mutate(nova_variavel = variavel2 * 2) %&gt;%  # insere `nova_variavel` no data frame\n  summarise(media = mean(nova_variavel))  # extrai a mÃ©dia da `nova_variavel`\n\n\nTransformaÃ§Ãµes Sequenciais: Use operadores pipe quando vocÃª precisa aplicar uma sÃ©rie de transformaÃ§Ãµes sequenciais nos dados. Eles permitem que vocÃª evite a criaÃ§Ã£o de variÃ¡veis temporÃ¡rias.\n\n\nresultado &lt;- dados |&gt;\n  filter(variavel1 &gt; 10) |&gt;\n  mutate(nova_variavel = variavel2 * 2) |&gt;\n  summarise(media = mean(nova_variavel))\n\n# Sem o operador pipe, esta sequÃ¢ncia de cÃ³digos poderia ficar:\nres1 &lt;- filter(dados, variÃ¡vel1 &gt; 10)\nres2 &lt;- mutate(res1, nova_variavel = variavel2 * 2)\nresultado &lt;- summarise(res2, media = mean(nova_variavel))\n\n\nConsistÃªncia de Sintaxe: Utilize pipes para manter uma sintaxe consistente em todo o seu cÃ³digo, especialmente se vocÃª estiver trabalhando em um projeto colaborativo onde a consistÃªncia de estilo Ã© importante.\nSimplificaÃ§Ã£o de FunÃ§Ãµes Aninhadas: Empregue operadores pipe para simplificar a leitura de funÃ§Ãµes aninhadas, evitando a necessidade de mÃºltiplos parÃªnteses.\n\n\nresultado &lt;- sqrt(sum(1:10))\n\n# versus\n\nresultado_pipe &lt;- 1:10 |&gt;\n  sum() |&gt;\n  sqrt()\n\n\nresultado\n\n[1] 7.416198\n\nresultado_pipe\n\n[1] 7.416198\n\n\n\nCodificaÃ§Ã£o Explorativa e Prototipagem RÃ¡pida: Use pipes durante a exploraÃ§Ã£o de dados e prototipagem rÃ¡pida, pois eles permitem que vocÃª altere e teste rapidamente diferentes transformaÃ§Ãµes."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#quando-nÃ£o-usar-operadores-pipe",
    "href": "content/manipulacao-dados-R/pipe.html#quando-nÃ£o-usar-operadores-pipe",
    "title": "Operadores pipe",
    "section": "7 Quando NÃ£o Usar Operadores Pipe",
    "text": "7 Quando NÃ£o Usar Operadores Pipe\n\nSimplicidade Excessiva: Evite usar operadores pipe para operaÃ§Ãµes extremamente simples onde o uso de pipes nÃ£o adiciona clareza. Por exemplo, sum(1:10) Ã© mais claro sem o pipe.\nDepuraÃ§Ã£o de CÃ³digo: NÃ£o use pipes se vocÃª estÃ¡ tendo dificuldades para depurar uma sequÃªncia de operaÃ§Ãµes. Em vez disso, atribua resultados intermediÃ¡rios a variÃ¡veis temporÃ¡rias para inspecionÃ¡-los.\n\n\npasso1 &lt;- filter(dados, variavel1 &gt; 10)\npasso2 &lt;- mutate(passo1, nova_variavel = variavel2 * 2)\nresultado &lt;- summarise(passo2, media = mean(nova_variavel))\n\n\nOperaÃ§Ãµes Complexas com VÃ¡rias Etapas: Evite usar pipes em operaÃ§Ãµes muito complexas que envolvem vÃ¡rias etapas interdependentes, onde a clareza do cÃ³digo pode ser comprometida. Por exemplo se vocÃª precisa manipular dois data frames independentes e depois unÃ­-los, fazer isso em uma Ãºnica sequencia de operadores pipe pode tornar o cÃ³digo difÃ­cil de interpretar.\n\n\n# Criando exemplos de data frames\ndados1 &lt;- data.frame(\n  categoria = rep(c(\"A\", \"B\", \"C\"), each = 4),\n  variavel1 = rnorm(12, mean = 6, sd = 2)\n)\n\ndados2 &lt;- data.frame(\n  categoria = rep(c(\"A\", \"B\", \"C\"), each = 4),\n  variavel2 = rnorm(12, mean = 10, sd = 5)\n)\n\nlibrary(dplyr)\n# OperaÃ§Ãµes complexas em uma Ãºnica sequÃªncia de operadores pipe\nresultado &lt;- dados1 |&gt;\n  group_by(categoria) |&gt;\n  summarise(media_variavel1 = mean(variavel1)) |&gt;\n  inner_join(\n    dados2 |&gt; \n      group_by(categoria) |&gt; \n      summarise(soma_variavel2 = sum(variavel2)),\n    by = \"categoria\"\n  ) |&gt;\n  mutate(nova_variavel = soma_variavel2 / media_variavel1) |&gt;\n  arrange(desc(nova_variavel))\n\nresultado\n\n# A tibble: 3 Ã— 4\n  categoria media_variavel1 soma_variavel2 nova_variavel\n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1 A                    5.79           27.6          4.77\n2 C                    5.41           25.4          4.70\n3 B                    5.74           24.6          4.28\n\n\nO exemplo acima pode ser reescrito de forma que cada etapa tenha uma leitura mais clara.\n\n# Passo 1: Filtrar e resumir dados1\nresumo_dados1 &lt;- dados1 |&gt;\n  group_by(categoria) |&gt;\n  summarise(media_variavel1 = mean(variavel1))\n\n# Passo 2: Filtrar e resumir dados2\nresumo_dados2 &lt;- dados2 |&gt;\n  group_by(categoria) |&gt;\n  summarise(soma_variavel2 = sum(variavel2))\n\n# Passo 3: Unir os resultados dos dois data frames\nresultado_unido &lt;- inner_join(resumo_dados1, \n                                     resumo_dados2, \n                                     by = \"categoria\")  |&gt;  \n  mutate(nova_variavel = soma_variavel2 / media_variavel1) |&gt;\n  arrange(desc(nova_variavel))\n\nresultado_unido\n\n# A tibble: 3 Ã— 4\n  categoria media_variavel1 soma_variavel2 nova_variavel\n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1 A                    5.79           27.6          4.77\n2 C                    5.41           25.4          4.70\n3 B                    5.74           24.6          4.28\n\n\nEmbora o cÃ³digo tenha ficado mais longo, fica tambÃ©m mais simples de ser inspecionado.\n\nDesempenho CrÃ­tico: Se vocÃª estÃ¡ preocupado com o desempenho crÃ­tico e a eficiÃªncia, pode ser melhor evitar pipes, jÃ¡ que eles podem adicionar alguma sobrecarga.\nAmbiguidade de FunÃ§Ãµes: Evite pipes se o uso deles torna a ordem das operaÃ§Ãµes ou a origem dos dados ambÃ­gua. Certifique-se de que a sequÃªncia de operaÃ§Ãµes Ã© clara e lÃ³gica."
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html",
    "href": "content/manipulacao-dados-R/import-export.html",
    "title": "Importando/Exportando dados",
    "section": "",
    "text": "O pacote responsÃ¡vel pela importaÃ§Ã£o de dados no tidyverse Ã© o readr. Este pacote permite importar arquivos de texto nos formatos .csv ou .txt.\nExistem diversas funÃ§Ãµes no pacote readr(veja aqui). A funÃ§Ã£o read_csv() importa arquivos texto em que as colunas sÃ£o separadas por vÃ­rgulas. A funÃ§Ã£o read_tsv() importa arquivos texto em que as colunas sÃ£o separadas por tabulaÃ§Ãµes."
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html#importando-dados-de-arquivos-texto",
    "href": "content/manipulacao-dados-R/import-export.html#importando-dados-de-arquivos-texto",
    "title": "Importando/Exportando dados",
    "section": "1 Importando dados de arquivos texto",
    "text": "1 Importando dados de arquivos texto\nA funÃ§Ã£o read_delim() oferece mais controle sobre o tipo de delimitador de colunas (vÃ­rgulas, tabulaÃ§Ãµes, ponto-e-vÃ­rgula, entre outros) ou o identificador decimal (vÃ­rgulas ou ponto).\nCarrege o pacote readr e importe o arquivo Reservatorios_Parana_parcial.csv disponÃ­vel no repositÃ³rio datasets do . Ã‰ possÃ­vel importar o arquivo diretamente do repositÃ³rio:\n\nlibrary(readr)\nres = read_delim(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n                  delim = ',',\n                  locale = locale(decimal_mark = '.',\n                                  encoding = 'latin1'))\n\n\n\n\n\n\n\nNota\n\n\n\nSe optar por fazer o download do arquivo, basta acessar pelo link (Reservatorios_Parana_parcial.csv), salvÃ¡-lo em seu diretÃ³rio de trabalho e importar com o comando:\n\nres = read_delim(file = \"Reservatorios_Parana_parcial.csv.csv\", delim = \",\")\n\n\n\nVerifique o objeto importado.\n\nres\n\n# A tibble: 31 Ã— 11\n   Reservatorio Bacia  Fechamento   Area Trofia    pH Condutividade Alcalinidade\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n 1 Cavernoso    Iguacu       1965   2.9  Oligoâ€¦   7.4          33.1        140. \n 2 Curucaca     Iguacu       1982   2    Oligoâ€¦   7            32.4        126. \n 3 Foz do Areia Iguacu       1980 139    Oligoâ€¦   7.3          35.5         97  \n 4 Irai         Iguacu       2000  15    EutrÃƒâ€¦   6.9          50.2          3.3\n 5 JMF          Iguacu       1970   0.45 Mesotâ€¦   7.3          40.2          3.7\n 6 Jordao       Iguacu       1996   3.4  Oligoâ€¦   7.1          23.7        153. \n 7 Passauna     Iguacu       1978  14    Oligoâ€¦   8.8         126.         526  \n 8 Piraquara    Iguacu       1979   3.3  Oligoâ€¦   7.1          22.8         50.7\n 9 Salto Caxias Iguacu       1998 124    Oligoâ€¦   7.3          39.6        106  \n10 Salto do Vau Iguacu       1959   2.9  Oligoâ€¦   6.5          23.2        279  \n# â„¹ 21 more rows\n# â„¹ 3 more variables: P.total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, CPUE &lt;dbl&gt;\n\n\nO objeto Ã© do tipo tibble com 31 linhas por 11 colunas. Uma tibble Ã© uma versÃ£o moderna do data.frame que preserva aspectos eficazes para manipulaÃ§Ã£o, visualizaÃ§Ã£o e transformaÃ§Ã£o de dados.\n\nclass(res)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html#exportando-um-data-frame",
    "href": "content/manipulacao-dados-R/import-export.html#exportando-um-data-frame",
    "title": "Importando/Exportando dados",
    "section": "2 Exportando um data frame",
    "text": "2 Exportando um data frame\nA funÃ§Ã£o para exportar data frames no pacote readr Ã© write_delim() e outras funÃ§Ãµes anÃ¡logas. Para exportar uma parte do data frame utiliza-se o comando:\n\nwrite_delim(res[1:10, 3:5],\n            file = \"Reservatorios_Parana_parcial.csv\", \n            delim = ',')"
  },
  {
    "objectID": "content/glms/intro.html",
    "href": "content/glms/intro.html",
    "title": "Modelos Lineares Generalizados (GLMs)",
    "section": "",
    "text": "1 IntroduÃ§Ã£o aos GLMs\n(ConteÃºdo em construÃ§Ã£o)"
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#preparaÃ§Ã£o-inicial",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#preparaÃ§Ã£o-inicial",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "1 ğŸ› ï¸ PreparaÃ§Ã£o Inicial",
    "text": "1 ğŸ› ï¸ PreparaÃ§Ã£o Inicial\nVamos importar as bibliotecas necessÃ¡rias:\n\nfrom google.colab import drive  # Permite que o Google Colab leia seu Google Drive\nimport pandas as pd  # AnÃ¡lise e manipulaÃ§Ã£o de dados"
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-1-montando-o-google-drive-no-colab",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-1-montando-o-google-drive-no-colab",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "2 ğŸ”— Etapa 1: Montando o Google Drive no Colab",
    "text": "2 ğŸ”— Etapa 1: Montando o Google Drive no Colab\nO primeiro passo Ã© montar seu Google Drive, dentro do Google Colab. Isto pode ser feito com o comando drive.mount(). No exemplo abaixo, vamos pedir que as pasats de seu Google Dive sejam incluÃ­das em uma estrutura de pastas dentro do caminho \"/content/drive\".\n\n# Montar o Google Drive (vai solicitar permissÃ£o)\ndrive.mount(\"/content/drive\")\n\nApÃ³s executar este comando, vocÃª verÃ¡ um link de autorizaÃ§Ã£o de acesso ao Google Drive pelo Google Colab. Permita todos os acessos.\n\n2.1 âœ… Verificando os arquivos e pastas\nVocÃª agora serÃ¡ capaz de navegar pela estrutura de pastas do seu Drive. Por exemplo, vocÃª pode verificar se seu arquivo estÃ¡ realmente salvo com o comando !ls.\n\n# Listando arquivos e subpastas na pasta raiz do Drive\n!ls \"/content/drive/MyDrive/MyDrive/Projetos/Dados\""
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-2-localizando-seu-arquivo-csv",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-2-localizando-seu-arquivo-csv",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "3 ğŸ“ Etapa 2: Localizando seu Arquivo CSV",
    "text": "3 ğŸ“ Etapa 2: Localizando seu Arquivo CSV\nCaso seu arquivo arquivo_exemplo.csv esteja listado na pasta acima, crie um objeto que conterÃ¡ todo o caminho atÃ© o arquivo:\n\ncaminho_arquivo = \"/content/drive/MyDrive/Projetos/Dados/arquivo_exemplo.csv\""
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-3-lendo-o-csv-com-pandas",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-3-lendo-o-csv-com-pandas",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "4 ğŸ“Š Etapa 3: Lendo o CSV com pandas",
    "text": "4 ğŸ“Š Etapa 3: Lendo o CSV com pandas\nLeia o arquivo com a funÃ§Ã£o read_csv() do pandas e salve-o em um data frame.\n\n# Lendo o CSV\ndf = pd.read_csv(caminho_arquivo)\n\n# Verique se os dados foram importados corretamente\nprint(df)\n\nPronto!! ApÃ³s verificar se a importaÃ§Ã£o foi feita corretamente, vocÃª pode utilizar o data frame no restante do cÃ³digo"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "",
    "text": "Neste tutorial, exploraremos como analisar padrÃµes de associaÃ§Ã£o entre diferentes tipos de variÃ¡veis em Python, utilizando o dataset de pinguins de Palmer."
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#pacotes-necessÃ¡rios",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#pacotes-necessÃ¡rios",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "1 Pacotes necessÃ¡rios",
    "text": "1 Pacotes necessÃ¡rios\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom palmerpenguins import load_penguins\nimport seaborn as sns\nimport numpy as np"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#carregando-e-preparando-os-dados",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#carregando-e-preparando-os-dados",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "2 Carregando e preparando os dados",
    "text": "2 Carregando e preparando os dados\n\npenguins = load_penguins().dropna()\npenguins.shape\n\n(333, 8)\n\n\n\n# Visualizando as primeiras linhas\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-duas-variÃ¡veis-qualitativas-categÃ³ricas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-duas-variÃ¡veis-qualitativas-categÃ³ricas",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "3 AssociaÃ§Ã£o entre Duas VariÃ¡veis Qualitativas (CategÃ³ricas)",
    "text": "3 AssociaÃ§Ã£o entre Duas VariÃ¡veis Qualitativas (CategÃ³ricas)\nQuando queremos analisar a relaÃ§Ã£o entre duas variÃ¡veis categÃ³ricas, utilizamos tabelas de contingÃªncia.\n\n3.1 Exemplo: AssociaÃ§Ã£o entre EspÃ©cie e Ilha\n\n# Tabela de contingÃªncia (frequÃªncias observadas)\ncontingency_table = pd.crosstab(penguins['species'], \n                                penguins['island'])\ncontingency_table\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\n\n\n\n3.2 FrequÃªncias Relativas\n\n# FrequÃªncias relativas por linha (marginais)\ntotal_row = contingency_table.sum(axis=1)\nrelative_row = contingency_table.div(total_row, axis=0)\nprint(\"FrequÃªncias relativas por linha (espÃ©cie):\")\nrelative_row\n\nFrequÃªncias relativas por linha (espÃ©cie):\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.30137\n0.376712\n0.321918\n\n\nChinstrap\n0.00000\n1.000000\n0.000000\n\n\nGentoo\n1.00000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n# FrequÃªncias relativas por coluna (marginais)\ntotal_col = contingency_table.sum(axis=0)\nrelative_col = contingency_table.div(total_col, axis=1)\nprint(\"FrequÃªncias relativas por coluna (ilha):\")\nrelative_col\n\nFrequÃªncias relativas por coluna (ilha):\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.269939\n0.447154\n1.0\n\n\nChinstrap\n0.000000\n0.552846\n0.0\n\n\nGentoo\n0.730061\n0.000000\n0.0\n\n\n\n\n\n\n\n\n# FrequÃªncias relativas conjuntas\nrelative_joint = contingency_table / contingency_table.sum().sum()\nprint(\"FrequÃªncias relativas conjuntas:\")\nrelative_joint\n\nFrequÃªncias relativas conjuntas:\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.132132\n0.165165\n0.141141\n\n\nChinstrap\n0.000000\n0.204204\n0.000000\n\n\nGentoo\n0.357357\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n3.3 VisualizaÃ§Ã£o: GrÃ¡fico de Barras Agrupadas\n\ncontingency_table.plot(kind='bar', stacked=False, figsize=(8, 6))\nplt.title(\"AssociaÃ§Ã£o entre EspÃ©cie e Ilha\")\nplt.xlabel(\"EspÃ©cie\")\nplt.ylabel(\"FrequÃªncia\")\nplt.legend(title=\"Ilha\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n# GrÃ¡fico alternativo com Seaborn\nplt.figure(figsize=(8, 6))\nsns.countplot(data=penguins, x='species', hue='island')\nplt.title(\"DistribuiÃ§Ã£o de EspÃ©cies por Ilha\")\nplt.xlabel(\"EspÃ©cie\")\nplt.ylabel(\"FrequÃªncia\")\nplt.legend(title=\"Ilha\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando a associaÃ§Ã£o:\n- Se as proporÃ§Ãµes fossem similares em todas as categorias, nÃ£o haveria associaÃ§Ã£o\n- DiferenÃ§as significativas nas proporÃ§Ãµes indicam possÃ­vel associaÃ§Ã£o\n- No exemplo, vemos que diferentes espÃ©cies tÃªm distribuiÃ§Ãµes distintas entre as ilhas"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-duas-variÃ¡veis-quantitativas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-duas-variÃ¡veis-quantitativas",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "4 AssociaÃ§Ã£o entre Duas VariÃ¡veis Quantitativas",
    "text": "4 AssociaÃ§Ã£o entre Duas VariÃ¡veis Quantitativas\nPara variÃ¡veis quantitativas, utilizamos correlaÃ§Ã£o e covariÃ¢ncia.\n\n4.1 Exemplo: Comprimento do Bico vs Massa Corporal\n\n# GrÃ¡fico de dispersÃ£o\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    s=60\n)\nplt.title(\"AssociaÃ§Ã£o entre Comprimento do Bico e Massa Corporal\")\nplt.xlabel(\"Comprimento do Bico (mm)\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n4.2 CovariÃ¢ncia e CorrelaÃ§Ã£o\n\n# CovariÃ¢ncia\ncovariance = penguins[['bill_length_mm', 'body_mass_g']].cov()\nprint(\"Matriz de CovariÃ¢ncia:\")\ncovariance\n\nMatriz de CovariÃ¢ncia:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n29.906333\n2595.623304\n\n\nbody_mass_g\n2595.623304\n648372.487699\n\n\n\n\n\n\n\n\n# CorrelaÃ§Ã£o de Pearson\ncorrelation = penguins[['bill_length_mm', 'body_mass_g']].corr()\nprint(\"Matriz de CorrelaÃ§Ã£o:\")\ncorrelation\n\nMatriz de CorrelaÃ§Ã£o:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.000000\n0.589451\n\n\nbody_mass_g\n0.589451\n1.000000\n\n\n\n\n\n\n\n\n\n4.3 Entendendo a CorrelaÃ§Ã£o como CovariÃ¢ncia Padronizada\n\n# Padronizando as variÃ¡veis (Z-score)\npenguins_padr = penguins[['bill_length_mm', 'body_mass_g']].copy()\npenguins_padr = (penguins_padr - penguins_padr.mean()) / penguins_padr.std()\n\nprint(\"MÃ©dia das variÃ¡veis padronizadas:\", penguins_padr.mean().values)\nprint(\"Desvio padrÃ£o das variÃ¡veis padronizadas:\", penguins_padr.std().values)\n\nMÃ©dia das variÃ¡veis padronizadas: [-9.38855266e-16 -8.53504788e-17]\nDesvio padrÃ£o das variÃ¡veis padronizadas: [1. 1.]\n\n\n\n# A covariÃ¢ncia de variÃ¡veis padronizadas = correlaÃ§Ã£o\nprint(\"CovariÃ¢ncia das variÃ¡veis padronizadas:\")\npenguins_padr.cov()\n\nCovariÃ¢ncia das variÃ¡veis padronizadas:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.000000\n0.589451\n\n\nbody_mass_g\n0.589451\n1.000000"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-variÃ¡vel-quantitativa-e-qualitativa",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associaÃ§Ã£o-entre-variÃ¡vel-quantitativa-e-qualitativa",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "5 3. AssociaÃ§Ã£o entre VariÃ¡vel Quantitativa e Qualitativa",
    "text": "5 3. AssociaÃ§Ã£o entre VariÃ¡vel Quantitativa e Qualitativa\n\n5.1 Exemplo: Massa Corporal por EspÃ©cie\n\n# Resumo descritivo por grupo\ngrouped_mass = penguins.groupby('species')['body_mass_g'].describe()\ngrouped_mass\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n146.0\n3706.164384\n458.620135\n2850.0\n3362.5\n3700.0\n4000.0\n4775.0\n\n\nChinstrap\n68.0\n3733.088235\n384.335081\n2700.0\n3487.5\n3700.0\n3950.0\n4800.0\n\n\nGentoo\n119.0\n5092.436975\n501.476154\n3950.0\n4700.0\n5050.0\n5500.0\n6300.0\n\n\n\n\n\n\n\n\n# Para outra variÃ¡vel\ngrouped_bill = penguins.groupby('species')['bill_length_mm'].describe()\ngrouped_bill\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n146.0\n38.823973\n2.662597\n32.1\n36.725\n38.85\n40.775\n46.0\n\n\nChinstrap\n68.0\n48.833824\n3.339256\n40.9\n46.350\n49.55\n51.075\n58.0\n\n\nGentoo\n119.0\n47.568067\n3.106116\n40.9\n45.350\n47.40\n49.600\n59.6\n\n\n\n\n\n\n\n\n\n5.2 VisualizaÃ§Ã£o: Boxplot por Grupos\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='species', y='body_mass_g', data=penguins)\nplt.title(\"DistribuiÃ§Ã£o da Massa Corporal por EspÃ©cie\")\nplt.xlabel(\"EspÃ©cie\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n5.3 GrÃ¡fico de MÃ©dias com Barras de Erro\n\nplt.figure(figsize=(10, 6))\nsns.pointplot(\n    data=penguins,\n    x='species',\n    y='body_mass_g',\n    capsize=0.1,\n    color='black',\n    errorbar='sd'\n)\nplt.title(\"MÃ©dia e Desvio PadrÃ£o da Massa Corporal por EspÃ©cie\")\nplt.xlabel(\"EspÃ©cie\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando boxplots por grupos:\n- Medianas diferentes: Indica diferenÃ§as entre os grupos\n- SobreposiÃ§Ã£o das caixas: Grupos com distribuiÃ§Ãµes similares\n- Outliers: Valores atÃ­picos em cada grupo"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#anÃ¡lises-multivariadas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#anÃ¡lises-multivariadas",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "6 AnÃ¡lises Multivariadas",
    "text": "6 AnÃ¡lises Multivariadas\n\n6.1 Scatter Plot com MÃºltiplas DimensÃµes\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    size='flipper_length_mm',\n    sizes=(50, 200)\n)\nplt.title(\"Massa Corporal vs Comprimento do Bico (tamanho = comprimento da nadadeira)\")\nplt.xlabel(\"Comprimento do Bico (mm)\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.2 RegressÃ£o Linear por Grupos\n\nsns.lmplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"RegressÃ£o Linear: Massa Corporal vs Comprimento do Bico por EspÃ©cie\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.3 Pairplot: Todas as CombinaÃ§Ãµes de VariÃ¡veis\n\n# Matriz de grÃ¡ficos de dispersÃ£o\nsns.pairplot(\n    data=penguins,\n    vars=['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],\n    hue='species',\n    diag_kind='kde',\n    height=2.5\n)\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.4 Matriz de CorrelaÃ§Ã£o Completa\n\n# Calcular correlaÃ§Ãµes para todas as variÃ¡veis numÃ©ricas\nnumeric_vars = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\ncorrelation_matrix = penguins[numeric_vars].corr()\n\n# Heatmap da matriz de correlaÃ§Ã£o\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    correlation_matrix,\n    annot=True,\n    cmap='coolwarm',\n    center=0,\n    square=True,\n    fmt='.2f'\n)\nplt.title(\"Matriz de CorrelaÃ§Ã£o das VariÃ¡veis Quantitativas\")\nplt.tight_layout()\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#exemplos-adicionais-de-visualizaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#exemplos-adicionais-de-visualizaÃ§Ã£o",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "7 Exemplos Adicionais de VisualizaÃ§Ã£o",
    "text": "7 Exemplos Adicionais de VisualizaÃ§Ã£o\n\n7.1 Comprimento da Nadadeira vs Massa Corporal\n\nsns.lmplot(\n    data=penguins,\n    x='flipper_length_mm',\n    y='body_mass_g',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"Massa Corporal vs Comprimento da Nadadeira por EspÃ©cie\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n7.2 Altura vs Comprimento do Bico\n\nsns.lmplot(\n    data=penguins,\n    x='bill_depth_mm',\n    y='bill_length_mm',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"Comprimento vs Altura do Bico por EspÃ©cie\")\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#resumo-dos-tipos-de-associaÃ§Ã£o",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#resumo-dos-tipos-de-associaÃ§Ã£o",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "8 Resumo dos Tipos de AssociaÃ§Ã£o",
    "text": "8 Resumo dos Tipos de AssociaÃ§Ã£o\n\n\n\n\n\n\n\n\nTipos de VariÃ¡veis\nMedidas\nVisualizaÃ§Ãµes\n\n\n\n\nQualitativa vs Qualitativa\nTabelas de contingÃªncia, frequÃªncias relativas\nBarras agrupadas, countplot\n\n\nQuantitativa vs Quantitativa\nCorrelaÃ§Ã£o, covariÃ¢ncia\nScatter plot, pairplot\n\n\nQuantitativa vs Qualitativa\nEstatÃ­sticas por grupo (mÃ©dia, mediana)\nBoxplot, pointplot\n\n\nMultivariada\nCorrelaÃ§Ãµes mÃºltiplas\nPairplot, heatmap, lmplot"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#dicas-prÃ¡ticas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#dicas-prÃ¡ticas",
    "title": "Medidas de AssociaÃ§Ã£o e Relacionamentos entre VariÃ¡veis com Python",
    "section": "9 Dicas PrÃ¡ticas",
    "text": "9 Dicas PrÃ¡ticas\n\n9.1 Escolhendo a visualizaÃ§Ã£o adequada\n\n# Para escolher o grÃ¡fico certo, considere:\nprint(\"Tipos de dados:\")\nprint(penguins.dtypes)\n\nTipos de dados:\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\n\n\n9.2 Identificando correlaÃ§Ãµes interessantes\n\n# Encontrar as maiores correlaÃ§Ãµes\ncorr_matrix = penguins[numeric_vars].corr()\n# Remover a diagonal (correlaÃ§Ã£o de uma variÃ¡vel consigo mesma)\ncorr_matrix_clean = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n# Empilhar e ordenar por valor absoluto\ncorrelations = corr_matrix_clean.stack().sort_values(key=abs, ascending=False)\nprint(\"CorrelaÃ§Ãµes mais fortes:\")\ncorrelations.head()\n\nCorrelaÃ§Ãµes mais fortes:\n\n\nflipper_length_mm  body_mass_g          0.872979\nbill_length_mm     flipper_length_mm    0.653096\n                   body_mass_g          0.589451\nbill_depth_mm      flipper_length_mm   -0.577792\n                   body_mass_g         -0.472016\ndtype: float64"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html",
    "title": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem",
    "section": "",
    "text": "Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel, interpretada e de propÃ³sito geral. Ã‰ amplamente utilizada em ciÃªncia de dados, desenvolvimento web, automaÃ§Ã£o e muitas outras Ã¡reas. Para anÃ¡lise de dados, utilizamos principalmente as bibliotecas NumPy para computaÃ§Ã£o numÃ©rica e Pandas para manipulaÃ§Ã£o de dados tabulares."
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#pacotes-essenciais",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#pacotes-essenciais",
    "title": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem",
    "section": "1 Pacotes essenciais",
    "text": "1 Pacotes essenciais\nAntes de comeÃ§armos, vamos importar os pacotes fundamentais que utilizaremos:\n\nimport math\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#operaÃ§Ãµes-aritmÃ©ticas",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#operaÃ§Ãµes-aritmÃ©ticas",
    "title": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem",
    "section": "2 OperaÃ§Ãµes aritmÃ©ticas",
    "text": "2 OperaÃ§Ãµes aritmÃ©ticas\nPython utiliza os operadores matemÃ¡ticos padrÃ£o de forma intuitiva:\n\n2 + 4\n\n6\n\n\n\n2 * 4\n\n8\n\n\n\n2 - 4\n\n-2\n\n\n\n2**4  # PotenciaÃ§Ã£o\n\n16\n\n\n\n13 / 2   # DivisÃ£o comum (resultado decimal)\n\n6.5\n\n\n\n13 // 2  # DivisÃ£o inteira\n\n6\n\n\n\n13 % 2   # MÃ³dulo (resto da divisÃ£o)\n\n1\n\n\nPython respeita a precedÃªncia dos operadores matemÃ¡ticos:\n\n5 * (9 + 2)\n\n55\n\n\n\n5 * 9 + 2\n\n47\n\n\n\n3 + 4**2\n\n19\n\n\n\n2.1 FunÃ§Ãµes matemÃ¡ticas\nPython oferece funÃ§Ãµes matemÃ¡ticas tanto no mÃ³dulo math quanto no NumPy:\n\nmath.log(100)      # Logaritmo natural\nmath.log10(100)    # Logaritmo base 10\nmath.sqrt(36)      # Raiz quadrada\nmath.pi            # Constante Ï€\n\n3.141592653589793\n\n\n\nmath.sin(0.5 * math.pi)       # Seno\nmath.sin(math.radians(90))    # Seno de 90 graus\n\n1.0\n\n\nCom NumPy, temos funÃ§Ãµes vetorizadas:\n\nnp.log(100)\nnp.sqrt(36)\n\nnp.float64(6.0)"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#atribuiÃ§Ã£o-de-valores",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#atribuiÃ§Ã£o-de-valores",
    "title": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem",
    "section": "3 AtribuiÃ§Ã£o de valores",
    "text": "3 AtribuiÃ§Ã£o de valores\nEm Python, atribuÃ­mos valores a variÃ¡veis usando o operador =:\n\nx = np.log(100)\nx\n\nnp.float64(4.605170185988092)\n\n\n\ny = x + 10\ny\n\nnp.float64(14.605170185988092)\n\n\nAo reatribuir um valor, o anterior Ã© substituÃ­do:\n\nx = 5\ny = x + 10\ny\n\n15\n\n\nPython diferencia maiÃºsculas de minÃºsculas:\n\na = math.sqrt(49)\nA = math.sqrt(81)\na, A\n\n(7.0, 9.0)"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#estruturas-de-dados",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#estruturas-de-dados",
    "title": "IntroduÃ§Ã£o ao Python: Estrutura da Linguagem",
    "section": "4 Estruturas de dados",
    "text": "4 Estruturas de dados\n\n4.1 Listas\nListas sÃ£o coleÃ§Ãµes ordenadas e mutÃ¡veis em Python:\n\nx = [4, 3.0, 5, 9, 10]\nx\n\n[4, 3.0, 5, 9, 10]\n\n\n\ntype(x)        # Tipo do objeto\nlen(x)         # Comprimento da lista\n\n5\n\n\nAcessando elementos (Ã­ndices comeÃ§am em 0):\n\nx[0]           # Primeiro elemento\nx[0:]          # Do primeiro elemento em diante\n\n[4, 3.0, 5, 9, 10]\n\n\nImportante: Multiplicar uma lista por um nÃºmero replica a lista:\n\nx * 2          # Replica a lista duas vezes\n\n[4, 3.0, 5, 9, 10, 4, 3.0, 5, 9, 10]\n\n\n\n\n4.2 Arrays NumPy\nArrays sÃ£o mais eficientes para operaÃ§Ãµes numÃ©ricas:\n\ny = np.array(x)\ny\n\narray([ 4.,  3.,  5.,  9., 10.])\n\n\n\ntype(y)\nlen(y)\ny[0]           # Primeiro elemento\ny[0:2]         # Primeiros dois elementos\n\narray([4., 3.])\n\n\nOperaÃ§Ãµes em arrays sÃ£o elemento por elemento:\n\ny * 2          # Multiplica cada elemento por 2\n\narray([ 8.,  6., 10., 18., 20.])\n\n\nComparaÃ§Ã£o entre listas e arrays:\n\nx * 2                    # Lista: replica\ny * 2                    # Array: multiplica cada elemento\n[i * 2 for i in x]      # List comprehension: multiplica cada elemento\n\n[8, 6.0, 10, 18, 20]\n\n\n\n\n4.3 SequÃªncias\nPython oferece vÃ¡rias formas de criar sequÃªncias:\n\nlist(range(2, 11))       # SequÃªncia de 2 a 10\nnp.linspace(2, 10, 4)    # 4 pontos igualmente espaÃ§ados entre 2 e 10\nnp.repeat(4, 6)          # Repete o valor 4 seis vezes\n\narray([4, 4, 4, 4, 4, 4])\n\n\n\n[2, 5] * 3               # Lista: replica\nnp.tile([2, 5], 3)       # Array: repete o padrÃ£o\n\narray([2, 5, 2, 5, 2, 5])\n\n\n\n\n4.4 Strings (cadeias de caracteres)\nStrings sÃ£o sequÃªncias de caracteres:\n\nespecies = [\"Deuterodon iguape\", \n           \"Characidium japuhybense\", \n           \"Trichomycterus zonatus\"]\nespecies\n\n['Deuterodon iguape', 'Characidium japuhybense', 'Trichomycterus zonatus']\n\n\n\nsorted(especies)         # Ordena alfabeticamente\n\n['Characidium japuhybense', 'Deuterodon iguape', 'Trichomycterus zonatus']\n\n\nImportante: Python Ã© tipado dinamicamente, mas operaÃ§Ãµes devem ser compatÃ­veis:\n\nespecies = [\n    \"Deuterodon iguape\",\n    \"Characidium japuhybense\", \n    \"Trichomycterus zonatus\",\n    4]\n\n# especies[3] + 3  # Isso causaria erro: nÃ£o pode somar string com nÃºmero\n\n\n\n4.5 Arrays 2D (matrizes)\nListas de listas podem representar matrizes:\n\nx = [\n    [21, 26, 5, 18],\n    [17, 28, 20, 15],\n    [13, 14, 27, 22]\n]\n\nx\nx[0]           # Primeira linha\nx[0][0]        # Elemento da primeira linha, primeira coluna\n\n21\n\n\nArrays NumPy oferecem indexaÃ§Ã£o mais conveniente:\n\ny = np.array(x)\ny\ny[0]           # Primeira linha\ny[0][0]        # Elemento [0,0]\ny[0, 0]        # NotaÃ§Ã£o matricial\ny[0,:]         # Primeira linha (todas as colunas)\ny[:,0]         # Primeira coluna (todas as linhas)\n\narray([21, 17, 13])\n\n\n\n\n4.6 DicionÃ¡rios\nDicionÃ¡rios armazenam pares chave-valor:\n\nnosso_dic = {\n    'Ilha' : ['Ilhabela', 'Anchieta', 'Cardoso'],\n    'Areaskm2': [347.5, 8.3, 131]\n}\nnosso_dic\nnosso_dic.keys()       # Mostra as chaves\n\ndict_keys(['Ilha', 'Areaskm2'])\n\n\n\n\n4.7 DataFrames\nDataFrames sÃ£o estruturas tabulares do Pandas, similares a planilhas:\n\ndf = pd.DataFrame(nosso_dic)\ndf\ndf['Ilha']             # Acessa a coluna 'Ilha'\n\n0    Ilhabela\n1    Anchieta\n2     Cardoso\nName: Ilha, dtype: object"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html",
    "href": "content/funcoes-modelos/funcoes-potencia.html",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#pacotes-e-bibliotecas",
    "href": "content/funcoes-modelos/funcoes-potencia.html#pacotes-e-bibliotecas",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#definiÃ§Ã£o-e-tipos-de-funÃ§Ãµes-potÃªncias",
    "href": "content/funcoes-modelos/funcoes-potencia.html#definiÃ§Ã£o-e-tipos-de-funÃ§Ãµes-potÃªncias",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "2 DefiniÃ§Ã£o e Tipos de FunÃ§Ãµes PotÃªncias",
    "text": "2 DefiniÃ§Ã£o e Tipos de FunÃ§Ãµes PotÃªncias\nUma funÃ§Ã£o potÃªncia Ã© definida como uma funÃ§Ã£o da forma \\(f(x) = x^k\\), em que \\(k\\) Ã© uma constante.\nO valor da constante \\(k\\) determina a classificaÃ§Ã£o da funÃ§Ã£o potÃªncia:\n\nMonÃ´mio: para \\(k = n\\), onde \\(n\\) Ã© um inteiro positivo. Exemplos - \\(f(x) = x^2\\) ou \\(f(x) = x^3\\).\nFunÃ§Ã£o raiz: para \\(k = 1/n\\), onde \\(n\\) Ã© um inteiro positivo. Exemplos - \\(f(x) = x^{1/2}\\) (raiz quadrada) ou \\(f(x) = x^{1/3}\\) (raiz cÃºbica).\nFunÃ§Ã£o recÃ­proca: para \\(k = -1\\). Ou seja, \\(f(x) = x^{-1} = 1/x\\).\n\n\n2.1 Definindo e Visualizando FunÃ§Ãµes PotÃªncias em Python\nVamos usar o Python para definir e plotar exemplos de cada tipo de funÃ§Ã£o potÃªncia. Isso nos ajudarÃ¡ a entender suas caracterÃ­sticas visuais.\n\n# Definindo a funÃ§Ã£o potÃªncia em python\ndef potencia(x, n):\n    \"\"\"FunÃ§Ã£o potÃªncia: f(x) = x^k.\"\"\"\n    return x**n\n\nUtilizando a funÃ§Ã£o criada.\n\n# Gerando um intervalo de valores para x para plotagem\n# ComeÃ§amos de 0.1 para evitar divisÃ£o por zero na funÃ§Ã£o recÃ­proca.\nx_values = np.linspace(0.1, 5, 400) \n# x_values\n\n\n# Gerando valores de y\ny_values = potencia(x_values, 2)\n# y_values\n\n\n# Criando trÃªs grÃ¡ficos lado a lado com diferentes valores de k\n# Criando os subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 3))\n\n# Primeiro grÃ¡fico: f(x) = xÂ²\nax1.plot(x_values, potencia(x_values, 2), label='f(x) = xÂ²')\nax1.set_title('MonÃ´mio')\nax1.set_xlabel('x')\nax1.set_ylabel('f(x)')\nax1.legend()\nax1.grid(True)\n\n# Segundo grÃ¡fico: f(x) = x^(1/2)\nax2.plot(x_values, potencia(x_values, 1/2), label='f(x) = x^(1/2)')\nax2.set_title('FunÃ§Ã£o Raiz')\nax2.set_xlabel('x')\nax2.set_ylabel('f(x)')\nax2.legend()\nax2.grid(True)\n\n# Terceiro grÃ¡fico: f(x) = xâ»Â¹\nax3.plot(x_values, potencia(x_values, -1), label='f(x) = xâ»Â¹')\nax3.set_title('FunÃ§Ã£o RecÃ­proca')\nax3.set_xlabel('x')\nax3.set_ylabel('f(x)')\nax3.legend()\nax3.grid(True)\n\n# Ajustando o layout e salvando a figura\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#exemplo-da-relaÃ§Ã£o-espÃ©cie-Ã¡rea",
    "href": "content/funcoes-modelos/funcoes-potencia.html#exemplo-da-relaÃ§Ã£o-espÃ©cie-Ã¡rea",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "3 Exemplo da RelaÃ§Ã£o EspÃ©cie-Ãrea",
    "text": "3 Exemplo da RelaÃ§Ã£o EspÃ©cie-Ãrea\nA funÃ§Ã£o potÃªncia Ã© amplamente utilizada em ecologia para modelar fenÃ´menos no mundo real. Um exemplo Ã© a relaÃ§Ã£o entre o nÃºmero de espÃ©cies (\\(S\\)) e a Ã¡rea de uma regiÃ£o (\\(A\\)). A relaÃ§Ã£o entre \\(S\\) e \\(A\\) Ã© geralmente modelada por:\n\\[S(A) = cA^k\\]\nEm que \\(c\\) e \\(k\\) sÃ£o coeficientes que precisam ser determinados a partir de dados observados.\nConsidere a tabela de dados que mostra valores de Ã¡rea (A) e riqueza de espÃ©cies (S):\n\n\n\nObservaÃ§Ã£o\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nA (kmÂ²)\n0,25\n0,5\n1\n2\n4\n7,9\n15,9\n31,6\n63\n\n\nS\n6\n10\n13\n14\n17\n19\n22\n24\n28\n\n\n\nPodemos observar esta relaÃ§Ã£o em Python como segue:\n\n3.1 Definindo a tabela de dados\n\n# Dados da tabela\ndata = {\n    'A': [0.25, 0.5, 1, 2, 4, 7.9, 15.9, 31.6, 63],\n    'S': [6, 10, 13, 14, 17, 19, 22, 24, 28]\n}\ndf = pd.DataFrame(data)\n\n\n\n3.2 Visualizando o grÃ¡fico de dispersÃ£o\n\nplt.figure(figsize=(8, 5))\nplt.scatter(df['A'], df['S'], label='Dados Observados')\nplt.title('Diagrama de DispersÃ£o: RelaÃ§Ã£o EspÃ©cie-Ãrea')\nplt.xlabel('Ãrea (kmÂ²)')\nplt.ylabel('NÃºmero de EspÃ©cies')\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#mÃ©todo-dos-mÃ­nimos-quadrados-mmq-para-o-modelo-de-regressÃ£o-potÃªncia",
    "href": "content/funcoes-modelos/funcoes-potencia.html#mÃ©todo-dos-mÃ­nimos-quadrados-mmq-para-o-modelo-de-regressÃ£o-potÃªncia",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "4 MÃ©todo dos MÃ­nimos Quadrados (MMQ) para o Modelo de RegressÃ£o PotÃªncia",
    "text": "4 MÃ©todo dos MÃ­nimos Quadrados (MMQ) para o Modelo de RegressÃ£o PotÃªncia\nPodemos utilizar o MMQ para encontrar os coeficientes da relaÃ§Ã£o de potÃªncia. Para isso precisamos antes linearizar a relaÃ§Ã£o, aplicando o logaritmo em ambos os lados da equaÃ§Ã£o.\n\n\n\n\n\n\nImportanteLinearizando a relaÃ§Ã£o potÃªncia\n\n\n\n\nComece com a equaÃ§Ã£o original: \\[S = cA^k\\]\nAplique o logaritmo (de qualquer base) nos dois lados: \\[\\log(S) = \\log(cA^k)\\]\nUse a propriedade do logaritmo do produto \\(\\log(xy) = \\log(x) + \\log(y)\\): \\[\\log(S) = \\log(c) + \\log(A^k)\\]\nUse a propriedade do logaritmo da potÃªncia \\(\\log(x^p) = p\\log(x)\\): \\[\\log(S) = \\log(c) + k\\log(A)\\]\n\nAo final, obtemos uma equaÃ§Ã£o linear na forma \\(y = a + bx\\), onde:\n\n\\(y = \\log(S)\\)\n\\(x = \\log(A)\\)\nO coeficiente angular Ã© \\(b = k\\)\nO intercepto linear (onde a reta cruza o eixo y) Ã© \\(a = \\log(c)\\)\n\n\n\nApÃ³s a linearizaÃ§Ã£o, os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{y}\\), sÃ£o definidos como segue:\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} \\log(x_1) \\\\ \\log(x_2) \\\\ \\vdots \\\\ \\log(x_n) \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} \\log(y_1) \\\\ \\log(y_2) \\\\ \\vdots \\\\ \\log(y_n) \\end{bmatrix}\\]\nA partir daÃ­, definimos as matrizes \\(X\\) e \\(Y\\) como no modelo linear simples e seguimos com as mesmas operaÃ§Ãµes matriciais.\nVamos criar uma funÃ§Ã£o em python que implementa o MMQ:\n\n\n\n\n\n\nImportanteFunÃ§Ã£o em python para MMQ\n\n\n\n\ndef mmq(x, y):\n    \"\"\"\n    Calcula os coeficientes (B) e o RÂ² de uma regressÃ£o linear simples.\n\n    Args:\n        x (list ou np.ndarray): Os valores da variÃ¡vel independente.\n        y (list ou np.ndarray): Os valores da variÃ¡vel dependente.\n\n    Returns:\n        tuple: Uma tupla contendo a matriz de coeficientes B e o valor de RÂ².\n    \"\"\"\n    # 1. DefiniÃ§Ã£o das matrizes do sistema\n    n = len(x)\n    # Converte para array numpy para garantir a funcionalidade\n    x_array = np.array(x)\n    f0 = np.ones(n)\n    f1 = x_array.copy()\n\n    X = np.column_stack((f0, f1))\n    Y = np.array(y).reshape(n, 1)\n\n    # 2. CÃ¡lculo dos coeficientes\n    XTX = X.T @ X\n    XTY = X.T @ Y\n    XTX_inv = np.linalg.inv(XTX)\n    B = XTX_inv @ XTY\n    \n    return B\n\n\n\nDefinida a funÃ§Ã£o mmq basta utilizarmos com um conjunto de dados de entrada.\n\n# Ajustando o modelo espÃ©cie-Ã¡rea\nB_ea = mmq(np.log(df['A']), np.log(df['S']))\nB_ea\n\narray([[2.4039032 ],\n       [0.24475497]])\n\n\n\n4.1 Visualizando os coeficientes ajustados\n\nc = np.exp(B_ea[0])\nk = B_ea[1]\n\nprint('c: ', c)\nprint('k: ', k)\n\nc:  [11.06628617]\nk:  [0.24475497]\n\n\nO modelo de regressÃ£o potÃªncia para a riqueza de espÃ©cies, com base nos dados fornecidos, foi determinado como\n\\[S(A) = 11.066A^{0.244}\\]\nOs valores de \\(c\\) e \\(k\\) foram, respectivamente, \\(11.066\\) e \\(0.244\\)."
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#visualizando-o-ajuste-da-curva-de-regressÃ£o-potÃªncia",
    "href": "content/funcoes-modelos/funcoes-potencia.html#visualizando-o-ajuste-da-curva-de-regressÃ£o-potÃªncia",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "5 Visualizando o Ajuste da Curva de RegressÃ£o PotÃªncia",
    "text": "5 Visualizando o Ajuste da Curva de RegressÃ£o PotÃªncia\nPodemos criar uma nova funÃ§Ã£o que permitirÃ¡ encontrar os valores ajustados para o modelo potÃªncia a partir dos coeficientes da regressÃ£o obtidos.\n\ndef S_modelo(novo_x, c, k):\n    y_fit = c * novo_x ** k\n    return y_fit\n\n\n5.1 Gerando novos valores de x\n\nA_values = np.linspace(np.min(df['A']), np.max(df['A']), 400) \nS_fit = S_modelo(A_values, c, k)\n\n\n\n5.2 Plotanto o grÃ¡fico\n\n# Plotar os dados e o modelo ajustado\nplt.figure(figsize=(8, 5))\nplt.scatter(df['A'], df['S'], label='Dados Observados')\nplt.plot(A_values, S_fit, color='red', label=f'Modelo Ajustado: S(A) = {c[0]:.3f}A^{k[0]:.3f}')\nplt.title('Modelo de RegressÃ£o PotÃªncia Ajustado para RelaÃ§Ã£o EspÃ©cie-Ãrea')\nplt.xlabel('Ãrea (kmÂ²)')\nplt.ylabel('NÃºmero de EspÃ©cies')\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#estimativas-e-previsÃµes-com-o-modelo",
    "href": "content/funcoes-modelos/funcoes-potencia.html#estimativas-e-previsÃµes-com-o-modelo",
    "title": "Explorando FunÃ§Ãµes PotÃªncias com Python",
    "section": "6 Estimativas e PrevisÃµes com o Modelo",
    "text": "6 Estimativas e PrevisÃµes com o Modelo\nCom o modelo, podemos estimar a riqueza de espÃ©cies para Ã¡reas especÃ­ficas.\n\n# Estimando a riqueza de espÃ©cies para Ã¡reas especÃ­ficas\nS_10km2 = S_modelo(10, c, k)\nS_70km2 = S_modelo(70, c, k)\n\nprint(f\"Riqueza estimada para uma Ã¡rea de 10 kmÂ²: {S_10km2[0]:.3f} â‰ˆ {round(S_10km2[0])} espÃ©cies\")\nprint(f\"Riqueza predita para uma Ã¡rea de 70 kmÂ²: {S_70km2[0]:.3f} â‰ˆ {round(S_70km2[0])} espÃ©cies\")\n\nRiqueza estimada para uma Ã¡rea de 10 kmÂ²: 19.443 â‰ˆ 19 espÃ©cies\nRiqueza predita para uma Ã¡rea de 70 kmÂ²: 31.304 â‰ˆ 31 espÃ©cies\n\n\n\n6.1 DeterminaÃ§Ã£o da Ãrea para Exceder uma Riqueza EspecÃ­fica\nO modelo tambÃ©m permite determinar qual Ã¡rea mÃ­nima Ã© necessÃ¡ria para que a riqueza de espÃ©cies exceda um certo valor. Por exemplo, para exceder 35 espÃ©cies, o cÃ¡lculo Ã©;\n\\[A &gt; \\left( \\frac{35}{c} \\right)^{1/k}\\]\n\n\n\n\n\n\nImportanteDeterminando a Ã¡rea mÃ­nima para exceder uma riqueza especÃ­fica\n\n\n\n\nComece com a equaÃ§Ã£o original: \\[S = cA^k\\]\nEstabeleÃ§a a desigualdade para exceder o valor alvo: \\[cA^k &gt; S_{\\text{alvo}}\\]\nDivida ambos os lados por \\(c\\) (como \\(c &gt; 0\\), a desigualdade se mantÃ©m): \\[A^k &gt; \\frac{S_{\\text{alvo}}}{c}\\]\nAplique a raiz \\(k\\)-Ã©sima em ambos os lados (como \\(k &gt; 0\\), a desigualdade se mantÃ©m): \\[A &gt; \\left( \\frac{S_{\\text{alvo}}}{c} \\right)^{1/k}\\]\n\n\n\n\n\n6.2 Resolvendo a Desigualdade\n\n# Riqueza de espÃ©cies alvo\ntarget_species = 35\n\n# Calculando a Ã¡rea necessÃ¡ria\narea_necessaria = (target_species / c)**(1/k)\n\nprint(f\"Para a riqueza exceder {target_species} espÃ©cies:\")\nprint(f\"Ãrea deve ser maior que aproximadamente {area_necessaria[0]:.3f} kmÂ².\")\n\nPara a riqueza exceder 35 espÃ©cies:\nÃrea deve ser maior que aproximadamente 110.441 kmÂ²."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "",
    "text": "A modelagem bayesiana constitui um processo sistemÃ¡tico e iterativo para integrar dados e conhecimento prÃ©vio, visando a compreensÃ£o aprofundada de um fenÃ´meno. O fluxo de trabalho bayesiano Ã© um ciclo contÃ­nuo que envolve:\nDescobertas ou problemas identificados em etapas posteriores (como diagnÃ³stico ou validaÃ§Ã£o) frequentemente levam Ã  revisÃ£o e ao refinamento de decisÃµes tomadas em etapas anteriores (como a especificaÃ§Ã£o do modelo ou a escolha das priors). Para uma dsicussÃ£o detalhada do fluxo de trabalho Bayesiano, veja o texto Bayesian workflow.\nPara demonstrar este fluxo de trabalho de forma prÃ¡tica, utilizaremos a biblioteca Bambi (BAyesian Model-Building Interface), uma interface de alto nÃ­vel construÃ­da sobre o PyMC que simplifica a implementaÃ§Ã£o de modelos bayesianos comuns em Python. A biblioteca Bambi utiliza uma sintaxe baseada em fÃ³rmulas, semelhante Ã quela encontrada em pacotes R como lme4 ou brms, permitindo que nos concentremos mais nas etapas analÃ­ticas do fluxo de trabalho do que nos detalhes computacionais subjacentes.\nNosso objetivo serÃ¡ percorrer estas etapas utilizando o conjunto de dados altura_adultos_subset.csv, que descreve a relaÃ§Ã£o entre altura de indivÃ­duos e nÃºmero do calÃ§ado. Ao fazer isso, esperamos que vocÃª reflita criticamente sobre como a avaliaÃ§Ã£o sistemÃ¡tica e o refinamento contÃ­nuo do modelo, facilitados por ferramentas como Bambi/PyMC, sÃ£o essenciais para extrair conhecimento cientÃ­fico robusto sobre os processos subjacentes aos dados observados.\nNosso objetivo serÃ¡ percorrer cada uma das etapas do fluxo de trabalho bayesiano utilizando o conjunto de dados altura_adultos_subset.csv, que descreve a relaÃ§Ã£o entre a altura de indivÃ­duos e o nÃºmero do calÃ§ado."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#preparaÃ§Ã£o-do-ambiente",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#preparaÃ§Ã£o-do-ambiente",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "1 PreparaÃ§Ã£o do ambiente",
    "text": "1 PreparaÃ§Ã£o do ambiente\n\n# ImportaÃ§Ã£o das principais bibliotecas necessÃ¡rias para anÃ¡lise de dados, visualizaÃ§Ã£o, modelagem bayesiana e diagnÃ³stico.\nimport arviz as az\nimport bambi as bmb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport random"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#importaÃ§Ã£o-e-visualizaÃ§Ã£o-dos-dados",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#importaÃ§Ã£o-e-visualizaÃ§Ã£o-dos-dados",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "2 ImportaÃ§Ã£o e visualizaÃ§Ã£o dos dados",
    "text": "2 ImportaÃ§Ã£o e visualizaÃ§Ã£o dos dados\nVamos visualizar a relaÃ§Ã£o entre o nÃºmero do calÃ§ado e a altura. Esta etapa Ã© importante para termos uma ideia preliminar do padrÃ£o nos dados a fim de julgarmos qual modelo adequado para descrever esta relaÃ§Ã£o.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura_adultos_subset.csv')\n\n\nsns.regplot(data=df, x='calcado', y='altura', ci=None, scatter=True, fit_reg=False)\n\n\n\n\n\n\n\n\nOs dados observados, sugere que um modelo linear Ã© razoÃ¡vel se buscamos prever a altura de uma passoal adultra como funÃ§Ã£o do nÃºmero do calÃ§ado o que justifica a implementaÃ§Ã£o de um modelo de regressÃ£o linear simples."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#especificaÃ§Ã£o-e-ajuste-do-modelo",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#especificaÃ§Ã£o-e-ajuste-do-modelo",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "3 EspecificaÃ§Ã£o e ajuste do modelo",
    "text": "3 EspecificaÃ§Ã£o e ajuste do modelo\nEspecificamos um modelo de regressÃ£o linear bayesiano em que a altura Ã© modelada como uma funÃ§Ã£o do nÃºmero do calÃ§ado. A biblioteca Bambi adota uma sintaxe onde expressamos a relaÃ§Ã£o entre as variÃ¡veis na forma y ~ x. Essa notaÃ§Ã£o indica que a variÃ¡vel resposta (y) Ã© explicada linearmente pela variÃ¡vel preditora (x), o que corresponde, ao modelo:\n\\[\ny = \\beta_0 + \\beta_1 x.\n\\]\nNesse caso, o Bambi interpreta a fÃ³rmula altura ~ calcado como uma especificaÃ§Ã£o de que a altura dos indivÃ­duos depende linearmente do nÃºmero do calÃ§ado, com coeficientes a serem estimados a partir dos dados.\n\nmod = bmb.Model(\"altura ~ calcado\", df)\nmod\n\n       Formula: altura ~ calcado\n        Family: gaussian\n          Link: mu = identity\n  Observations: 5\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 172.0, sigma: 300.3331)\n            calcado ~ Normal(mu: 0.0, sigma: 7.3612)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 11.8659)\n\n\n\n\n\n\n\n\nDicaEstrutura do modelo em Bambi\n\n\n\nAo inspecionair o objeto mod, podemos verificar um resumo da estrutura do modelo especificado:\n\nFormula: altura ~ calcado: Descreve a fÃ³rmula estatÃ­stica especificada no modelo.\nFamily: gaussian: Indica a famÃ­lia da distribuiÃ§Ã£o de probabilidade que Bambi assumiu para a variÃ¡vel resposta.\nLink: mu = identity: Especifica a funÃ§Ã£o de ligaÃ§Ã£o que conecta o modelo linear ao parÃ¢metro da famÃ­lia da distribuiÃ§Ã£o.\nObservations: 5: Mostra o nÃºmero de linhas (observaÃ§Ãµes) no DataFrame que foram usadas para construir o modelo.\nPriors: DistribuiÃ§Ãµes a priori. Se nÃ£o especificadas pelo usuÃ¡rio, o Bambi atribui priors padrÃ£o razoÃ¡veis parea o conjuto de dados e o modelo utilizado.\n\ntarget = mu: Indica que o modelo linear estÃ¡ focando em estimar a mÃ©dia (mu) da distribuiÃ§Ã£o Gaussiana.\n\nCommon-level effects: Lista os parÃ¢metros associados aos termos fixos no modelo linear.\nIntercept ~ Normal(â€¦): Define a prior para o intercepto (\\(\\beta_0\\))\ncalcado ~ Normal(â€¦): Define a prior para o coeficiente de regressÃ£o associado Ã  variÃ¡vel calcado (\\(\\beta_1\\)).\n\nAuxiliary parameters: ParÃ¢metros nÃ£o diretamente modelados pelo predictor linear.\n\nsigma ~ HalfStudentT(â€¦): Define a prior para o parÃ¢metro de desvio padrÃ£o (\\(\\sigma\\))."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#amostragem-mcmc",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#amostragem-mcmc",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "4 Amostragem MCMC",
    "text": "4 Amostragem MCMC\nRealizamos a amostragem MCMC (Markov Chain Monte Carlo) para obter amostras da distribuiÃ§Ã£o a posteriori dos parÃ¢metros, combinando as informaÃ§Ãµes fornecidas pelos dados com as distribuiÃ§Ãµes a priori.\n\nmod_fit = mod.fit()\nmod_fit\n\n\n\n\n\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:    (chain: 4, draw: 1000)\nCoordinates:\n  * chain      (chain) int64 32B 0 1 2 3\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\nData variables:\n    sigma      (chain, draw) float64 32kB 12.82 5.324 4.266 ... 7.573 19.83 4.2\n    Intercept  (chain, draw) float64 32kB -6.19 79.7 72.66 ... 3.963 11.6 104.6\n    calcado    (chain, draw) float64 32kB 4.255 2.204 2.379 ... 3.947 1.687\nAttributes:\n    created_at:                  2026-02-19T12:17:54.860559+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    sampling_time:               1.056750774383545\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (3)sigma(chain, draw)float6412.82 5.324 4.266 ... 19.83 4.2array([[12.81741535,  5.32434608,  4.26571042, ...,  7.19993658,\n        18.07536279, 15.50659824],\n       [ 7.26439627,  9.49991108,  9.55902361, ..., 11.4661689 ,\n        10.74318121,  6.98709945],\n       [15.47477747, 13.03995877, 14.70813622, ...,  6.28721435,\n         8.42474631,  9.2594542 ],\n       [ 5.93351046,  4.58998872, 12.66511175, ...,  7.57266598,\n        19.82840813,  4.19956176]], shape=(4, 1000))Intercept(chain, draw)float64-6.19 79.7 72.66 ... 11.6 104.6array([[ -6.19002754,  79.69758448,  72.65792859, ...,  66.34573898,\n         11.42168586,   0.21231097],\n       [113.37660505,  83.33559985,  77.07392243, ...,  -8.89825319,\n         56.66426362,  31.95409566],\n       [ 27.282223  , -43.20413615,  60.13479023, ...,  92.20121133,\n         34.81016428,  51.79221444],\n       [ 49.1165146 ,  78.32703166,  12.44660229, ...,   3.96294101,\n         11.60458819, 104.57452517]], shape=(4, 1000))calcado(chain, draw)float644.255 2.204 2.379 ... 3.947 1.687array([[4.25496197, 2.20358419, 2.37866834, ..., 2.62769952, 3.99674521,\n        4.46528147],\n       [1.45262439, 2.28667928, 2.40997987, ..., 4.46953765, 2.64979557,\n        3.37974788],\n       [3.8324902 , 4.88799605, 2.61513966, ..., 1.8536024 , 3.36991379,\n        2.91825591],\n       [2.9832878 , 2.35062828, 3.94609027, ..., 4.12731208, 3.94672787,\n        1.6866787 ]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2026-02-19T12:17:54.860559+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1sampling_time :1.056750774383545tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 528kB\nDimensions:                (chain: 4, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 32B 0 1 2 3\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/18)\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 30.27 30.68 ... 30.95\n    acceptance_rate        (chain, draw) float64 32kB 1.0 0.6788 ... 0.9679\n    perf_counter_start     (chain, draw) float64 32kB 7.678e+04 ... 7.678e+04\n    index_in_trajectory    (chain, draw) int64 32kB 2 2 -1 -2 -2 2 ... 0 2 2 2 3\n    lp                     (chain, draw) float64 32kB -29.4 -27.12 ... -28.84\n    ...                     ...\n    tree_depth             (chain, draw) int64 32kB 2 2 2 2 2 2 ... 2 1 2 2 2 3\n    n_steps                (chain, draw) float64 32kB 3.0 3.0 3.0 ... 3.0 7.0\n    perf_counter_diff      (chain, draw) float64 32kB 0.0001957 ... 0.0003335\n    process_time_diff      (chain, draw) float64 32kB 0.0001957 ... 0.0003336\n    energy_error           (chain, draw) float64 32kB -0.08676 ... -1.165\n    max_energy_error       (chain, draw) float64 32kB -0.1561 1.997 ... -1.435\nAttributes:\n    created_at:                  2026-02-19T12:17:54.873214+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    sampling_time:               1.056750774383545\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (18)reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))energy(chain, draw)float6430.27 30.68 28.56 ... 30.91 30.95array([[30.27393878, 30.67543373, 28.56101895, ..., 29.28834498,\n        30.75944379, 34.44819584],\n       [29.90123906, 28.70629638, 27.64538882, ..., 29.79278723,\n        30.39238441, 30.32281733],\n       [30.82192164, 35.95668999, 34.72839293, ..., 30.13014212,\n        29.11322617, 27.53532614],\n       [30.38110092, 26.96631799, 29.53502712, ..., 28.56744654,\n        30.91345457, 30.95141848]], shape=(4, 1000))acceptance_rate(chain, draw)float641.0 0.6788 0.5379 ... 0.8919 0.9679array([[1.        , 0.67878498, 0.5379292 , ..., 0.71582217, 0.73838575,\n        0.78614672],\n       [0.26708511, 0.80102127, 1.        , ..., 0.99856967, 0.97472883,\n        0.78149229],\n       [1.        , 0.34647542, 0.97975062, ..., 0.18083964, 0.96185254,\n        0.96531319],\n       [0.00989953, 0.96340269, 0.22685756, ..., 0.93412117, 0.89194835,\n        0.96785717]], shape=(4, 1000))perf_counter_start(chain, draw)float647.678e+04 7.678e+04 ... 7.678e+04array([[76782.59272149, 76782.59298821, 76782.59326042, ...,\n        76782.94385301, 76782.94410061, 76782.94434225],\n       [76782.60839864, 76782.60866101, 76782.60908722, ...,\n        76782.92483403, 76782.92510155, 76782.92561194],\n       [76782.62023255, 76782.62050318, 76782.62093457, ...,\n        76782.97129487, 76782.97153542, 76782.97177893],\n       [76782.61768904, 76782.61793218, 76782.61897322, ...,\n        76782.99912862, 76782.99937174, 76782.99961328]], shape=(4, 1000))index_in_trajectory(chain, draw)int642 2 -1 -2 -2 2 3 ... 1 0 0 2 2 2 3array([[ 2,  2, -1, ...,  0,  2, -1],\n       [ 0,  1, -1, ...,  2,  3, -1],\n       [ 1,  3, -2, ...,  0, -2, -1],\n       [ 0,  2, -2, ...,  2,  2,  3]], shape=(4, 1000))lp(chain, draw)float64-29.4 -27.12 ... -30.66 -28.84array([[-29.40385555, -27.1203794 , -27.7456118 , ..., -26.42615354,\n        -30.21853676, -30.71018626],\n       [-27.45173278, -27.60796675, -27.34997936, ..., -28.90480287,\n        -28.80930955, -27.21956464],\n       [-30.6292007 , -33.76882204, -29.21037938, ..., -28.10749287,\n        -27.07349483, -27.13772958],\n       [-26.51487079, -26.86958249, -28.67399841, ..., -28.12686346,\n        -30.65672201, -28.84172835]], shape=(4, 1000))step_size_bar(chain, draw)float640.6221 0.6221 ... 0.5931 0.5931array([[0.622073  , 0.622073  , 0.622073  , ..., 0.622073  , 0.622073  ,\n        0.622073  ],\n       [0.67658689, 0.67658689, 0.67658689, ..., 0.67658689, 0.67658689,\n        0.67658689],\n       [0.73021543, 0.73021543, 0.73021543, ..., 0.73021543, 0.73021543,\n        0.73021543],\n       [0.59309938, 0.59309938, 0.59309938, ..., 0.59309938, 0.59309938,\n        0.59309938]], shape=(4, 1000))diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))divergences(chain, draw)int640 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], shape=(4, 1000))step_size(chain, draw)float640.6071 0.6071 ... 0.4018 0.4018array([[0.60705735, 0.60705735, 0.60705735, ..., 0.60705735, 0.60705735,\n        0.60705735],\n       [0.59858393, 0.59858393, 0.59858393, ..., 0.59858393, 0.59858393,\n        0.59858393],\n       [0.8307564 , 0.8307564 , 0.8307564 , ..., 0.8307564 , 0.8307564 ,\n        0.8307564 ],\n       [0.40181627, 0.40181627, 0.40181627, ..., 0.40181627, 0.40181627,\n        0.40181627]], shape=(4, 1000))smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(4, 1000))largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(4, 1000))tree_depth(chain, draw)int642 2 2 2 2 2 3 2 ... 3 2 2 1 2 2 2 3array([[2, 2, 2, ..., 2, 2, 3],\n       [2, 3, 1, ..., 2, 3, 3],\n       [2, 3, 3, ..., 2, 2, 3],\n       [1, 2, 3, ..., 2, 2, 3]], shape=(4, 1000))n_steps(chain, draw)float643.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 7.0array([[3., 3., 3., ..., 3., 3., 7.],\n       [3., 7., 1., ..., 3., 7., 7.],\n       [3., 7., 7., ..., 3., 3., 7.],\n       [1., 3., 7., ..., 3., 3., 7.]], shape=(4, 1000))perf_counter_diff(chain, draw)float640.0001957 0.000198 ... 0.0003335array([[0.00019572, 0.00019799, 0.00018841, ..., 0.00017997, 0.00017787,\n        0.00032984],\n       [0.00019109, 0.00035057, 0.00012336, ..., 0.0001983 , 0.00043593,\n        0.00033786],\n       [0.00019956, 0.00035933, 0.0003723 , ..., 0.00017631, 0.00017898,\n        0.00034069],\n       [0.00010224, 0.00019691, 0.00035692, ..., 0.00017861, 0.00017772,\n        0.0003335 ]], shape=(4, 1000))process_time_diff(chain, draw)float640.0001957 0.0001981 ... 0.0003336array([[0.00019567, 0.00019813, 0.00018853, ..., 0.00018003, 0.00017798,\n        0.00032994],\n       [0.00019112, 0.00035065, 0.00012334, ..., 0.00019844, 0.00043603,\n        0.00033802],\n       [0.00019968, 0.00035942, 0.0003725 , ..., 0.00017642, 0.0001791 ,\n        0.00034083],\n       [0.0001021 , 0.00019684, 0.00035714, ..., 0.00017866, 0.00017778,\n        0.00033364]], shape=(4, 1000))energy_error(chain, draw)float64-0.08676 -0.5571 ... 0.1704 -1.165array([[-0.08676354, -0.55707971,  0.46624801, ...,  0.        ,\n         0.325291  , -0.21060465],\n       [ 0.        ,  0.10864021, -0.01464868, ..., -0.04108794,\n        -0.03409156, -0.21987311],\n       [-0.00613259,  0.04629629, -0.42920601, ...,  0.        ,\n        -0.04840926,  0.03876647],\n       [ 0.        ,  0.11630007,  0.70080163, ...,  0.1755585 ,\n         0.17036824, -1.16462335]], shape=(4, 1000))max_energy_error(chain, draw)float64-0.1561 1.997 ... 0.1704 -1.435array([[-0.15613274,  1.99704598,  0.99571865, ...,  0.73611675,\n         0.325291  ,  0.85477271],\n       [ 4.67880379,  0.96693172, -0.01464868, ..., -0.04108794,\n        -0.16684677,  0.46602193],\n       [-0.00924969,  2.85872406, -0.55769345, ...,  6.74226374,\n         0.12153775, -0.13772793],\n       [ 4.61526805, -0.12556977,  6.95041544, ...,  0.1755585 ,\n         0.17036824, -1.43494468]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2026-02-19T12:17:54.873214+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1sampling_time :1.056750774383545tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 80B\nDimensions:  (__obs__: 5)\nCoordinates:\n  * __obs__  (__obs__) int64 40B 0 1 2 3 4\nData variables:\n    altura   (__obs__) float64 40B 178.0 163.0 175.0 155.0 189.0\nAttributes:\n    created_at:                  2026-02-19T12:17:54.877341+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:__obs__: 5Coordinates: (1)__obs__(__obs__)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (1)altura(__obs__)float64178.0 163.0 175.0 155.0 189.0array([178., 163., 175., 155., 189.])Indexes: (1)__obs__PandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='__obs__'))Attributes: (6)created_at :2026-02-19T12:17:54.877341+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1modeling_interface :bambimodeling_interface_version :0.15.0"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verificaÃ§Ã£o-das-priors",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verificaÃ§Ã£o-das-priors",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "5 VerificaÃ§Ã£o das priors",
    "text": "5 VerificaÃ§Ã£o das priors\nNeste exemplo as priors foram atribuÃ­das automaticamente. Veremos como especificÃ¡-las manualmente mais adiante. Por enquanto, iremos nos concentrar em visualizar as distribuiÃ§Ãµes a priori para entender as expectativas iniciais do modelo sobre os parÃ¢metros antes de processar os dados.\n\nmod.plot_priors(var_names=['Intercept', 'calcado', 'sigma'], figsize=(9, 4))\n\narray([&lt;Axes: title={'center': 'Intercept'}&gt;,\n       &lt;Axes: title={'center': 'calcado'}&gt;,\n       &lt;Axes: title={'center': 'sigma'}&gt;], dtype=object)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#diagnÃ³sticos-de-convergÃªncia",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#diagnÃ³sticos-de-convergÃªncia",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "6 DiagnÃ³sticos de convergÃªncia",
    "text": "6 DiagnÃ³sticos de convergÃªncia\nApÃ³s realizar a amostragem MCMC, Ã© fundamental verificar se o processo de amostragem funcionou corretamente. Para isso, utilizamos diagnÃ³sticos de convergÃªncia, que nos ajudam a avaliar se as cadeias geradas estÃ£o representando adequadamente a distribuiÃ§Ã£o a posteriori dos parÃ¢metros.\nUma das ferramentas mais comuns para essa avaliaÃ§Ã£o sÃ£o os trace plots â€” grÃ¡ficos que mostram os valores amostrados para cada parÃ¢metro ao longo das iteraÃ§Ãµes. Idealmente, essas cadeias devem parecer bem misturadas e sem padrÃµes visÃ­veis, o que indica que a amostragem atingiu o chamado estado estacionÃ¡rio, sugerindo que as estimativas sÃ£o confiÃ¡veis.\nTendÃªncias, oscilaÃ§Ãµes sistemÃ¡ticas ou falta de sobreposiÃ§Ã£o entre diferentes cadeias pode ser um sinal de que o algoritmo nÃ£o convergiu adequadamente, exigindo ajustes no modelo ou no processo de amostragem.\n\n# GrÃ¡ficos de diagnÃ³stico\nfig, axes = plt.subplots(3, 2, figsize=(8, 8))\n\n# Trace plots\naz.plot_trace(mod_fit, var_names=['Intercept', 'calcado', 'sigma'], axes=axes)\nplt.suptitle('Trace Plots - ConvergÃªncia das Cadeias MCMC', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#resumo-do-ajuste",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#resumo-do-ajuste",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "7 Resumo do ajuste",
    "text": "7 Resumo do ajuste\n\naz.summary(mod_fit)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nsigma\n8.946\n4.194\n3.423\n16.528\n0.134\n0.156\n1013.0\n1041.0\n1.0\n\n\nIntercept\n66.679\n44.019\n-24.246\n146.581\n0.959\n1.430\n2226.0\n1800.0\n1.0\n\n\ncalcado\n2.596\n1.069\n0.504\n4.635\n0.023\n0.034\n2291.0\n1781.0\n1.0\n\n\n\n\n\n\n\nApÃ³s a amostragem MCMC e a verificaÃ§Ã£o da convergÃªncia, exploramos um resumo estatÃ­stico das distribuiÃ§Ãµes a posteriori dos parÃ¢metros do modelo. Na tabela acima, cada linha corresponde a um parÃ¢metro (sigma, Intercept, calcado). As colunas fornecem estimativas pontuais (MEAN), intervalos de incerteza (SD, HDI) e mÃ©tricas para verificar a qualidade e a confiabilidade das amostras MCMC (MCSE, ESS, R_HAT).\n\n\n\n\n\n\nDicaTabela resumo em um modelo bayesiano\n\n\n\n\nMEAN: A mÃ©dia das amostras a posteriori para o parÃ¢metro.\nSD: O desvio padrÃ£o das amostras a posteriori.\nHDI_3% e HDI_97%: Os limites inferior (3%) e superior (97%) do Intervalo de Credibilidade de Maior Densidade (HDI).\nMCSE_MEAN (Monte Carlo Standard Error of the Mean): O Erro PadrÃ£o de Monte Carlo da MÃ©dia estima a variabilidade da estimativa da mÃ©dia a posteriori devido ao nÃºmero finito e Ã  correlaÃ§Ã£o entre as amostras MCMC.\nMCSE_SD (Monte Carlo Standard Error of the Standard Deviation): O Erro PadrÃ£o de Monte Carlo do Desvio PadrÃ£o. Similar ao MCSE_MEAN, mas estima a precisÃ£o com que o desvio padrÃ£o a posteriori foi estimado a partir das amostras.\nESS_BULK (Effective Sample Size - Bulk): O Tamanho Efetivo da Amostra. Devido Ã  autocorrelaÃ§Ã£o nas cadeias MCMC, o nÃºmero de amostras efetivamente independentes Ã© geralmente menor que o nÃºmero total de amostras coletadas.\nESS_TAIL (Effective Sample Size - Tail): O Tamanho Efetivo da Amostra para as caracterÃ­sticas das caudas da distribuiÃ§Ã£o (como quantis extremos).\nR_HAT (Gelman-Rubin statistic): O R-hat Ã© um diagnÃ³stico de convergÃªncia que compara a variabilidade dentro de cada cadeia MCMC com a variabilidade entre as diferentes cadeias. Se todas as cadeias convergiram para a mesma distribuiÃ§Ã£o estacionÃ¡ria (a posteriori alvo), o valor de R_HAT deve ser muito prÃ³ximo de 1 (idealmente &lt;= 1.01 ou &lt;= 1.05 no mÃ¡ximo). Valores significativamente maiores que 1 indicam que as cadeias nÃ£o convergiram bem."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verificaÃ§Ã£o-das-posteriores-e-comparaÃ§Ã£o-com-as-priors",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verificaÃ§Ã£o-das-posteriores-e-comparaÃ§Ã£o-com-as-priors",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "8 VerificaÃ§Ã£o das posteriores e comparaÃ§Ã£o com as priors",
    "text": "8 VerificaÃ§Ã£o das posteriores e comparaÃ§Ã£o com as priors\nA comparaÃ§Ã£o grÃ¡fica entre as distribuiÃ§Ãµes a priori e a posteriori dos parÃ¢metros nos ajuda a avaliar o quanto os dados foram informativos, mostrando quais parÃ¢metros foram mais ou menos atualizados em relaÃ§Ã£o Ã s nossas crenÃ§as iniciais. Uma pequena mudanÃ§a da prior para a posteriori indica que os dados trouxeram pouca informaÃ§Ã£o nova sobre aquele parÃ¢metro, enquanto uma grande diferenÃ§a sugere que os dados foram bastante informativos. No grÃ¡fico abaixo, visualizamos essa comparaÃ§Ã£o para os parÃ¢metros do modelo (Intercept, calcado e sigma), onde a linha superior exibe as distribuiÃ§Ãµes a priori (atribuÃ­das automaticamente) e a linha inferior apresenta as distribuiÃ§Ãµes a posteriori resultantes da anÃ¡lise bayesiana.\n\nparam_order = ['Intercept', 'calcado', 'sigma']\n\nfig, axes = plt.subplots(nrows=2, ncols=len(param_order), figsize=(9, 6))\n\nmod.plot_priors(var_names=param_order, ax=axes[0, :])\naz.plot_posterior(mod_fit, var_names=param_order, ax=axes[1, :])\n\naxes[0, 0].set_ylabel('Densidade das Prioris')\naxes[1, 0].set_ylabel('Densidade das Posteriores')\n\nText(0, 0.5, 'Densidade das Posteriores')\n\n\n\n\n\n\n\n\n\n\naz.plot_trace(mod_fit, figsize=(9,10))\n\narray([[&lt;Axes: title={'center': 'sigma'}&gt;,\n        &lt;Axes: title={'center': 'sigma'}&gt;],\n       [&lt;Axes: title={'center': 'Intercept'}&gt;,\n        &lt;Axes: title={'center': 'Intercept'}&gt;],\n       [&lt;Axes: title={'center': 'calcado'}&gt;,\n        &lt;Axes: title={'center': 'calcado'}&gt;]], dtype=object)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#prediÃ§Ã£o-bayesiana",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#prediÃ§Ã£o-bayesiana",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "9 PrediÃ§Ã£o Bayesiana",
    "text": "9 PrediÃ§Ã£o Bayesiana\nO processo de prediÃ§Ã£o nos permite estimar valores da variÃ¡vel resposta para novas observaÃ§Ãµes nÃ£o incluÃ­das no conjunto de dados original. Na abordagem bayesiana, a prediÃ§Ã£o vai alÃ©m de fornecer uma estimativa pontual (isto Ã©, da mÃ©dia), incorporando explicitamente a incerteza associada tanto aos parÃ¢metros do modelo quanto Ã  variabilidade intrÃ­nseca do processo gerador dos dados.\nA prediÃ§Ã£o bayesiana utiliza toda a distribuiÃ§Ã£o a posteriori dos parÃ¢metros para gerar a distribuiÃ§Ã£o preditiva a posteriori. Esta distribuiÃ§Ã£o captura duas fontes principais de incerteza:\n\nIncerteza epistÃªmica: Relacionada ao nosso conhecimento limitado sobre os verdadeiros valores dos parÃ¢metros do modelo (representada pela distribuiÃ§Ã£o a posteriori dos parÃ¢metros).\nIncerteza aleatÃ³ria: Relacionada Ã  variabilidade natural do processo (representada pelo componente estocÃ¡stico do modelo, como o termo de erro \\(\\sigma\\)).\n\nA combinaÃ§Ã£o dessas duas fontes de incerteza resulta em intervalos de prediÃ§Ã£o mais amplos que os intervalos de credibilidade da reta mÃ©dia, refletindo de forma mais realista nossa incerteza sobre observaÃ§Ãµes futuras.\n\n9.1 PrediÃ§Ã£o sobre a reta mÃ©dia (Incerteza epistÃªmica)\nA prediÃ§Ã£o da reta mÃ©dia quantifica nossa incerteza sobre o valor esperado da variÃ¡vel resposta, considerando apenas a incerteza nos parÃ¢metros do modelo. As amostras da posteriori geradas pelo mÃ©todo MCMC nos fornecem vÃ¡rias combinaÃ§Ãµes de parÃ¢metros possÃ­veis ajustadas ao conjunto de dados. Podemos entender estas como retas possÃ­veis para o conjunto observado - algumas combinaÃ§Ãµes dos parÃ¢metros fornecem retas mais provÃ¡veis, outras menos.\n\n9.1.1 VisualizaÃ§Ã£o das retas possÃ­veis\nPara visualizar essa incerteza epistÃªmica, vamos primeiro obter amostras da distribuiÃ§Ã£o posterior e construir algumas retas possÃ­veis:\n\n# Definir pontos extremos para construÃ§Ã£o das retas\nx_vals = [32, 48]\nnovo_x = pd.DataFrame({\"calcado\": x_vals})\nposterior_par = mod.predict(mod_fit, kind=\"response_params\", data=novo_x, inplace=False)\nmu_vals = posterior_par.posterior['mu'].values\nmu_flat = mu_vals.reshape(-1, mu_vals.shape[-1])\n\n\n# Calcular a reta mÃ©dia\ny_mean = (posterior_par.posterior['Intercept'].mean().values + \n          posterior_par.posterior['calcado'].mean().values * x_vals)\n\n\n# Plotar uma amostra de retas possÃ­veis\nn = 100\nindices = np.random.choice(mu_flat.shape[0], size=n, replace=False)\n\nplt.figure(figsize=(9, 6))\nfor i in indices:\n    plt.plot(x_vals, mu_flat[i, :], '#e37d76', alpha=0.1)\n\nplt.plot(x_vals, y_mean, '#162be0', linewidth=2, label='Reta mÃ©dia')\n\n# Adicionar os pontos observados e reta mÃ©dia\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', label='ObservaÃ§Ãµes', s = 100)\n\n\nplt.xlabel(\"CalÃ§ado\")\nplt.ylabel(\"Altura prevista\")\nplt.title(f\"Amostra de {n} retas da posteriori\")\nplt.legend()\nplt.grid(True)\nplt.ylim(120, 210)\nplt.xlim(32, 48)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n9.1.2 Intervalo de Credibilidade (IC) para \\(\\mu\\)\nAo invÃ©s de representar todas as retas possÃ­veis, podemos criar um envelope contendo as combinaÃ§Ãµes que determinam os intervalos de credibilidade para a reta mÃ©dia, representando nossa incerteza sobre o valor esperado da resposta:\n\n# Criar sequÃªncia contÃ­nua para visualizaÃ§Ã£o\nx_seq = np.linspace(32, 48, 100)\n\n# Extrair amostras dos parÃ¢metros\nintercept = posterior_par.posterior['Intercept'].values.flatten()\nslope = posterior_par.posterior['calcado'].values.flatten()\n\n# Calcular retas para toda a sequÃªncia\ny_seq = intercept[:, None] + slope[:, None] * x_seq[None, :]\n\n# Calcular intervalo de credibilidade de 95%\ny_ci = np.percentile(y_seq, [2.5, 97.5], axis=0)\n\n# Reta mÃ©dia para toda a sequÃªncia\nintercept_mean = posterior_par.posterior['Intercept'].mean().values\nslope_mean = posterior_par.posterior['calcado'].mean().values\ny_mean_seq = intercept_mean + slope_mean * x_seq\n\n\n# Plotar resultados\nplt.figure(figsize=(9, 6))\n\n# Intervalo de credibilidade (envelope)\nplt.fill_between(x_seq, y_ci[0], y_ci[1], color='#e37d76', alpha=0.2, \n                 label='IC 95% da reta mÃ©dia')\n\n# Pontos observados\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', label='ObservaÃ§Ãµes', s = 100)\n\nplt.plot(x_seq, y_mean_seq, '#162be0', linewidth=2, label='Reta mÃ©dia')\n\nplt.xlabel(\"CalÃ§ado\")\nplt.ylabel(\"Resposta mÃ©dia predita ($\\mu$)\")\nplt.title(\"Reta mÃ©dia e intervalo de credibilidade (95%)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nO Intervalo de Credibilidade representa nossa incerteza sobre o valor mÃ©dio esperado da altura para indivÃ­duos com um determinado nÃºmero de calÃ§ado, refletindo exclusivamente a incerteza epistÃªmica associada aos parÃ¢metros do modelo. Note que a maioria das retas passa prÃ³xima ao centro da distribuiÃ§Ã£o de \\(x\\) e \\(y\\), pois, nas proximidades da mÃ©dia de \\(x\\), hÃ¡ maior confianÃ§a na estimativa da trajetÃ³ria da reta. Ã€ medida que nos afastamos desse centro, a incerteza aumenta, resultando em maior variabilidade nas regiÃµes mais afastadas de \\(x\\).\n\n\n\n9.2 PrediÃ§Ã£o sobre novos pontos (Incerteza epistÃªmica + aleatÃ³ria)\nA prediÃ§Ã£o de novas observaÃ§Ãµes vai alÃ©m da estimativa da mÃ©dia, incorporando tambÃ©m a variabilidade intrÃ­nseca do processo. Enquanto o intervalo de credibilidade nos representa nossa incerteza quanto Ã  reta mÃ©dia, o Intervalo de PrediÃ§Ã£o (IP) nos informa sobre a incerteza associada ao valor que uma nova observaÃ§Ã£o especÃ­fica pode assumir.\n\n9.2.1 ImplementaÃ§Ã£o da prediÃ§Ã£o para novas observaÃ§Ãµes\n\n# Definir valores para prediÃ§Ã£o\ncalcado_pred = np.array([35, 40, 45])\ndados_pred = pd.DataFrame({\"calcado\": calcado_pred})\n\n# PrediÃ§Ã£o da resposta mÃ©dia (Î¼ - apenas incerteza epistÃªmica)\npred_mu = mod.predict(mod_fit, kind=\"response_params\", data=dados_pred, inplace=False)\n\n# PrediÃ§Ã£o de novas observaÃ§Ãµes (Î¼ + Ïƒ - ambas as incertezas)\npred_obs = mod.predict(mod_fit, kind=\"response\", data=dados_pred, inplace=False)\n\nprint(\"Valores preditos para nÃºmero do calÃ§ado:\", calcado_pred)\nprint(\"\\nResumo das prediÃ§Ãµes:\")\nprint(f\"CalÃ§ado 35: Î¼ = {pred_mu.posterior['mu'].values[:,:,0].mean():.1f} cm\")\nprint(f\"CalÃ§ado 40: Î¼ = {pred_mu.posterior['mu'].values[:,:,1].mean():.1f} cm\") \nprint(f\"CalÃ§ado 45: Î¼ = {pred_mu.posterior['mu'].values[:,:,2].mean():.1f} cm\")\n\nValores preditos para nÃºmero do calÃ§ado: [35 40 45]\n\nResumo das prediÃ§Ãµes:\nCalÃ§ado 35: Î¼ = 157.6 cm\nCalÃ§ado 40: Î¼ = 170.5 cm\nCalÃ§ado 45: Î¼ = 183.5 cm\n\n\n\n# VisualizaÃ§Ã£o das prediÃ§Ãµes pontuais\n# Extrair amostras aleatÃ³rias de novas observaÃ§Ãµes para cada valor de calÃ§ado\nn_samples = 80\ncalcado_pred = [35, 40, 45]\ncores = ['#ff6b6b', '#4ecdc4', '#d1c845']\n\nplt.figure(figsize=(8, 5))\n\n# Reta mÃ©dia\nplt.plot(x_seq, y_mean_seq, '#162be0', linewidth=2, label='Reta mÃ©dia (Î¼)')\n\n# Plotar dados originais\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', s=100, \n                label='Dados observados', zorder=5)\n\n# Plotar uma amostra das prediÃ§Ãµes para novos pontos\nfor i, (calcado_val, cor) in enumerate(zip(calcado_pred, cores)):\n    x_sample = [calcado_val] * n_samples\n    y_sample = random.sample(list(pred_mu.posterior['mu'].values[:,:,i].flatten()), n_samples)\n    plt.scatter(x_sample, y_sample, color=cor, alpha=0.4, s=50, label=f'PrediÃ§Ãµes calÃ§ado n. {calcado_val}')\n\nplt.xlabel(\"NÃºmero do calÃ§ado\")\nplt.ylabel(\"Altura (cm)\")\nplt.title(f\"Reta mÃ©dia e amostra de {n_samples} prediÃ§Ãµes para cada valor de calÃ§ado\")\nplt.legend(loc='lower right')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHistograma das novas prediÃ§Ãµes\n\nplt.figure(figsize=(8, 5))\n\nfor i, (calcado_val, cor) in enumerate(zip(calcado_pred, cores)):\n    y_sample = random.sample(\n        list(pred_mu.posterior['mu'].values[:, :, i].flatten()), n_samples\n    )\n    sns.kdeplot(y_sample, color=cor, fill=True, alpha=0.3, linewidth=2,\n                label=f'CalÃ§ado n. {calcado_val}')\n\nplt.xlabel(\"Altura prevista\")\nplt.ylabel(\"Densidade\")\nplt.title(\"DistribuiÃ§Ãµes de altura\\ndas novas prediÃ§Ãµes por nÃºmero de calÃ§ado\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nObserve que as mÃ©dias das prediÃ§Ãµes para novas observaÃ§Ãµes coincidem com a reta mÃ©dia estimada (\\(\\mu\\)), mas a variabilidade em torno dessas mÃ©dias Ã© maior. Isso ocorre porque essas prediÃ§Ãµes incorporam tanto a incerteza epistÃªmica, proveniente da estimaÃ§Ã£o dos parÃ¢metros do modelo, e a incerteza aleatÃ³ria, associada Ã  variabilidade intrÃ­nseca do processo (\\(\\sigma\\)).\n\n\n\n\n\n\nNotaInterpretaÃ§Ã£o dos tipos de prediÃ§Ã£o bayesiana\n\n\n\nA abordagem bayesiana fornece uma caracterizaÃ§Ã£o completa e hierÃ¡rquica da incerteza preditiva: primeiro quantificando nossa incerteza sobre a relaÃ§Ã£o mÃ©dia entre as variÃ¡veis, e depois expandindo essa anÃ¡lise para incluir a variabilidade natural do fenÃ´meno. Essa distinÃ§Ã£o Ã© fundamental para decisÃµes informadas, pois diferentes tipos de decisÃ£o podem requerer diferentes tipos de intervalo preditivo.\nIntervalo de Credibilidade (IC) para Î¼: Representa nossa incerteza sobre o valor mÃ©dio esperado da altura para indivÃ­duos com um determinado nÃºmero de calÃ§ado. Este intervalo reflete apenas a incerteza epistÃªmica sobre os parÃ¢metros do modelo. Ã‰ mais estreito porque representa nossa incerteza sobre a linha mÃ©dia da relaÃ§Ã£o.\nIntervalo de PrediÃ§Ã£o (IP) para novas observaÃ§Ãµes: Representa nossa incerteza sobre a altura de um novo indivÃ­duo especÃ­fico com um determinado nÃºmero de calÃ§ado. Este intervalo Ã© sempre mais amplo pois incorpora tanto a incerteza epistÃªmica (sobre os parÃ¢metros) quanto a incerteza aleatÃ³ria (variabilidade natural representada por \\(\\sigma\\)).\nA razÃ£o entre as larguras dos intervalos indica o quanto a variabilidade intrÃ­nseca do processo contribui para a incerteza total. Valores maiores sugerem que a variabilidade natural dos dados (\\(\\sigma\\)) Ã© a principal fonte de incerteza nas prediÃ§Ãµes, enquanto valores prÃ³ximos de 1 indicariam que a incerteza sobre os parÃ¢metros Ã© dominante. Essa razÃ£o tambÃ©m permite avaliar aspectos do delineamento experimental, pois a incerteza epistÃªmica diminui Ã  medida que obtemos mais dados, aumentando nossa confianÃ§a na posiÃ§Ã£o da reta mÃ©dia. Por outro lado, a incerteza aleatÃ³ria Ã© inerente ao processo gerador dos dados e nÃ£o Ã© afetada pelo tamanho da amostra, representando um limite irreducÃ­vel da precisÃ£o nas prediÃ§Ãµes."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#estrutura-de-cÃ³digo-bambi-vs-pymc",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#estrutura-de-cÃ³digo-bambi-vs-pymc",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "10 Estrutura de cÃ³digo: Bambi vs PyMC",
    "text": "10 Estrutura de cÃ³digo: Bambi vs PyMC\nNeste bloco, utilizamos a biblioteca Bambi como alternativa ao PyMC. Segue portanto uma comparaÃ§Ã£o entre as duas abordagens para a implementaÃ§Ã£o de uma regressÃ£o linear bayesiana.\n\n\n\n\n\n\nDicaQuando usar cada abordagem\n\n\n\nBambi: estrutura de cÃ³digo\n\n# Bambi\nmodelo = bmb.Model(\"altura ~ calcado\", df, priors=priors)\nresultados = modelo.fit()\n\nQuando usar:\n\nDeseja implementar modelos estatÃ­sticos padrÃ£o (regressÃ£o linear, GLMs, modelos hierÃ¡rquicos)\nNecessita de rapidez de desenvolvimento e ajustes\n\nPyMC: estrutura de cÃ³digo\n\n# PyMC - requer definiÃ§Ã£o manual de todas as componentes\nwith pm.Model() as modelo:\n    # Priors\n    beta_0 = pm.Normal(\"beta_0\", mu=60, sigma=5)\n    beta_1 = pm.Normal(\"beta_1\", mu=2.8, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n    \n    # VerossimilhanÃ§a\n    mu = beta_0 + beta_1 * X\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, observed=Y)\n    trace = pm.sample()\n\nQuando usar:\n\nNecessitar controle total sobre a especificaÃ§Ã£o do modelo\nNecessita implementar modelos customizados ou muito complexos\nNecessita de funcionalidades especÃ­ficas nÃ£o disponÃ­veis no Bambi"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "",
    "text": "Vamos utilizar modelos estatÃ­sticos para analisar a complexidade tecnolÃ³gica tradicional em ilhas da Oceania (Kline e Boyd 2010). Nosso objetivo Ã© compreender como o tamanho populacional influenciou o nÃºmero de ferramentas disponÃ­veis em cada sociedade.\nCompararemos trÃªs estratÃ©gias de modelagem, todas implementadas com PyMC:"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#analisando-o-conjunto-de-dados",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#analisando-o-conjunto-de-dados",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "1 Analisando o conjunto de dados",
    "text": "1 Analisando o conjunto de dados\nImporte os dados kline.csv.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pymc as pm\nimport bambi as bmb\nimport arviz as az\nimport xarray as xr\n\n\nkline = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/kline.csv')\nkline\n\n\n\n\n\n\n\n\nculture\npopulation\ncontact\ntotal_tools\nmean_TU\nlat\nlon\n\n\n\n\n0\nMalekula\n1100\nlow\n13\n3.2\n-16.3\n167.5\n\n\n1\nTikopia\n1500\nlow\n22\n4.7\n-12.3\n168.8\n\n\n2\nSanta Cruz\n3600\nlow\n24\n4.0\n-10.7\n166.0\n\n\n3\nYap\n4791\nhigh\n43\n5.0\n9.5\n138.1\n\n\n4\nLau Fiji\n7400\nhigh\n33\n5.0\n-17.7\n178.1\n\n\n5\nTrobriand\n8000\nhigh\n19\n4.0\n-8.7\n150.9\n\n\n6\nChuuk\n9200\nhigh\n40\n3.8\n7.4\n151.6\n\n\n7\nManus\n13000\nlow\n28\n6.6\n-2.1\n146.9\n\n\n8\nTonga\n17500\nhigh\n55\n5.4\n-21.2\n-175.2\n\n\n9\nHawaii\n275000\nlow\n71\n6.6\n19.9\n-155.6\n\n\n\n\n\n\n\nVisualize a relaÃ§Ã£o entre tamanho populacional (P) e nÃºmero total de ferramentas (T).\n\n# Definir tema com fonte maior\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\n# PersonalizaÃ§Ã£o dos rÃ³tulos e tema\nplt.xlabel('Tamanho populacional', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nsns.set_theme(style=\"whitegrid\")\n\n\n\n\n\n\n\nFiguraÂ 1: RelaÃ§Ã£o entre o nÃºmero total de ferramentas e o tamanho populacional em ilhas na Oceania"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-1-regressÃ£o-linear-com-transformaÃ§Ã£o-logarÃ­tmica",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-1-regressÃ£o-linear-com-transformaÃ§Ã£o-logarÃ­tmica",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "2 EstratÃ©gia 1: RegressÃ£o Linear com TransformaÃ§Ã£o LogarÃ­tmica",
    "text": "2 EstratÃ©gia 1: RegressÃ£o Linear com TransformaÃ§Ã£o LogarÃ­tmica\nA relaÃ§Ã£o na FiguraÂ 1 Ã© claramente nÃ£o linear e pode ser descrita por:\n\\[T = \\beta_0P^{\\beta_1}\\]\nUma alternativa simples neste caso Ã© utilizar uma transformaÃ§Ã£o logarÃ­tmica para linearizar a expressÃ£o:\n\\[\\log(T) = \\log(\\beta_0P^{\\beta_1}) \\Rightarrow \\log(T) = \\log(\\beta_0) + \\log(P^{\\beta_1}) \\Rightarrow\\]\n\\[\\log(T) = B_0 + \\beta_1 \\log(P)\n\\tag{1}\\]\nem que \\(B_0 = \\log(\\beta_0)\\)\nVisualizando na escala logarÃ­tmica:\n\nkline['log_tools'] = np.log(kline['total_tools'])\nkline['log_pop'] = np.log(kline['population'])\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='log_pop', y='log_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\n# PersonalizaÃ§Ã£o dos rÃ³tulos e tema\nplt.xlabel('log do Tamanho populacional', fontsize=14)\nplt.ylabel('log do NÃºmero total de ferramentas', fontsize=14)\n\n\n\n\n\n\nText(0, 0.5, 'log do NÃºmero total de ferramentas')\n\n\n(a) RelaÃ§Ã£o entre o logarÃ­tmo do nÃºmero total de ferramentas e o logarÃ­tmo do tamanho populacional\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFiguraÂ 2\n\n\n\n\nConsiderando que a relaÃ§Ã£o na FiguraÂ 2 Ã© aproximadamente linear, vamos ajustar o modelo de regressÃ£o linear descrito na EquaÃ§Ã£oÂ 1.\nNeste modelo, estamos assumindo que \\(\\log(T)\\) Ã© uma variÃ¡vel aleatÃ³ria normnalmente distribuÃ­da:\n\\[\\log(T) \\sim \\mathcal{N}(\\mu,\\,\\sigma)\\]\n\\[\\mu = B_0 + \\beta_1 \\log(P)\\]\n\n2.1 ImplementaÃ§Ã£o\n\nmlinear = bmb.Model(\"log_tools ~ log_pop\", data=kline)\ntrace_linear = mlinear.fit()\n\n\n\n\n\n\n\n\n# Resumo dos parÃ¢metros\naz.summary(trace_linear)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nsigma\n0.368\n0.104\n0.209\n0.560\n0.002\n0.003\n2206.0\n2375.0\n1.0\n\n\nIntercept\n1.018\n0.756\n-0.375\n2.499\n0.015\n0.019\n2817.0\n2172.0\n1.0\n\n\nlog_pop\n0.269\n0.083\n0.117\n0.430\n0.002\n0.002\n2828.0\n2080.0\n1.0\n\n\n\n\n\n\n\n\n\n2.2 Gerando prediÃ§Ãµes do modelo linear\n\npred_linear = mlinear.predict(trace_linear, kind = 'response', data = kline, inplace=False)\npred_linear_draws = pred_linear.posterior_predictive.log_tools\npred_linear_mean = pred_linear_draws.mean(dim=['chain', 'draw'])\n\n\n\n2.3 VisualizaÃ§Ã£o do modelo linear\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='log_pop', y='log_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\nplt.plot(kline['log_pop'],pred_linear_mean.values, color='red', linewidth=2, label='PrediÃ§Ã£o mÃ©dia')\naz.plot_hdi(\n    kline['log_pop'],\n    pred_linear.posterior_predictive.log_tools,\n    hdi_prob=0.95, # Intervalo de 95%\n    color='#f3ae1a',\n    fill_kwargs={'alpha': 0.3, 'label': 'Intervalo de Credibilidade (95%)'}\n)\n\nplt.xlabel('log(PopulaÃ§Ã£o)', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nplt.title('Modelo de linear: log_tools ~ log_pop', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\n\n2.3.1 VisualizaÃ§Ã£o do modelo linear na escala original\nComo a escala original Ã© um modelo nÃ£o linear, teremos que gerar os valores preditos para mais pontos a partir dos parÃ¢metros estimaos\n\nlog_pop = np.linspace(min(kline['log_pop']), np.max(kline['log_pop']), num=1000)\nnew_x =  xr.DataArray(\n    log_pop,\n    dims=['obs'],\n    coords={'obs': range(len(log_pop))},\n    name='log_pop'\n)\n\nmlinear_pars = mlinear.predict(trace_linear, kind = 'response_params', data = kline, inplace=False)\n\nB0 = mlinear_pars.posterior['Intercept']\nb1 = mlinear_pars.posterior['log_pop']\nnew_pred_linear_mean = B0.values.mean() + b1.values.mean() * new_x\n\nnew_pred_linear = np.exp(B0 + b1 * new_x)\nic_linear = az.hdi(new_pred_linear, hdi_prob=0.95)\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\nplt.plot(np.exp(new_x),np.exp(new_pred_linear_mean))\n\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='HDI 95%')"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-2-regressÃ£o-de-poisson-glm",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-2-regressÃ£o-de-poisson-glm",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "3 EstratÃ©gia 2: RegressÃ£o de Poisson (GLM)",
    "text": "3 EstratÃ©gia 2: RegressÃ£o de Poisson (GLM)\nEmbora a transformaÃ§Ã£o logarÃ­tmica torne linear a porÃ§Ã£o determinÃ­stica do modelo, ela nÃ£o resolve adequadamente a natureza discreta da variÃ¡vel de resposta. No caso do nÃºmero de ferramentas (total_tools), estamos lidando com dados de contagem â€” valores inteiros nÃ£o negativos. Uma abordagem mais apropriada Ã© utilizar uma regressÃ£o de Poisson, que modela diretamente a distribuiÃ§Ã£o da variÃ¡vel como uma variÃ¡vel aleatÃ³ria de contagem.\nVamos assumir que o que realmente influencia a diversidade tecnolÃ³gica nÃ£o Ã© o tamanho absoluto da populaÃ§Ã£o, mas sim sua ordem de grandeza (Kline e Boyd 2010). Espera-se, portanto, uma associaÃ§Ã£o positiva entre o nÃºmero de ferramentas e o logaritmo do tamanho populacional.\nEste modelo generativo pode ser descrito como:\n\\[T_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 \\cdot \\log(P_i)\\]\nOnde: * \\(T_i\\) Ã© o nÃºmero de ferramentas na sociedade i * \\(P_i\\) Ã© o tamanho populacional * A funÃ§Ã£o de ligaÃ§Ã£o logarÃ­tmica garante que \\(\\lambda_i &gt; 0\\)\n\n3.1 ImplementaÃ§Ã£o\n\nmpoisson = bmb.Model(\"total_tools ~ log_pop\", \n                     data=kline, \n                     family=\"poisson\")\n\n\ntrace_poisson = mpoisson.fit(draws=2000, tune=1000)\n\n\n\n\n\n\n\n\n# Resumo dos parÃ¢metros\naz.summary(trace_poisson)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.334\n0.301\n0.760\n1.890\n0.004\n0.003\n7127.0\n5501.0\n1.0\n\n\nlog_pop\n0.239\n0.031\n0.181\n0.295\n0.000\n0.000\n7194.0\n5795.0\n1.0\n\n\n\n\n\n\n\n\n\n3.2 Gerando prediÃ§Ãµes do modelo Poisson\n\n# PrediÃ§Ãµes para os dados originais\npred_poisson = mpoisson.predict(trace_poisson, kind='response', data=kline, inplace=False)\npred_poisson_draws = pred_poisson.posterior_predictive.total_tools\npred_poisson_mean = pred_poisson_draws.mean(dim=['chain', 'draw'])\n\n\n# Criar dados para prediÃ§Ã£o suave\nlog_pop_new = np.linspace(min(kline['log_pop']), max(kline['log_pop']), num=100)\nnew_data = pd.DataFrame({'log_pop': log_pop_new})\n\n# Gerar prediÃ§Ãµes\nnew_pred_poisson = mpoisson.predict(trace_poisson, kind='response', data=new_data, inplace=False)\nnew_pred_poisson_mean = new_pred_poisson.posterior_predictive.total_tools.mean(dim=['chain', 'draw'])\n\n\n\n3.3 VisualizaÃ§Ã£o do modelo Poisson\n\nplt.figure(figsize=(8, 6))\n\n# Pontos originais\nsns.scatterplot(data=kline, x='log_pop', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4', label='Dados observados')\n\n# Linha de prediÃ§Ã£o mÃ©dia\nplt.plot(log_pop_new, new_pred_poisson_mean.values, \n         color='red', linewidth=2, label='PrediÃ§Ã£o mÃ©dia')\n\n# Intervalo de credibilidade\naz.plot_hdi(\n    log_pop_new,\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#f3ae1a',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95%'}\n)\n\nplt.xlabel('log(PopulaÃ§Ã£o)', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nplt.title('Modelo de Poisson: total_tools ~ log_pop', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\n\n\n3.4 VisualizaÃ§Ã£o na escala original (populaÃ§Ã£o)\n\nplt.figure(figsize=(12, 8))\n\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95% Poisson'},\n)\n\nplt.xlabel('PopulaÃ§Ã£o', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nplt.title('ComparaÃ§Ã£o de Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n3.5 ComparaÃ§Ã£o com modelo linear\n\nplt.figure(figsize=(12, 8))\n\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\n# Modelo Linear com transformaÃ§Ã£o log (escala original)\nplt.plot(np.exp(new_x), np.exp(new_pred_linear_mean), \n         color='red', linewidth=2, label='Modelo Linear')\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='HDI 95% Linear')\n\n# Modelo Poisson (GLM)\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95% Poisson'},\n)\n\nplt.xlabel('PopulaÃ§Ã£o', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nplt.title('ComparaÃ§Ã£o de Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-3-modelo-cientÃ­fico-mecanicista",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estratÃ©gia-3-modelo-cientÃ­fico-mecanicista",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "4 EstratÃ©gia 3: Modelo CientÃ­fico (Mecanicista)",
    "text": "4 EstratÃ©gia 3: Modelo CientÃ­fico (Mecanicista)\nPartindo de uma descriÃ§Ã£o teÃ³rica da dinÃ¢mica de inovaÃ§Ã£o tecnolÃ³gica, podemos expressar a mudanÃ§a esperada no nÃºmero de ferramentas ao longo do tempo como:\n\\[\\Delta T = \\alpha P^\\beta - \\gamma T\\]\nOnde: * \\(P\\) Ã© o tamanho da populaÃ§Ã£o * \\(T\\) Ã© o nÃºmero de ferramentas * \\(\\alpha\\), \\(\\beta\\) e \\(\\gamma\\) sÃ£o parÃ¢metros a serem estimados * \\(\\alpha P^\\beta\\) representa a taxa de inovaÃ§Ã£o (dependente da populaÃ§Ã£o) * \\(\\gamma T\\) representa a taxa de perda de ferramentas\nAssumindo que o sistema estÃ¡ em equilÃ­brio (\\(\\Delta T = 0\\)), podemos resolver para \\(T\\):\n\n\n\n\n\n\nNotaSituaÃ§Ã£o de equilÃ­brio\n\n\n\nComeÃ§amos com: \\[0 = \\alpha P^\\beta - \\gamma T\\]\nIsolando o termo \\(T\\): \\[\\gamma T = \\alpha P^\\beta\\]\nDividindo ambos os lados por \\(\\gamma\\): \\[T = \\frac{\\alpha P^\\beta}{\\gamma}\n\\tag{2}\\]\n\n\nIncorporando a EquaÃ§Ã£oÂ 2 a um modelo de Poisson:\n\\[T_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\\[\\lambda_i = \\frac{\\alpha P_i^{\\beta}}{\\gamma}\\]\n\n4.1 ImplementaÃ§Ã£o em PyMC\nPara facilitar a implementaÃ§Ã£o, vamos reparametrizar usando:\n\\[\\log(\\lambda_i) = \\log(\\alpha) + \\beta \\cdot \\log(P_i) - \\log(\\gamma)\\]\nou equivalentemente:\n\\[\\log(\\lambda_i) = \\theta_\\alpha + \\beta \\cdot \\log(P_i) + \\theta_\\gamma\\]\nonde \\(\\theta_\\alpha = \\log(\\alpha)\\) e \\(\\theta_\\gamma = -\\log(\\gamma)\\).\n\nlog_pop = np.log(kline['population'])\ntools = kline['total_tools'].values\n\nwith pm.Model() as scientific_model:\n    # Priors\n    theta_alpha = pm.Normal(\"theta_alpha\", mu=0, sigma=2)\n    beta = pm.Normal(\"beta\", mu=0, sigma=1)\n    theta_gamma = pm.Normal(\"theta_gamma\", mu=0, sigma=1)\n\n    # EsperanÃ§a em escala log\n    log_lambda = theta_alpha + beta * log_pop + theta_gamma\n    lambda_ = pm.math.exp(log_lambda)\n\n    # Likelihood\n    T_obs = pm.Poisson(\"total_tools\", mu=lambda_, observed=tools)\n\n    # Amostragem\n    trace_scientific = pm.sample(2000, tune=1000, target_accept=0.95)\n    pm.compute_log_likelihood(trace_scientific)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace_scientific, var_names=[\"theta_alpha\", \"beta\", \"theta_gamma\"], hdi_prob=0.89)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_5.5%\nhdi_94.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta_alpha\n1.068\n0.955\n-0.523\n2.524\n0.021\n0.015\n2058.0\n2524.0\n1.0\n\n\nbeta\n0.241\n0.032\n0.193\n0.293\n0.001\n0.001\n2906.0\n2656.0\n1.0\n\n\ntheta_gamma\n0.248\n0.926\n-1.159\n1.818\n0.021\n0.014\n2024.0\n2427.0\n1.0\n\n\n\n\n\n\n\n\n\n4.2 Gerando prediÃ§Ãµes do modelo cientÃ­fico\n\nposterior = trace_scientific.posterior\n\n# Recuperar parÃ¢metros transformados\nalpha_samples = np.exp(posterior['theta_alpha'])\nbeta_samples = posterior['beta']\ngamma_samples = np.exp(-posterior['theta_gamma'])\n\n# Grid de populaÃ§Ã£o para prediÃ§Ãµes\npop_pred = np.linspace(kline['population'].min(), kline['population'].max(), 200)\n\n# Calcular prediÃ§Ãµes usando a fÃ³rmula cientÃ­fica\npred_samples = []\nfor i in range(len(alpha_samples.chain)):\n    for j in range(len(alpha_samples.draw)):\n        alpha_val = alpha_samples.isel(chain=i, draw=j).values\n        beta_val = beta_samples.isel(chain=i, draw=j).values\n        gamma_val = gamma_samples.isel(chain=i, draw=j).values\n        \n        pred = (alpha_val * (pop_pred ** beta_val)) / gamma_val\n        pred_samples.append(pred)\n\npred_samples = np.array(pred_samples)\n\n# Calcular estatÃ­sticas\nmean_scientific = pred_samples.mean(axis=0)\nhdi_scientific = az.hdi(pred_samples, hdi_prob=0.89)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#comparaÃ§Ã£o-dos-trÃªs-modelos",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#comparaÃ§Ã£o-dos-trÃªs-modelos",
    "title": "Modelos EstatÃ­sticos e Modelos CientÃ­ficos",
    "section": "5 ComparaÃ§Ã£o dos TrÃªs Modelos",
    "text": "5 ComparaÃ§Ã£o dos TrÃªs Modelos\nVamos comparar as prediÃ§Ãµes dos trÃªs modelos em um Ãºnico grÃ¡fico:\n\nplt.figure(figsize=(8, 6))\n\n# Dados observados (plotados apenas uma vez)\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\n# 1. Modelo Linear com transformaÃ§Ã£o log (escala original)\nplt.plot(np.exp(new_x), np.exp(new_pred_linear_mean), \n         color='red', linewidth=2, label='Modelo Linear')\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='IC 95% Linear')\n\n# 2. Modelo Poisson (GLM)\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'IC 95% Poisson'},\n)\n\n# 3. Modelo CientÃ­fico (Mecanicista)\n# Modelo CientÃ­fico\nplt.plot(pop_pred, mean_scientific, color='#2ca02c', linewidth=3, \n         label='Modelo Mecanicista')\nplt.fill_between(pop_pred, hdi_scientific[:, 0], hdi_scientific[:, 1],\n                 color='#2ca02c', alpha=0.2, label = 'IC Mecanicista) 95%')\n\n# ConfiguraÃ§Ãµes do grÃ¡fico\nplt.xlabel('PopulaÃ§Ã£o', fontsize=14)\nplt.ylabel('NÃºmero total de ferramentas', fontsize=14)\nplt.title('ComparaÃ§Ã£o dos TrÃªs Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()"
  },
  {
    "objectID": "content/teste-hipoteses/teste-variancia.html",
    "href": "content/teste-hipoteses/teste-variancia.html",
    "title": "Comparando variÃ¢ncias",
    "section": "",
    "text": "DicaPacotes, funÃ§Ãµes e base de dados utilizadas no capÃ­tulo\n\n\n\n\n\n\nlibrary(gt)\nlibrary(tidyverse)\nlibrary(patchwork)\nA mesma lÃ³gica para testar uma hipÃ³tese sobre a mÃ©dia populacional \\(\\mu\\) pode ser utilizada para testar uma hipÃ³tese sobre a variÃ¢ncia populacional \\(\\sigma^2\\). Veja o exemplo a seguir.\nA TabelaÂ 1 Ã© proviniente de um estudo em que foi analizada a riqueza de espÃ©cies da macro-fauna da zona entre-marÃ©s em nove praias costa da Holanda. Neste exemplo vamos usar as praias 5 e 8.\nCÃ³digo\nRIKZ &lt;- read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/RIKZ.csv')\n\nS &lt;- RIKZ |&gt; \n  subset(Beach == 5 | Beach == 8) |&gt; \n  select(Richness, Beach)\n\nS |&gt; \n  gt() |&gt; \n  cols_width(\n    Richness ~ px(150),\n    Beach ~ px(150)\n  )\n\n\n\n\nTabelaÂ 1: Riqueza da macro-fauna em duas praias da costa Holandesa. Dados completos no arquivo â€œRIKZâ€ do pacote â€œAEDâ€.\n\n\n\n\n\n\n\n\n\nRichness\nBeach\n\n\n\n\n3\n5\n\n\n22\n5\n\n\n6\n5\n\n\n0\n5\n\n\n6\n5\n\n\n3\n8\n\n\n5\n8\n\n\n7\n8\n\n\n5\n8\n\n\n0\n8\nPodemos nos perguntar se em uma praia a riqueza de espÃ©cies varia mais que na outra, ou seja, se em uma das praias amostras difere uma das outras em maior grau que na outra praia. Neste caso, estamos interessados em testar as variÃ¢ncias, nÃ£o as mÃ©dias. Para testarmos a homogeneidade de variÃ¢ncias entre as praias podemos estabelecer as seguintes hipÃ³teses:\n1. Estabelcer as hipÃ³teses estatÃ­sticas\n\\(H_0: \\sigma^2_5 = \\sigma^2_8\\)\n\\(H_a: \\sigma^2_5 \\ne \\sigma^2_8\\)\nA hipÃ³tese nula \\(H_0\\) estabelece aqui que as variÃ¢ncias populacionais na praia 1 (\\(\\sigma^2_5\\)) seja igual a variÃ¢ncia populacional da praia 2 (\\(\\sigma^2_8\\)), enquento \\(H_a\\) estabelece que sÃ£o diferentes.\n2. Definir o nÃ­vel de significÃ¢ncia\nNeste caso podemos estabelecer \\(\\alpha = 0,05\\) como de costume.\n3. Definir a estatÃ­stica do teste\nExistem vÃ¡rias formas possÃ­veis de testar a homogeneidade de variÃ¢ncias, a mais simples Ã© o teste de razÃ£o de variÃ¢ncias que tem como estatÃ­stica:\n\\[F = \\frac{s^2_{maior}}{s^2_{menor}}\\]\nem que \\(s^2_{maior}\\) Ã© a maior variÃ¢ncia amostral e \\(s^2_{menor}\\) Ã© a menor variÃ¢ncia amostral.\n4. Calcular a estatÃ­stica do teste \\(F_{calc}\\)\nCÃ³digo\nS_var = S |&gt; \n  group_by(Beach) |&gt; \n  summarise(Variancias = var(Richness),\n            n = n())\nsmax = max(S_var[,2])\nsmin = min(S_var[,2])\nn1 = as.numeric(S_var[1,3])\nn2 = as.numeric(S_var[2,3])\n\nFcalc = smax/smin\np = pf(Fcalc, df1 = n1-1, df2 = n2-1, lower.tail = FALSE)\nNeste exemplo, as variÃ¢ncias amostrais sÃ£o:\nPraia 5: \\(s^2_{1} = 72.8\\) e,\nPraia 8: \\(s^2_{2} = 7\\)\nO \\(F_{calc}\\) fica:\n\\[F_{calc} = \\frac{72.8}{7} = 10.4\\] mostrando de a variÃ¢ncia na praia 5 Ã© \\(10.4\\) vezes maior que na praia 8.\n5. Calcular o valor de p para a distribuiÃ§Ã£o estatÃ­stica apropriada\nNo teste de hipÃ³tese para uma mÃ©dia a distribuiÃ§Ã£o estatÃ­stica apropriada para a estatÃ­stica \\(Z\\) era a distribuiuÃ§Ã£o normal padronizada. No caso do teste de razÃ£o de variÃ¢ncias, a distribuiÃ§Ã£o apropriada Ã© chamada de ditribuiÃ§Ã£o \\(F\\), que tem um formato assimÃ©trico Ã  direita. Em nosso exemplo, o valor de \\(p = 0.022\\).\nFiguraÂ 1: DistribuiÃ§Ã£o F de Fisher para 4 graus de liberdade no numerador e 4 graus de liberdade no denominador.\nO formato da distribuiÃ§Ã£o F varia em funÃ§Ã£o dos graus de liberdade do numerador e do denominador. Para este exemplo, os graus de liberdade do numerador e denominador sÃ£o calculados como \\(gl = n-1\\). Como foram tomadas 5 amostras em cada uma das praias, \\(gl_{numerador} = gl_{denominador} = n-1 = 4\\).\nTomada de decisÃ£o sobre \\(H_0\\)\nAssumindo que o valor de \\(p = 0.022\\) Ã© menor que o nÃ­vel de significÃ¢ncia adotado \\(\\alpha = 0,05\\), rejeitamos \\(H_0\\) e concluÃ­mos que a distribuiÃ§Ã£o da riqueza de espÃ©cies na praia 5 Ã© mais heterogÃªnea que na praia 8."
  },
  {
    "objectID": "content/teste-hipoteses/teste-variancia.html#teste-de-razÃ£o-de-variÃ¢ncias-no-r",
    "href": "content/teste-hipoteses/teste-variancia.html#teste-de-razÃ£o-de-variÃ¢ncias-no-r",
    "title": "Comparando variÃ¢ncias",
    "section": "1 Teste de razÃ£o de variÃ¢ncias no R",
    "text": "1 Teste de razÃ£o de variÃ¢ncias no R\nOs cÃ¡lculos acima podem ser replicados no R com o comando var.test().\n\nvar.test(Richness ~ Beach, data = S, alternative = 'greater')\n\n\n    F test to compare two variances\n\ndata:  Richness by Beach\nF = 10.4, num df = 4, denom df = 4, p-value = 0.02173\nalternative hypothesis: true ratio of variances is greater than 1\n95 percent confidence interval:\n 1.627993      Inf\nsample estimates:\nratio of variances \n              10.4 \n\n\n\n\n\n\n\n\nNotaDistribuiÃ§Ã£o \\(F\\) para outros graus de liberdade\n\n\n\n\n\n\n\n\n\n\n\nFiguraÂ 2: DistribuiÃ§Ã£o F de Fisher para diferentes combinaÃ§Ãµes de graus de liberdade no numerador e denominador."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html",
    "title": "InferÃªncia Bayesiana Binomial",
    "section": "",
    "text": "A estratÃ©gia de inferÃªncia via grid consiste em discretizar o parÃ¢metro \\(p\\) em pequenos intervalos, avaliando a distribuiÃ§Ã£o a priori e a verossimilhanÃ§a em cada ponto da grade. Em seguida, multiplica-se esses valores e normaliza-se o resultado para obter a distribuiÃ§Ã£o a posteriori."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#aproximaÃ§Ã£o-bayesiana-via-grid",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#aproximaÃ§Ã£o-bayesiana-via-grid",
    "title": "InferÃªncia Bayesiana Binomial",
    "section": "1 AproximaÃ§Ã£o Bayesiana via Grid",
    "text": "1 AproximaÃ§Ã£o Bayesiana via Grid\n\nDefinir os dados\n\n\\(N\\): nÃºmero total de observaÃ§Ãµes (ensaios Bernoulli).\n\n\\(k\\): nÃºmero de sucessos observados.\n\nCriar a malha (grid) de valores para \\(p\\)\n\nDivida o intervalo \\([0, 1]\\) em muitos pontos (ex. 1000 pontos).\n\nCada ponto serÃ¡ uma hipÃ³tese para o valor de \\(p\\).\n\nAvaliar a priori\n\nEscolha uma forma para a distribuiÃ§Ã£o a priori de \\(p\\).\n\nExemplos: uma Beta(\\(\\alpha, \\beta\\)) ou mesmo uma priori uniforme.\n\nCalcule a densidade da priori em cada ponto do grid.\n\nCalcular a verossimilhanÃ§a\n\nPara cada valor de \\(p\\) no grid, calcule \\(P(Y = k \\mid p, N)\\) usando a distribuiÃ§Ã£o Binomial:\n\\[\\mathcal{L}(p) = \\binom{N}{k}\\, p^k (1-p)^{N-k}.\\]\nUse por exempo o mÃ©todo binom.pmf(k, N, p) do mÃ³dulo SciPy ou escreva a fÃ³rmula manualmente.\n\nCombinar priori e verossimilhanÃ§a\n\nA posteriori nÃ£o normalizada em cada ponto do grid Ã©:\n\\[\\text{posterior}_{\\text{unnorm}}(p) = \\text{prior}(p) \\times \\mathcal{L}(p).\\]\n\nNormalizar a posteriori\n\nSome os valores de \\(\\text{posterior}_{\\text{unnorm}}(p)\\) sobre todos os pontos \\(p\\).\n\nDivida cada valor pela soma total (use integraÃ§Ã£o, como scipy.integrate.simpson para maior precisÃ£o).\n\nO resultado Ã© a distribuiÃ§Ã£o a posteriori discreta (aproximada).\n\nCalcular probabilidades de intervalo\n\nPara calcular \\(P(x_1 \\leq p \\leq x_2)\\), some (ou integre) os valores da posteriori nos pontos entre \\(x_1\\) e \\(x_2\\).\n\nVisualizar os resultados\n\nFaÃ§a grÃ¡ficos do perfil da priori, da verossimilhanÃ§a e da posteriori ao longo do grid de \\(p\\).\n\nDestaque intervalos de interesse (\\(x_1, x_2\\)) e use os valores de probabilidade para estimar o valor de \\(p\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#exemplo-em-python",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#exemplo-em-python",
    "title": "InferÃªncia Bayesiana Binomial",
    "section": "2 Exemplo em Python",
    "text": "2 Exemplo em Python\nA seguir, um exemplo completo usando numpy e matplotlib para ilustrar cada etapa. Ajuste os valores de \\(N\\), \\(k\\), \\(\\alpha\\) e \\(\\beta\\) conforme necessÃ¡rio.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, beta\nfrom scipy.integrate import simpson\n\n# ParÃ¢metros do experimento\nN = 10   # nÃºmero total de ensaios\nk = 6    # nÃºmero de sucessos observados\n\n# ParÃ¢metros da priori Beta\nalpha_param = 1\nbeta_param = 1\n\n# Grid de p (1000 pontos entre 0 e 1)\np_grid = np.linspace(0, 1, 1000)\n\n# 1) Prior: densidade Beta em cada ponto do grid\nprior = beta.pdf(p_grid, a=alpha_param, b=beta_param)\n\n# 2) VerossimilhanÃ§a: Binomial(k | N, p)\nlikelihood = binom.pmf(k, N, p_grid)\n\n# 3) Posterior nÃ£o normalizada\nposterior_unnorm = prior * likelihood\n\n# 4) Normaliza para obter a posteriori propriamente dita\narea = simpson(y=posterior_unnorm, x=p_grid)  # integra usando Simpson\nposterior = posterior_unnorm / area\n\n# 5) (Opcional) Calcular probabilidade de um intervalo [x1, x2]\nx1, x2 = 0.4, 0.7\nmask_interval = (p_grid &gt;= x1) & (p_grid &lt;= x2)\nprob_interval = simpson(y=posterior[mask_interval], x=p_grid[mask_interval])\n\n# Visualizar\nfig, axs = plt.subplots(3, 1, figsize=(6, 8))\n\n# Plot da Prior\naxs[0].plot(p_grid, prior, color='red')\naxs[0].set_title(\"Priori Beta\")\naxs[0].set_ylabel(\"Densidade\")\n\n# Plot da VerossimilhanÃ§a\naxs[1].plot(p_grid, likelihood, color='green')\naxs[1].set_title(f\"VerossimilhanÃ§a Binomial (k={k}, N={N})\")\naxs[1].set_ylabel(\"PMF\")\n\n# Plot da Posterior\naxs[2].plot(p_grid, posterior, color='blue')\naxs[2].set_title(f\"Posteriori - Prob({x1:.2f} â‰¤ p â‰¤ {x2:.2f}) = {prob_interval:.3f}\")\naxs[2].set_xlabel(\"p\")\naxs[2].set_ylabel(\"Densidade\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#interpretaÃ§Ã£o",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#interpretaÃ§Ã£o",
    "title": "InferÃªncia Bayesiana Binomial",
    "section": "3 InterpretaÃ§Ã£o",
    "text": "3 InterpretaÃ§Ã£o\n\nObserve como a forma da posteriori (curva azul) Ã© proporcional ao produto da priori (vermelho) pela verossimilhanÃ§a (verde).\nSe a priori for \\(Beta(1,1)\\) (uniforme), a posteriori fica essencialmente guiada pelos dados.\nAlterar \\(\\alpha\\) e \\(\\beta\\) faz a priori pesar mais (ou menos) no resultado final, dependendo de quÃ£o informativa ela Ã© e do tamanho amostral \\(N\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html",
    "title": "Construindo um modelo bayesiano",
    "section": "",
    "text": "Considere um globo representando o planeta Terra, pequeno o suficiente para caber em suas mÃ£os. Seu objetivo Ã© estimar a fraÃ§Ã£o da superfÃ­cie coberta por Ã¡gua. Para isso, vocÃª adota a seguinte estratÃ©gia: joga o globo para cima girando e, ao pegÃ¡-lo, registra se o ponto tocado pelo seu dedo indicador direito Ã© Ã¡gua (ğŸŒŠ) ou terra (ğŸœï¸). VocÃª repete esse procedimento algumas vezes, obtendo uma sequÃªncia de \\(n\\) observaÃ§Ãµes.\nVocÃª faz quatro lanÃ§amentos do globo e conta quantos deles resultam em Ã¡gua. Um possÃ­vel resultado seria \\(ğŸŒŠğŸŒŠğŸœï¸ğŸŒŠ\\), totalizando 3 observaÃ§Ãµes de Ã¡gua e 1 de terra. Outro resultado possÃ­vel Ã© \\(ğŸœï¸ğŸœï¸ğŸŒŠğŸŒŠ\\), com 2 observaÃ§Ãµes de Ã¡gua e 2 de terra. Para \\(n = 4\\) observaÃ§Ãµes, existem 16 resultados possÃ­veis (TabelaÂ 1).\nObserve que apenas um dos resultados contÃ©m 4 observaÃ§Ãµes de terra e somente um contÃ©m 4 observaÃ§Ãµes de Ã¡gua. Os demais sÃ£o variaÃ§Ãµes entre esses extremos.\nPodemos reorganizar a tabela para evidenciar todas as combinaÃ§Ãµes que levam ao mesmo nÃºmero \\(y_i\\) de pontos em Ã¡gua:\nDefina \\(p\\) como a probabilidade de observar Ã¡gua e \\(1 - p\\) como a probabilidade de observar terra apÃ³s cada lanÃ§amento do globo.\nA Ãºltima linha da TabelaÂ 2 (ğŸŒŠğŸŒŠğŸŒŠğŸŒŠ) tem probabilidade: \\[P(4) = p \\times p \\times p \\times p.\\]\nEnquanto a primeira linha (ğŸœï¸ğŸœï¸ğŸœï¸ğŸœï¸) ocorre com probabilidade: \\[P(0) = (1 - p) \\times (1 - p) \\times (1 - p) \\times (1 - p).\\]\nAs linhas correspondentes a \\(P(1)\\), \\(P(2)\\) e \\(P(3)\\) sÃ£o combinaÃ§Ãµes de \\(p\\) e \\((1 - p)\\), multiplicadas pelo nÃºmero de formas pelas quais 1, 2 ou 3 registros de Ã¡gua podem ocorrer em 4 lanÃ§amentos."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#o-modelo-binomial",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#o-modelo-binomial",
    "title": "Construindo um modelo bayesiano",
    "section": "1 O modelo Binomial",
    "text": "1 O modelo Binomial\nA partir das expressÃµes para \\(P(y)\\) apresentadas na TabelaÂ 3, obtÃ©m-se uma fÃ³rmula geral que pode ser escrita como:\n\\[P(y \\mid n, p) = \\binom{n}{y} \\, p^y (1 - p)^{n - y}.\n\\tag{1}\\]\nOnde:\n\n\\(y \\in \\{0, 1, 2, \\dots, n\\}\\) Ã© o nÃºmero de observaÃ§Ãµes de ğŸŒŠ;\n\\(n\\) Ã© o nÃºmero total de observaÃ§Ãµes;\n\\(p\\) Ã© a fraÃ§Ã£o de ğŸŒŠ que cobre o globo;\n\\(\\binom{n}{y}\\) Ã© o coeficiente binomial, calculado por \\(\\frac{n!}{y!(n - y)!}\\), indicando de quantas maneiras a combinaÃ§Ã£o \\(p^y (1 - p)^{n - y}\\) pode ocorrer.\n\nA EquaÃ§Ã£oÂ 1 fornece a probabilidade de cada resultado possÃ­vel (nÃºmero de observaÃ§Ãµes ğŸŒŠ) em \\(n\\) tentativas, permitindo calcular a probabilidade de todos os possÃ­veis resultados do experimento."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#verossimilhanÃ§a-a-plausibilidade-de-uma-hipÃ³tese",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#verossimilhanÃ§a-a-plausibilidade-de-uma-hipÃ³tese",
    "title": "Construindo um modelo bayesiano",
    "section": "2 VerossimilhanÃ§a: a plausibilidade de uma hipÃ³tese",
    "text": "2 VerossimilhanÃ§a: a plausibilidade de uma hipÃ³tese\nA partir do modelo binomial, podemos definir a funÃ§Ã£o de verossimilhanÃ§a para um resultado observado. Imagine que, em \\(n = 4\\) lanÃ§amentos, foram observados \\(y = 2\\) pontos sobre a Ã¡gua. NÃ£o sabemos a verdadeira proporÃ§Ã£o \\(p\\) de Ã¡gua que cobre a Terra; portanto, fazemos conjecturas e avaliamos cada uma com base nas observaÃ§Ãµes.\nPor exemplo, se supormos que a proporÃ§Ã£o verdadeira seja 40% \\((p = 0.4)\\), a distribuiÃ§Ã£o binomial determina que a probabilidade de observar \\(y = 2\\) sucessos em \\(n = 4\\) lanÃ§amentos seja:\n\\[P(y = 2 \\mid n = 4, p = 0.4) = \\binom{4}{2} \\, 0.4^2 (1 - 0.4)^{4 - 2} = 0.35\\]\nEssa hipÃ³tese Ã© apenas uma das possÃ­veis. Para ilustrar outras conjecturas, considere:\n\nSe \\(p = 0.3\\):\n\\(P(2 \\mid 4, 0.3) = \\binom{4}{2} \\, 0.3^2 (1 - 0.3)^{4 - 2} = 0.26\\)\nSe \\(p = 0.8\\):\n\\(P(2 \\mid 4, 0.8) = \\binom{4}{2} \\, 0.8^2 (1 - 0.8)^{4 - 2} = 0.15\\)\n\nEm cada caso, os dados observados \\((y)\\) e o nÃºmero total de observaÃ§Ãµes \\((n)\\) estÃ£o fixos, enquanto o parÃ¢metro \\(p\\) varia conforme a hipÃ³tese considerada. Embora a forma matemÃ¡tica seja idÃªntica Ã  da funÃ§Ã£o de probabilidade binomial, seu uso Ã© diferente. Na funÃ§Ã£o de probabilidade, lemos a probabilidade de \\(y\\) dado \\(n\\) e \\(p\\), enquanto nos exemplos acima, avaliamos a plausibilidade de diferentes hipÃ³teses sobre \\(p\\) dados valores fixos de \\(y\\) e \\(n\\).\nPara evitar confusÃµes, vamos definir a funÃ§Ã£o de verossimilhanÃ§a como:\n\\[\n\\mathcal{L}(p \\mid n, y) = \\binom{n}{y} \\, p^y (1 - p)^{n - y}.\n\\tag{2}\\]\nAssim, as verossimilhanÃ§as para as trÃªs conjecturas especÃ­ficas sobre a proporÃ§Ã£o de Ã¡gua na superfÃ­cie do globo serÃ£o:\n\n\\(\\mathcal{L}(p = 0.4 \\mid n = 4, y = 2) = 0.35\\),\n\\(\\mathcal{L}(p = 0.3 \\mid n = 4, y = 2) = 0.26\\),\n\\(\\mathcal{L}(p = 0.8 \\mid n = 4, y = 2) = 0.15\\).\n\nDessa forma, entre as trÃªs hipÃ³teses levantadas, aquela em que \\(p = 0.4\\) recebe maior suporte das evidÃªncias, por estar associada Ã  maior verossimilhanÃ§a.\nPodemos quantificar esse suporte por meio da razÃ£o de verossimilhanÃ§as:\n\\[RV = \\frac{\\mathcal{L}(p = 0.4 \\mid 4, 2)}{\\mathcal{L}(p = 0.3 \\mid 4, 2)} = \\frac{0.35}{0.26} = 1.35,\\]\no que indica que, com base nos dados observados, a hipÃ³tese de \\(p = 0.4\\) Ã© aproximadamente \\(1.35\\) vezes mais verossÃ­mil do que a hipÃ³tese de \\(p = 0.3\\).\n\n\n\n\n\n\nAvisoResumo: A FunÃ§Ã£o de VerossimilhanÃ§a Binomial\n\n\n\n\nA expressÃ£o Ã© matematicamente idÃªntica Ã  funÃ§Ã£o de probabilidade binomial, porÃ©m interpretada como uma funÃ§Ã£o de \\(p\\) quando os dados \\(Y\\) e \\(n\\) sÃ£o fixos.\nA verossimilhanÃ§a indica a plausibilidade de diferentes valores de \\(p\\) Ã  luz dos dados observados.\nNa distribuiÃ§Ã£o binomial, lemos: probabilidade de \\(Y\\) dado \\(n\\) e \\(p\\).\nNa funÃ§Ã£o de verossimilhanÃ§a, interpretamos: verossimilhanÃ§a de \\(p\\) dado \\(n\\) e \\(Y\\).\nA razÃ£o de verossimilhanÃ§as pode ser utilizada para quantificar o suporte relativo entre diferentes hipÃ³teses.\n\n\n\n\n2.1 O perfil de verossimilhanÃ§a\nAcima, foram testadas trÃªs conjecturas especÃ­ficas para a proporÃ§Ã£o de Ã¡gua na superfÃ­cie da Terra (\\(p = 0.3\\), \\(p = 0.4\\), \\(p = 0.8\\)). Para uma avaliaÃ§Ã£o mais completa, podemos analisar o perfil de verossimilhanÃ§a para uma sÃ©rie de valores de \\(p\\) entre 0 e 1:\n\n\n\n\n\n\n\n\n\nO perfil de verossimilhanÃ§a indica que, Ã  luz dos nossos dados \\(y = 2\\), a conjectura mais plausÃ­vel Ã© que a proporÃ§Ã£o de Ã¡gua que cobre a Terra esteja prÃ³xima de 0.5 (neste caso, a verossimilhanÃ§a mÃ¡xima Ã© exatamente para \\(p = 0.5\\))."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#inferÃªncia-bayesiana-distribuiÃ§Ãµes-a-priori-e-a-posteriori",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#inferÃªncia-bayesiana-distribuiÃ§Ãµes-a-priori-e-a-posteriori",
    "title": "Construindo um modelo bayesiano",
    "section": "3 InferÃªncia Bayesiana: distribuiÃ§Ãµes a priori e a posteriori",
    "text": "3 InferÃªncia Bayesiana: distribuiÃ§Ãµes a priori e a posteriori\nA inferÃªncia bayesiana utiliza o Teorema de Bayes para derivar a distribuiÃ§Ã£o a posteriori dos parÃ¢metros de interesse, \\(p(\\theta \\mid Y)\\), a partir da verossimilhanÃ§a \\(p(Y \\mid \\theta)\\) e da distribuiÃ§Ã£o a priori \\(p(\\theta)\\):\n\\[p(\\theta \\mid Y) = \\frac{p(Y \\mid \\theta) \\times p(\\theta)}{p(Y)} \\tag{3}\\]\nEm que:\n\n\\(p(\\theta \\mid Y)\\): distribuiÃ§Ã£o a posteriori de \\(\\theta\\) dado os dados observados \\(Y\\);\n\\(p(Y \\mid \\theta)\\): verossimilhanÃ§a dos dados \\(Y\\) dada \\(\\theta\\);\n\\(p(\\theta)\\): distribuiÃ§Ã£o a priori de \\(\\theta\\);\n\\(p(Y)\\): probabilidade marginal dos dados, obtida por\n\n\\[\\int p(Y \\mid \\theta) \\times p(\\theta) \\, d\\theta\\]\nNo contexto bayesiano, Ã© comum substituir \\(p(Y \\mid \\theta)\\) pela funÃ§Ã£o de verossimilhanÃ§a \\(\\mathcal{L}(\\theta \\mid Y)\\), pois ambas sÃ£o matematicamente equivalentes. Assim, a fÃ³rmula da distribuiÃ§Ã£o a posteriori pode ser reescrita como:\n\\[p(\\theta \\mid Y) = \\frac{\\mathcal{L}(\\theta \\mid Y) \\times p(\\theta)}{p(Y)} \\tag{4}\\]"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#priori-informativa-e-nÃ£o-informativa",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#priori-informativa-e-nÃ£o-informativa",
    "title": "Construindo um modelo bayesiano",
    "section": "4 Priori informativa e nÃ£o informativa",
    "text": "4 Priori informativa e nÃ£o informativa\nDenominamos priori nÃ£o informativa aquela que nÃ£o acrescenta informaÃ§Ãµes relevantes Ã  distribuiÃ§Ã£o a posteriori alÃ©m daquelas jÃ¡ contidas nos dados observados. Nesses casos, a distribuiÃ§Ã£o a posteriori Ã© proporcional apenas Ã  verossimilhanÃ§a:\n\\[p(\\theta \\mid Y) \\propto \\mathcal{L}(\\theta \\mid Y) \\tag{5}\\]\nPor outro lado, ao adotarmos uma priori informativa, atribuÃ­mos diferentes densidades de probabilidade Ã s regiÃµes especÃ­ficas do espaÃ§o de parÃ¢metros, refletindo o conhecimento prÃ©vio sobre o fenÃ´meno estudado. A distribuiÃ§Ã£o a posteriori, nesse caso, serÃ¡ proporcional ao produto entre a verossimilhanÃ§a e a priori, integrando evidÃªncias anteriores com a informaÃ§Ã£o contida nos dados:\n\\[p(\\theta \\mid Y) \\propto \\mathcal{L}(\\theta \\mid Y) \\times p(\\theta) \\tag{6}\\]\nNo modelo binomial aplicado Ã  proporÃ§Ã£o de Ã¡gua na superfÃ­cie oceÃ¢nica, o parÃ¢metro \\(\\theta\\) representa a proporÃ§Ã£o de Ã¡gua \\(p\\), e sua distribuiÃ§Ã£o posterior Ã© condicional ao nÃºmero de observaÃ§Ãµes \\(n\\) e aos dados observados \\(y\\).\nA distribuiÃ§Ã£o a priori para \\(p\\) pode ser nÃ£o informativa, como no caso da distribuiÃ§Ã£o uniforme, que nÃ£o favorece nenhum valor especÃ­fico de \\(p\\). Alternativamente, pode-se adotar uma priori informativa, como a distribuiÃ§Ã£o Beta, que permite ajustar a forma da densidade de probabilidade por meio dos parÃ¢metros \\(\\alpha\\) e \\(\\beta\\), incorporando conhecimento prÃ©vio sobre o fenÃ´meno de interesse.\nPara ilustrar o efeito de prioris informativas e nÃ£o-informativas sobre a distribuiÃ§Ã£o a posteriori, siga a atividade abaixo:\n\n\n\n\n\n\nDicaAtividades interativas: estimando a proporÃ§Ã£o da superfÃ­cie oceÃ¢nica!\n\n\n\n\nAmostre pontos no globo e faÃ§a sua prÃ³pria inferÃªncia bayesiana\nNo app abaixo, gere pontos aleatÃ³rios na superfÃ­cie da Terra e verifique quantos caem em Ã¡gua ou em terra.\nğŸ‘‰ Estimando a ProporÃ§Ã£o da SuperfÃ­cie OceÃ¢nica\n\nEscolha quantos pontos deseja amostrar (1 a 1000).\n\nClique em â€œGerar Pontos AleatÃ³riosâ€ e observe quantos ficam sobre a Ã¡gua versus sobre a terra.\n\nRegistre esses valores como \\(k\\) sucessos em \\(N\\) pontos (N observaÃ§Ãµes).\n\nUtilize seus dados na inferÃªncia Bayesiana\nEm seguida, abra o app abaixo para visualizar como as observaÃ§Ãµes (sucessos e fracassos) combinadas a diferentes escolhas de parÃ¢metros a priori (\\(\\alpha\\), \\(\\beta\\)) geram a distribuiÃ§Ã£o a posteriori:\nğŸ‘‰ InferÃªncia Bayesiana\nDicas de uso\n\nInsira o mesmo nÃºmero de observaÃ§Ãµes (N) e sucessos (k) obtidos no primeiro app.\n\nAjuste interativamente a distribuiÃ§Ã£o a priori Beta, modificando os parÃ¢metros \\(\\alpha\\) e \\(\\beta\\).\nObserve como a curva azul (â€œposterioriâ€) se altera de acordo com a a priori e com os dados observados, e compare com o perfil de verossimilhanÃ§a (curva verde).\nNote que ao escolher \\(\\alpha = 1\\) e \\(\\beta = 1\\) a distribuiÃ§Ã£o assume um formato uniforme, tornando-se nÃ£o-informativa."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html",
    "title": "Modelo Normal Bayesiano",
    "section": "",
    "text": "Exploraremos a inferÃªncia bayesiana, com foco na modelagem de dados contÃ­nuos por meio da distribuiÃ§Ã£o normal. Nosso objetivo serÃ¡ desenvolver a intuiÃ§Ã£o sobre como escolher distribuiÃ§Ãµes a priori e como o PyMC nos auxilia a visualizar as consequÃªncias dessas escolhas sobre a distribuiÃ§Ã£o preditiva a priori da variÃ¡vel de interesse. Para isso, utilizaremos um exemplo baseado na distribuiÃ§Ã£o de altura em adultos.\n# ConfiguraÃ§Ã£o inicial e importaÃ§Ã£o de bibliotecas\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# ConfiguraÃ§Ãµes para plots\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (9, 6)"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#explorando-a-distribuiÃ§Ã£o-normal",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#explorando-a-distribuiÃ§Ã£o-normal",
    "title": "Modelo Normal Bayesiano",
    "section": "1 Explorando a DistribuiÃ§Ã£o Normal",
    "text": "1 Explorando a DistribuiÃ§Ã£o Normal\nA DistribuiÃ§Ã£o Normal, frequentemente chamada de curva de sino ou curva Gaussiana, Ã© central em estatÃ­stica. Ela Ã© caracterizada por dois parÃ¢metros: a mÃ©dia (\\(\\mu\\)) e o desvio padrÃ£o (\\(\\sigma\\)). A mÃ©dia determina o centro da distribuiÃ§Ã£o, enquanto o desvio padrÃ£o determina sua dispersÃ£o ou largura. Muitos fenÃ´menos naturais podem ser adequadamente descritos por essa distribuiÃ§Ã£o.\nA ideia intuitiva: Pense na altura de adultos. HÃ¡ um valor central (a mÃ©dia) em torno do qual a maioria das alturas se agrupa. HÃ¡ tambÃ©m uma variaÃ§Ã£o: algumas pessoas sÃ£o mais altas, outras mais baixas. O desvio padrÃ£o nos diz o quÃ£o espalhadas essas alturas tendem a ser em relaÃ§Ã£o Ã  mÃ©dia.\n\n1.1 Curva de densidade de probabilidade\nGerando a DistribuiÃ§Ã£o de Densidade Normal para diferentes valores de \\(\\mu\\) e \\(\\sigma\\).\n\n# ParÃ¢metros da distribuiÃ§Ã£o\nmu_1 = 20\nsigma_1 = 3\n\nmu_2 = 20\nsigma_2 = 6\n\nmu_3 = 30\nsigma_3 = 5\n\n# Limites grÃ¡ficos\nx_min = np.min(np.array([mu_1, mu_2, mu_3]) - 4*np.array([sigma_1, sigma_2, sigma_3]))\nx_max = np.max(np.array([mu_1, mu_2, mu_3]) + 4*np.array([sigma_1, sigma_2, sigma_3]))\nx = np.linspace(x_min, x_max, 1000) # Faixa de alturas para plotar\n\npdf_1 = stats.norm.pdf(x, loc=mu_1, scale=sigma_1)\npdf_2 = stats.norm.pdf(x, loc=mu_2, scale=sigma_2)\npdf_3 = stats.norm.pdf(x, loc=mu_3, scale=sigma_3)\n\nVisualizando as distribuiÃ§Ãµes de densidade de probabilidade\n\nplt.plot(x, pdf_1, label=f'$\\mu={mu_1}, \\sigma={sigma_1}$', color='b', lw=2)\nplt.plot(x, pdf_2, label=f'$\\mu={mu_2}, \\sigma={sigma_2}$', color='r', lw=2)\nplt.plot(x, pdf_3, label=f'$\\mu={mu_3}, \\sigma={sigma_3}$', color='g', lw=2)\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade de Probabilidade', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='-', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFiguraÂ 1: Desidades da distribuiÃ§Ã£o normal para diferentes valores de Î¼ e Ïƒ.\n\n\n\n\n\n\n\n1.2 Amostrando valores de distribuiÃ§Ã£o normal\nNa FiguraÂ 1 vemos as curvas teÃ³ricas de densidade da distribuiÃ§ao normal. Podemos tambÃ©m gerar amostras valores ao acaso destas distribuiÃ§Ãµes para verificar como estas amostras se parecem. Isso simula o processo de sortear alturas de uma populaÃ§Ã£o que segue essa distribuiÃ§Ã£o.\n\nmu = 20\nsigma = 4\nnum_amostras = 60\n\nVerificando o histograma dos valores sorteados.\n\namostras_y = stats.norm.rvs(loc=mu, scale=sigma, size=num_amostras)\nx_dens = np.linspace(mu-4*sigma, mu+4*sigma, 500)\n\nplt.hist(amostras_y, bins=30, density=True, alpha=0.8, color='lightblue', label='Amostras Geradas')\nsns.kdeplot(amostras_y, color='blue', linewidth=2, label='Densidade EmpÃ­rica')\nplt.plot(x_dens, stats.norm.pdf(x_dens, loc=mu, scale=sigma), color='red', linewidth=2.5, label='Densidade TeÃ³rica')\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade / FrequÃªncia Normalizada', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFiguraÂ 2: Histograma de amostras geradas a partir de uma distribuiÃ§Ã£o normal com mÃ©dia \\(\\mu\\) e desvio padrÃ£o \\(\\sigma\\), acompanhado da densidade empÃ­rica estimada por kernel e da densidade teÃ³rica correspondente.\n\n\n\n\n\n\n\n\n\n\n\nDicaAtividade em laboratÃ³rio\n\n\n\n\nRode este o trecho de cÃ³digo acima algumas vezes e observe como se dÃ¡ a variaÃ§Ã£o amostral.\nAumente e diminua o tamanho da amostras e verifique a variaÃ§Ã£o entre as curvas enpÃ­ricas e a curva teÃ³rica."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#intuiÃ§Ã£o-bayesiana",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#intuiÃ§Ã£o-bayesiana",
    "title": "Modelo Normal Bayesiano",
    "section": "2 IntuiÃ§Ã£o Bayesiana",
    "text": "2 IntuiÃ§Ã£o Bayesiana\nEm inferÃªncia Bayesiana, comeÃ§amos com crenÃ§as sobre os parÃ¢metros (a priori) e as atualizamos com dados (a posteriori). Para a altura humana (\\(y\\)), podemos assumir que a distribuiÃ§Ã£o normal Ã© um bom modelo preditivo.\nDeste modo, escrevemos que:\n\\[y \\sim \\mathcal{N}(\\mu, \\sigma)\n\\tag{1}\\]\nEm seguida, precisamos sugerir uma dristribuiÃ§Ã£o a priori para a mÃ©dia \\(\\mu\\) e o desvio padrÃ£o \\(\\sigma\\) que traduzam de forma adequada o que esperamos sobre a distribuiÃ§Ã£o de altura em adultos. Sabemos por exemplo que a mÃ©dia da altura de adultos nÃ£o Ã© 50 cm nem 300 cm. Qual sua intuiÃ§Ã£o sobre o desvio padrÃ£o?\n\n\n\n\n\n\nDicaAtividade em laboratÃ³rio\n\n\n\n\nAssumindo que a distribuiÃ§Ã£o de alturas em adultos segue uma dsitribuiÃ§Ã£o normal proponha valores razoÃ¡veis para a mÃ©dia (\\(\\mu\\)) e o desvio padrÃ£o (\\(\\sigma\\)).\nPara ajudar a decidir sobre o que seriam valores valores razoÃ¡veis, plote as curvas de densidade de probabilidade resultante de sua escolha e faÃ§a algumas simulaÃ§Ãµes para verificar quais valores estremos sua escolha Ã© capaz de gerar, utilizando os cÃ³digos da SeÃ§Ã£oÂ 1.2.\n\n\n\n\n2.1 Checagem Priori Preditiva\nAssumindo que a altura de adultos segue uma distribuiÃ§Ã£o (EquaÃ§Ã£oÂ 1), vamos assumir que o parÃ¢metro \\(\\mu\\) segue tambÃ©m uma distribuiÃ§Ã£o normal e que \\(\\sigma\\) segue uma distribuiÃ§Ã£o log-normal\nComo utilizamos estes pressupostos para escolher distribuiÃ§Ã£o razoiÃ¡veis para \\(\\mu\\) e \\(\\sigma\\)?\nPriori para \\(\\mu\\)\n\nmean_prior_mu =  # INSIRA SUA ESCOLHA PARA A MÃ‰DIA DA PRIORI DE mu\nsd_prior_mu =  # INSIRA SUA ESCOLHA PARA O DESVIO PADRÃƒO DA PRIORI DE mu\n\n# Gere sequancia de x e calcule a PDF\nxmean_prior = np.linspace(mean_prior_mu - 4*sd_prior_mu, mean_prior_mu + 4*sd_prior_mu, 1000)\npdf_mean_prior = stats.norm.pdf(x = xmean_prior, loc = mean_prior_mu, scale = sd_prior_mu)\n\n# Plote os resultados\nplt.plot(xmean_prior, pdf_mean_prior)\nplt.title(f'Priori para $\\mu$')\nplt.show()\n\nPriori para \\(\\sigma\\)\n\nlmean_prior_sigma =  # INSIRA SUA ESCOLHA PARA A MÃ‰DIA DA PRIORI DE sigma\nlsd_prior_sigma =  # INSIRA SUA ESCOLHA PARA O DESVIO PADRÃƒO DA PRIORI DE sigma\n\nxsd_prior = np.linspace(0.01, 20, 1000)\npdf_sd_prior = stats.lognorm.pdf(xsd_prior, s=lsd_prior_sigma, scale=lmean_prior_sigma)\n\nplt.close()\nplt.plot(xsd_prior, pdf_sd_prior)\nplt.title(f'Priori para $\\sigma$')\nplt.show()\n\nExtraindo distribuiÃ§Ã£o a priori preditiva de \\(y\\) no PyMC\n\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a mÃ©dia\n    mu = pm.Normal(\"mu\", mu = mean_prior_mu, sigma = sd_prior_mu)\n\n    # Priori lognormal para o desvio padrÃ£o\n    sigma = pm.Lognormal(\"sigma\", mu = np.log(lmean_prior_sigma), sigma = lsd_prior_sigma)\n\n    # DistribuiÃ§Ã£o preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu = mu, sigma = sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n\nAgora, vamos visualizar a distribuiÃ§Ã£o dessas amostras preditivas a priori:\n\n\n\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nplt.figure(figsize=(10, 6))\nplt.hist(y_pred_prior, color='skyblue', edgecolor='black')\nplt.xlabel('Alturas priori simulada (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\nFiguraÂ 3\n\n\n\n\n\n\n\n\n\nDicaDiscussÃ£o\n\n\n\nOlhe para o histograma. As alturas simuladas parecem razoÃ¡veis para alturas de adultos? A distribuiÃ§Ã£o faz sentido dada a sua intuiÃ§Ã£o? Se sim, suas priores iniciais eram sensatas. Se nÃ£o, Ã© importante considerar um ajuste de suas priores (ex: tornar a priori de \\(\\sigma\\) mais restrita se a dispersÃ£o for muito grande, ou ajustar a localizaÃ§Ã£o/escala da priori de \\(\\mu\\)).\n\n\nChecagem priori preditiva com PyMC\nPodemos chegar nÃ£o somente a distribuiÃ§Ã£o preditiva de \\(y\\), mas tambÃ©m dos parÃ¢metros \\(\\mu\\) e \\(\\sigma\\) usando o PyMC. AlÃ©m disso, poderÃ­amos testar outras distribuiÃ§Ãµes a priori para algum dos parÃ¢metros, por exemplo sigma. Teste cada uma destas e verifique os efeitos sobre as distribuiÃ§Ãµes preditivas.\n\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a mÃ©dia\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)\n\n    # Escolha uma das prioris para sigma:\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(0.08), sigma=0.5)\n    # sigma = pm.InverseGamma(\"sigma\", alpha=8, beta=0.9)\n    # sigma = pm.HalfNormal(\"sigma\", sigma=0.1)\n    # sigma = pm.HalfCauchy(\"sigma\", beta=0.1)\n    # sigma = pm.Exponential(\"sigma\", lam=20)\n    # sigma = pm.TruncatedNormal(\"sigma\", mu=0.08, sigma=0.02, lower=0)\n    # sigma = pm.Uniform(\"sigma\", lower=0, upper=1)\n\n    # DistribuiÃ§Ã£o preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu=mu, sigma=sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n\n\n\n\nmu_pred_prior = prior_predictive_samples.prior[\"mu\"].values.flatten()\nsigma_pred_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nfig, axes = plt.subplots(1, 3, figsize=(9, 3))\n\naxes[0].hist(mu_pred_prior, bins=30, color='skyblue', edgecolor='black')\naxes[0].set_xlabel(\"Î¼\")\naxes[0].set_ylabel(\"FrequÃªncia\")\n\naxes[1].hist(sigma_pred_prior, bins=30, color='lightgreen', edgecolor='black')\naxes[1].set_xlabel(\"Ïƒ\")\naxes[1].set_ylabel(\"FrequÃªncia\")\n\naxes[2].hist(y_pred_prior, bins=30, color='salmon', edgecolor='black')\naxes[2].set_xlabel(\"alturas (y)\")\naxes[2].set_ylabel(\"FrequÃªncia\")\n\nplt.tight_layout()\nplt.show()\n\n\nFiguraÂ 4"
  }
]