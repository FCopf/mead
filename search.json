[
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html",
    "title": "Probabilidade condicional e independ√™ncia",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(ggVennDiagram)\nsource(\"scripts/conditional-tree.r\")"
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#probabilidade-condicional",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#probabilidade-condicional",
    "title": "Probabilidade condicional e independ√™ncia",
    "section": "1 Probabilidade Condicional",
    "text": "1 Probabilidade Condicional\nConsideremos o experimento ‚Äúvirar uma estrutura (folha ou galho) e contar o n√∫mero de itens‚Äù:\n\\(\\Omega = \\{(F0), (F1), (F2), (F3), (F4), (F5), (F6), (G0), (G1), (G2), (G3), (G4)\\}\\)\nSejam definidos os eventos:\n\n\\(A\\): ‚Äúvirar uma folha‚Äù:\n\\[A = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6)}\\}.\\]\n\\(B\\): ‚Äúobter 3 ou mais itens‚Äù:\n\\[B = \\{\\text{(F3), (F4), (F5), (F6), (G3), (G4)}\\}.\\]\n\nQue podem ser representados no diagrama de Venn:\n\n\n\n\n\n\n\n\n\nPodemos perguntar:\n\nConsiderando que tenha sido virada uma folha, qual a probabilidade de que tenham sido obtidos mais de 3 itens?\n\nAo informar que a estrutura era uma folha, sabemos que nem todos os eventos de \\(\\Omega\\) podem ter ocorrido. Neste exemplo, somente as 7 observa√ß√µes do evento e \\(A\\) consistem de uma folha.\nDestas, apenas 4 possuem mais de 3 itens, de modo a resposta √† pergunta seria \\(\\frac{4}{7}\\). Este resultado √© conhecido como probabilidade condicional, denotada pelo s√≠mbolo (\\(|\\)). Neste exemplo espec√≠fico estamos perguntando:\n\nDado que \\(A\\) OCORREU, qual a probabilidade de que \\(B\\) ocorra? Simbolicamente, esta quest√£o √© escrita como \\(P(B|A)\\) e lida como probabilidade de \\(B\\) dado \\(A\\).\n\n\\[P(B|A) = \\frac{4}{7} = 0.57\\]\nEsta probabilidade condicional foi calculada pelo n√∫mero de observa√ß√µes favor√°veis √† intersec√ß√£o de \\(A\\) e \\(B\\) (\\(A \\cap B\\)) relativa ao n√∫mero de observa√ß√µes do evento \\(A\\). Isto significa que ao sabermos parte dos resultados, o espa√ßo amostral inicial foi reduzido, neste caso, ao espa√ßo coincidente com \\(A\\).\nDeste modo, a probabilidade condicional pode ser expressacomo:\n\\[P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}\\]\nque neste exemplo ser√°:\n\\[P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{4}{7} = 0.57\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#representa√ß√£o-de-eventos-diagrama-de-√°rvore",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#representa√ß√£o-de-eventos-diagrama-de-√°rvore",
    "title": "Probabilidade condicional e independ√™ncia",
    "section": "2 Representa√ß√£o de eventos: diagrama de √°rvore",
    "text": "2 Representa√ß√£o de eventos: diagrama de √°rvore\nQuando lidamos com experimentos em etapas ou eventos sequenciais, um diagrama de √°rvore ajuda a visualizar cada est√°gio, indicando as probabilidades e as condicionais:\n\n\n\n\n\n\n\n\n\nNesse diagrama, cada ramo representa um cen√°rio: por exemplo, ao ocorrer \\(A\\), \\(B\\) pode acontecer com \\(P(B \\mid A)\\), resultando na intersec√ß√£o \\(A \\cap B\\). Assim, o diagrama possibilita mapear todos os cen√°rios poss√≠veis de maneira organizada."
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes",
    "title": "Probabilidade condicional e independ√™ncia",
    "section": "3 Eventos independentes",
    "text": "3 Eventos independentes\nDois eventos \\(A\\) e \\(B\\) s√£o independentes quando conhecer a ocorr√™ncia de um deles n√£o altera a probabilidade do outro, ou seja, conhecer \\(A\\) n√£o nos diz nada sobre a probabilidade de ocorr√™ncia de \\(B\\), de modo que \\(P(B) = P(B \\mid A)\\).\nNo experimento ‚Äúvirar uma estrutura e contar o n√∫mero de itens‚Äù, temos por exemplo.\n\\(P(B) = 0.5\\)\ne que\n\\(P(B \\mid A) = 0.57\\)\nPortanto, ao sabermos que a estrutura virada foi uma folha, a probalidade de que tenham sido observados 3 ou mais items foi alterada.\nOs eventos \\(A\\) e \\(B\\) s√£o portanto eventos dependentes em que \\(P(B) \\neq P(B \\mid A)\\).\n\n3.1 Exemplo de eventos independentes\nSuponha que foram investigadas 600 pessoas, classificadas por idade e local de origem. Nesse contexto temos os eventos:\n\n\\(A\\): ter at√© 20 anos; \\(\\overline{A}\\): ter mais de 20 anos.\n\n\\(B\\): ser da cidade; \\(\\overline{B}\\): ser de fora da cidade.\n\nConsidere a matriz:\n\n\n\n\n\n\n\n\nidade\nDa cidade\nDe fora da cidade\n\n\n\n\nAt√© 20\n30\n170\n\n\nMais de 20\n60\n340\n\n\n\n\n\n\n\nAs probabilidades s√£o:\n\\(P(A) = \\frac{200}{600} = 0.33\\)\n\\(P(\\overline{A}) \\;=\\; \\frac{400}{600} = 0.67\\)\n\\(P(B) = \\frac{90}{600} = 0.15\\)\n\\(P(\\overline{B}) \\;=\\; \\frac{510}{600} = 0.85\\)\nSabendo, por exemplo, que a pessoa tem mais de 20 anos, a probabilidade de ela ser da cidade √©:\n\\[P(B \\mid A) = \\frac{60}{400} = 0.15.\\]\nUma vez que \\(P(B) = P(B \\mid A)\\), ent√£o \\(A\\) e \\(B\\) s√£o eventos independentes."
  },
  {
    "objectID": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes-vs-mutuamente-exclusivos",
    "href": "content/fundamentos-probabilidade/probabilidade-condicional.html#eventos-independentes-vs-mutuamente-exclusivos",
    "title": "Probabilidade condicional e independ√™ncia",
    "section": "4 Eventos independentes vs mutuamente exclusivos",
    "text": "4 Eventos independentes vs mutuamente exclusivos\n\nDois eventos s√£o mutuamente exclusivos quando \\(P(A \\cap B) = 0\\). Se ambos ocorrerem, excluem-se mutuamente. Logo, se \\(A\\) ocorre, \\(B\\) n√£o pode ocorrer. Nesse caso, \\(P(B \\mid A) = 0\\), caracterizando depend√™ncia, pois a informa√ß√£o de \\(A\\) determina que \\(B\\) n√£o ocorrer√°.\nDois eventos s√£o independentes se \\(P(A \\cap B) = P(A)\\times P(B)\\). Isso significa que conhecer \\(A\\) n√£o altera a probabilidade de \\(B\\). Se \\(P(A)\\) e \\(P(B)\\) forem n√£o nulos, ent√£o n√£o podem ser ao mesmo tempo mutuamente exclusivos e independentes.\n\nA representa√ß√£o de eventos mutuamente exclusivos no diagrama de √°rvore √© ilustrada por \\(P(B \\mid A)=0\\), pois, ao ocorrer \\(A\\), j√° se sabe que \\(B\\) n√£o ocorrer√°. Assim, eventos mutuamente exclusivos implica serem eventos dependentes. Se n√£o h√° exclusividade, os eventos podem ou n√£o ser independentes, dependendo de \\(P(B)\\) em rela√ß√£o a \\(P(B \\mid A)\\)."
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html",
    "title": "Teorema de Bayes",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas\n\n\n\n\n\n\nsource(\"scripts/conditional-tree.r\")\nO Teorema de Bayes prov√©m da defini√ß√£o de probabilidade condicional:\n\\[P(B|A) = \\frac{P(A \\cap B)}{P(A)},\\]\no que implica:\n\\[P(A \\cap B) = P(A)\\,P(B|A).\\]\nPodemos tamb√©m escrever:\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\quad P(A \\cap B) = P(B)\\,P(A|B).\\]\nComo \\(P(A \\cap B) = P(B \\cap A)\\), segue:\n\\[P(A)\\,P(B|A) = P(B)\\,P(A|B),\\]\nresultando na forma geral do Teorema de Bayes:\n\\[P(B|A) = \\frac{P(B)\\,P(A|B)}{P(A)}.\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html#teorema-da-probabilidade-total",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html#teorema-da-probabilidade-total",
    "title": "Teorema de Bayes",
    "section": "1 Teorema da probabilidade total",
    "text": "1 Teorema da probabilidade total\nConsidere o esquema de um diagrama de √°rvore:\n\n\n\n\n\n\n\n\n\nDois caminhos podem levar √† ocorr√™ncia de \\(A\\): um em que \\(B\\) ocorre \\(\\bigl[P(A \\cap B)\\bigr]\\) e outro em que \\(B\\) n√£o ocorre \\(\\bigl[P(A \\cap \\overline{B})\\bigr]\\). Por serem mutuamente exclusivos:\n\\[P(A) = P(A \\cap B) + P(A \\cap \\overline{B}),\\]\nque pode ser reescrito como:\n\\[P(A) = P(B)\\,P(A|B) + P(\\overline{B})\\,P(A|\\overline{B}).\\]\nEste resultado √© conhecido como Teorema da probabilidade total. Assim, o Teorema de Bayes pode ser expresso por:\n\\[\nP(B|A) = \\frac{P(B)\\,P(A|B)}{P(B)\\,P(A|B) + P(\\overline{B})\\,P(A|\\overline{B})}.\n\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/teorema-bayes.html#o-problema-da-detec√ß√£o-de-esp√©cies",
    "href": "content/fundamentos-probabilidade/teorema-bayes.html#o-problema-da-detec√ß√£o-de-esp√©cies",
    "title": "Teorema de Bayes",
    "section": "2 O problema da detec√ß√£o de esp√©cies",
    "text": "2 O problema da detec√ß√£o de esp√©cies\nSuponha um estudo sobre a presen√ßa de uma esp√©cie de peixe em riachos costeiros da Mata Atl√¢ntica. Ela ocorre em 5% dos riachos \\(\\bigl[P(O) = 0,05\\bigr]\\), sendo, portanto, rara. A detec√ß√£o se d√° por captura e identifica√ß√£o taxon√¥mica. Se a esp√©cie est√° presente, a probabilidade de captura √© \\(0,99\\), havendo \\(0,01\\) de falso negativo (quando a esp√©cie n√£o √© detectada mesmo presente).\nH√° tamb√©m a possibilidade de falso positivo: mesmo quando ausente, existe uma chance de 0,10 de a esp√©cie ser registrada erroneamente, devido √† semelhan√ßa com outra esp√©cie presente na regi√£o.\nPodemos organizar essas probabilidades em um diagrama de √°rvore:\n\n\n\nDiagrama de √°rvore representando as probabilidades de ocorr√™ncia P(O) e detec√ß√£o P(D) de uma esp√©cie.\n\n\nAs ramifica√ß√µes mostram as bifurca√ß√µes do evento ‚Äúesp√©cie presente ou ausente‚Äù e, em seguida, ‚Äúdetec√ß√£o ou n√£o-detec√ß√£o‚Äù. Assim, s√£o poss√≠veis:\n\n\\(P(O \\cap D) = 0,0495\\)\n\\(P(O \\cap \\overline{D}) = 0,0005\\)\n\\(P(\\overline{O} \\cap D) = 0,095\\)\n\\(P(\\overline{O} \\cap \\overline{D}) = 0,855\\)\n\nA probabilidade total de detec√ß√£o \\(P(D)\\) √©:\n\\[P(D) = P(O \\cap D) + P(\\overline{O} \\cap D) = 0,0495 + 0,095 = 0,1445.\\]\n\n2.1 Raz√£o de verossimilhan√ßa, infer√™ncia bayesiana e teste de hip√≥teses\nUma pergunta relevante √©:\n\nAo sabermos de uma poss√≠vel detec√ß√£o, podemos ter certeza da presen√ßa dessa esp√©cie?\n\nEm infer√™ncia estat√≠stica, buscamos tomar decis√µes a respeito de um fen√¥meno desconhecido com base em dados observados. Aqui, exploramos duas abordagens: verossimilhan√ßa e infer√™ncia bayesiana.\n\n2.1.1 Verossimilhan√ßa: uma medida indireta para \\(P(O|D)\\)\nSe \\(P(D|O)\\) for alta, a presen√ßa da esp√©cie se torna mais plaus√≠vel, pois a chance de detect√°-la quando est√° presente √© elevada. J√° \\(P(D|\\overline{O})\\) alto indicaria que a n√£o-ocorr√™ncia √© mais prov√°vel, pois h√° muitos falsos positivos.\nEm estat√≠stica, \\(P(D|O)\\) √© an√°logo √† verossimilhan√ßa de \\(O\\) dado \\(D\\). De modo simplificado, contrastamos duas hip√≥teses:\n\nEsp√©cie ocorre e √© detectada;\nEsp√©cie n√£o ocorre, mas h√° detec√ß√£o falsa.\n\nA raz√£o de verossimilhan√ßa (\\(RV\\)) √©:\n\\[RV = \\frac{P(D|O)}{P(D|\\overline{O})} = \\frac{0,99}{0,10} = 9,9.\\]\nInterpretamos como sendo cerca de 10 vezes mais prov√°vel a hip√≥tese ‚Äúesp√©cie ocorre‚Äù do que ‚Äúesp√©cie n√£o ocorre‚Äù quando h√° detec√ß√£o.\n\n\n2.1.2 Infer√™ncia bayesiana: o conhecimento a priori importa?\nNa abordagem bayesiana, inclu√≠mos a probabilidade a priori de ocorr√™ncia, \\(P(O)\\). Quando recebemos a informa√ß√£o de detec√ß√£o, atualizamos essa probabilidade, tornando-a \\(P(O|D)\\).\nNo exemplo, conhecemos:\n\n\\(P(O) = 0,05\\) e \\(P(\\overline{O}) = 0,95\\);\n\\(P(D|O) = 0,99\\) e \\(P(D|\\overline{O}) = 0,10\\).\n\nPelo Teorema de Bayes:\n\\[P(O|D) = \\frac{P(O)\\,P(D|O)}{P(O)\\,P(D|O) + P(\\overline{O})\\,P(D|\\overline{O})}.\\]\nSubstituindo valores:\n\\[P(O|D) = \\frac{0,02 \\times 0,99}{0,02 \\times 0,99 + 0,98 \\times 0,10} \\approx 0.17.\\]\nE:\n\\[P(\\overline{O}|D) = \\frac{0,98 \\times 0,10}{0,02 \\times 0,99 + 0,98 \\times 0,10} \\approx 0.83.\\]\nMesmo com a detec√ß√£o, a chance de n√£o-ocorr√™ncia ainda √© maior, favorecendo a hip√≥tese de falso positivo.\n\n\n2.1.3 Diferen√ßas entre as abordagens\nA verossimilhan√ßa foca em \\(P(D|O)\\), enquanto a infer√™ncia bayesiana calcula \\(P(O|D)\\) diretamente, ponderada por \\(P(O)\\). Se \\(P(O) = 0,5\\), ent√£o:\n\\[P(O|D) = \\frac{0,5 \\times 0,99}{0,5 \\times 0,99 + 0,5 \\times 0,10} \\approx 0,91,\\] \\[P(\\overline{O}|D) \\approx 0,09,\\]\ne a raz√£o \\(\\frac{P(O|D)}{P(\\overline{O}|D)}\\) ser√° igual a \\(RV = 9,9\\), tal como na verossimilhan√ßa. Por√©m, quando \\(P(O)\\) indica uma esp√©cie muito rara, esse valor a priori altera o resultado final de \\(P(O|D)\\). Por isso, as duas abordagens s√≥ coincidem quando usamos uma priori n√£o-informativa (probabilidades iniciais iguais para presen√ßa e aus√™ncia)."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html",
    "href": "content/medidas-associacao/biquali.html",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas no cap√≠tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(gridExtra)\nsource('scripts/assoc-municipies.r')\nImagine que haver√° uma obra de revitaliza√ß√£o de uma √°rea na regi√£o central da cidade. A obra implicar√° na melhoria de acesso, de seguran√ßa e na oferta de servi√ßos. Entretanto como levar√° tempo para ser conclu√≠da, haver√° a√ß√µes de remo√ß√£o de moradias irregulares, interdi√ß√£o de ruas e avenidas por longos per√≠odos, etc. A prefeitura encomenda uma pesquisa para saber a opini√£o dos mun√≠cipes. A cada entrevistado s√£o feitas duas perguntas:\nA base de dados completa est√° dispon√≠vel em datasets\nCom estas entrevistas desejamos responder √† seguinte quest√£o:\nImporte a base de dados\nmun = read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Entrevista_municipes.csv',\n                  delim = ',')\n\nn_amostra = 12\nn = nrow(mun)  # N√∫mero de entrevistados\nAp√≥s entrevistar 200 pessoas selecionadas ao acaso de uma lista da moradores da cidade, foi constru√≠da uma tabela com tr√™s colunas: Entrevistado (sequ√™ncia num√©rica do primeiro ao √∫ltimo respondente), Opini√£o e Moradia.\nVeja os primeiros 12 resultados das entrevistas:\nTabela¬†1: Respostas dos primeiros mun√≠cipies entrevistados.\n\n\n\n\n\n\n\n\n\nEntrevistado\nOpiniao\nMoradia\n\n\n\n\n1\nA favor\nResidente\n\n\n2\nA favor\nResidente\n\n\n3\nA favor\nResidente\n\n\n4\nA favor\nResidente\n\n\n5\nContra\nN√£o-Residente\n\n\n6\nContra\nResidente\n\n\n7\nA favor\nN√£o-Residente\n\n\n8\nContra\nN√£o-Residente\n\n\n9\nA favor\nN√£o-Residente\n\n\n10\nA favor\nN√£o-Residente\n\n\n11\nA favor\nResidente\n\n\n12\nA favor\nN√£o-Residente\nEst√£o descritos na Tabela¬†1 os resultados das primeiras 12 entrevistas, onde √© poss√≠vel ver ao menos uma combina√ß√£o de todas as poss√≠veis respostas. O entrevistado pode ser:"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#tabelas-de-frequ√™ncia-e-gr√°ficos-de-barras",
    "href": "content/medidas-associacao/biquali.html#tabelas-de-frequ√™ncia-e-gr√°ficos-de-barras",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "1 Tabelas de frequ√™ncia e gr√°ficos de barras",
    "text": "1 Tabelas de frequ√™ncia e gr√°ficos de barras\nInicialmente, vamos representar cada uma das vari√°veis por meio de uma tabela de frequ√™ncia dos 200 entrevistados.\n\n\nC√≥digo\nresumo_opiniao = mun |&gt; \n  group_by(Opiniao) |&gt; \n  summarise(Op_n = n()) |&gt; \n  mutate(Op_rel = Op_n/sum(Op_n))\n\nresumo_opiniao |&gt; \n  gt()\n\n\n\n\n\n\n\n\nOpiniao\nOp_n\nOp_rel\n\n\n\n\nA favor\n144\n0.72\n\n\nContra\n56\n0.28\n\n\n\n\n\n\n\nDas \\(200\\) respostas tivemos \\(144\\) pessoas A favor (\\(72\\%\\)) e \\(56\\) pessoas Contra (\\(28\\%\\)).\n\n\nC√≥digo\nresumo_opiniao = mun |&gt; \n  group_by(Opiniao) |&gt; \n  summarise(Op_n = n()) |&gt; \n  mutate(Op_rel = Op_n/sum(Op_n))\n\nresumo_opiniao |&gt; \n  gt()\n\n\n\n\n\n\n\n\nOpiniao\nOp_n\nOp_rel\n\n\n\n\nA favor\n144\n0.72\n\n\nContra\n56\n0.28\n\n\n\n\n\n\n\nCom rela√ß√£o ao local de resid√™ncia:\n\n\nC√≥digo\nresumo_morad = mun |&gt; \n  group_by(Moradia) |&gt; \n  summarise(Morad_n = n()) |&gt; \n  mutate(Morad_rel = Morad_n/sum(Morad_n))\n\nresumo_morad |&gt; \n  gt()\n\n\n\n\n\n\n\n\nMoradia\nMorad_n\nMorad_rel\n\n\n\n\nN√£o-Residente\n117\n0.585\n\n\nResidente\n83\n0.415\n\n\n\n\n\n\n\nResponderam √† entrevistas um total de \\(117\\) pessoas N√£o-Residente (\\(58.5\\%\\)) e \\(83\\) pessoas Residente (\\(41.5\\%\\))\nSe visualizarmos estes totais em gr√°ficos de barras individuais teremos:\n\n\nC√≥digo\nplt_op = ggplot(mun, aes(x = Opiniao)) +\n  geom_bar(fill = 'darkblue', color = 'white') +\n  coord_cartesian(ylim = c(0, 150)) +\n  labs(y = 'N√∫mero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_morad = ggplot(mun, aes(x = Moradia)) +\n  geom_bar(fill = 'darkred', color = 'white') +\n  coord_cartesian(ylim = c(0, 150)) +\n  labs(y = 'N√∫mero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_op + plt_morad\n\n\n\n\n\n\n\n\nFigura¬†1: Respostas dos mun√≠cipies entrevistados para cada quest√£o separadamente.\n\n\n\n\n\nExiste portanto um predom√≠nio de pessoas A Favor e um ligeiro predom√≠nio de entrevistados N√£o-Residentes.\nPara responder √† quest√£o do cap√≠tulo, precisamos verificar se existe alguma associa√ß√£o entre as respostas dadas √†s duas perguntas explorando a distribui√ß√£o conjunta dos totais respondidos."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#tabelas-de-conting√™ncia",
    "href": "content/medidas-associacao/biquali.html#tabelas-de-conting√™ncia",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "2 Tabelas de conting√™ncia",
    "text": "2 Tabelas de conting√™ncia\nTabelas de contig√™ncia s√£o organizadas para verificarmos a associa√ß√£o entre duas vari√°veis qualitativas. S√£o conhecidas tamb√©m como tabelas de dupla entrada. Nas colunas est√£o os n√≠veis da vari√°vel \\(X\\) e nas linhas os n√≠veis da vari√°vel \\(Y\\).\nPara nosso exemplo, podemos fazer simplesmente:\n\ntcont = table(mun$Opiniao, mun$Moradia)\ntcont\n\n         \n          N√£o-Residente Residente\n  A favor            81        63\n  Contra             36        20\n\n\nTemos:\n\n81 - A favor e N√£o-Residente;\n63 - A favor e Residente;\n36 - Contra e N√£o-Residente;\n20 - Contra e Residente\n\nPodemos ver os totais marginais das linhas:\n\ntcont_linhas = apply(tcont, 1, sum)\ntcont_linhas\n\nA favor  Contra \n    144      56 \n\n\nOu os totais marginais das colunas:\n\ntcont_colunas = apply(tcont, 2, sum)\ntcont_colunas\n\nN√£o-Residente     Residente \n          117            83 \n\n\nQue s√£o justamente os totais que verificamos nas distribui√ß√µes individuais.\nSe quisermos ver as frequ√™ncias relativas marginais podemos fazer:\n\ntrel_linha = prop.table(tcont, 1)\ntrel_linha\n\n         \n          N√£o-Residente Residente\n  A favor     0.5625000 0.4375000\n  Contra      0.6428571 0.3571429\n\n\nNeste caso estamos vendo as frequ√™ncias relativas das linhas, isto √©, cada linha nesta tabela soma \\(1\\). O que vemos nesta tabela √© que:\n\ndos \\(144\\) entrevistados que s√£o A favor, cerca de \\(56.25\\%\\) s√£o N√£o-Residente, enquanto os demais \\(43.75\\%\\) s√£o Residente\ndos \\(56\\) entrevistados que s√£o Contra, cerca de \\(64.29\\%\\) s√£o N√£o-Residente, enquanto os demais \\(35.71\\%\\) s√£o Residente\n\nPodemos fazer exatamente o mesmo olhando para as frequ√™ncias marginais por colunas:\n\ntrel_coluna = prop.table(tcont, 2)\ntrel_coluna\n\n         \n          N√£o-Residente Residente\n  A favor     0.6923077 0.7590361\n  Contra      0.3076923 0.2409639\n\n\nNeste caso s√£o as colunas que somam \\(1\\), portanto:\n\ndos \\(117\\) entrevistados que s√£o N√£o-Residente, cerca de \\(69.23\\%\\) s√£o A favor, enquanto os demais \\(30.77\\%\\) s√£o Contra\ndos \\(83\\) entrevistados que s√£o Residente, cerca de \\(75.9\\%\\) s√£o A favor, enquanto os demais \\(75.9\\%\\) s√£o Contra\n\nPodemos finalmente ver a frequ√™ncia relativa conjunta:\n\ntrel_conjunta = prop.table(tcont)\ntrel_conjunta\n\n         \n          N√£o-Residente Residente\n  A favor         0.405     0.315\n  Contra          0.180     0.100\n\n\nEm que o somat√≥rio das linhas √© igual a:\n\ntcont_linhas / sum(tcont_linhas)\n\nA favor  Contra \n   0.72    0.28 \n\n\nindicando os valores relativos das opini√µes A Favor e Contra.\nO somat√≥rio das colunas √© igual a:\n\ntcont_colunas / sum(tcont_colunas)\n\nN√£o-Residente     Residente \n        0.585         0.415 \n\n\nindicando os valores relativos de N√£o-Residentes e Residentes.\nNa tabela de frequ√™ncia relativa conjunta, o somat√≥rio total da tabela deve ser igual a \\(1\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#o-gr√°fico-de-barras-para-duas-vari√°veis-qualitativas",
    "href": "content/medidas-associacao/biquali.html#o-gr√°fico-de-barras-para-duas-vari√°veis-qualitativas",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "3 O gr√°fico de barras para duas vari√°veis qualitativas",
    "text": "3 O gr√°fico de barras para duas vari√°veis qualitativas\nExistem v√°rias formas de gerar um gr√°fico de barras combinando as duas vari√°veis. Se quisermos utilizar a pr√≥pria tabela de conting√™ncia obtida a partir do comando table(mun$Opiniao, mun$Moradia), podemos utilizar o comando barplot(). Por outro lado, se quisermos utilizar a tabela original de dados (objeto mun) podemos fazer uso do pacote ggplot2:\n\n\nC√≥digo\nplt_bar1 = ggplot(mun) +\n  aes(x = Moradia, fill = Opiniao) +\n  geom_bar(color = 'white', position = 'dodge') +\n  scale_fill_manual(values = c('Contra' = 'darkred',\n                               'A favor' = 'darkblue')) +\n  coord_cartesian(ylim = c(0, 80)) +\n  labs(y = 'N√∫mero de respostas') +\n  theme_classic(base_size = 15)\n\nplt_bar1\n\n\n\n\n\n\n\n\nFigura¬†2: Respostas dos mun√≠cipies entrevistados combinando local de moradia e opini√£o.\n\n\n\n\n\nVeja que nesta figura, existem mais opini√µes A favor, independente do entrevistado ser ou n√£o residente da regi√£o central. Este padr√£o √© o mesmo que observamos no gr√°fico da vari√°vel Opini√£o isoladamente, o que sugere n√£o haver associa√ß√£o entre as vari√°veis Opini√£o e Moradia. Ao que parece, a opini√£o de um entrevistado sobre a constru√ß√£o da obra n√£o depende de seu local de moradia.\n\n\n\n\n\n\nExemplos de associa√ß√µes entre duas vari√°veis\n\n\n\nAbaixo s√£o apresentadas quatro situa√ß√µes em que existe associa√ß√£o Opini√£o e Moradia.\n\n\n\n\n\n\n\n\n\n\n\nEm todos estes exemplos, note que a rela√ß√£o as opini√µes A favor ou Contra dependem se o entrevistado √© ou n√£o Residente na regi√£o. Esses padr√µes configuram diferentes tipos de associa√ß√£o entre as vari√°veis Opini√£o e Moradia, a saber:\n\nFigura A: N√£o-Residentes tendem a ser A favor e Residentes s√£o em sua maioria Contra;\nFigura B: todos tendem a ser Contra, mas a diferen√ßa de opini√µes √© maior entre os Residentes;\nFigura C: N√£o-Residentes tendem a ser Contra, enquanto n√£o parece haver diferen√ßas entre os Residentes;\nFigura D: Residentes tendem a ser A favor, enquanto n√£o parece haver diferen√ßas entre os Residentes;"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#medindo-a-discrep√¢ncia-com-o-√≠ndice-de-chi2-de-pearson",
    "href": "content/medidas-associacao/biquali.html#medindo-a-discrep√¢ncia-com-o-√≠ndice-de-chi2-de-pearson",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "4 Medindo a discrep√¢ncia com o √≠ndice de \\(\\chi^2\\) de Pearson",
    "text": "4 Medindo a discrep√¢ncia com o √≠ndice de \\(\\chi^2\\) de Pearson\nO √≠ndice de qui-quadrado (\\(\\chi^2\\)) mede a discrep√¢ncia entre os valores observados e os valores esperados em uma tabela de conting√™ncia.\nDigamos que um munic√≠pio tenha \\(20\\%\\) de sua popula√ß√£o morando em √°rea Rural e os outros \\(80\\%\\) em √°rea Urbana. Se fizermos uma amostragem ao acaso dos moradores √© esperado que esta frequ√™ncia relativa se reflita na amostra. Neste caso se sorteamos \\(200\\) pessoas, seria esperado:\n\nZona Rural: \\(40\\) moradores\nZona Urbana \\(160\\) moradores\n\nEntretando, se fazemos um sorteio ao acaso, haver√° alguma varia√ß√£o ao redor destes valores, de modo que as frequ√™ncias observadas (\\(o\\)) dever√£o ser diferentes das esperadas (\\(e\\)). O \\(\\chi^2\\) mede a discrep√¢ncia entre \\(o\\) e \\(e\\) para cada c√©lula de uma tabela de contig√™ncia como:\n\\[\\chi^2 = \\sum_{i=1}^{n}\\frac{(o_i - e_i)^2}{e_i}\\] Para uma tabela de frequ√™ncias, devemos determinar portanto os valores de \\(o_i\\) e \\(e_i\\).\nSuponha que uma amostra de \\(200\\) moradores tenha resultado em:\n\n\nC√≥digo\nset.seed(10)\nnor = sum(rbinom(n = n, size = 1, prob = pr))\nMoradia_obs = data.frame(Regiao = c(rep('Rural', nor),\n                           rep('Urbana', n - nor)))\n\ntb_dfo = table(Moradia_obs)\ntb_dfo\n\n\nRegiao\n Rural Urbana \n    31    169 \n\n\nAs frequ√™ncias observadas e esperadas ser√£o:\n\nZona Rural:\n\n\\(o_{Rural} = 31\\)\n\\(e_{Rural} = 0.2 \\times 200 = 40\\)\n\nZona Urbana\n\n\\(o_{Urbana} = 169\\)\n\\(e_{Urbana} = 0.8 \\times 200 = 160\\)\nDe modo que o valor de \\(\\chi^2\\) ser√°:\n\\(\\chi^2 = \\frac{(31 - 40)^2}{40} + \\frac{(169 - 160)^2}{160} = \\frac{(-9)^2}{40} + \\frac{(9)^2}{160} = 2.025 + 0.50625 = 2.53125\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#o-√≠ndice-de-chi2-em-uma-tabela-de-contig√™ncia",
    "href": "content/medidas-associacao/biquali.html#o-√≠ndice-de-chi2-em-uma-tabela-de-contig√™ncia",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "5 O √≠ndice de \\(\\chi^2\\) em uma tabela de contig√™ncia",
    "text": "5 O √≠ndice de \\(\\chi^2\\) em uma tabela de contig√™ncia\nNo exemplo acima, as contagens esperadas foram definidas a partir de um modelo que dizia que as popula√ß√µes rurais e urbanas se dividiam nas propor√ß√µes \\(20\\%:80\\%\\). Em uma tabela de contig√™ncia, a hip√≥tese em verifica√ß√£o √© a de que n√£o h√° associa√ß√£o entre \\(X\\) e \\(Y\\). Se for assim, √© esperado que as frequ√™ncias conjuntas sejam porporcionais √†s frequ√™ncias marginais. Vamos apresentar esta ideia utilizando uma nota√ß√£o geral para tabelas de conting√™ncia e, em seguida, discutir com um exemplo.\nA tabela Tabela¬†2 apresenta \\(r\\) linhas por \\(s\\) colunas com as contagens de todas as combina√ß√µes dos n√≠veis da vari√°vel \\(X\\) (N√≠veis \\(A_{1}\\) a \\(A_{r}\\)) e da vari√°vel \\(Y\\) (N√≠veis \\(B_{1}\\) a \\(B_{s}\\)). Os totais marginais de \\(X\\) e \\(Y\\) s√£o expressos respectivamente na √∫ltima coluna e na √∫ltima linha.\n\n\n\nTabela¬†2: Representa√ß√£o de uma tabela de contig√™ncia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX ‚üç Y\n\\(B_{1}\\)\n\\(B_{2}\\)\n\\(\\cdots\\)\n\\(B_{j}\\)\n\\(\\cdots\\)\n\\(B_{s}\\)\nTotais em \\(X\\)\n\n\n\n\n\\(A_{1}\\)\n\\(n_{11}\\)\n\\(n_{12}\\)\n\\(\\cdots\\)\n\\(n_{1j}\\)\n\\(\\cdots\\)\n\\(n_{1s}\\)\n\\(n_{1.}\\)\n\n\n\\(A_{2}\\)\n\\(n_{21}\\)\n\\(n_{22}\\)\n\\(\\cdots\\)\n\\(n_{2j}\\)\n\\(\\cdots\\)\n\\(n_{2s}\\)\n\\(n_{2.}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(A_{i}\\)\n\\(n_{i1}\\)\n\\(n_{i2}\\)\n\\(\\cdots\\)\n\\(n_{ij}\\)\n\\(\\cdots\\)\n\\(n_{is}\\)\n\\(n_{i.}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\cdots\\)\n\\(\\cdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(A_{r}\\)\n\\(n_{r1}\\)\n\\(n_{r2}\\)\n\\(\\cdots\\)\n\\(n_{rj}\\)\n\\(\\cdots\\)\n\\(n_{rs}\\)\n\\(n_{r.}\\)\n\n\nTotais em \\(Y\\)\n\\(n_{.1}\\)\n\\(n_{.2}\\)\n\\(\\cdots\\)\n\\(n_{.j}\\)\n\\(\\cdots\\)\n\\(n_{rs}\\)\n\\(n\\)\n\n\n\n\n\n\nSob a hip√≥tese de n√£o-associa√ß√£o entre \\(X\\) e \\(Y\\) teremos que:\n\\(\\frac{n_{i1}}{n_{.1}} = \\frac{n_{i2}}{n_{.2}} = \\cdots = \\frac{n_{is}}{n_{.s}} = \\frac{n_{i.}}{n}\\)\ne assim:\n\\(\\frac{n_{ij}}{n_{.j}} = \\frac{n_{i.}}{n}\\)\nDeste modo:\n\\(n_{ij}^{e} = \\frac{n_{i.} \\times n_{.j}}{n}\\)\n\n\n\n\n\n\nObserva√ß√µes\n\n\n\nA nota√ß√£o \\(n_{ij}^{e}\\) est√° sendo utilizada para denotar que a express√£o acima determina a contagem de cada c√©lula da tabela sob a hip√≥tese de n√£o associa√ß√£o e portanto, se refere ao valor esperado de \\(n_{ij}\\).\n\n\nTendo definido os valores esperados em uma tabela de conting√™ncia de \\(r \\times s\\), o \\(\\chi^2\\) √© dado por:\n\\[\\chi^2 = \\sum_{i=1}^{r}\\sum_{j=1}^{s}\\frac{(n_{ij} - n_{ij}^{e})^2}{n_{ij}^{e}}\\]\nRetornando ao exemplo das entrevistas\nA tabela de conting√™ncia contendo os dados observados do in√≠cio do cap√≠tulo pode ser escrita como:\n\n\n\nTabela¬†3: Resultados das entrevistas dos 200 mun√≠cipies.\n\n\n\n\n\n\n\n\n\n\n\n\nN√£o-Residente\nResidente\nTotal Opini√£o\n\n\n\n\nA favor\n81\n63\n144\n\n\nContra\n36\n20\n56\n\n\nTotal Moradia\n117\n83\n200\n\n\n\n\n\n\nOs Valores esperados na linha \\(i\\) e coluna \\(j\\) s√£o:\n\nLinha \\(1\\) - Coluna \\(1\\) (N√£o-Residente - A favor):\n\n\\(n_{ii}^{e} = \\frac{n_{1.} \\times n_{.1}}{n} =  \\frac{144 \\times 117}{200} = 84.24\\)\n\nLinha \\(1\\) - Coluna \\(2\\) (Residente - A favor):\n\n\\(n_{ii}^{e} = \\frac{n_{1.} \\times n_{.2}}{n} =  \\frac{144 \\times 83}{200} = 59.76\\)\n\nLinha \\(2\\) - Coluna \\(1\\) (N√£o-Residente - Contra):\n\n\\(n_{ii}^{e} = \\frac{n_{2.} \\times n_{.1}}{n} =  \\frac{56 \\times 117}{200} = 32.76\\)\n\nLinha \\(2\\) - Coluna \\(2\\) (Residente - Contra):\n\n\\(n_{ii}^{e} = \\frac{n_{2.} \\times n_{.2}}{n} =  \\frac{56 \\times 83}{200} = 23.24\\)\nDe modo que a tabela com os valores esperados ser√°:\n\n\n\nTabela¬†4: Valores esperados na hip√≥tese de n√£o-associa√ß√£o entre Opiniao e locals de Moradia dos 200 mun√≠cipies entrevistados.\n\n\n\n\n\n\n\n\n\n\n\n\nN√£o-Residente\nResidente\nTotal Opini√£o\n\n\n\n\nA favor\n84.24\n59.76\n144\n\n\nContra\n32.76\n23.24\n56\n\n\nTotal Moradia\n117\n83\n200\n\n\n\n\n\n\nFinalmente, o valor de \\(\\chi^2\\) pode ser calculado por:\n\\(\\chi^2 = \\frac{(81 - 84.24)^2}{84.24} + \\frac{(36 - 32.76)^2}{84.24} + \\frac{(63 - 59.76)^2}{84.24} + \\frac{(20 - 23.24)^2}{84.24} = 1.072\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#valores-de-chi2-quando-existe-associa√ß√£o",
    "href": "content/medidas-associacao/biquali.html#valores-de-chi2-quando-existe-associa√ß√£o",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "6 Valores de \\(\\chi^2\\) quando existe associa√ß√£o",
    "text": "6 Valores de \\(\\chi^2\\) quando existe associa√ß√£o\nO valor de \\(\\chi^2\\) ser√° zero somente se os valores observados forem exatamente iguais aos valores esperados. Pequenas discrep√¢ncias ir√£o gerar valores de \\(\\chi^2\\) acima de zero, que se tornar√£o mais altos √† medida que aumentam as diferen√ßas entre \\(n_{ij}\\) e \\(n_{ij}^e\\).\n\n\n\n\n\n\nQuantificando as associa√ß√µes\n\n\n\nAbaixo est√£o diferentes exemplos em que existe associa√ß√£o entre Opini√£o e Moradia. Compare os valores e os gr√°ficos abaixo aos que fizemos no exemplo do cap√≠tulo e veja que todos os valores de \\(\\chi^2\\) s√£o mais elevados.\n\n\n\n\n\n\n\n\n\n\n\nTente aplicar a f√≥rmula do \\(\\chi^2\\) para chegar aos resultados apresentados em cada exemplo."
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#varia√ß√µes-do-√≠ndice-de-chi2",
    "href": "content/medidas-associacao/biquali.html#varia√ß√µes-do-√≠ndice-de-chi2",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "7 Varia√ß√µes do √≠ndice de \\(\\chi^2\\)",
    "text": "7 Varia√ß√µes do √≠ndice de \\(\\chi^2\\)\nO valor de \\(\\chi^2\\) aumenta com o tamanho da amostra, o que torna dif√≠cil compara√ß√µes entre diferentes estudos. Para corrigir este efeito existe o coeficiente de contig√™ncia de Pearson (\\(C\\)) que √© baseado no resultado de \\(\\chi^2\\)\n\\[C = \\sqrt{\\frac{\\chi^2}{\\chi^2 + n}}\\]\nem que \\(n\\) √© o tamanho da amostra.\nO valor m√°ximo de \\(C\\) depende do n√∫mero de linhas (\\(r\\)) e de colunas (\\(s\\)) na tabela de conting√™cia. Podemos definir um coeficiente que esteja limitado entre \\(0\\) e \\(1\\):\n\\[T = \\sqrt{\\frac{\\frac{\\chi^2}{n}}{(r-1) \\times (s-1)}}\\] O valor \\(T = 0\\) ocorre quando n√£o h√° associa√ß√£o (\\(\\chi^2 = 0\\)) e o valor m√°ximo de \\(T = 1\\) s√≥ ser√° atingido se houver associa√ß√£o e \\(r = s\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquali.html#obtendo-o-√≠ndice-de-chi2-de-uma-tabela-de-dados",
    "href": "content/medidas-associacao/biquali.html#obtendo-o-√≠ndice-de-chi2-de-uma-tabela-de-dados",
    "title": "Associa√ß√£o entre duas vari√°veis qualitativas",
    "section": "8 Obtendo o √≠ndice de \\(\\chi^2\\) de uma tabela de dados",
    "text": "8 Obtendo o √≠ndice de \\(\\chi^2\\) de uma tabela de dados\nA fun√ß√£o para o c√°lculo do \\(\\chi^2\\) no R √© chisq.test e pode ser utilizada a partir da tabela de contig√™ncia gerada pela fun√ß√£o table:\n\ntcont = table(mun$Opiniao, mun$Moradia)\nchisq.test(tcont)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tcont\nX-squared = 0.76697, df = 1, p-value = 0.3812\n\n\nO resultado mostra o o valor de \\(\\chi^2\\) calculado (X-squared) e outras duas quantias denominadas de graus de liberdade (df) e valor de p (p-value), t√≥picos abordados em infer√™ncia estat√≠stica.\nNote que o resultado √© diferente do que obtivemos neste cap√≠tulo. Isto ocorre pois, por padr√£o, a fun√ß√£o utiliza a corre√ß√£o de Yates, em que \\(\\chi_{Yates}^{2}\\) √© calculado por:\n\\[\\chi_{Yates}^{2} = \\sum_{i=1}^{r}\\sum_{j=1}^{s}\\frac{(|n_{ij} - n_{ij}^{e}| - 0,5)^2}{n_{ij}^{e}}\\]\nO termo \\(|n_{ij} - n_{ij}^{e}|\\) se refere ao m√≥dulo da dist√¢ncia entre os valores observados e calculados.\nSe quisermos obter exatamente os resultados descritos no exemplo deste cap√≠tulo, basta fazermos:\n\nchisq.test(tcont, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  tcont\nX-squared = 1.0724, df = 1, p-value = 0.3004"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html",
    "href": "content/medidas-associacao/biquanti.html",
    "title": "Associa√ß√£o entre duas vari√°veis quantitativas",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas no cap√≠tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(mvtnorm)\nIremos medir o grau de associa√ß√£o entre duas vari√°veis quantitativas \\(X\\) e \\(Y\\) por meio dos coeficientes de covari√¢ncia e correla√ß√£o linear. N√£o estamos interessados em verificar se \\(Y\\) depende funcionalmente de \\(X\\) ou vice-versa. Estamos interessados somente em medir a intensidade de associa√ß√£o linear entre as duas vari√°veis. Ao calcularmos a covari√¢ncia entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)), por exemplo, poder√≠amos inverter a ordem fazendo \\(s_{XY}\\) e ter√≠amos exatamente os mesmo resultados. O mesmo vale para o coeficiente de correla√ß√£o (\\(r_{YX} = r_{XY}\\)). Dizemos que existe uma simetria ao calcular estes coeficientes.\nEstamos interessados em diferenciar tr√™s situa√ß√µes que podem ser visualizadas nos gr√°ficos de dispers√£o abaixo:"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#covari√¢ncia-entre-y-e-x",
    "href": "content/medidas-associacao/biquanti.html#covari√¢ncia-entre-y-e-x",
    "title": "Associa√ß√£o entre duas vari√°veis quantitativas",
    "section": "1 Covari√¢ncia entre \\(Y\\) e \\(X\\)",
    "text": "1 Covari√¢ncia entre \\(Y\\) e \\(X\\)\nA vari√¢ncia amostral de \\(Y\\) pode ser obtida subtraindo cada observa√ß√£o em \\(Y\\) de sua m√©dia (\\(\\overline{Y}\\)) e elevando esta subtra√ß√£o ao quadrado \\((Y_i - \\overline{Y})^2\\). Ao somar para todos os valores de \\(Y_i\\) teremos o somat√≥rio dos quadrados de \\(Y\\) (\\(SQ_Y\\)).\n\\[SQ_Y = \\sum_{i-1}^{n} (Y_i - \\overline{Y})^2 = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (Y_i - \\overline{Y})\\]\nDividindo \\(SQ_Y\\) por \\(n-1\\) teremos a vari√¢ncia amostral de \\(Y\\) (\\(s^2_Y\\)).\n\\[s^2_Y = \\frac{\\sum_{i-1}^{n} (Y_i - \\overline{Y})^2}{n-1}\\]\nA vari√¢ncia amostral √© representada por \\(s^2\\). Aqui vamos usar a nota√ß√£o (\\(s^2_Y\\)), pois haver√° outros estimadores de vari√¢ncia envolvidos, de modo que deveremos ser mais claros a respeito de qual estimador estaremos nos referindo.\nAdotando o mesmo procedimento para \\(X\\), podemos calcular o somat√≥rio dos quadrados de \\(X\\) (\\(SQ_X\\)).\n\\[SQ_X = \\sum_{i-1}^{n} (X_i - \\overline{X})^2 = \\sum_{i-1}^{n}(X_i - \\overline{X}) (X_i - \\overline{X})\\]\ne a vari√¢ncia amostral de \\(X\\) (\\(s^2_X\\)).\n\\[s^2_X = \\frac{\\sum_{i-1}^{n} (X_i - \\overline{X})^2}{n-1}\\]\nCombinando as duas ideias, teremos o produto cruzado de \\(Y\\) e \\(X\\) (\\(SQ_{YX}\\))\n\\[SQ_{YX} = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})\\]\ne finalmente a covari√¢ncia amostral entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)).\n\n\n\n\n\n\nCovari√¢ncia amostral\n\n\n\n\\[s_{YX} = \\frac{\\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})}{n-1}\\]"
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#coeficiente-de-correla√ß√£o-linear-de-pearson-r",
    "href": "content/medidas-associacao/biquanti.html#coeficiente-de-correla√ß√£o-linear-de-pearson-r",
    "title": "Associa√ß√£o entre duas vari√°veis quantitativas",
    "section": "2 Coeficiente de correla√ß√£o linear de Pearson \\(r\\)",
    "text": "2 Coeficiente de correla√ß√£o linear de Pearson \\(r\\)\nAssim como a covari√¢ncia, o coeficiente de correla√ß√£o de Pearson (\\(r\\)) mede a intensidade da associa√ß√£o linear entre \\(Y\\) e \\(X\\). A covari√¢ncia entretanto, n√£o tem limite superior ou inferior, pois sua magnitude depende da ordem de grandeza das vari√°veis envolvidas. O coeficiente de correla√ß√£o \\(r\\) √© calculado como a covari√¢ncia entre \\(Y\\) e \\(X\\) padronizada pelo produto dos desvios padr√µes de \\(Y\\) e de \\(X\\).\n\\[r = \\frac{s_{YX}}{s_Y s_X} = \\frac{\\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{n-1}} {\\sqrt{\\frac{\\sum{(Y_i - \\overline{Y})^2}}{n-1}}  \\times \\sqrt{\\frac{\\sum{(X_i - \\overline{X})^2}}{n-1}}}\\]\n\n\n\n\n\n\nCoeficiente de correla√ß√£o\n\n\n\n\\[r = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sqrt{\\sum{(Y_i - \\overline{Y})^2 \\sum{(X_i - \\overline{X})^2}}}}\\]\n\n\nEsta padroniza√ß√£o garante que \\(r\\) pode variar entre \\(-1\\) (correla√ß√£o perfeitamente linear e negativa) e \\(+1\\) (correla√ß√£o perfeitamente linear e positiva), se aproximando de zero quando n√£o existe correla√ß√£o."
  },
  {
    "objectID": "content/medidas-associacao/biquanti.html#exemplo",
    "href": "content/medidas-associacao/biquanti.html#exemplo",
    "title": "Associa√ß√£o entre duas vari√°veis quantitativas",
    "section": "3 Exemplo",
    "text": "3 Exemplo\nA Tabela¬†1 apresenta dados da pesca do camar√£o tigre e do camar√£o rei entre nos anos de 1976 a 1987 (Haddon 2010). O camar√£o tigre constitui a esp√©cie alvo da pesca, enquanto o camar√£o rei aparece como uma esp√©cie acidental.\nImporte a base de dados ctigre_haddon.csv\n\ntigre = read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/ctigre_haddon.csv')\nrtk = cor(tigre$Tiger, tigre$King)\nstk = cov(tigre$Tiger, tigre$King)\n\n\n\n\n\nTabela¬†1: Captura do camar√£o tigre e do camar√£o rei (ton) entre 1976 e 1987.\n\n\n\n\n\n\n\n\n\nAno\nCamar√£o tigre\nCamar√£o rei\n\n\n\n\n1976\n566\n10\n\n\n1977\n1437\n22\n\n\n1978\n1646\n42\n\n\n1979\n2056\n33\n\n\n1980\n3171\n64\n\n\n1981\n2743\n34\n\n\n1982\n2838\n59\n\n\n1983\n4434\n146\n\n\n1984\n4149\n78\n\n\n1985\n3480\n75\n\n\n1986\n2375\n81\n\n\n1987\n3355\n52\n\n\n\n\n\n\n\n\n\n\nNas figuras abaixo temos as abund√¢ncias das esp√©cies ao longo dos anos e o gr√°fico de dispers√£o.\n\n\nC√≥digo\nc1 = ggplot(tigre, aes(x = Year)) +\n  geom_line(aes(y = Tiger), color = 'red') +\n  geom_point(aes(y = Tiger), color = 'red', \n             shape = 19, size = 4) +\n  geom_line(aes(y = King), color = 'blue') +\n  geom_point(aes(y = King), color = 'blue', \n             shape = 19, size = 4) +\n  geom_segment(x = 1976, xend = 1976.3, \n               y = 4000, yend = 4000, \n               color = 'red') +\n  geom_segment(x = 1976, xend = 1976.3, \n               y = 3700, yend = 3700, \n               color = 'blue') +\n  geom_text(x = 1976.4, y = 4000, \n            label = 'Camar√£o tigre', hjust = 0) +\n  geom_text(x = 1976.4, y = 3700, \n            label = 'Camar√£o rei', hjust = 0) +\n  scale_x_continuous(breaks = tigre$Year) +\n  labs(title = 'A', \n       y = 'Abund√¢ncia (Ton)') +\n  theme_classic(base_size = 12)\n\nc2 = ggplot(tigre, aes(y = King, x = Tiger)) +\n  geom_point(shape = 19, size = 4) +\n  scale_y_continuous(breaks = seq(0, 150, by = 20)) +\n  scale_x_continuous(breaks = seq(500, 5000, by = 500)) +\n  labs(title = 'B',\n       x = 'Camar√£o tigre (Ton)', \n       y = 'Camar√£o rei  (Ton)') +\n  theme_classic(base_size = 12)\n\nc1 | c2\n\n\n\n\n\n\n\n\nFigura¬†1: A - Captura do camar√£o tigre e do camar√£o-rei (ton) entre 1976 e 1987. B - Associa√ß√£o positiva nas capturas anuais entre 1976 e 1987.\n\n\n\n\n\nA captura em toneladas do camar√£o tigre √© sempre mais elevada. Entretanto, a figura da direita sugere haver uma associa√ß√£o linear entre as capturas. Nos anos em que houve maiores capturas do camar√£o tigre parece ter havido tamb√©m um aumento nas capturas do camar√£o rei. Dizemos as capturas covariam positivamente. Portanto existe uma correla√ß√£o positiva entre a captura das duas esp√©cies.\nEm nenhum momento estamos dizendo que a captura de uma esp√©cie resulta no aumento na captura da outra. Muito provavelmente, as abund√¢ncias das duas esp√©cies est√£o relacionadas a um terceiro fator que gera um comportamento similar na varia√ß√£o das capturas ano a ano. Estamos interessados em mensurar o grau de associa√ß√£o seja pela covari√¢ncia ou pelo coeficiente de correla√ß√£o de Pearson.\na covari√¢ncia entre as abund√¢ncias dos camar√µes tigre e rei √© positiva (\\(s_{tigre-rei} = 3.3293\\times 10^{4}\\)) e consequentemente a correla√ß√£o de Pearson tamb√©m √© positiva (\\(r = 0.82\\)). Confira os c√°lculos utilizando as express√µes apresentadas no cap√≠tulo.\nNo R, a covari√¢ncia entre \\(Y\\) e \\(X\\) pode ser obtida pela fun√ß√£o cov:\n\ncov(tigre$Tiger, tigre$King)\n\n[1] 33293\n\n\nE a correla√ß√£o pela fun√ß√£o cor:\n\ncor(tigre$Tiger, tigre$King)\n\n[1] 0.8196913"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html",
    "href": "content/intro-bayes/intro-bayes-counting.html",
    "title": "Contando possibilidades",
    "section": "",
    "text": "A infer√™ncia bayesiana, em ess√™ncia, √© uma forma de contar e comparar as diferentes maneiras pelas quais algo pode acontecer. A seguir, vamos desenvolver os princ√≠pios da infer√™ncia bayesiana de forma simples e intuitiva utilizando o princ√≠pio da contagem.\nImagine que temos uma caixa contendo quatro bolinhas de gude, que podem ser azuis ou brancas. Sabemos que h√° exatamente quatro bolinhas, mas n√£o conhecemos a distribui√ß√£o entre as cores. Com base nessa informa√ß√£o, podemos listar cinco configura√ß√µes poss√≠veis:\nEssas s√£o todas as possibilidades compat√≠veis com o que sabemos sobre o conte√∫do da caixa ‚Äî o conhecimento a priori. Chamamos essas cinco configura√ß√µes de hip√≥teses.\nNosso objetivo ser√° descobrir qual dessas hip√≥teses √© mais plaus√≠vel √† medida que obtivermos evid√™ncias sobre o conte√∫do da caixa."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#um-leque-de-possibilidades",
    "href": "content/intro-bayes/intro-bayes-counting.html#um-leque-de-possibilidades",
    "title": "Contando possibilidades",
    "section": "1 Um leque de possibilidades",
    "text": "1 Um leque de possibilidades\nA caixa possui um orif√≠cio pelo qual podemos ver apenas uma bolinha por vez. Assim, a √∫nica forma de obter evid√™ncias sobre o conte√∫do da caixa ser√° fazer uma observa√ß√£o, misturar as bolinhas, fazer outra observa√ß√£o e assim por diante. Antes de iniciar esse processo, vamos entender como cada observa√ß√£o nos ajuda a alcan√ßar nosso objetivo, avaliando-as √† luz das hip√≥teses sobre o conte√∫do da caixa.\nVamos come√ßar assumindo que seja verdadeira a situa√ß√£o (2) [üîµ‚ö™‚ö™‚ö™]. Nesse caso, ter√≠amos 1 possibilidade de observar a bolinha azul e 3 possibilidades de observar uma bolinha branca (Figura¬†1).\n\n\n\n\n\n\nFigura¬†1: As quatro possibilidades, assumindo que existam tr√™s bolinhas brancas e uma azul. Extra√≠do de McElreath (2018).\n\n\n\n\n\n\n\n\n\nDica √∫til\n\n\n\nObserve que, embora as tr√™s bolinhas brancas pare√ßam iguais do ponto de vista dos dados (pois apenas registramos suas cores), elas s√£o eventos diferentes. Isso √© importante, pois significa que h√° tr√™s maneiras a mais de observar ‚ö™ do que üîµ.\n\n\nObservamos agora uma segunda bolinha. Isso expande nosso leque de possibilidades em mais uma camada (Figura¬†2). Agora existem 16 caminhos poss√≠veis (um para cada par de observa√ß√µes), pois, na segunda observa√ß√£o, cada um dos caminhos anteriores se ramifica em outros quatro caminhos poss√≠veis.\n\n\n\n\n\n\nFigura¬†2: Os 16 caminhos poss√≠veis, assumindo que existam tr√™s bolinhas brancas e uma azul. Extra√≠do de McElreath (2018).\n\n\n\nAo observar uma terceira bolinha da caixa, a terceira camada √© constru√≠da da mesma forma, e agora temos \\(4^3 = 64\\) caminhos poss√≠veis para uma sequ√™ncia de observa√ß√µes de cores em uma caixa com 4 bolinhas (Figura¬†3).\n\n\n\n\n\n\nFigura¬†3: Os 64 caminhos poss√≠veis, assumindo que existam tr√™s bolinhas brancas e uma azul. Extra√≠do de McElreath (2018).\n\n\n\n\n\n\n\n\n\nPressuposto Importante\n\n\n\nAcreditamos que, ao sacudir a caixa, cada bolinha tem a mesma chance de ser observada pelo orif√≠cio, independentemente de qual tenha sa√≠do anteriormente. Por isso, cada caminho do leque √© igualmente prov√°vel de ser observado."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-evid√™ncias",
    "href": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-evid√™ncias",
    "title": "Contando possibilidades",
    "section": "2 Avaliando as evid√™ncias",
    "text": "2 Avaliando as evid√™ncias\n√Ä medida que observamos a cor de uma nova bolinha da caixa, alguns desses caminhos s√£o logicamente eliminados.\nSuponha que a sequ√™ncia de cores observada tenha sido:\n1¬™ bolinha: üîµ\n2¬™ bolinha: ‚ö™\n3¬™ bolinha: üîµ\nAp√≥s a primeira retirada resultar em üîµ, os tr√™s caminhos que levariam √† observa√ß√£o de uma bolinha branca na primeira camada s√£o imediatamente eliminados. Na segunda retirada, obtivemos ‚ö™, de modo que um dos caminhos poss√≠veis na segunda camada foi eliminado, restando os tr√™s caminhos que se ramificam a partir do primeiro caminho azul. Ap√≥s a terceira observa√ß√£o, cada um dos tr√™s caminhos restantes na segunda camada segue somente para a bolinha azul na terceira camada. Assim, assumindo que a caixa contenha [üîµ‚ö™‚ö™‚ö™], existe um total de tr√™s maneiras para a sequ√™ncia [üîµ ‚Üí ‚ö™ ‚Üí üîµ] aparecer. Todas as outras possibilidades foram descartadas √† medida que as evid√™ncias surgiam.\nDos caminhos restantes na Figura¬†4, n√£o podemos ter certeza de qual dos tr√™s caminhos os dados reais seguiram, pois n√£o podemos identificar as bolinhas individualmente, apenas por sua cor. Entretanto, considerando a hip√≥tese de que a caixa contenha [üîµ‚ö™‚ö™‚ö™], podemos afirmar que os dados seguiram um desses tr√™s caminhos, pois s√£o os √∫nicos compat√≠veis tanto com nosso conhecimento pr√©vio (4 bolinhas, azuis ou brancas) quanto com a sequ√™ncia de dados observada ([üîµ ‚Üí ‚ö™ ‚Üí üîµ]).\n\n\n\n\n\n\nFigura¬†4: Ap√≥s eliminar caminhos inconsistentes com a sequ√™ncia observada, apenas 3 dos 64 caminhos permanecem. Extra√≠do de McElreath (2018)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-demais-hip√≥teses",
    "href": "content/intro-bayes/intro-bayes-counting.html#avaliando-as-demais-hip√≥teses",
    "title": "Contando possibilidades",
    "section": "3 Avaliando as demais hip√≥teses",
    "text": "3 Avaliando as demais hip√≥teses\nConsiderando que a caixa contenha [üîµ‚ö™‚ö™‚ö™], verificamos que apenas tr√™s dos 64 caminhos poss√≠veis poderiam gerar a sequ√™ncia [üîµ ‚Üí ‚ö™ ‚Üí üîµ]. Falta agora aplicar a mesma l√≥gica √†s demais hip√≥teses. Por exemplo, considere [‚ö™‚ö™‚ö™‚ö™]. H√° zero maneiras de essa hip√≥tese produzir os dados observados, pois uma √∫nica üîµ j√° √© logicamente incompat√≠vel com ela. A hip√≥tese [üîµüîµüîµüîµ] tamb√©m n√£o pode produzir a sequ√™ncia, pois h√° ao menos uma ‚ö™ observada. Assim, podemos eliminar essas duas hip√≥teses, pois nenhuma delas fornece sequer um √∫nico caminho consistente com os dados.\nPara as hip√≥teses restantes, isto √©, [üîµüîµ‚ö™‚ö™] e [üîµüîµüîµ‚ö™], o leque de possibilidades se abre novamente.\nA Figura¬†5 mostra o leque completo para as tr√™s hip√≥teses compat√≠veis com os dados observados: [üîµ‚ö™‚ö™‚ö™], [üîµüîµ‚ö™‚ö™] e [üîµüîµüîµ‚ö™].\n\n\n\n\n\n\nFigura¬†5: Caminhos de composi√ß√£o poss√≠vel para cada hip√≥tese logicamente compat√≠vel com a sequ√™ncia observada. Extra√≠do de McElreath (2018).\n\n\n\nAgora, contamos todas as maneiras pelas quais cada hip√≥tese poderia produzir os dados observados. Para uma bolinha azul e tr√™s brancas, existem tr√™s maneiras (como j√° contamos). Para duas bolinhas azuis e duas brancas, h√° oito caminhos consistentes com a sequ√™ncia. Para tr√™s bolinhas azuis e uma branca, h√° nove caminhos que sobrevivem √†s observa√ß√µes.\nConsideramos, assim, as cinco hip√≥teses diferentes sobre o conte√∫do da caixa, variando de zero bolinhas üîµ a quatro bolinhas üîµ e, para cada uma dessas hip√≥teses, contamos quantas possibilidades (ou ‚Äúcaminhos‚Äù) poderiam potencialmente produzir a sequ√™ncia observada.\n\n\n\nTabela¬†1: Total de maneiras pelas quais cada hip√≥tese pode gerar a sequ√™ncia [üîµ ‚Üí ‚ö™ ‚Üí üîµ].\n\n\n\n\n\nHip√≥tese\nManeiras de produzir [üîµ ‚Üí ‚ö™ ‚Üí üîµ]\n\n\n\n\n1. [‚ö™‚ö™‚ö™‚ö™]\n\\(0 \\times 4 \\times 0 = 0\\)\n\n\n2. [üîµ‚ö™‚ö™‚ö™]\n\\(1 \\times 3 \\times 1 = 3\\)\n\n\n3. [üîµüîµ‚ö™‚ö™]\n\\(2 \\times 2 \\times 2 = 8\\)\n\n\n4. [üîµüîµüîµ‚ö™]\n\\(3 \\times 1 \\times 3 = 9\\)\n\n\n5. [üîµüîµüîµüîµ]\n\\(4 \\times 0 \\times 4 = 0\\)\n\n\n\n\n\n\nObserve que o n√∫mero de maneiras de produzir os dados, para cada hip√≥tese, pode ser obtido contando as ramifica√ß√µes em cada camada do leque de possibilidades e, em seguida, multiplicando esses valores (Tabela¬†1). Isso √© apenas um recurso computacional. Ele nos diz a mesma coisa que a Figura¬†5, mas sem precisar desenhar todo o diagrama. O fato de multiplicarmos os n√∫meros n√£o altera o sentido de estarmos apenas contando caminhos logicamente poss√≠veis."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-counting.html#atualizando-o-conhecimento",
    "href": "content/intro-bayes/intro-bayes-counting.html#atualizando-o-conhecimento",
    "title": "Contando possibilidades",
    "section": "4 Atualizando o conhecimento",
    "text": "4 Atualizando o conhecimento\nSuponha que o experimento anterior, sumarizado na Tabela¬†1, tenha sido finalizado. Isso nos diz que, por ora, temos evid√™ncias melhores para as hip√≥teses 3 e 4, isto √©, de que a caixa contenha 2 ou 3 bolinhas azuis. Para ajudar a diferenciar essas duas possibilidades ainda mais, resolvemos continuar o experimento e amostrar outra bolinha, o que resultou na observa√ß√£o de uma bolinha azul. Como se trata de um novo experimento, poder√≠amos recome√ßar todo o processo. No entanto, h√° uma forma melhor de aproveitar o conhecimento adquirido a priori ‚Äî para cada hip√≥tese, listamos as maneiras anteriores de produzir as observa√ß√µes (o prior) e multiplicamos pelo n√∫mero de maneiras de produzir a nova evid√™ncia üîµ:\n\n\n\nTabela¬†2: Total de maneiras pelas quais cada hip√≥tese pode gerar a sequ√™ncia completa [üîµ ‚Üí ‚ö™ ‚Üí üîµ ‚Üí üîµ], combinando a contagem anterior com a nova evid√™ncia.\n\n\n\n\n\n\n\n\n\n\n\nHip√≥tese\nContagem anterior (prior)\nManeiras de produzir a nova observa√ß√£o üîµ\nContagem posterior\n\n\n\n\n1. [‚ö™‚ö™‚ö™‚ö™]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n2. [üîµ‚ö™‚ö™‚ö™]\n3\n1\n\\(3 \\times 1 = 3\\)\n\n\n3. [üîµüîµ‚ö™‚ö™]\n8\n2\n\\(8 \\times 2 = 16\\)\n\n\n4. [üîµüîµüîµ‚ö™]\n9\n3\n\\(9 \\times 3 = 27\\)\n\n\n5. [üîµüîµüîµüîµ]\n0\n4\n\\(0 \\times 4 = 0\\)\n\n\n\n\n\n\nA nova contagem na coluna da direita da Tabela¬†2 resume as evid√™ncias a favor de cada hip√≥tese, de modo que sejam compat√≠veis tanto com as observa√ß√µes anteriores quanto com a nova observa√ß√£o. Portanto, √† medida que novos dados chegam e, desde que sejam independentes dos anteriores, o total de caminhos logicamente poss√≠veis para explicar tanto as observa√ß√µes antigas quanto as novas pode ser calculado pela multiplica√ß√£o das contagens anteriores pelas novas.\nEm outras palavras, sempre que temos \\(W_\\text{prior}\\) maneiras de uma hip√≥tese produzir observa√ß√µes anteriores (\\(D_\\text{prior}\\)) e, em seguida, obtemos novas observa√ß√µes (\\(D_\\text{novo}\\)) que essa mesma hip√≥tese pode produzir de \\(W_\\text{novo}\\) maneiras, a quantidade total de formas poss√≠veis para essa hip√≥tese explicar tanto os dados antigos quanto os novos √© dada simplesmente por \\(W_\\text{prior} \\times W_\\text{novo}\\). Por exemplo, na Tabela¬†2, a hip√≥tese [üîµüîµ‚ö™‚ö™] apresenta \\(W_\\text{prior} = 8\\) maneiras de gerar as observa√ß√µes anteriores [üîµ ‚Üí ‚ö™ ‚Üí üîµ] e \\(W_\\text{novo} = 2\\) maneiras de gerar a nova observa√ß√£o [üîµ]. Logo, \\(8 \\times 2 = 16\\) caminhos poss√≠veis para explicar tanto os dados antigos quanto os novos.\n\n\n\n\n\n\nCombinando evid√™ncias\n\n\n\nNo exemplo acima, os dados antigos e os novos s√£o do mesmo tipo (bolinhas observadas na caixa). Entretanto, n√£o h√° motivo para excluir a situa√ß√£o em que os dados antigos e os novos tenham sido obtidos de forma diferente. Suponha, por exemplo, que algu√©m da f√°brica de bolinhas informe que as azuis s√£o raras. Para cada caixa contendo [üîµüîµüîµ‚ö™], a f√°brica produz duas caixas contendo [üîµüîµ‚ö™‚ö™] e tr√™s caixas contendo [üîµ‚ö™‚ö™‚ö™]. Tamb√©m garante que cada caixa contenha pelo menos uma bolinha azul e uma bolinha branca. Com essa nova informa√ß√£o, podemos atualizar nossas contagens novamente (Tabela¬†3).\n\n\n\nTabela¬†3: Contagens atualizadas ap√≥s incorporar a nova observa√ß√£o üîµ e as informa√ß√µes externas sobre a frequ√™ncia das hip√≥teses.\n\n\n\n\n\n\n\n\n\n\n\nHip√≥tese\nContagem anterior (prior)\nManeiras de produzir üîµ informadas pela f√°brica\nNova contagem\n\n\n\n\n1. [‚ö™‚ö™‚ö™‚ö™]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n2. [üîµ‚ö™‚ö™‚ö™]\n3\n3\n\\(3 \\times 3 = 9\\)\n\n\n3. [üîµüîµ‚ö™‚ö™]\n16\n2\n\\(16 \\times 2 = 32\\)\n\n\n4. [üîµüîµüîµ‚ö™]\n27\n1\n\\(27 \\times 1 = 27\\)\n\n\n5. [üîµüîµüîµüîµ]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n\n\n\n\nAgora, √† luz dessa informa√ß√£o adicional, a hip√≥tese [üîµüîµ‚ö™‚ö™] torna-se ligeiramente mais plaus√≠vel do que [üîµüîµüîµ‚ö™]."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html",
    "title": "Infer√™ncia Bayesiana Binomial com PyMC",
    "section": "",
    "text": "O PyMC √© uma biblioteca de programa√ß√£o probabil√≠stica em Python que facilita a constru√ß√£o de modelos bayesianos, utilizando m√©todos como a amostragem MCMC (Markov Chain Monte Carlo) para estimar distribui√ß√µes a posteriori de forma eficiente.\nPara modelar uma vari√°vel aleat√≥ria com distribui√ß√£o Binomial, podemos especificar uma distribui√ß√£o a priori do tipo Beta para o par√¢metro \\(p\\), observar os dados (n√∫mero de sucessos em \\(N\\) ensaios) e, ent√£o, obter a distribui√ß√£o a posteriori utilizando t√©cnicas de amostragem fornecidas pelo PyMC."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#estimativa-bayesiana-com-pymc",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#estimativa-bayesiana-com-pymc",
    "title": "Infer√™ncia Bayesiana Binomial com PyMC",
    "section": "1 Estimativa Bayesiana com PyMC",
    "text": "1 Estimativa Bayesiana com PyMC\n\nDefinir os dados\n\n\\(N\\): n√∫mero total de observa√ß√µes (ensaios Bernoulli).\n\n\\(k\\): n√∫mero de sucessos observados.\n\nDefinir o modelo probabil√≠stico\n\nEspecifique uma distribui√ß√£o a priori para o par√¢metro \\(p\\), como uma Beta(\\(\\alpha\\), \\(\\beta\\)).\n\nModele os dados observados usando uma distribui√ß√£o Binomial(\\(N\\), \\(p\\)):\nwith pm.Model() as modelo:\n    p = pm.Beta(\"p\", alpha=Œ±_prior, beta=Œ≤_prior)\n    y = pm.Binomial(\"y\", n=N, p=p, observed=k)\n\nExecutar a amostragem MCMC\n\nUse o m√©todo pm.sample() para gerar amostras da distribui√ß√£o a posteriori.\n\nO PyMC utiliza, por padr√£o, o algoritmo NUTS (No-U-Turn Sampler), baseado em Hamiltonian Monte Carlo.\ntrace = pm.sample()\n\nInspecionar os resultados da amostragem\n\nUse az.summary(trace) para obter estat√≠sticas descritivas: m√©dia, desvio padr√£o, intervalos de credibilidade, \\(\\hat{R}\\) (diagn√≥stico de converg√™ncia), entre outros.\n\nVisualize as cadeias com az.plot_trace(trace), que mostra as s√©ries temporais e histogramas das amostras.\n\nVisualize a distribui√ß√£o a posteriori com az.plot_posterior(trace, var_names=[\"p\"]).\n\nCalcular probabilidades e intervalos de credibilidade\n\nUse as amostras da posteriori para calcular quantidades como \\(P(x_1 \\leq p \\leq x_2)\\), filtrando os valores de p entre esses limites e estimando a propor√ß√£o.\n\nExemplo:\namostras_p = trace.posterior[\"p\"].values.flatten()\nprob = ((amostras_p &gt;= x1) & (amostras_p &lt;= x2)).mean()\n\nVisualizar os resultados\n\nFa√ßa gr√°ficos para comparar a priori e a posteriori, ou destacar regi√µes de interesse com os intervalos de credibilidade.\n\nCombine visualiza√ß√µes com matplotlib, arviz e outras bibliotecas para tornar as conclus√µes mais claras."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#exemplo-em-python",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#exemplo-em-python",
    "title": "Infer√™ncia Bayesiana Binomial com PyMC",
    "section": "2 Exemplo em Python",
    "text": "2 Exemplo em Python\n\nimport pymc as pm\nimport arviz as az  # Pacote auxiliar para an√°lise e visualiza√ß√£o dos resultados\n\n# 1. Definir os dados observados\nN = 10    # N√∫mero total de ensaios (Bernoulli)\nk = 6     # N√∫mero de sucessos observados\n\n# 2. Par√¢metros da distribui√ß√£o a priori (Beta)\nalpha_param = 2\nbeta_param = 2\n\n# 3. Definir o modelo probabil√≠stico no PyMC\nwith pm.Model() as model:\n    # 3.1. Defini√ß√£o da distribui√ß√£o a priori para p\n    p = pm.Beta(\"p\", alpha=alpha_param, beta=beta_param)\n    \n    # 3.2. Observa√ß√µes via distribui√ß√£o Binomial\n    obs = pm.Binomial(\"obs\", n=N, p=p, observed=k)\n    \n    # 4. Amostragem MCMC (posteriori)\n    trace = pm.sample()\n\n# 5. Inspe√ß√£o dos resultados\nprint(az.summary(trace, var_names=[\"p\"], kind=\"stats\"))\n\n# 6. Visualiza√ß√µes da amostragem e da posteriori\naz.plot_trace(trace, var_names=[\"p\"])  # Trajet√≥ria e histograma das amostras\naz.plot_posterior(trace, var_names=[\"p\"], rope=[0.3, 0.7]);  # Posteriori com intervalo de relev√¢ncia\n\n\n\n\n\n\n\n    mean     sd  hdi_3%  hdi_97%\np  0.566  0.129   0.326    0.806"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#interpreta√ß√£o",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#interpreta√ß√£o",
    "title": "Infer√™ncia Bayesiana Binomial com PyMC",
    "section": "3 Interpreta√ß√£o",
    "text": "3 Interpreta√ß√£o\n\nA forma e a localiza√ß√£o da posteriori depender√£o tanto dos dados observados (\\(k\\), \\(N\\)) quanto dos par√¢metros da distribui√ß√£o a priori (\\(\\alpha\\), \\(\\beta\\)).\n\nConforme \\(N\\) aumenta, a verossimilhan√ßa passa a dominar o resultado, reduzindo o impacto de uma a priori moderada.\n\nSe voc√™ alterar \\(\\alpha_{\\mathrm{prior}}\\) e \\(\\beta_{\\mathrm{prior}}\\), ver√° como suposi√ß√µes pr√©vias mudam a forma inicial da posteriori, sobretudo em situa√ß√µes com poucos dados."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-pymc.html#exerc√≠cio",
    "href": "content/intro-bayes/intro-bayes-binomial-pymc.html#exerc√≠cio",
    "title": "Infer√™ncia Bayesiana Binomial com PyMC",
    "section": "4 Exerc√≠cio",
    "text": "4 Exerc√≠cio\n\nVarie \\(N\\) e \\(k\\) para simular cen√°rios distintos (poucos sucessos, muitos sucessos) e veja como a posteriori se adapta.\n\nAltere \\(\\alpha_{\\mathrm{prior}}\\) e \\(\\beta_{\\mathrm{prior}}\\) (por exemplo, prior fortemente concentrada em 0.8) e observe se, com poucos dados, a posteriori permanece pr√≥xima da distribui√ß√£o a priori."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-distr-prob.html",
    "href": "content/intro-bayes/intro-bayes-distr-prob.html",
    "title": "De contagens a probabilidades",
    "section": "",
    "text": "Voltemos ao problema das bolinhas de gude. Temos uma caixa contendo quatro bolinhas, que podem ser azuis ou brancas. Sabemos que h√° exatamente quatro bolinhas, mas n√£o conhecemos a distribui√ß√£o entre as cores, pois podemos ver apenas uma bolinha por vez atrav√©s de um orif√≠cio. Para estimar quantas bolas de cada cor h√° na caixa, fazemos uma observa√ß√£o, misturamos as bolinhas, fazemos outra observa√ß√£o e assim por diante. Antes de realizarmos qualquer observa√ß√£o, podemos listar cinco configura√ß√µes poss√≠veis para o conte√∫do da caixa:\nNosso objetivo √© estimar o n√∫mero \\(N\\) de bolas azuis, o qual pode variar, neste exemplo, de 0 a 4. Como n√£o dispomos de conhecimento pr√©vio sobre a composi√ß√£o da caixa antes da primeira observa√ß√£o, adotamos uma distribui√ß√£o a priori uniforme entre as hip√≥teses. Assim, cada hip√≥tese recebe uma probabilidade de \\(p = \\frac{1}{5}\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-distr-prob.html#distribui√ß√µes-a-priori-a-posteriori-e-verossimilhan√ßa",
    "href": "content/intro-bayes/intro-bayes-distr-prob.html#distribui√ß√µes-a-priori-a-posteriori-e-verossimilhan√ßa",
    "title": "De contagens a probabilidades",
    "section": "1 Distribui√ß√µes a priori, a posteriori e verossimilhan√ßa",
    "text": "1 Distribui√ß√µes a priori, a posteriori e verossimilhan√ßa\nSuponha que realizamos tr√™s observa√ß√µes da caixa e a sequ√™ncia registrada seja [üîµ, ‚ö™, üîµ] ‚Äì ou seja, duas bolas azuis. Para atualizar nosso conhecimento sobre a composi√ß√£o da caixa, combinamos nossa distribui√ß√£o a priori com a verossimilhan√ßa de cada hip√≥tese. A verossimilhan√ßa √© calculada a partir da contagem do n√∫mero de maneiras em que cada hip√≥tese pode gerar a sequ√™ncia observada. Em seguida, aplicamos a regra de Bayes, que nos fornece a distribui√ß√£o a posteriori por meio da f√≥rmula:\n\\[\\text{Posterior}_i = \\frac{\\text{Priori}_i \\times P_i}{\\sum_{j} \\left(\\text{Priori}_j \\times P_j\\right)}, \\tag{1}\\]\nonde \\(P_i\\) representa, de forma proporcional, o n√∫mero de caminhos poss√≠veis para que a hip√≥tese \\(i\\) gere a sequ√™ncia [üîµ, ‚ö™, üîµ].\nA equa√ß√£o Equa√ß√£o¬†1 indica que, para cada valor que \\(N\\) pode assumir, julgamos sua plausibilidade como proporcional ao n√∫mero de maneiras pelas quais esse valor pode ter gerado os dados, multiplicado pela sua evid√™ncia anterior (a distribui√ß√£o a priori). Esse produto ‚Äì representado na Tabela¬†2 por \\(\\text{Priori}_i \\times P_i\\) ‚Äì √© ent√£o normalizado, dividindo cada um deles pelo somat√≥rio \\(\\sum (1/5 \\times \\text{N¬∫ de caminhos})\\). Essa normaliza√ß√£o gera a distribui√ß√£o a posteriori, que reflete nosso conhecimento atualizado ap√≥s a incorpora√ß√£o das evid√™ncias observadas.\nNa Tabela¬†2, a coluna ‚ÄúManeiras de produzir N = 2 [üîµ‚ö™üîµ]‚Äù indica o n√∫mero de caminhos poss√≠veis para que cada hip√≥tese gere a sequ√™ncia observada. Note que as hip√≥teses [‚ö™‚ö™‚ö™‚ö™] e [üîµüîµüîµüîµ] n√£o conseguem gerar a sequ√™ncia (ou seja, possuem verossimilhan√ßa zero).\n\n\n\nTabela¬†2: Atualiza√ß√£o da distribui√ß√£o de probabilidade combinando a priori e verossimilhan√ßa\n\n\n\n\n\n\n\n\n\n\n\n\nHip√≥tese\nN\nPriori\nManeiras de produzir N = 2 [üîµ‚ö™üîµ]\nPosterior\n\n\n\n\n[‚ö™‚ö™‚ö™‚ö™]\n0\n\\(1/5\\)\n\\(0 \\times 4 \\times 0 = 0\\)\n\\(\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{N¬∫ de caminhos})} = 0\\)\n\n\n[üîµ‚ö™‚ö™‚ö™]\n1\n\\(1/5\\)\n\\(1 \\times 3 \\times 1 = 3\\)\n\\(\\dfrac{(1/5 \\times 3)}{\\sum (1/5 \\times \\text{N¬∫ de caminhos})} = 0.15\\)\n\n\n[üîµüîµ‚ö™‚ö™]\n2\n\\(1/5\\)\n\\(2 \\times 2 \\times 2 = 8\\)\n\\(\\dfrac{(1/5 \\times 8)}{\\sum (1/5 \\times \\text{N¬∫ de caminhos})} = 0.40\\)\n\n\n[üîµüîµüîµ‚ö™]\n3\n\\(1/5\\)\n\\(3 \\times 1 \\times 3 = 9\\)\n\\(\\dfrac{(1/5 \\times 9)}{\\sum (1/5 \\times \\text{N¬∫ de caminhos})} = 0.45\\)\n\n\n[üîµüîµüîµüîµ]\n4\n\\(1/5\\)\n\\(4 \\times 0 \\times 4 = 0\\)\n\\(\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{N¬∫ de caminhos})} = 0\\)\n\n\n\n\n\n\nDessa forma, a plausibilidade de cada hip√≥tese √© convertida em probabilidades ‚Äì valores n√£o negativos cuja soma √© igual a 1 ‚Äì para cada uma das hip√≥teses sobre o conte√∫do da caixa. O resultado final da infer√™ncia bayesiana √© fornecer uma base probabil√≠stica para a tomada de decis√£o sobre um fen√¥meno parcialmente desconhecido, expressando o qu√£o plaus√≠vel √© cada hip√≥tese √† luz dos dados dispon√≠veis (Figura¬†1).\n\n\n\n\n\n\n\n\nFigura¬†1: Distribui√ß√£o a priori (esquerda) e a posteriori (direita) para o n√∫mero de bolas azuis. A priori, as hip√≥teses t√™m probabilidade uniforme; a posteriori, a observa√ß√£o [üîµ, ‚ö™, üîµ] atualiza a plausibilidade, favorecendo hip√≥teses intermedi√°rias\n\n\n\n\n\nEsses conceitos possuem nomenclaturas espec√≠ficas, e vale a pena aprend√™-los, pois voc√™ os encontrar√° repetidamente:\n\nA conjectura sobre o n√∫mero de bolinhas azuis \\(N\\) √© chamada de valor do par√¢metro ‚Äì uma maneira de indexar as poss√≠veis explica√ß√µes para os dados.\nO n√∫mero relativo de maneiras pelo qual esse par√¢metro pode produzir os dados √© chamado de verossimilhan√ßa (likelihood). Essa medida √© obtida ao enumerar todas as sequ√™ncias de dados poss√≠veis e, em seguida, descartar aquelas que n√£o s√£o compat√≠veis com os dados observados.\nA plausibilidade anterior de um valor espec√≠fico √© denominada distribui√ß√£o de probabilidade a priori.\nA plausibilidade atualizada de um valor espec√≠fico, ap√≥s a incorpora√ß√£o dos dados, √© denominada distribui√ß√£o de probabilidade a posteriori, utilizada para inferir a probabilidade de cada hip√≥tese ou conjunto de hip√≥teses sobre o par√¢metro."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html",
    "href": "content/amostragem/pop-amostra.html",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas no cap√≠tulo\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(knitr)"
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#popula√ß√£o-amostra-e-unidade-amostral",
    "href": "content/amostragem/pop-amostra.html#popula√ß√£o-amostra-e-unidade-amostral",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "1 Popula√ß√£o, amostra e unidade amostral",
    "text": "1 Popula√ß√£o, amostra e unidade amostral\nUma popula√ß√£o estat√≠stica s√£o todos os elementos sobre os quais queremos tirar conclus√µes. Refere-se ao conjunto de medidas que podem ser mensuradas como resultado de um experimento. As medidas que comp√µem a popula√ß√£o estat√≠stica podem ser pesos, temperaturas, velocidades, tempos de rea√ß√£o, entre outras, a depender das caracter√≠sticas de um estudo particular. Uma popula√ß√£o estat√≠stica pode ser finita ou infinita. Quando √© finita, o n√∫mero de elementos √© dado por \\(N\\). O termo popula√ß√£o n√£o pode ser confundido com seu uso do dia-a-dia, quando refere-se a conjuntos de pessoas ou de organismos, nem mesmo com os elementos f√≠sicos nos quais as vari√°veis foram mensuradas.\nA abrang√™ncia da popula√ß√£o estat√≠stica depende do contexto e do escopo da pergunta que se pretende responder.\n\nExemplo 1: Suponha um estudo para descrever o comprimento do lambari Deuterodon iguape em riachos do litoral de S√£o Paulo. A popula√ß√£o estat√≠stica n√£o s√£o os peixes em si, mas o comprimento de cada indiv√≠duo que habita os riachos destas bacias. Dado o escopo do estudo (bacias do litoral de S√£o Paulo), a popula√ß√£o estat√≠stica abrange somente comprimentos dos organismos existem nesta regi√£o.\nExemplo 2: Suponha agora que desejamos estudar a diversidade de esp√©cies de peixes em bacias costeiras do litoral de S√£o Paulo. Neste caso, a popula√ß√£o estat√≠stica seria constituida de um √≠ndice de diversidade calculado para cada uma das bacias costeiras do litoral. Fica claro que, neste caso, popula√ß√£o estat√≠stica n√£o se refere a popula√ß√£o biol√≥gica, mas sim a vari√°vel que foi mensurada a partir do conjunto de esp√©cies que habitam cada bacia.\n\nNestes dois exemplos √© invi√°vel obter informa√ß√µes de todos os elementos que comp√µem a popula√ß√£o esta√≠stica. No caso dos comprimentos, n√£o temos como capturar todos os animais presentes em uma bacia hidrogr√°fica, mas ainda que tiv√©ssemos seria invi√°vel medir todos, pois existem provavelmente alguns milhares de peixes somente em um pequeno trecho de riacho. J√° o n√∫mero de Bacias costeiras no litoral do Estado de S√£o Paulo √© bem menor, por√©m ainda seria invi√°vel mensurar a diversidade de esp√©cies em todas elas.\nUm censo ocorre nos raros exemplos em que √© poss√≠vel mensurar todos os elementos da popula√ß√£o estat√≠stica. Entretanto, a pr√°tica cient√≠fica lida com a maioria dos casos em que mensuramos um subconjunto da popula√ß√£o estat√≠stica, definido como uma amostra. O tamanho da amostra √© denominado de \\(n\\).\nFinalmente, unidade amostral √© definida como um √∫nico elemento da popula√ß√£o estat√≠stica. A unidade amostral √© uma determinada observa√ß√£o da vari√°vel de interesse. No exemplo dos lambaris, unidade amostral √© o comprimento mensurado em um indiv√≠duo da esp√©cie de interesse, enquanto no exemplo das bacias costeiras, as unidades amostrais s√£o cada um dos valores de diversidade calculados para cada bacia costeira.\n\n\n\n\n\n\nDEFINI√á√ïES\n\n\n\nPopula√ß√£o estat√≠stica: todos os elementos que podem compor uma amostra. Podem ser medidas como comprimentos, temperaturas, velocidades, etc.\nUnidade amostral: um √∫nico elemento da popula√ß√£o.\nCenso: o levantamento de todos os elementos da popula√ß√£o.\nAmostra: um subconjunto extra√≠do da popula√ß√£o.\nTamanho populacional (N): o n√∫mero de elementos da popula√ß√£o.\nTamanho amostral (n): o n√∫mero de elementos da amostra."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribui√ß√£o-de-frequ√™ncias-na-popula√ß√£o-estat√≠stica",
    "href": "content/amostragem/pop-amostra.html#distribui√ß√£o-de-frequ√™ncias-na-popula√ß√£o-estat√≠stica",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "2 Distribui√ß√£o de frequ√™ncias na popula√ß√£o estat√≠stica",
    "text": "2 Distribui√ß√£o de frequ√™ncias na popula√ß√£o estat√≠stica\nOs valores em uma popula√ß√£o estat√≠stica n√£o s√£o id√™nticos, de modo que poder√≠amos descrev√™-los por meio de uma distribui√ß√£o de frequ√™ncia, em que algumas faixas de valores s√£o mais frequentes que outras. Os comprimentos de Deuterodon iguape por exemplo devem variar de alguns mil√≠metros (p√≥s-larva) a cerca de 20 cm (adulto), em que nem todos os comprimentos s√£o igualmente representados. Certamente, existem mais lambaris pequenos e m√©dios do que lambaris grandes. De fato, animais muito grandes s√£o os mais raros, de modo que se tiv√©ssemos informa√ß√£o da popula√ß√£o estat√≠stica, ver√≠amos que faixas de valores muito elevados se tornariam cada vez menos frequentes.\nSe fosse poss√≠vel observar todos os elementos da popula√ß√£o estat√≠stica, saber√≠amos exatamente qual o formato de sua distribui√ß√£o de frequ√™ncias. Suponha por exemplo, a altura de adultos acima de 18 anos. Seria razo√°vel supor que a maioria das alturas consiste de valores intermedi√°rios ao redor de, por exemplo, 170 cent√≠metros. √â razo√°vel supor tamb√©m que a frequ√™ncia de pessoas muito altas ou muito baixas vai diminuindo gradativamente, de modo que √© muito raro encontrarmos adultos muito altos (ex. acima de \\(200\\) cent√≠metros) ou muito baixos (ex. menores que \\(150\\) cent√≠metros). A figura abaixo, descreve uma distribui√ß√£o de frequ√™ncia de uma popula√ß√£o fict√≠cia de exatamente \\(N = 1000\\) alturas.\n\n\nC√≥digo\nmu = 170\nsd = 10\nN = 1000\nset.seed(1)\nadultos = data.frame(\n  CP = round(rnorm(n = N, mean = mu, sd = sd),2)\n  )\n\nplt_pop = ggplot(adultos, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', \n                 color = 'black', bins = 20) +\n   labs(x = \"Alturas em cent√≠metros\",\n        y = \"Frequ√™ncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 200, by = 20)) +\n  coord_cartesian(ylim = c(0, 200), xlim = c(130, 220)) +\n  theme_classic(base_size = 15)\n\n\n\n\nC√≥digo\nplt_pop +\n  annotate(geom = 'text', x = 130, y = 175, \n           label = deparse(bquote('N' == .(N))), parse = TRUE, hjust = 0, size = 7) +\n  annotate(geom = 'text', x = 130, y = 155, \n           label = deparse(bquote(mu == .(mu) ~ 'm')), parse = TRUE, hjust = 0, size = 7)\n\n\n\n\n\n\n\n\nFigura¬†1: Distribui√ß√£o de uma popula√ß√£o estat√≠stica representando as alturas (em cent√≠metros) de adultos acima de 18 anos.\n\n\n\n\n\nVemos que existem mais valores entre \\(160\\) e \\(180\\) e poucas observa√ß√µes extremas. Por exemplo, das \\(1000\\) observa√ß√µes, apenas 27 mais extremas que \\(190\\) cm, o que √© condizente com nossa expectativa para a distribui√ß√£o de frequ√™ncias das alturas de indiv√≠duos adultos."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribui√ß√£o-de-probabilidade-da-popula√ß√£o-estat√≠stica",
    "href": "content/amostragem/pop-amostra.html#distribui√ß√£o-de-probabilidade-da-popula√ß√£o-estat√≠stica",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "3 Distribui√ß√£o de probabilidade da popula√ß√£o estat√≠stica",
    "text": "3 Distribui√ß√£o de probabilidade da popula√ß√£o estat√≠stica\nNa pr√°tica, como n√£o temos acesso a toda a popula√ß√£o estat√≠stica, n√£o temos como visualizar toda a sua distribui√ß√£o de frequ√™ncia. Dizemos portanto, que conhecemos a popula√ß√£o estat√≠stica quando conhecemos a fun√ß√£o de probabilidades associada a vari√°vel que est√° sendo mensurada. No exemplo da Figura¬†1, dir√≠amos que a vari√°vel altura segue uma distribui√ß√£o normal de probabilidades. Quando descrevemos uma distribui√ß√£o de probabilidades, precisamos caracteriz√°-la por meio de certas quantidades, ou par√¢metros da distribui√ß√£o. Na distribui√ß√£o normal, os par√¢metros de interesse s√£o a m√©dia \\(\\mu\\) e o desvio padr√£o \\(\\sigma\\). No exemplo das alturas, \\(\\mu = 170\\) e \\(\\sigma = 10\\)."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#distribui√ß√µes-de-frequ√™ncias-na-amostra",
    "href": "content/amostragem/pop-amostra.html#distribui√ß√µes-de-frequ√™ncias-na-amostra",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "4 Distribui√ß√µes de frequ√™ncias na amostra",
    "text": "4 Distribui√ß√µes de frequ√™ncias na amostra\n\n\nC√≥digo\nn = 50\nset.seed(2)\nselecao = sample(N, size = n)\nAm1 = sort(adultos$CP[selecao], decreasing = FALSE)\n\n\nAinda que n√£o tenhamos acesso a toda popula√ß√£o estat√≠stica, gostar√≠amos de ter informa√ß√µes sobre a vari√°vel de interesse. Utilizamos o processo de amostragem para obter estas informa√ß√µes.\nSuponha, uma amostra de \\(n = 50\\) adultos. Se organizarmos esta amostra em valores crescentes ter√≠amos:\n140.03, 151.5, 152.13, 152.91, 154.07, 158.14, 158.32, 159.59, 159.69, 160.14, 160.42, 160.46, 161.48, 161.89, 162.05, 163.11, 163.59, 163.77, 165.36, 166.11, 166.38, 166.69, 166.76, 167.03, 168.55, 169.72, 170.56, 172.17, 172.94, 173.8, 173.92, 174.34, 174.5, 175.24, 175.76, 175.95, 176.16, 177.13, 177.63, 177.66, 178.03, 178.48, 180.96, 180.97, 183.94, 184.17, 187.54, 187.64, 188.87, 191.69\nOs valores est√£o entre \\(140.03\\) e \\(191.69\\), o que certamente n√£o √© igual aos valores m√°ximos e m√≠nimos da popula√ß√£o. Vamos representar esta amostra por meio de um histograma.\n\n\nC√≥digo\namostra_df = data.frame(CP = adultos$CP[selecao]) \nggplot(amostra_df, aes(x = CP)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 15) +\n   labs(x = \"Alturas em cent√≠metros\",\n        y = \"Frequ√™ncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 10)) +\n  scale_y_continuous(breaks = seq(0, 10, by = 1)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 10)) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nFigura¬†2: Amostra de tamanho n = 50 da popula√ß√£o estat√≠stica de alturas.\n\n\n\n\n\nAinda que a distribui√ß√£o da amostra n√£o seja igual √† da popula√ß√£o estat√≠stica, podemos perceber que h√° uma concentra√ß√£o de valores justamente entre \\(160\\) cm e \\(180\\) cm, assim como na popula√ß√£o estat√≠stica.\nA diferen√ßa entre a distribui√ß√£o da popula√ß√£o e a distribui√ß√£o da amostra √© esperada e ocorre porque estamos observando um subconjunto particular de elementos. Deste modo, sempre que amostrarmos uma popula√ß√£o estat√≠stica, teremos uma amostra ligeiramente diferente.\nVamos verificar por exemplo, as distribui√ß√µes de frequ√™ncia de seis amostras poss√≠ves de tamanho \\(n = 50\\) desta mesma popula√ß√£o.\n\n\nC√≥digo\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em cent√≠metros\",\n         y = \"Frequ√™ncia\") +\n  scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n  scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n  coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\n\n\n\nFigura¬†3: Seis diferentes amostra de tamanho n = 50 da popula√ß√£o estat√≠stica de alturas.\n\n\n\n\n\nCada amostra resulta em distribui√ß√µes diferentes, mas em todas a frequ√™ncia de observa√ß√µes na faixa intermedi√°ria √© maior. O processo de amostragem nos forneceu portanto amostras representativas da popula√ß√£o estat√≠stica, isto √©, amostras em que a distribui√ß√£o de frequ√™ncias se aproximou da distribui√ß√£o de frequ√™ncias da popula√ß√£o.\nNeste exemplo fict√≠cio, como conhecemos a popula√ß√£o estat√≠stica √© f√°cil verificar que as amostras foram representativas. Na pr√°tica cient√≠fica n√£o conhecemos a popula√ß√£o estat√≠stica e, consequentemente, n√£o temos como saber se a nossa amostra em particular foi ou n√£o representativa.\nDevemos portanto conduzir o processo de tal forma que a teoria da amostragem nos garanta que a amostra resultante de um determinado experimento seja, em m√©dia, representativa da popula√ß√£o. O modo mais simples de garantir este comportamento √© realizarmos uma amostra aleat√≥ria dos elementos da popula√ß√£o estat√≠stica."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#par√¢metros-e-estimadores",
    "href": "content/amostragem/pop-amostra.html#par√¢metros-e-estimadores",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "5 Par√¢metros e estimadores",
    "text": "5 Par√¢metros e estimadores\nA popula√ß√£o estat√≠stica tem determinadas quantias de interesse que definimos como par√¢metros da popula√ß√£o. Se fosse poss√≠vel medir as alturas dos \\(N = 1000\\) adultos, poder√≠amos calcular a m√©dia da popula√ß√£o. Seja uma vari√°vel \\(X\\) composta por \\(X_1, X_2, X_3, \\cdots , X_N,\\), a m√©dia da popula√ß√£o estat√≠stica √© denominada de \\(\\mu\\) e definida por:\n\\[\\mu=\\frac{X_1+X_2+X_3+\\cdots+X_N}{N}=\\frac{\\sum_{i=1}^N{X_i}}{N}\\] Como n√£o temos acesso a toda a popula√ß√£o n√£o podemos obter \\(\\mu\\), mas podemos estim√°-lo por meio de uma amostra. Neste caso, seja uma amostra de tamanho \\(n\\) composta por \\(X_1, X_2, X_3, \\cdots, X_n\\), a m√©dia da amosta √© denominada de \\(\\overline{X}\\) e definida por:\n\\[\\overline{X}=\\frac{X_1+X_2+X_3+\\cdots+X_n}{n}=\\frac{\\sum_{i=1}^n{X_i}}{n}\\]\nDizemos que \\(\\overline{X}\\) √© um estimador n√£o viciado de \\(\\mu\\).\nComo os valores da popula√ß√£o estat√≠stica n√£o s√£o id√™nticos, podemos obter uma medida de dispers√£o como a vari√¢ncia populacional (\\(\\sigma^2\\)) definida por:\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N}\\]\nNovamente, como n√£o temos acesso a todos os \\(N\\) elementos, podemos apenas calcular a vari√¢ncia amostral (\\(s^2\\)) definida por:\n\\[s^2=\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}\\]\nNote que na express√£o acima, substituimos \\(\\mu\\) por \\(\\overline{X}\\) pois estamos nos referindo √† vari√¢ncia da amostra. No denominador fizemos a divis√£o por \\(n-1\\) n√£o por \\(N\\). Estas mudan√ßas s√£o necess√°rias para que \\(s^2\\) seja um estimador n√£o-viciado de \\(\\sigma^2\\).\nDenominamos de par√¢metro ao descritor obtido a partir da mensura√ß√£o de todos os elementos da popula√ß√£o estat√≠stica e de estimador (ou estat√≠stica), a quantia obtida a partir da amostra. Os par√¢metros s√£o comumente representados por letras gregas. O s√≠mbolo \\(\\mu\\) e \\(\\sigma^2\\) representam, respectivamente, a m√©dia e vari√¢ncia populacionais, enquanto \\(\\overline{X}\\) e \\(s^2\\) s√£o a m√©dia e vari√¢ncia amostrais.\n\n\n\n\n\n\nDEFINI√á√ïES\n\n\n\nPar√¢metro: a medida que descreve uma caracter√≠stica da popula√ß√£o estat√≠stica. Ex.: a m√©dia (\\(\\mu\\)) ou a vari√¢ncia (\\(\\sigma^2\\)) populacional.\nEstimador ou Estat√≠stica: Uma medida que descreve uma caracter√≠stica da amostra. Ex.: a m√©dia amostral (\\(\\overline{X}\\)) ou a vari√¢ncia amostral (\\(s^2\\)). Os estimadores t√°mbem podem ser representados por letras gregas com o s√≠mbolo \\(\\hat{}\\). A vari√¢ncia amostral, por exemplo, pode ser representada por \\(\\hat{\\sigma}^2\\).\nEstimativa: √© o valor num√©rico assumido pelo estimador. Ex. o valor num√©rico calculado para a m√©dia ou vari√¢ncia de uma amostra em particular.\n\n\n\n5.1 Verificando as propriedades de \\(\\overline{X}\\) e \\(s^2\\)\n\n\nC√≥digo\nNsmall = 5\nnsmall = 2\nset.seed(5)\npop_small = sample(20, size = Nsmall, replace = F)\nmu = mean(pop_small)\nsigma2 = sum((pop_small - mu)^2)/Nsmall\n\nm = matrix(NA, ncol = Nsmall, nrow = Nsmall)\nrownames(m) = colnames(m) = as.character(pop_small)\nfor (i in 1:Nsmall){\n  for (j in 1:Nsmall){\n    m[i,j] = paste('(', pop_small[i], ' ; ', pop_small[j], ')', sep = '')\n  }\n}\n\n\nPor meio de um exmplo, vamos verificar empiricamente que \\(\\overline{X}\\) e \\(s^2\\) s√£o estimadores n√£o viciados de \\(\\mu\\) e \\(\\sigma^2\\) respectivamente. Suponha uma popula√ß√£o de somente \\(5\\) elementos.\n\\[2 - 11 - 15 - 19 - 9\\]\n1. Calculando \\(\\mu\\) e \\(\\sigma^2\\).\nComo conhecemos a popula√ß√£o vamos obter:\n\\[\\mu = \\frac{\\sum_{i=1}^N{X_i}}{N} = \\frac{2 + 11 + 15 + 19 + 9}{5}= \\frac{5}{5} = 11.2\\]\ne\n\\[\\sigma^2=\\frac{\\sum_{i=1}^N{(X_i - \\mu)^2}}{N} = \\frac{164.8}{5} = 32.96\\]\n2. Amostrando a popula√ß√£o estat√≠stica\nA Tabela¬†1 mostra todas as \\(25\\) amostras com reposi√ß√£o de tamanho \\(n = 2\\) que podem ser obtidas desta popula√ß√£o.\nA tabela abaixo mostra todas as \\(25\\) amostras com reposi√ß√£o de tamanho \\(n = 2\\) que podem ser obtidas desta popula√ß√£o.\n\n\nC√≥digo\nknitr::kable(m)\n\n\n\n\nTabela¬†1: Todas as amostras poss√≠veis de tamanho n = 2 da popula√ß√£o estat√≠stica com N = 5\n\n\n\n\n\n\n\n2\n11\n15\n19\n9\n\n\n\n\n2\n(2 ; 2)\n(2 ; 11)\n(2 ; 15)\n(2 ; 19)\n(2 ; 9)\n\n\n11\n(11 ; 2)\n(11 ; 11)\n(11 ; 15)\n(11 ; 19)\n(11 ; 9)\n\n\n15\n(15 ; 2)\n(15 ; 11)\n(15 ; 15)\n(15 ; 19)\n(15 ; 9)\n\n\n19\n(19 ; 2)\n(19 ; 11)\n(19 ; 15)\n(19 ; 19)\n(19 ; 9)\n\n\n9\n(9 ; 2)\n(9 ; 11)\n(9 ; 15)\n(9 ; 19)\n(9 ; 9)\n\n\n\n\n\n\n\n\n3. Calculando \\(\\overline{X}\\) e \\(s^2\\).\nEm seguida, organizamos as amostras em uma outra tabela, de modo que possamos calcular, para cada uma, os estimadores \\(\\overline{X}\\) e \\(s^2\\)\n\n\nC√≥digo\ntab_df = data.frame(expand_grid(pop_small, pop_small))\ncolnames(tab_df) = c('X1', 'X2')\ntab_df = tab_df |&gt; \n  rowwise() |&gt; \n  mutate(Xm = mean(c(X1,X2)),\n         s2 = var(c(X1,X2)))\nEx = mean(tab_df$Xm)\nEs2 = mean(tab_df$s2)\n\n\n\n\nC√≥digo\ntab_df |&gt; \n  knitr::kable(col.names = c('$x_1$', '$x_2$', '$\\\\overline{X}$', '$s^2$'))\n\n\n\n\nTabela¬†2: M√©dia e vari√¢ncia amostrais para todas as amostras poss√≠veis de tamanho n = 2 da popula√ß√£o estat√≠stica com N = 5\n\n\n\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(\\overline{X}\\)\n\\(s^2\\)\n\n\n\n\n2\n2\n2.0\n0.0\n\n\n2\n11\n6.5\n40.5\n\n\n2\n15\n8.5\n84.5\n\n\n2\n19\n10.5\n144.5\n\n\n2\n9\n5.5\n24.5\n\n\n11\n2\n6.5\n40.5\n\n\n11\n11\n11.0\n0.0\n\n\n11\n15\n13.0\n8.0\n\n\n11\n19\n15.0\n32.0\n\n\n11\n9\n10.0\n2.0\n\n\n15\n2\n8.5\n84.5\n\n\n15\n11\n13.0\n8.0\n\n\n15\n15\n15.0\n0.0\n\n\n15\n19\n17.0\n8.0\n\n\n15\n9\n12.0\n18.0\n\n\n19\n2\n10.5\n144.5\n\n\n19\n11\n15.0\n32.0\n\n\n19\n15\n17.0\n8.0\n\n\n19\n19\n19.0\n0.0\n\n\n19\n9\n14.0\n50.0\n\n\n9\n2\n5.5\n24.5\n\n\n9\n11\n10.0\n2.0\n\n\n9\n15\n12.0\n18.0\n\n\n9\n19\n14.0\n50.0\n\n\n9\n9\n9.0\n0.0\n\n\n\n\n\n\n\n\nVemos que a m√©dia amostral pode variar entre 2, quando amostramos o menor valor da popula√ß√£o duas vezes (isto √©, o n√∫mero 2) e 19, quando a amostra cont√©m o maior valor da popula√ß√£o (isto √©, 19). Vemos ainda que existe uma maior concentra√ß√£o de valores entre \\(8\\) e \\(14\\) e que a distribui√ß√£o das m√©dias √© aproximadamente sim√©trica.\nPara a vari√¢ncia amostral \\(s^2\\) tamb√©m verificamos uma grande diferen√ßa entre as amostras particulares, com resultados que varia entre 0 e 144.5, al√©m de uma distribui√ß√£o altamente assim√©trica.\n\n\nC√≥digo\nplt_Xm = ggplot(tab_df, aes(x = Xm)) +\n  geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n   labs(x = bquote('Distribui√ß√£o de ' ~ bar(X)),\n        y = \"Frequ√™ncia\") +\n  scale_x_continuous(breaks = seq(0, 20, by = 2)) +\n  theme_classic(base_size = 15)\n\nplt_s2 = ggplot(tab_df, aes(x = s2)) +\n  geom_histogram(fill = 'red4', color = 'black', bins = 12) +\n   labs(x = bquote('Distribui√ß√£o de ' ~ s^2),\n        y = \"Frequ√™ncia\") +\n  scale_x_continuous(breaks = seq(0, 200, by = 20)) +\n  theme_classic(base_size = 15)\n\n\n\n\nC√≥digo\nplt_Xm | plt_s2\n\n\n\n\n\n\n\n\nFigura¬†4: Distribui√ß√£o das m√©dias e vari√¢ncias amostrais com n = 2\n\n\n\n\n\n3. Verificando os valores esperados de \\(\\overline{X}\\) e \\(s^2\\).\nPara verificar empiricamente os valores esperados de \\(\\overline{X}\\) e \\(s^2\\) podemos encontrar sua m√©dias. Vemos que:\n\\[\\overline{\\overline{X}} = \\frac{\\sum_{i=1}^{25}{280}}{25} = 11.2 = \\mu\\]\ne que\n\\[\\overline{s^2} = \\frac{\\sum_{i=1}^{25}{824}}{25} = 32.96 = \\sigma^2\\]\nEstes resultados mostram que, em m√©dia, espera-se que as estimativas de \\(\\overline{X}\\) e \\(s^2\\) coincidem exatamente com os par√¢metros \\(\\mu\\) e \\(\\sigma^2\\). Quando isto ocorre dizemos que o estimador √© n√£o viciado.\n\n\n\n\n\n\nAmostragem com e sem reposi√ß√£o\n\n\n\nA discuss√£o acima √© v√°lida para a amostragem de uma popula√ß√£o infinita ou para a amostragem com reposi√ß√£o de uma popula√ß√£o finita de tamanho \\(N\\). Se a amostragem for feita sem reposi√ß√£o de uma popula√ß√£o finita, \\(\\overline{X}\\) continua sendo o estimador n√£o viciado de \\(\\mu\\), por√©m o estimador n√£o viciado da vari√¢ncia fica:\n\\(s^2 = \\left( \\frac{N-1}{N} \\right) \\left( \\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1} \\right)\\)\nNa pr√°tica, raramente conduzimos uma amostragem com reposi√ß√£o. No entanto, ou a popula√ß√£o √© infinita como nos casos de estudos experimentais, ou a popula√ß√£o √© finita por√©m muito grande, como na maioria dos estudos observacionais. Neste segundo caso, para popula√ß√µes finitas com \\(N\\) grande, o termo \\(\\left( \\frac{N-1}{N}  \\right)\\sim 1\\)."
  },
  {
    "objectID": "content/amostragem/pop-amostra.html#amostragem-e-infer√™ncia",
    "href": "content/amostragem/pop-amostra.html#amostragem-e-infer√™ncia",
    "title": "Descrevendo popula√ß√µes e amostras",
    "section": "6 Amostragem e infer√™ncia",
    "text": "6 Amostragem e infer√™ncia\nO problema central que come√ßamos e discutir neste cap√≠tulo e com o qual iremos lidar em estat√≠stica √© que:\n\nEstamos interessados nas caracter√≠sticas da popula√ß√£o estat√≠stica, por√©m s√≥ temos informa√ß√£o sobre a amostra.\nA estimativa obtida a partir de uma amostra particular √© sujeita √† varia√ß√£o decorrente do processo de amostragem.\n\nConsidere por exemplo, as diferentes amostras que podem ser obtidas a partir da popula√ß√£o estat√≠stica de alturas para um \\(n = 50\\) amostras:\n\n\nC√≥digo\nplot_list = list()\nfor (i in 1:6){\n  df = slice_sample(adultos, n = n)\n  x_bar = mean(df$CP)\n  s2_bar = var(df$CP)\n  p = ggplot(df, aes(x = CP)) +\n    geom_histogram(fill = 'dodgerblue4', color = 'black', bins = 10) +\n    labs(x = \"Alturas em cent√≠metros\",\n         y = \"Frequ√™ncia\") +\n    scale_x_continuous(breaks = seq(130, 220, by = 20)) +\n    scale_y_continuous(breaks = seq(0, 16, by = 2)) +\n    coord_cartesian(xlim = c(130, 220), ylim = c(0, 16)) +\n    annotate(geom = 'text', x = 130, y = 15, label = deparse(bquote('n' == .(n))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 14, label = deparse(bquote(bar(X) == .(round(x_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    annotate(geom = 'text', x = 130, y = 13, label = deparse(bquote(s^2 == .(round(s2_bar,2)))), parse = TRUE, hjust = 0, size = 3) +\n    theme_classic()\n  plot_list[[i]] = p\n}\n\n(plot_list[[1]] + plot_list[[2]] + plot_list[[3]]) /\n  (plot_list[[4]] + plot_list[[5]] + plot_list[[6]])\n\n\n\n\n\n\n\n\nFigura¬†5: Seis diferentes amostras de tamanho n = 50 da popula√ß√£o de alturas.\n\n\n\n\n\nVemos que a cada nova amostra, \\(\\overline{X}\\) e \\(s^2\\) s√£o numericamente diferentes e n√£o coicidem com os par√¢metros da popula√ß√£o estat√≠stica (\\(\\mu = 11.2\\), \\(\\sigma^2 = 100\\)). Vemos entretanto, que mesmo sendo diferentes, est√£o ao redor dos par√¢metros populacionais. Se pudermos conhecer algumas propriedades destes estimadores, seremos capazes de estabelecer limites de confian√ßa sobre as conclus√µes que podemos tirar as respeito da popula√ß√£o estat√≠stica.\nNeste sentido, o processo de amostragem e infer√™ncia consiste em:\n\nObter uma amostra representativa da popula√ß√£o estat√≠stica;\nCalcular estimativas a partir das caracter√≠sticas da amostra (ex. \\(\\overline{X}\\) e \\(s^2\\));\nAssumir distribui√ß√µes de probabilidade apropriadas para os estimadores;\nUtilizar para estas distribui√ß√µes para calcular intervalos de confian√ßa ou testar hip√≥teses estat√≠sticas.\n\nEste processo pode ser resumido na figura abaixo e ser√° discutido nos pr√≥ximos cap√≠tulos.\n\n\n\n\n\n\nFigura¬†6: Processo de amostragem e infer√™ncia estat√≠stica.\n\n\n\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html",
    "title": "Regress√£o Linear Bayesiana",
    "section": "",
    "text": "Na infer√™ncia bayesiana, atualizamos nossas cren√ßas sobre os par√¢metros de um modelo combinando o conhecimento pr√©vio (expresso pela distribui√ß√£o a priori) com a informa√ß√£o contida nos dados observados (expressa pela verossimilhan√ßa) para obter a distribui√ß√£o a posteriori. A infer√™ncia bayesiana fornece uma distribui√ß√£o completa de probabilidade para os par√¢metros, refletindo explicitamente a incerteza sobre seus valores.\nNo modelo de regress√£o linear bayesiano, assumimos que a vari√°vel resposta \\(y\\) √© uma vari√°vel aleat√≥ria com distribui√ß√£o Normal, cuja m√©dia depende linearmente de uma vari√°vel preditora \\(x\\), ou seja, \\(\\mu = \\beta_0 + \\beta_1 x\\), e com desvio padr√£o \\(\\sigma\\).\n\\[\ny \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x, \\sigma)\n\\tag{1}\\]\nOnde:\nA especifica√ß√£o completa do modelo bayesiano requer a defini√ß√£o das distribui√ß√µes a priori para os par√¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\). Podemos assumir, por exemplo, distribui√ß√µes normais para os coeficientes da regress√£o e uma distribui√ß√£o Lognormal para o desvio padr√£o, garantindo que \\(\\sigma\\) assuma apenas valores positivos. As distribui√ß√µes a priori s√£o ent√£o:\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\tag{2}\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\tag{3}\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\tag{4}\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html#atividate-pr√°tica",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana.html#atividate-pr√°tica",
    "title": "Regress√£o Linear Bayesiana",
    "section": "1 Atividate pr√°tica",
    "text": "1 Atividate pr√°tica\n\n\n\n\n\n\nObjetivos de Aprendizagem\n\n\n\n\nCompreender os fundamentos da regress√£o linear sob a abordagem bayesiana.\nSimular dados utilizando a biblioteca SciPy.\nAplicar conhecimento pr√©vio para especificar distribui√ß√µes a priori informativas para os par√¢metros do modelo.\nImplementar um modelo de regress√£o linear bayesiana com PyMC, realizar a checagem preditiva a priori e ajust√°-lo a dados reais para obter as distribui√ß√µes a posteriori dos par√¢metros.\nInterpretar e validar os resultados da infer√™ncia bayesiana.\n\n\n\nNesta atividade, aplicaremos a infer√™ncia bayesiana para modelar a rela√ß√£o entre duas vari√°veis cont√≠nuas: a altura de indiv√≠duos e o n√∫mero do cal√ßado que utilizam. O conjunto de dados de altura (cm) e n√∫mero do cal√ßado est√° dispon√≠vel no link: altura_adultos.csv.\nIntuitivamente, esperamos que haja uma rela√ß√£o positiva: pessoas com p√©s maiores tendem a ser mais altas. Para quantificar essa rela√ß√£o, utilizaremos um modelo de regress√£o linear. O co\n\n# Configura√ß√£o inicial e importa√ß√£o de bibliotecas\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, lognorm\nimport pandas as pd\nimport seaborn as sns\nimport arviz as az\n\n\n\n1.1 Escolhendo as prioris\nDesenvolver uma boa intui√ß√£o sobre os par√¢metros √© essencial para construir modelos coerentes com o conhecimento pr√©vio. Esta atividade tem como finalidade apoiar a defini√ß√£o informada das distribui√ß√µes a priori no modelo bayesiano, de modo que reflitam o que sabemos (ou assumimos saber) sobre os par√¢metros antes de observar os dados. O objetivo √© explorar diferentes valores para os par√¢metros da regress√£o linear e identificar combina√ß√µes que representem, de forma realista, a rela√ß√£o esperada entre essas duas vari√°veis, e que possam ser utilizadas como prioris no modelo.\n1. Escolha valores para os par√¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) (Equa√ß√£o¬†1).\n\n\\(\\beta_0\\) (intercepto): representa altura esperada quando o n√∫mero do cal√ßado √© 0. Embora esse valor n√£o tenha significado f√≠sico direto, ele influencia a posi√ß√£o da reta ajustada.\n\\(\\beta_1\\) (inclina√ß√£o da reta): representa a varia√ß√£o m√©dia na altura para cada n√∫mero a mais de cal√ßado.\n\\(\\sigma\\) (desvio padr√£o): representa a varia√ß√£o natural nas alturas entre pessoas com o mesmo n√∫mero de cal√ßado.\n\n\n# Par√¢metros para simula√ß√£o\nbeta_0 =       # ESCOLHA a altura base (quando o n√∫mero do cal√ßado √© zero)\nbeta_1 =      # ESCOLHA a taxa m√©dia de aumento na altura para cada n√∫mero a mais de cal√ßado\nsigma =         # ESCOLHA a varia√ß√£o individual na altura (desvio padr√£o dos erros)\n\n2. Crie uma sequ√™ncia de valores para \\(x\\) abrangendo limites coerentes com n√∫mero do cal√ßado para indiv√≠duos adultos e utilize a fun√ß√£o norm.rvs da biblioteca SciPy para gerar dados simulados de altura com base no n√∫mero do cal√ßado.\n\n# Simule o n√∫mero do cal√ßado (ex.: valores inteiros de 33 a 48, com 100 repeti√ß√µes por n√∫mero)\nx_sim = np.repeat(np.arange(33, 49), 100)\n\n# Gere as alturas simuladas com erro normal\nmu = beta_0 + beta_1 * x_sim\ny_sim = norm.rvs(loc=mu, scale=sigma, size=len(x_sim))\n\n3. Utilize o matplotlib para visualizar os dados simulados. O gr√°fico de dispers√£o mostrar√° a altura em fun√ß√£o do n√∫mero do cal√ßado. Isso ajudar√° a avaliar se a simula√ß√£o √© coerente com sua expectativa sobre essa rela√ß√£o.\n\n# Use o matplotlib para plotar o resultado da simula√ß√£o, isto √©, altura_sim em fun√ß√£o de x_sim\nplt.figure(figsize=(9, 6))\nplt.scatter(x_sim, y_sim, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\nplt.xlabel(\"N√∫mero do cal√ßado\")\nplt.ylabel(\"Altura (cm)\")\nplt.title(\"Rela√ß√£o simulada entre n√∫mero do cal√ßado e altura\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n4. Ajuste os valores de \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) e repita a simula√ß√£o at√© obter uma distribui√ß√£o de pontos que represente adequadamente sua espectativa sobre a rela√ß√£o entre as vari√°veis.\n\n\n\n1.2 Implementando distribui√ß√µes a priori no PyMC\nAgora que voc√™ j√° explorou os efeitos dos par√¢metros \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\), o pr√≥ximo passo √© formalizar esse conhecimento na distribui√ß√µes a priori (Equa√ß√µes 2, 3 e 4). Para isso, vamos utilizar a biblioteca de programa√ß√£o probabil√≠stica PyMC.\n1. Defina as distribui√ß√µes a priori\nUtilize os valores escolhidos anteriormente como os centros das distribui√ß√µes a priori, isto √©, utilize beta_0, beta_1 e sigma respectivamente para representar \\(\\mu_{\\beta_0}\\) (Equa√ß√£o¬†2), \\(\\mu_{\\beta_1}\\) (Equa√ß√£o¬†3) e \\(\\mu_{\\log \\sigma}\\) (Equa√ß√£o¬†4). A implementa√ß√£o em PyMC tem por objetivo facilitar a escolha de valores razo√°veis para \\(\\sigma_{\\beta_0}\\) (Equa√ß√£o¬†2), \\(\\sigma_{\\beta_1}\\) (Equa√ß√£o¬†3) e \\(\\sigma_{\\log \\sigma}\\) (Equa√ß√£o¬†4) compat√≠veis com seu grau de incerteza sobre estes par√¢metros.\n\n# Gera√ß√£o de valores simulados para a vari√°vel preditora (calcado)\ncalcado_sim = np.arange(33, 49)\n\n# ESCOLHA altura base (quando o n√∫mero do cal√ßado √© zero)\nmu_beta_0 =  # M√©dia\nsd_beta_0 =  # Desvio padr√£o\n\n# ESCOLHA a taxa m√©dia de aumento na altura para cada n√∫mero a mais de cal√ßad\nmu_beta_1 =   # M√©dia\nsd_beta_1 =   # Desvio padr√£o\n\n# ESCOLHA a varia√ß√£o individual na altura (desvio padr√£o dos erros)\nmu_lsigma =   # M√©dia\nsd_lsigma =   # Desvio padr√£o\n\n\nn_samples = 1000\nwith pm.Model() as modelo_regressao-linear:\n\n    # Prioris\n    beta_0 = pm.Normal(\"beta_0\", mu=mu_beta_0, sigma=sd_beta_0) \n    beta_1 = pm.Normal(\"beta_1\", mu=mu_beta_1, sigma=sd_beta_1)\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(mu_lsigma), sigma=sd_lsigma)\n\n    # Verossimilhan√ßa\n    mu = beta_0 + beta_1 * calcado_sim\n    altura_sim = pm.Normal(\"altura_sim\", mu=mu, sigma=sigma, shape=len(calcado_sim))\n\n    # Amostragem da distribui√ß√£o preditiva a priori\n    prior_predictive_samples = pm.sample_prior_predictive(samples=n_samples)\n\n2. Checagem preditiva a priori: Extraia as distribui√ß√µes a priori dos par√¢metros\n\n# Extra√ß√£o das distribui√ß√µes a priori dos par√¢metros\nbeta_0_prior = prior_predictive_samples.prior[\"beta_0\"].values.flatten()\nbeta_1_prior = prior_predictive_samples.prior[\"beta_1\"].values.flatten()\nsigma_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\n\n# Extra√ß√£o da distribui√ß√£o preditiva de y\naltura_sim_prior = prior_predictive_samples.prior[\"altura_sim\"].values.flatten()\n\n# Repita calcado_sim para alinhar com os n_samples valores de altura_sim_prior\ncalcado_sim_rep = np.tile(calcado_sim, n_samples)\n\n3. Verifique os histogramas das distribui√ß√µes a priori e a distribui√ß√£o preditiva com os dados simulados\n\n\n\n# Plot dos histogramas e do gr√°fico de dispers√£o\nfig, axes = plt.subplots(2, 2, figsize=(8, 8))\n\n# Histograma do beta_0\naxes[0, 0].hist(beta_0_prior, bins=30, color='lightcoral', edgecolor='black')\naxes[0, 0].set_title(\"Intercepto: Œ≤‚ÇÄ\")\naxes[0, 0].set_xlabel(\"Œ≤‚ÇÄ\")\naxes[0, 0].set_ylabel(\"Frequ√™ncia\")\n\n# Histograma do beta_1\naxes[0, 1].hist(beta_1_prior, bins=30, color='cornflowerblue', edgecolor='black')\naxes[0, 1].set_title(\"Inclina√ß√£o: Œ≤‚ÇÅ\")\naxes[0, 1].set_xlabel(\"Œ≤‚ÇÅ\")\naxes[0, 1].set_ylabel(\"Frequ√™ncia\")\n\n# Histograma de sigma\naxes[1, 0].hist(sigma_prior, bins=30, color='mediumseagreen', edgecolor='black')\naxes[1, 0].set_title(\"Desvio padr√£o: œÉ\")\naxes[1, 0].set_xlabel(\"œÉ\")\naxes[1, 0].set_ylabel(\"Frequ√™ncia\")\n\n# Gr√°fico de dispers√£o dos dados simulados anteriormente\naxes[1, 1].scatter(calcado_sim_rep, altura_sim_prior, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\naxes[1, 1].set_title(\"Rela√ß√£o a priori predita\")\naxes[1, 1].set_xlabel(\"N√∫mero do cal√ßado\")\naxes[1, 1].set_ylabel(\"Altura (cm)\")\naxes[1, 1].legend()\naxes[1, 1].grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\nFigura¬†1\n\n\n\n4. Ajuste os valores dos par√¢metros e repita a implementa√ß√£o do modelo at√© obter uma distribui√ß√£o de pontos que represente adequadamente sua espectativa sobre a rela√ß√£o entre as vari√°veis.\n\n\n1.3 Ajustando o modelo a dados reais\n1. Importe os dados altura_adultos.csv\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura_adultos.csv')\ndf\n\nOs dados cont√©m informa√ß√µes sobre altura (cm), n√∫mero do calcado e ano de adultos.\n2. Fa√ßa um gr√°fico de dispers√£o entre altura (\\(y\\)) e calcado (\\(x\\)).\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=df, x='calcado', y='altura', \n                alpha=0.7,           # transpar√™ncia dos pontos\n                s=60,                # tamanho dos pontos\n                color='firebrick')   # cor dos pontos\n\nplt.title('Rela√ß√£o entre N√∫mero do Cal√ßado e Altura', fontsize=14, fontweight='bold')\nplt.xlabel('N√∫mero do Cal√ßado', fontsize=12)\nplt.ylabel('Altura (cm)', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n3. Implemente os dados no PyMC para estimar as distribui√ß√µes posteriores\nDADOS DE ENTRADA\n\n# ENTRE com os par√¢metros das prioris\nmu_beta_0 = \nsd_beta_0 = \n\nmu_beta_1 = \nsd_beta_1 = \n\nmu_lsigma = \nsd_lsigma = \n\n# Dados observados\nX = df['calcado']\nY = df['altura']\n\nIMPLEMENTA√á√ÉO EM PYMC\n\nwith pm.Model() as modelo_regressao-linear:\n    \n    # Priori\n    beta_0 = pm.Normal(\"beta_0\", mu=mu_beta_0, sigma=sd_beta_0)\n    beta_1 = pm.Normal(\"beta_1\", mu=mu_beta_1, sigma=sd_beta_1)\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(mu_lsigma), sigma=sd_lsigma)\n\n    # Verossimilhan√ßa\n    mu = beta_0 + beta_1 * calcado_sim # Equa√ß√£o da reta (modelo preditivo)\n    altura_obs = pm.Normal(\"altura_obs\", mu=beta_0 + beta_1 * X, \n                           sigma=sigma, observed = Y)\n    \n    # Amostragem MCMC para estimar a posterior e da distribui√ß√£o preditiva posterior\n    trace = pm.sample(draws=1000, tune=1000, chains=4, target_accept=0.95)\n    posterior_predictive_samples = pm.sample_posterior_predictive(trace)\n\n4. Resultados do ajuste\n4.1. Resumo dos par√¢metros posteriores\n\naz.summary(trace)\n\n\n4.2. Gr√°ficos de diagn√≥stico\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 6))\n\n# Trace plots\naz.plot_trace(trace, var_names=['beta_0', 'beta_1', 'sigma'], axes=axes)\nplt.suptitle('Trace Plots - Converg√™ncia das Cadeias MCMC')\nplt.tight_layout()\nplt.show()\n\n\n4.3. Distribui√ß√µes posteriores\n\naz.plot_posterior(trace, var_names=['beta_0', 'beta_1', 'sigma'], \n                 hdi_prob=0.95, figsize=(8, 4))\nplt.suptitle('Distribui√ß√µes Posteriores dos Par√¢metros')\nplt.show()\n\n\n4.4. Ajuste do modelo (dados observados vs predi√ß√µes)\nPredi√ß√µes\n\n# Intervalo de credibilidade das predi√ß√µes\ncalcado_range = np.linspace(X.min(), X.max(), 100)\nposterior_beta_0 = trace.posterior['beta_0'].values.flatten()\nposterior_beta_1 = trace.posterior['beta_1'].values.flatten()\n\n# Calculando intervalos de credibilidade para a linha de regress√£o\npredictions = []\nfor x in calcado_range:\n    pred = posterior_beta_0 + posterior_beta_1 * x\n    predictions.append(pred)\n\npredictions = np.array(predictions)\npred_mean = np.mean(predictions, axis=1)\npred_lower = np.percentile(predictions, 2.5, axis=1)\npred_upper = np.percentile(predictions, 97.5, axis=1)\n\n Gr√°fico de valores preditos\n\nplt.figure(figsize=(8, 6))\n\nplt.scatter(X, Y, alpha=0.6, label='Dados Observados', color = 'firebrick')\nplt.plot(calcado_range, pred_mean, color = 'darkgreen', label='Regress√£o (M√©dia Posterior)', \n        linewidth=2, linestyle=\"--\")\nplt.fill_between(calcado_range, pred_lower, pred_upper, \n                alpha=0.2, color='darkgreen', label='IC 95% (Posterior)')\nplt.xlabel('N√∫mero do Cal√ßado')\nplt.ylabel('Altura (cm)')\nplt.title('Ajuste do Modelo de Regress√£o Linear Bayesiana')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "",
    "text": "Vamos utilizar modelos estat√≠sticos para analisar a complexidade tecnol√≥gica tradicional em ilhas da Oceania (Kline e Boyd 2010). Nosso objetivo √© compreender como o tamanho populacional influenciou o n√∫mero de ferramentas dispon√≠veis em cada sociedade.\nCompararemos tr√™s estrat√©gias de modelagem, todas implementadas com PyMC:"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#analisando-o-conjunto-de-dados",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#analisando-o-conjunto-de-dados",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "1 Analisando o conjunto de dados",
    "text": "1 Analisando o conjunto de dados\nImporte os dados kline.csv.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pymc as pm\nimport bambi as bmb\nimport arviz as az\nimport xarray as xr\n\n\nkline = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/kline.csv')\nkline\n\n\n\n\n\n\n\n\nculture\npopulation\ncontact\ntotal_tools\nmean_TU\nlat\nlon\n\n\n\n\n0\nMalekula\n1100\nlow\n13\n3.2\n-16.3\n167.5\n\n\n1\nTikopia\n1500\nlow\n22\n4.7\n-12.3\n168.8\n\n\n2\nSanta Cruz\n3600\nlow\n24\n4.0\n-10.7\n166.0\n\n\n3\nYap\n4791\nhigh\n43\n5.0\n9.5\n138.1\n\n\n4\nLau Fiji\n7400\nhigh\n33\n5.0\n-17.7\n178.1\n\n\n5\nTrobriand\n8000\nhigh\n19\n4.0\n-8.7\n150.9\n\n\n6\nChuuk\n9200\nhigh\n40\n3.8\n7.4\n151.6\n\n\n7\nManus\n13000\nlow\n28\n6.6\n-2.1\n146.9\n\n\n8\nTonga\n17500\nhigh\n55\n5.4\n-21.2\n-175.2\n\n\n9\nHawaii\n275000\nlow\n71\n6.6\n19.9\n-155.6\n\n\n\n\n\n\n\nVisualize a rela√ß√£o entre tamanho populacional (P) e n√∫mero total de ferramentas (T).\n\n# Definir tema com fonte maior\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\n# Personaliza√ß√£o dos r√≥tulos e tema\nplt.xlabel('Tamanho populacional', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nsns.set_theme(style=\"whitegrid\")\n\n\n\n\n\n\n\nFigura¬†1: Rela√ß√£o entre o n√∫mero total de ferramentas e o tamanho populacional em ilhas na Oceania"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-1-regress√£o-linear-com-transforma√ß√£o-logar√≠tmica",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-1-regress√£o-linear-com-transforma√ß√£o-logar√≠tmica",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "2 Estrat√©gia 1: Regress√£o Linear com Transforma√ß√£o Logar√≠tmica",
    "text": "2 Estrat√©gia 1: Regress√£o Linear com Transforma√ß√£o Logar√≠tmica\nA rela√ß√£o na Figura¬†1 √© claramente n√£o linear e pode ser descrita por:\n\\[T = \\beta_0P^{\\beta_1}\\]\nUma alternativa simples neste caso √© utilizar uma transforma√ß√£o logar√≠tmica para linearizar a express√£o:\n\\[\\log(T) = \\log(\\beta_0P^{\\beta_1}) \\Rightarrow \\log(T) = \\log(\\beta_0) + \\log(P^{\\beta_1}) \\Rightarrow\\]\n\\[\\log(T) = B_0 + \\beta_1 \\log(P)\n\\tag{1}\\]\nem que \\(B_0 = \\log(\\beta_0)\\)\nVisualizando na escala logar√≠tmica:\n\nkline['log_tools'] = np.log(kline['total_tools'])\nkline['log_pop'] = np.log(kline['population'])\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='log_pop', y='log_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\n# Personaliza√ß√£o dos r√≥tulos e tema\nplt.xlabel('log do Tamanho populacional', fontsize=14)\nplt.ylabel('log do N√∫mero total de ferramentas', fontsize=14)\n\n\n\n\n\n\nText(0, 0.5, 'log do N√∫mero total de ferramentas')\n\n\n(a) Rela√ß√£o entre o logar√≠tmo do n√∫mero total de ferramentas e o logar√≠tmo do tamanho populacional\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigura¬†2\n\n\n\n\nConsiderando que a rela√ß√£o na Figura¬†2 √© aproximadamente linear, vamos ajustar o modelo de regress√£o linear descrito na Equa√ß√£o¬†1.\nNeste modelo, estamos assumindo que \\(\\log(T)\\) √© uma vari√°vel aleat√≥ria normnalmente distribu√≠da:\n\\[\\log(T) \\sim \\mathcal{N}(\\mu,\\,\\sigma)\\]\n\\[\\mu = B_0 + \\beta_1 \\log(P)\\]\n\n2.1 Implementa√ß√£o\n\nmlinear = bmb.Model(\"log_tools ~ log_pop\", data=kline)\ntrace_linear = mlinear.fit()\n\n\n\n\n\n\n\n\n# Resumo dos par√¢metros\naz.summary(trace_linear)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nsigma\n0.368\n0.104\n0.209\n0.560\n0.002\n0.003\n2206.0\n2375.0\n1.0\n\n\nIntercept\n1.018\n0.756\n-0.375\n2.499\n0.015\n0.019\n2817.0\n2172.0\n1.0\n\n\nlog_pop\n0.269\n0.083\n0.117\n0.430\n0.002\n0.002\n2828.0\n2080.0\n1.0\n\n\n\n\n\n\n\n\n\n2.2 Gerando predi√ß√µes do modelo linear\n\npred_linear = mlinear.predict(trace_linear, kind = 'response', data = kline, inplace=False)\npred_linear_draws = pred_linear.posterior_predictive.log_tools\npred_linear_mean = pred_linear_draws.mean(dim=['chain', 'draw'])\n\n\n\n2.3 Visualiza√ß√£o do modelo linear\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='log_pop', y='log_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\nplt.plot(kline['log_pop'],pred_linear_mean.values, color='red', linewidth=2, label='Predi√ß√£o m√©dia')\naz.plot_hdi(\n    kline['log_pop'],\n    pred_linear.posterior_predictive.log_tools,\n    hdi_prob=0.95, # Intervalo de 95%\n    color='#f3ae1a',\n    fill_kwargs={'alpha': 0.3, 'label': 'Intervalo de Credibilidade (95%)'}\n)\n\nplt.xlabel('log(Popula√ß√£o)', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nplt.title('Modelo de linear: log_tools ~ log_pop', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\n\n2.3.1 Visualiza√ß√£o do modelo linear na escala original\nComo a escala original √© um modelo n√£o linear, teremos que gerar os valores preditos para mais pontos a partir dos par√¢metros estimaos\n\nlog_pop = np.linspace(min(kline['log_pop']), np.max(kline['log_pop']), num=1000)\nnew_x =  xr.DataArray(\n    log_pop,\n    dims=['obs'],\n    coords={'obs': range(len(log_pop))},\n    name='log_pop'\n)\n\nmlinear_pars = mlinear.predict(trace_linear, kind = 'response_params', data = kline, inplace=False)\n\nB0 = mlinear_pars.posterior['Intercept']\nb1 = mlinear_pars.posterior['log_pop']\nnew_pred_linear_mean = B0.values.mean() + b1.values.mean() * new_x\n\nnew_pred_linear = np.exp(B0 + b1 * new_x)\nic_linear = az.hdi(new_pred_linear, hdi_prob=0.95)\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4')\n\nplt.plot(np.exp(new_x),np.exp(new_pred_linear_mean))\n\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='HDI 95%')"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-2-regress√£o-de-poisson-glm",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-2-regress√£o-de-poisson-glm",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "3 Estrat√©gia 2: Regress√£o de Poisson (GLM)",
    "text": "3 Estrat√©gia 2: Regress√£o de Poisson (GLM)\nEmbora a transforma√ß√£o logar√≠tmica torne linear a por√ß√£o determin√≠stica do modelo, ela n√£o resolve adequadamente a natureza discreta da vari√°vel de resposta. No caso do n√∫mero de ferramentas (total_tools), estamos lidando com dados de contagem ‚Äî valores inteiros n√£o negativos. Uma abordagem mais apropriada √© utilizar uma regress√£o de Poisson, que modela diretamente a distribui√ß√£o da vari√°vel como uma vari√°vel aleat√≥ria de contagem.\nVamos assumir que o que realmente influencia a diversidade tecnol√≥gica n√£o √© o tamanho absoluto da popula√ß√£o, mas sim sua ordem de grandeza (Kline e Boyd 2010). Espera-se, portanto, uma associa√ß√£o positiva entre o n√∫mero de ferramentas e o logaritmo do tamanho populacional.\nEste modelo generativo pode ser descrito como:\n\\[T_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\\[\\log(\\lambda_i) = \\beta_0 + \\beta_1 \\cdot \\log(P_i)\\]\nOnde: * \\(T_i\\) √© o n√∫mero de ferramentas na sociedade i * \\(P_i\\) √© o tamanho populacional * A fun√ß√£o de liga√ß√£o logar√≠tmica garante que \\(\\lambda_i &gt; 0\\)\n\n3.1 Implementa√ß√£o\n\nmpoisson = bmb.Model(\"total_tools ~ log_pop\", \n                     data=kline, \n                     family=\"poisson\")\n\n\ntrace_poisson = mpoisson.fit(draws=2000, tune=1000)\n\n\n\n\n\n\n\n\n# Resumo dos par√¢metros\naz.summary(trace_poisson)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.334\n0.301\n0.760\n1.890\n0.004\n0.003\n7127.0\n5501.0\n1.0\n\n\nlog_pop\n0.239\n0.031\n0.181\n0.295\n0.000\n0.000\n7194.0\n5795.0\n1.0\n\n\n\n\n\n\n\n\n\n3.2 Gerando predi√ß√µes do modelo Poisson\n\n# Predi√ß√µes para os dados originais\npred_poisson = mpoisson.predict(trace_poisson, kind='response', data=kline, inplace=False)\npred_poisson_draws = pred_poisson.posterior_predictive.total_tools\npred_poisson_mean = pred_poisson_draws.mean(dim=['chain', 'draw'])\n\n\n# Criar dados para predi√ß√£o suave\nlog_pop_new = np.linspace(min(kline['log_pop']), max(kline['log_pop']), num=100)\nnew_data = pd.DataFrame({'log_pop': log_pop_new})\n\n# Gerar predi√ß√µes\nnew_pred_poisson = mpoisson.predict(trace_poisson, kind='response', data=new_data, inplace=False)\nnew_pred_poisson_mean = new_pred_poisson.posterior_predictive.total_tools.mean(dim=['chain', 'draw'])\n\n\n\n3.3 Visualiza√ß√£o do modelo Poisson\n\nplt.figure(figsize=(8, 6))\n\n# Pontos originais\nsns.scatterplot(data=kline, x='log_pop', y='total_tools', \n                s=100, alpha=0.7, color='#1f77b4', label='Dados observados')\n\n# Linha de predi√ß√£o m√©dia\nplt.plot(log_pop_new, new_pred_poisson_mean.values, \n         color='red', linewidth=2, label='Predi√ß√£o m√©dia')\n\n# Intervalo de credibilidade\naz.plot_hdi(\n    log_pop_new,\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#f3ae1a',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95%'}\n)\n\nplt.xlabel('log(Popula√ß√£o)', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nplt.title('Modelo de Poisson: total_tools ~ log_pop', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n\n\n\n\n\n\n\n\n\n3.4 Visualiza√ß√£o na escala original (popula√ß√£o)\n\nplt.figure(figsize=(12, 8))\n\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95% Poisson'},\n)\n\nplt.xlabel('Popula√ß√£o', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nplt.title('Compara√ß√£o de Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n3.5 Compara√ß√£o com modelo linear\n\nplt.figure(figsize=(12, 8))\n\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\n# Modelo Linear com transforma√ß√£o log (escala original)\nplt.plot(np.exp(new_x), np.exp(new_pred_linear_mean), \n         color='red', linewidth=2, label='Modelo Linear')\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='HDI 95% Linear')\n\n# Modelo Poisson (GLM)\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'HDI 95% Poisson'},\n)\n\nplt.xlabel('Popula√ß√£o', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nplt.title('Compara√ß√£o de Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-3-modelo-cient√≠fico-mecanicista",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#estrat√©gia-3-modelo-cient√≠fico-mecanicista",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "4 Estrat√©gia 3: Modelo Cient√≠fico (Mecanicista)",
    "text": "4 Estrat√©gia 3: Modelo Cient√≠fico (Mecanicista)\nPartindo de uma descri√ß√£o te√≥rica da din√¢mica de inova√ß√£o tecnol√≥gica, podemos expressar a mudan√ßa esperada no n√∫mero de ferramentas ao longo do tempo como:\n\\[\\Delta T = \\alpha P^\\beta - \\gamma T\\]\nOnde: * \\(P\\) √© o tamanho da popula√ß√£o * \\(T\\) √© o n√∫mero de ferramentas * \\(\\alpha\\), \\(\\beta\\) e \\(\\gamma\\) s√£o par√¢metros a serem estimados * \\(\\alpha P^\\beta\\) representa a taxa de inova√ß√£o (dependente da popula√ß√£o) * \\(\\gamma T\\) representa a taxa de perda de ferramentas\nAssumindo que o sistema est√° em equil√≠brio (\\(\\Delta T = 0\\)), podemos resolver para \\(T\\):\n\n\n\n\n\n\nSitua√ß√£o de equil√≠brio\n\n\n\nCome√ßamos com: \\[0 = \\alpha P^\\beta - \\gamma T\\]\nIsolando o termo \\(T\\): \\[\\gamma T = \\alpha P^\\beta\\]\nDividindo ambos os lados por \\(\\gamma\\): \\[T = \\frac{\\alpha P^\\beta}{\\gamma}\n\\tag{2}\\]\n\n\nIncorporando a Equa√ß√£o¬†2 a um modelo de Poisson:\n\\[T_i \\sim \\text{Poisson}(\\lambda_i)\\]\n\\[\\lambda_i = \\frac{\\alpha P_i^{\\beta}}{\\gamma}\\]\n\n4.1 Implementa√ß√£o em PyMC\nPara facilitar a implementa√ß√£o, vamos reparametrizar usando:\n\\[\\log(\\lambda_i) = \\log(\\alpha) + \\beta \\cdot \\log(P_i) - \\log(\\gamma)\\]\nou equivalentemente:\n\\[\\log(\\lambda_i) = \\theta_\\alpha + \\beta \\cdot \\log(P_i) + \\theta_\\gamma\\]\nonde \\(\\theta_\\alpha = \\log(\\alpha)\\) e \\(\\theta_\\gamma = -\\log(\\gamma)\\).\n\nlog_pop = np.log(kline['population'])\ntools = kline['total_tools'].values\n\nwith pm.Model() as scientific_model:\n    # Priors\n    theta_alpha = pm.Normal(\"theta_alpha\", mu=0, sigma=2)\n    beta = pm.Normal(\"beta\", mu=0, sigma=1)\n    theta_gamma = pm.Normal(\"theta_gamma\", mu=0, sigma=1)\n\n    # Esperan√ßa em escala log\n    log_lambda = theta_alpha + beta * log_pop + theta_gamma\n    lambda_ = pm.math.exp(log_lambda)\n\n    # Likelihood\n    T_obs = pm.Poisson(\"total_tools\", mu=lambda_, observed=tools)\n\n    # Amostragem\n    trace_scientific = pm.sample(2000, tune=1000, target_accept=0.95)\n    pm.compute_log_likelihood(trace_scientific)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace_scientific, var_names=[\"theta_alpha\", \"beta\", \"theta_gamma\"], hdi_prob=0.89)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_5.5%\nhdi_94.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta_alpha\n1.068\n0.955\n-0.523\n2.524\n0.021\n0.015\n2058.0\n2524.0\n1.0\n\n\nbeta\n0.241\n0.032\n0.193\n0.293\n0.001\n0.001\n2906.0\n2656.0\n1.0\n\n\ntheta_gamma\n0.248\n0.926\n-1.159\n1.818\n0.021\n0.014\n2024.0\n2427.0\n1.0\n\n\n\n\n\n\n\n\n\n4.2 Gerando predi√ß√µes do modelo cient√≠fico\n\nposterior = trace_scientific.posterior\n\n# Recuperar par√¢metros transformados\nalpha_samples = np.exp(posterior['theta_alpha'])\nbeta_samples = posterior['beta']\ngamma_samples = np.exp(-posterior['theta_gamma'])\n\n# Grid de popula√ß√£o para predi√ß√µes\npop_pred = np.linspace(kline['population'].min(), kline['population'].max(), 200)\n\n# Calcular predi√ß√µes usando a f√≥rmula cient√≠fica\npred_samples = []\nfor i in range(len(alpha_samples.chain)):\n    for j in range(len(alpha_samples.draw)):\n        alpha_val = alpha_samples.isel(chain=i, draw=j).values\n        beta_val = beta_samples.isel(chain=i, draw=j).values\n        gamma_val = gamma_samples.isel(chain=i, draw=j).values\n        \n        pred = (alpha_val * (pop_pred ** beta_val)) / gamma_val\n        pred_samples.append(pred)\n\npred_samples = np.array(pred_samples)\n\n# Calcular estat√≠sticas\nmean_scientific = pred_samples.mean(axis=0)\nhdi_scientific = az.hdi(pred_samples, hdi_prob=0.89)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-poisson.html#compara√ß√£o-dos-tr√™s-modelos",
    "href": "content/modelos-regressao-bayes/regressao-poisson.html#compara√ß√£o-dos-tr√™s-modelos",
    "title": "Modelos Estat√≠sticos e Modelos Cient√≠ficos",
    "section": "5 Compara√ß√£o dos Tr√™s Modelos",
    "text": "5 Compara√ß√£o dos Tr√™s Modelos\nVamos comparar as predi√ß√µes dos tr√™s modelos em um √∫nico gr√°fico:\n\nplt.figure(figsize=(8, 6))\n\n# Dados observados (plotados apenas uma vez)\nsns.scatterplot(data=kline, x='population', y='total_tools', \n                s=100, alpha=0.7, color='black', label='Dados observados')\n\n# 1. Modelo Linear com transforma√ß√£o log (escala original)\nplt.plot(np.exp(new_x), np.exp(new_pred_linear_mean), \n         color='red', linewidth=2, label='Modelo Linear')\nplt.fill_between(np.exp(new_x),\n                 ic_linear.sel(hdi='lower')['x'],\n                 ic_linear.sel(hdi='higher')['x'],\n                 alpha=0.3, color='#f3ae1a', \n                 label='IC 95% Linear')\n\n# 2. Modelo Poisson (GLM)\nplt.plot(np.exp(log_pop_new), new_pred_poisson_mean.values, \n         color='blue', linewidth=2, linestyle='--', label='Modelo Poisson')\naz.plot_hdi(\n    np.exp(log_pop_new),\n    new_pred_poisson.posterior_predictive.total_tools,\n    hdi_prob=0.95,\n    color='#1f77b4',\n    fill_kwargs={'alpha': 0.3, 'label': 'IC 95% Poisson'},\n)\n\n# 3. Modelo Cient√≠fico (Mecanicista)\n# Modelo Cient√≠fico\nplt.plot(pop_pred, mean_scientific, color='#2ca02c', linewidth=3, \n         label='Modelo Mecanicista')\nplt.fill_between(pop_pred, hdi_scientific[:, 0], hdi_scientific[:, 1],\n                 color='#2ca02c', alpha=0.2, label = 'IC Mecanicista) 95%')\n\n# Configura√ß√µes do gr√°fico\nplt.xlabel('Popula√ß√£o', fontsize=14)\nplt.ylabel('N√∫mero total de ferramentas', fontsize=14)\nplt.title('Compara√ß√£o dos Tr√™s Modelos', fontsize=16)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html",
    "href": "content/introducao-r/estrutura-linguagem.html",
    "title": "Estrutura da linguagem",
    "section": "",
    "text": "R √© um ambiente de software livre para computa√ß√£o estat√≠stica e gr√°fica que roda em uma variedade de plataformas UNIX, Windows e MacOS (R Project). A instala√ß√£o pode ser feita a partir do site oficial CRAN, seguindo as instru√ß√µes para cada plataforma. O RStudio √© uma Interface de Desenvolvimento Integrado (IDE) dedicada ao ambiente R, embora existam outras op√ß√µes como Jupyter Notebook, Jupyter Lab, Visual Studio Code e Google Colab."
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#o-r-para-c√°lculos-aritm√©ticos",
    "href": "content/introducao-r/estrutura-linguagem.html#o-r-para-c√°lculos-aritm√©ticos",
    "title": "Estrutura da linguagem",
    "section": "1 O R para c√°lculos aritm√©ticos",
    "text": "1 O R para c√°lculos aritm√©ticos\nVamos iniciar nossa introdu√ß√£o ao R com seu uso mais simples, um ambiente para c√°lculos aritm√©ticos. Como voc√™ ver√°, o R usa os operadores matem√°ticos de subtra√ß√£o (-), adi√ß√£o (+), multiplica√ß√£o (*), divis√£o (/) e potencia√ß√£o (^) do modo an√°logo a outros softwares.\n\n2 + 4\n\n[1] 6\n\n2 * 4\n\n[1] 8\n\n2 - 4\n\n[1] -2\n\n2^4\n\n[1] 16\n\n\nAl√©m destes, temos operadores para extrairmos a parte inteira (%%) e o resto (%/%) de uma divis√£o.\n\n13%/%2\n\n[1] 6\n\n13%%2\n\n[1] 1\n\n\nO uso de par√™nteses tamb√©m permite o controle das opera√ß√µes matem√°ticas seguindo as prioridades conhecidas nestas opera√ß√µes. Por exemplo, a express√£o:\n\n5 * (9 + 2)\n\n[1] 55\n\n\n√© diferente de:\n\n5 * 9 + 2\n\n[1] 47\n\n\nAssim como a express√£o:\n\n(3 + 4)^2\n\n[1] 49\n\n\n√© diferente de:\n\n3 + 4^2\n\n[1] 19\n\n\nExistem tamb√©m fun√ß√µes aritm√©ticas comuns como \\(log(x)\\), \\(\\sqrt(x)\\), \\(\\sin(x)\\), o n√∫mero \\(\\pi\\), etc.\n\nlog(100)\n\n[1] 4.60517\n\nlog10(100)\n\n[1] 2\n\nlog(100, base = 2)\n\n[1] 6.643856\n\nsqrt(36)\n\n[1] 6\n\npi\n\n[1] 3.141593\n\nsin(0.5 * pi)\n\n[1] 1"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#atribui√ß√£o-de-valores",
    "href": "content/introducao-r/estrutura-linguagem.html#atribui√ß√£o-de-valores",
    "title": "Estrutura da linguagem",
    "section": "2 Atribui√ß√£o de valores",
    "text": "2 Atribui√ß√£o de valores\nO R se estrutura por meio de objetos. Ao atribuir um valor a uma vari√°vel, esta se torna um objeto que fica dispon√≠vel na mem√≥ria. Para atribuir valor \\(2\\) √† vari√°vel x fazemos:\n\nx &lt;- 2\nx\n\n[1] 2\n\n\nAp√≥s atribuir um valor √† vari√°vel, esta fica dispon√≠vel na mem√≥ria da se√ß√£o atual e pode ser utilizada em opera√ß√µes subsequentes.\n\ny &lt;- x + 10\ny\n\n[1] 12\n\n\nAo atribuir outro valor √† mesma vari√°vel, o valor inicial √© substitu√≠do:\n\nx &lt;- 5\ny &lt;- x + 10\ny\n\n[1] 15\n\n\nO R diferencia caracteres min√∫sculos de MAI√öSCULOS. Portanto:\n\na &lt;- sqrt(49)\nA &lt;- sqrt(81)\na\n\n[1] 7\n\nA\n\n[1] 9"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#estruturas-de-dados",
    "href": "content/introducao-r/estrutura-linguagem.html#estruturas-de-dados",
    "title": "Estrutura da linguagem",
    "section": "3 Estruturas de dados",
    "text": "3 Estruturas de dados\nOs objetos em R podem ser vetores (num√©ricos, alfanum√©ricos ou fatores), matrizes (num√©ricas ou alfanum√©tricas), data frames (estrutura bidimensional que pode combinar colunas de diferentes tipos como vetores num√©ricos, alfanum√©ricos ou fatores) ou listas (que pode combinar em sua estrutura, todos os objetos descritos acima). As fun√ß√µes em R s√£o sequ√™ncias de comandos que podem transformar objetos.\n\n3.1 Vetores num√©ricos\nOs objetos podem guardar mais de um √∫nico valor. A fun√ß√£o concatenar c() pode ser utilizada para criar um vetor com m√∫ltiplos valores. Dizemos que cada valor individual √© uma entrada.\n\nx &lt;- c(4, 3.0, 5, 9, 10)\nx\n\n[1]  4  3  5  9 10\n\n\nPodemos utilizar estes vetores em nossas opera√ß√µes.\n\ny &lt;- x * 2\ny\n\n[1]  8  6 10 18 20\n\n\nNote que na opera√ß√£o acima, cada entrada foi multiplicada por \\(2\\).\nPodemos ainda acessar e modificar entradas individuais. Por exemplo, o objeto y criado acima tem 5 elementos. O segundo elemento pode ser acessado com o comando:\n\ny[2]\n\n[1] 6\n\n\nE alterado com o comando:\n\ny[2] &lt;- 300\ny\n\n[1]   8 300  10  18  20\n\n\nSe quisermos excluir o quarto elemento de y e gravar o resultado em um novo objeto z fazemos:\n\nz &lt;- y[-4]\nz\n\n[1]   8 300  10  20\n\n\nObs: Veja que o quarto elemento, 18, foi exclu√≠do.\nPodemos obter a informa√ß√£o sobre o n√∫mero de elementro do vetor. O vetor y tem tamanho igual a 5, enquanto o vetor z tem 4 elementos.\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 4\n\n\n\nSequ√™ncias regulares e repeti√ß√µes\nPodemos criar sequencias regulares.\n\n2:10\n\n[1]  2  3  4  5  6  7  8  9 10\n\nseq(2, 10, by = 2)\n\n[1]  2  4  6  8 10\n\nseq(2, 10, length = 4)\n\n[1]  2.000000  4.666667  7.333333 10.000000\n\nseq(2, 10, length = 10)\n\n [1]  2.000000  2.888889  3.777778  4.666667  5.555556  6.444444  7.333333\n [8]  8.222222  9.111111 10.000000\n\n\nE repeti√ß√µes de valores e vetores.\n\nrep(4, times = 6)\n\n[1] 4 4 4 4 4 4\n\nrep(c(2, 5), times = 3)\n\n[1] 2 5 2 5 2 5\n\nrep(c(2, 5), each = 3)\n\n[1] 2 2 2 5 5 5\n\n\nOs resultados destas sequ√™ncias podem ser guardadas em um objeto para utiliza√ß√£o subsequente.\n\na &lt;- seq(2, 10, by = 2)\na\n\n[1]  2  4  6  8 10\n\nb &lt;- seq(10, 2, by = -2)\nb\n\n[1] 10  8  6  4  2\n\nc &lt;- a + b\nc\n\n[1] 12 12 12 12 12\n\n\n\n\n\n3.2 Vetores alfanum√©ricos\nS√£o vetores em que cada entrada √© um caracter alfanumerico.\n\nespecie = c(\"Deuterodon iguape\", \n            \"Characidium japuhybense\", \n            \"Trichomycterus zonatus\")\nespecie\n\n[1] \"Deuterodon iguape\"       \"Characidium japuhybense\"\n[3] \"Trichomycterus zonatus\" \n\n\nExiste uma variedade de fun√ß√µes para manipula√ß√£o de vetores alfanum√©ricos.\nA fun√ß√£o sort() por exemplo, aplicada a um vetor num√©rico √© utilizada para orden√°-lo de forma crescente:\n\na = c(5,2,15,12)\na\n\n[1]  5  2 15 12\n\nsort(a)\n\n[1]  2  5 12 15\n\n\nou decrescente:\n\nsort(a, decreasing = T)\n\n[1] 15 12  5  2\n\n\nSe aplicada a um vetor alfanumerico esta fun√ß√£o ordena o vetor em ordem alfab√©tica:\n\nsort(especie, decreasing = FALSE)\n\n[1] \"Characidium japuhybense\" \"Deuterodon iguape\"      \n[3] \"Trichomycterus zonatus\" \n\nsort(especie, decreasing = TRUE)\n\n[1] \"Trichomycterus zonatus\"  \"Deuterodon iguape\"      \n[3] \"Characidium japuhybense\"\n\n\n\n\n3.3 Unindo vetores: comando paste\nSuponha que desejamos unir dois vetores alfanum√©ricos\n\nx1 &lt;- c(\"Experimento\")\nx2 &lt;- c(\"A\", \"B\", \"C\")\nx3 &lt;- paste(x1, x2, sep = \"_\")\n\nO mesmo resultado pode ser obtido de forma mais concisa com o comando:\n\nx4 &lt;- paste(\"Experimento\", LETTERS[1:3], sep = \"_\")\nx4\n\n[1] \"Experimento_A\" \"Experimento_B\" \"Experimento_C\"\n\n\n\n\n3.4 Fatores\nFatores s√£o como vetores alfanum√©ricos, por√©m com um atributo adicional. Fatores s√£o compostos por diferentes n√≠veis. Por exemplo, podemos criar o objeto dosagem com o comando:\n\ndosagem &lt;- c(\"Alta\", \"Alta\", \"Alta\", \n            \"Media\", \"Media\", \"Media\", \n            \"Baixa\", \"Baixa\", \"Baixa\")\ndosagem\n\n[1] \"Alta\"  \"Alta\"  \"Alta\"  \"Media\" \"Media\" \"Media\" \"Baixa\" \"Baixa\" \"Baixa\"\n\n\nNo exemplo acima, o R n√£o reconhece as palavras Alta, Media e Baixa como diferentes n√≠veis. Para isto devemos transform√°-lo em um fator:\n\ndosagem &lt;- factor(dosagem)\ndosagem\n\n[1] Alta  Alta  Alta  Media Media Media Baixa Baixa Baixa\nLevels: Alta Baixa Media\n\n\nO objeto dosagem agora √© um fator com 3 n√≠veis.\n\nlevels(dosagem)\n\n[1] \"Alta\"  \"Baixa\" \"Media\"\n\nnlevels(dosagem)\n\n[1] 3\n\nlevels(dosagem)[2]\n\n[1] \"Baixa\"\n\n\nNote entretanto que os n√≠veis foram reconhecidos em ordem alfab√©tica. Se quisermos ordenar este n√≠veis de outro modo fazemos:\n\ndosagem &lt;- factor(dosagem, ordered = TRUE, \n                 levels = c(\"Baixa\", \"Media\", \"Alta\"))\ndosagem\n\n[1] Alta  Alta  Alta  Media Media Media Baixa Baixa Baixa\nLevels: Baixa &lt; Media &lt; Alta\n\n\nComo veremos a frente, esta opera√ß√£o facilita a visualiza√ß√£o gr√°fica de fatores ordenados.\n\n\n3.5 Matrizes\nMatrizes s√£o objetos compostos por linhas e colunas. No R, uma matriz pode ser constru√≠da inicialmente criando um vetor num√©rico:\n\na &lt;- c(21,26,5,18,17,28,20,15,13,14,27,22)\na\n\n [1] 21 26  5 18 17 28 20 15 13 14 27 22\n\n\nEm seguida o vetor pode ser organizado em uma matriz definindo-se o n√∫mero de linhas e de colunas que sejam compat√≠veis com o tamanho do vetor. No exemplo acima o vetor tem comprimento 12 e pode ser organizado em uma matriz de \\(3\\) linhas e \\(4\\) colunas:\n\nx &lt;- matrix(a, nrow = 3, ncol = 4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   18   20   14\n[2,]   26   17   15   27\n[3,]    5   28   13   22\n\n\nNote que os elementos foram adicionados um por vez de coluna em coluna. Se quisermos preencher a matriz por linhas adicionamos ao comando, o argumento byrow = TRUE.\n\nx &lt;- matrix(a, nrow = 3, ncol = 4, byrow = TRUE)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28   20   15\n[3,]   13   14   27   22\n\n\nOs elementos de uma matriz podem ser acessados indicando sua posi√ß√£o na linha e na coluna. Por exemplo, o elemento da \\(2^a\\) linha e \\(3^a\\) coluna de x pode ser acessados pelo comando:\n\nx[2, 3]\n\n[1] 20\n\n\nDe modo an√°logo, a \\(2^a\\) linha pode ser acessada por:\n\nx[2, ]\n\n[1] 17 28 20 15\n\n\nE a \\(4^a\\) coluna por:\n\nx[, 4]\n\n[1] 18 15 22\n\n\nValores individuais em matrizes podem ser alterados de forma similar ao que √© realizasdo em vetores. Por exemplo, para alterar o elemento da \\(2^a\\) linha e \\(3^a\\) coluna de x por \\(1000\\) fazemos:\n\nx[2, 3] &lt;- 1000\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28 1000   15\n[3,]   13   14   27   22\n\n\nTamb√©m podemos excluir linhas e colunas de uma matriz.\n\nx[-2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   13   14   27   22\n\nx[,-3]\n\n     [,1] [,2] [,3]\n[1,]   21   26   18\n[2,]   17   28   15\n[3,]   13   14   22\n\n\nNote que, acima, n√£o salvamos os resultados da exclus√£o das linhas e colunas de x em nenhum objeto, de modo que x continua inalterado.\n\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   21   26    5   18\n[2,]   17   28 1000   15\n[3,]   13   14   27   22\n\n\nPodemos criar matrizes unindo vetores de tamanho iguais em linhas ou colunas.\n\nx &lt;- 3:12\ny &lt;- 12:3\nrbind(x, y)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\nx    3    4    5    6    7    8    9   10   11    12\ny   12   11   10    9    8    7    6    5    4     3\n\ncbind(x, y)\n\n       x  y\n [1,]  3 12\n [2,]  4 11\n [3,]  5 10\n [4,]  6  9\n [5,]  7  8\n [6,]  8  7\n [7,]  9  6\n [8,] 10  5\n [9,] 11  4\n[10,] 12  3\n\n\nEventualmente, se desejarmos atribuir nomes √†s linhas e √†s colunas de uma matriz, podemos faz√™-lo por meio das fun√ß√µes rownames() e colnames() respectivamente:\n\nx_mat &lt;- matrix(1:12, nrow = 3, ncol = 4)\nx_mat\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nrownames(x_mat) &lt;- paste(\"Linha\", 1:3, sep = \"\")\nx_mat\n\n       [,1] [,2] [,3] [,4]\nLinha1    1    4    7   10\nLinha2    2    5    8   11\nLinha3    3    6    9   12\n\ncolnames(x_mat) &lt;- paste(\"Coluna\", 1:4, sep = \"\")\nx_mat\n\n       Coluna1 Coluna2 Coluna3 Coluna4\nLinha1       1       4       7      10\nLinha2       2       5       8      11\nLinha3       3       6       9      12\n\n\n\n\n3.6 Data frames\nAssim como Matrizes, Data frames s√£o estruturas que permitem organizar dados em formato de linhas e colunas. No R entanto, as Matrizes n√£o podem guardar objetos de diferentes caracter√≠sticas. Por exemplo, uma matriz pode ser composta inteiramente num√©rica:\n\nmatrix(1:12, nrow = 4, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\nOu alfanum√©rica:\n\nmatrix(letters[1:12], nrow = 4, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"e\"  \"i\" \n[2,] \"b\"  \"f\"  \"j\" \n[3,] \"c\"  \"g\"  \"k\" \n[4,] \"d\"  \"h\"  \"l\" \n\n\nPor√©m, se tentarmos unir um vetor num√©rico a um vetor alfanum√©rico, toda a matriz ser√° convertida no formato alfanum√©rico.\n\nz &lt;- LETTERS[3:12]\nz\n\n [1] \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\"\n\ncbind(x, z)\n\n      x    z  \n [1,] \"3\"  \"C\"\n [2,] \"4\"  \"D\"\n [3,] \"5\"  \"E\"\n [4,] \"6\"  \"F\"\n [5,] \"7\"  \"G\"\n [6,] \"8\"  \"H\"\n [7,] \"9\"  \"I\"\n [8,] \"10\" \"J\"\n [9,] \"11\" \"K\"\n[10,] \"12\" \"L\"\n\n\nPara unir diferentes tipos de vetores devemos usar transformar a matriaz para um objeto do tipo data.frame que cria uma estrutura com colunas independentes, permitindo que estas tenham diferentes formatos. Podemos unir os objetos x e z acima em um data frame como segue:\n\ndata.frame(x, z)\n\n    x z\n1   3 C\n2   4 D\n3   5 E\n4   6 F\n5   7 G\n6   8 H\n7   9 I\n8  10 J\n9  11 K\n10 12 L\n\n\nNote que automaticamente, a fun√ß√£o atribui nomes as colunas (x e z) e √†s linhas (\\(1\\) a 10). Estes nomes podem ser alterados com as fun√ß√µes rownames() e colnames().\nNeste caso, a coluna x continua sendo num√©rica e a coluna z continua alfanum√©rica.\nPodemos acessar os elementos de um data frame do mesmo modo que fizemos para matrizes.\nPodemos criar um data frame diretamente:\n\nDados &lt;- data.frame(Regiao = factor(c(\"Santos\", \"Santos\", \n                                     \"Bertioga\", \"Bertioga\", \n                                     \"Peruibe\", \"Peruibe\")),\n                   Especie_A = c(12,43,80,91,75,115), \n                   Especie_B = c(0, 59, 300, 350, 154, 200))\n\nE acess√°-lo de diferentes formas:\n\nDados\n\n    Regiao Especie_A Especie_B\n1   Santos        12         0\n2   Santos        43        59\n3 Bertioga        80       300\n4 Bertioga        91       350\n5  Peruibe        75       154\n6  Peruibe       115       200\n\nDados$Regiao\n\n[1] Santos   Santos   Bertioga Bertioga Peruibe  Peruibe \nLevels: Bertioga Peruibe Santos\n\nDados[\"Regiao\"]\n\n    Regiao\n1   Santos\n2   Santos\n3 Bertioga\n4 Bertioga\n5  Peruibe\n6  Peruibe\n\nDados[,\"Regiao\"]\n\n[1] Santos   Santos   Bertioga Bertioga Peruibe  Peruibe \nLevels: Bertioga Peruibe Santos\n\nDados[,c(\"Especie_A\",\"Especie_B\")]\n\n  Especie_A Especie_B\n1        12         0\n2        43        59\n3        80       300\n4        91       350\n5        75       154\n6       115       200\n\n\n\n\n3.7 Listas\nCombinam em um √∫nico objeto todas as estruturas anteriores. Veja o exemplo em que combinamos um vetor alfanum√©rico, um vetor nominal e um data frame dentro da mesma lista.\n\nnossalista &lt;- list(Ilha = c(\"Ilhabela\", \"Anchieta\", \"Cardoso\"), \n                  Areaskm2 = c(347.5, 8.3, 131), \n                  Localizacao = data.frame(\n                    Bioma = rep(\"Mata Atlantica\", 3),\n                  Lat = c(23, 25, 23),\n                  Long = c(45, 47, 45)))\nnossalista\n\n$Ilha\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\n$Areaskm2\n[1] 347.5   8.3 131.0\n\n$Localizacao\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45\n\n\nPodemos ainda inserir listas dentro de outras listas, criando estruturas altamente complexas.\nPara acessar os elementos de uma lista podemos identificar seu nome ap√≥s o operador $ ou sua posi√ß√£o das formas que se seguem:\n\nnossalista$Ilha\n\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\nnossalista[[1]]\n\n[1] \"Ilhabela\" \"Anchieta\" \"Cardoso\" \n\nnossalista$Localizacao\n\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45\n\nnossalista[[3]]\n\n           Bioma Lat Long\n1 Mata Atlantica  23   45\n2 Mata Atlantica  25   47\n3 Mata Atlantica  23   45"
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#operadores-relacionais",
    "href": "content/introducao-r/estrutura-linguagem.html#operadores-relacionais",
    "title": "Estrutura da linguagem",
    "section": "4 Operadores relacionais",
    "text": "4 Operadores relacionais\nOperadores relacionais s√£o aqueles de verificam as rela√ß√µes de menor que (&lt;), maior que (&gt;), menor ou igual (&lt;=), maior ou igual (&gt;=), igual a (==) ou diferente de (!=). O resultado de uma compara√ß√£o retorna um objeto com o argumento verdadeiro (TRUE) ou falso (FALSE). Veja por exemplo:\n\n3 &gt; 5\n\n[1] FALSE\n\n\n\n3 &gt; 3\n\n[1] FALSE\n\n\n\n3 &gt;= 3\n\n[1] TRUE\n\n\n\na &lt;- 5\nb &lt;- 7\na == b\n\n[1] FALSE\n\na != b\n\n[1] TRUE\n\n\nSe os objetos t√™m mais de um elemento, no caso de vetores, matrizes ou data frames, a compara√ß√£o √© feita elemento-a-elemento, comparando aqueles que est√£o na mesma posi√ß√£o, ou seja, os que t√™m o mesmo √≠ndice de posi√ß√£o.\n\na &lt;- c(3,5,5,7,1)\nb &lt;- c(3,6,1,9,-3)\na &lt; b\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n\nOs operadores TRUE e FALSE, quanto utilizados em opera√ß√µes aritm√©ticas se comportam respectivamente como valores 1 e 0.\n\na &lt;- 5\nb &lt;- c(3,6,1,9,-3)\ny &lt;- b &gt; a\ny\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n\nSomando os elementos de y temos o n√∫mero de elementos que atendendem √† condi√ß√£o acima:\n\nsum(y)\n\n[1] 2\n\n\nE se tirarmos a m√©dia aritm√©tica, teremos a propor√ß√£o de 1‚Äôs no vetor y.\n\nmean(y)\n\n[1] 0.4\n\n\n\n\n\n\n\n\nNota\n\n\n\nLembre-se que ao compararmos vetores de tamanhos distintos, o R n√£o retorna um erro, mas recicla os elementos do vetor menor para compensar elementos faltantes."
  },
  {
    "objectID": "content/introducao-r/estrutura-linguagem.html#operadores-l√≥gicos",
    "href": "content/introducao-r/estrutura-linguagem.html#operadores-l√≥gicos",
    "title": "Estrutura da linguagem",
    "section": "5 Operadores l√≥gicos",
    "text": "5 Operadores l√≥gicos\nOperadores l√≥gicos s√£o os de NEGA√á√ÉO (!), E l√≥gico, OU l√≥gico vers√£o vetorizada (|) e OU exclusivo (xor()). Exemplos destes operadores s√£o:\n\nx &lt;- 3:5\ny &lt;- 5:3\n\n\n(x &lt; 4)\n\n[1]  TRUE FALSE FALSE\n\n!(x &lt; 4)\n\n[1] FALSE  TRUE  TRUE\n\n\n\n(x &lt; 4) & (y &gt; 4)\n\n[1]  TRUE FALSE FALSE\n\n\n\n(x &lt; 4) | (y &gt; 4)\n\n[1]  TRUE FALSE FALSE\n\n\n\nxor(x,y)\n\n[1] FALSE FALSE FALSE"
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html",
    "href": "content/manipulacao-dados-R/pipe.html",
    "title": "Operadores pipe",
    "section": "",
    "text": "Em R, operadores pipe s√£o usados para passar a sa√≠da de uma fun√ß√£o para a entrada de outra, tornando o c√≥digo mais leg√≠vel e conciso. Este tutorial compara o operador pipe nativo |&gt; introduzido no R 4.1.0 e o operador %&gt;% do pacote magrittr."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#operador-pipe-nativo",
    "href": "content/manipulacao-dados-R/pipe.html#operador-pipe-nativo",
    "title": "Operadores pipe",
    "section": "1 Operador Pipe nativo |>",
    "text": "1 Operador Pipe nativo |&gt;\nO operador pipe nativo |&gt; √© uma nova adi√ß√£o ao R base. Ele permite escrever c√≥digo mais limpo e leg√≠vel ao encadear fun√ß√µes.\n\n# Exemplo usando o operador pipe nativo |&gt;\nresultado &lt;- 1:10 |&gt; \n  sum() |&gt;\n  sqrt()\n\nresultado\n\n[1] 7.416198\n\n\nNeste exemplo, a sequ√™ncia de 1 a 10 √© passada para a fun√ß√£o sum(), e o resultado √© ent√£o passado para a fun√ß√£o `sqrt()```.\nO mesmo resultado √© obtido sem o operador pipe por:\n\nresultado &lt;- sqrt(sum(1:10))\n\nresultado\n\n[1] 7.416198"
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#operador-pipe-do-pacote-magrittr",
    "href": "content/manipulacao-dados-R/pipe.html#operador-pipe-do-pacote-magrittr",
    "title": "Operadores pipe",
    "section": "2 Operador Pipe do pacote magrittr %>%",
    "text": "2 Operador Pipe do pacote magrittr %&gt;%\nO operador %&gt;% do pacote `magrittr``` tem sido amplamente usado na comunidade R h√° v√°rios anos. Ele serve ao mesmo prop√≥sito que o operador pipe nativo, mas possui alguns recursos adicionais.\n\nlibrary(magrittr)\n\n# Exemplo usando o operador pipe do magrittr %&gt;%\nresultado &lt;- 1:10 %&gt;%\n  sum() %&gt;%\n  sqrt()\n\nresultado\n\n[1] 7.416198\n\n\nEste exemplo alcan√ßa o mesmo resultado que o anterior, mas usa o operador %&gt;% do pacote magrittr."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#diferen√ßas-e-considera√ß√µes",
    "href": "content/manipulacao-dados-R/pipe.html#diferen√ßas-e-considera√ß√µes",
    "title": "Operadores pipe",
    "section": "3 Diferen√ßas e Considera√ß√µes",
    "text": "3 Diferen√ßas e Considera√ß√µes\n\n3.1 Suporte a Placeholder\nUma diferen√ßa chave √© que %&gt;% suporta placeholders (.), que podem ser √∫teis para pipelines mais complexos.\n\n# Usando placeholder com %&gt;%\nresultado &lt;- 1:10 %&gt;%\n  sum() %&gt;%\n  { . / 2 } %&gt;%\n  sqrt()\n\nresultado\n\n[1] 5.244044\n\n\nO operador pipe nativo |&gt; n√£o suporta placeholders diretamente.\nUsando o pipe nativo, a mesma express√£o ficaria:\n\nresultado &lt;- 1:10 |&gt;\n  sum() |&gt;\n  (\\(x) x / 2)() |&gt;  # Esta linha √© similar √†: `(function(x) x / 2)()`\n  sqrt()\n\nPortanto, torna-se necess√°rio declarar uma fun√ß√£o dentro da sequ√™ncia se comandos."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#tratamento-de-erros-e-depura√ß√£o",
    "href": "content/manipulacao-dados-R/pipe.html#tratamento-de-erros-e-depura√ß√£o",
    "title": "Operadores pipe",
    "section": "4 Tratamento de Erros e Depura√ß√£o",
    "text": "4 Tratamento de Erros e Depura√ß√£o\nO operador %&gt;% do magrittr fornece mensagens de erro mais detalhadas e melhores capacidades de depura√ß√£o. Se voc√™ encontrar um erro em um pipeline usando |&gt;, a mensagem de erro pode ser menos informativa em compara√ß√£o com o uso de %&gt;%."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#desempenho",
    "href": "content/manipulacao-dados-R/pipe.html#desempenho",
    "title": "Operadores pipe",
    "section": "5 Desempenho",
    "text": "5 Desempenho\nAmbos os operadores pipe t√™m desempenho semelhante na maioria dos casos. No entanto, |&gt; por ser parte do R base, pode ter ligeiras vantagens de desempenho em alguns cen√°rios devido √† sua integra√ß√£o com a linguagem principal."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#quando-usar-operadores-pipe",
    "href": "content/manipulacao-dados-R/pipe.html#quando-usar-operadores-pipe",
    "title": "Operadores pipe",
    "section": "6 Quando usar operadores pipe",
    "text": "6 Quando usar operadores pipe\nTanto o operador pipe nativo |&gt; quanto o operador %&gt;% do magrittr s√£o ferramentas poderosas para escrever c√≥digo R limpo e leg√≠vel. A escolha entre eles depende de suas necessidades espec√≠ficas e prefer√™ncias. Se voc√™ precisa de suporte a placeholders e depura√ß√£o aprimorada, %&gt;% √© uma boa escolha. Para uma depend√™ncia mais leve e potencialmente melhor desempenho, |&gt; √© uma op√ß√£o s√≥lida. A seguir algumas sugest√µes para a escolha entre os operadores.\n\nLeitura e Legibilidade: Use operadores pipe quando voc√™ deseja aumentar a legibilidade do c√≥digo. Eles ajudam a encadear opera√ß√µes de forma linear, tornando o fluxo de dados claro e f√°cil de seguir.\n\n\nresultado &lt;- dados %&gt;%\n  filter(variavel1 &gt; 10) %&gt;%  # Filtra os dados\n  mutate(nova_variavel = variavel2 * 2) %&gt;%  # insere `nova_variavel` no data frame\n  summarise(media = mean(nova_variavel))  # extrai a m√©dia da `nova_variavel`\n\n\nTransforma√ß√µes Sequenciais: Use operadores pipe quando voc√™ precisa aplicar uma s√©rie de transforma√ß√µes sequenciais nos dados. Eles permitem que voc√™ evite a cria√ß√£o de vari√°veis tempor√°rias.\n\n\nresultado &lt;- dados |&gt;\n  filter(variavel1 &gt; 10) |&gt;\n  mutate(nova_variavel = variavel2 * 2) |&gt;\n  summarise(media = mean(nova_variavel))\n\n# Sem o operador pipe, esta sequ√¢ncia de c√≥digos poderia ficar:\nres1 &lt;- filter(dados, vari√°vel1 &gt; 10)\nres2 &lt;- mutate(res1, nova_variavel = variavel2 * 2)\nresultado &lt;- summarise(res2, media = mean(nova_variavel))\n\n\nConsist√™ncia de Sintaxe: Utilize pipes para manter uma sintaxe consistente em todo o seu c√≥digo, especialmente se voc√™ estiver trabalhando em um projeto colaborativo onde a consist√™ncia de estilo √© importante.\nSimplifica√ß√£o de Fun√ß√µes Aninhadas: Empregue operadores pipe para simplificar a leitura de fun√ß√µes aninhadas, evitando a necessidade de m√∫ltiplos par√™nteses.\n\n\nresultado &lt;- sqrt(sum(1:10))\n\n# versus\n\nresultado_pipe &lt;- 1:10 |&gt;\n  sum() |&gt;\n  sqrt()\n\n\nresultado\n\n[1] 7.416198\n\nresultado_pipe\n\n[1] 7.416198\n\n\n\nCodifica√ß√£o Explorativa e Prototipagem R√°pida: Use pipes durante a explora√ß√£o de dados e prototipagem r√°pida, pois eles permitem que voc√™ altere e teste rapidamente diferentes transforma√ß√µes."
  },
  {
    "objectID": "content/manipulacao-dados-R/pipe.html#quando-n√£o-usar-operadores-pipe",
    "href": "content/manipulacao-dados-R/pipe.html#quando-n√£o-usar-operadores-pipe",
    "title": "Operadores pipe",
    "section": "7 Quando N√£o Usar Operadores Pipe",
    "text": "7 Quando N√£o Usar Operadores Pipe\n\nSimplicidade Excessiva: Evite usar operadores pipe para opera√ß√µes extremamente simples onde o uso de pipes n√£o adiciona clareza. Por exemplo, sum(1:10) √© mais claro sem o pipe.\nDepura√ß√£o de C√≥digo: N√£o use pipes se voc√™ est√° tendo dificuldades para depurar uma sequ√™ncia de opera√ß√µes. Em vez disso, atribua resultados intermedi√°rios a vari√°veis tempor√°rias para inspecion√°-los.\n\n\npasso1 &lt;- filter(dados, variavel1 &gt; 10)\npasso2 &lt;- mutate(passo1, nova_variavel = variavel2 * 2)\nresultado &lt;- summarise(passo2, media = mean(nova_variavel))\n\n\nOpera√ß√µes Complexas com V√°rias Etapas: Evite usar pipes em opera√ß√µes muito complexas que envolvem v√°rias etapas interdependentes, onde a clareza do c√≥digo pode ser comprometida. Por exemplo se voc√™ precisa manipular dois data frames independentes e depois un√≠-los, fazer isso em uma √∫nica sequencia de operadores pipe pode tornar o c√≥digo dif√≠cil de interpretar.\n\n\n# Criando exemplos de data frames\ndados1 &lt;- data.frame(\n  categoria = rep(c(\"A\", \"B\", \"C\"), each = 4),\n  variavel1 = rnorm(12, mean = 6, sd = 2)\n)\n\ndados2 &lt;- data.frame(\n  categoria = rep(c(\"A\", \"B\", \"C\"), each = 4),\n  variavel2 = rnorm(12, mean = 10, sd = 5)\n)\n\nlibrary(dplyr)\n# Opera√ß√µes complexas em uma √∫nica sequ√™ncia de operadores pipe\nresultado &lt;- dados1 |&gt;\n  group_by(categoria) |&gt;\n  summarise(media_variavel1 = mean(variavel1)) |&gt;\n  inner_join(\n    dados2 |&gt; \n      group_by(categoria) |&gt; \n      summarise(soma_variavel2 = sum(variavel2)),\n    by = \"categoria\"\n  ) |&gt;\n  mutate(nova_variavel = soma_variavel2 / media_variavel1) |&gt;\n  arrange(desc(nova_variavel))\n\nresultado\n\n# A tibble: 3 √ó 4\n  categoria media_variavel1 soma_variavel2 nova_variavel\n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1 A                    5.79           27.6          4.77\n2 C                    5.41           25.4          4.70\n3 B                    5.74           24.6          4.28\n\n\nO exemplo acima pode ser reescrito de forma que cada etapa tenha uma leitura mais clara.\n\n# Passo 1: Filtrar e resumir dados1\nresumo_dados1 &lt;- dados1 |&gt;\n  group_by(categoria) |&gt;\n  summarise(media_variavel1 = mean(variavel1))\n\n# Passo 2: Filtrar e resumir dados2\nresumo_dados2 &lt;- dados2 |&gt;\n  group_by(categoria) |&gt;\n  summarise(soma_variavel2 = sum(variavel2))\n\n# Passo 3: Unir os resultados dos dois data frames\nresultado_unido &lt;- inner_join(resumo_dados1, \n                                     resumo_dados2, \n                                     by = \"categoria\")  |&gt;  \n  mutate(nova_variavel = soma_variavel2 / media_variavel1) |&gt;\n  arrange(desc(nova_variavel))\n\nresultado_unido\n\n# A tibble: 3 √ó 4\n  categoria media_variavel1 soma_variavel2 nova_variavel\n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1 A                    5.79           27.6          4.77\n2 C                    5.41           25.4          4.70\n3 B                    5.74           24.6          4.28\n\n\nEmbora o c√≥digo tenha ficado mais longo, fica tamb√©m mais simples de ser inspecionado.\n\nDesempenho Cr√≠tico: Se voc√™ est√° preocupado com o desempenho cr√≠tico e a efici√™ncia, pode ser melhor evitar pipes, j√° que eles podem adicionar alguma sobrecarga.\nAmbiguidade de Fun√ß√µes: Evite pipes se o uso deles torna a ordem das opera√ß√µes ou a origem dos dados amb√≠gua. Certifique-se de que a sequ√™ncia de opera√ß√µes √© clara e l√≥gica."
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html",
    "href": "content/manipulacao-dados-R/import-export.html",
    "title": "Importando/Exportando dados",
    "section": "",
    "text": "O pacote respons√°vel pela importa√ß√£o de dados no tidyverse √© o readr. Este pacote permite importar arquivos de texto nos formatos .csv ou .txt.\nExistem diversas fun√ß√µes no pacote readr(veja aqui). A fun√ß√£o read_csv() importa arquivos texto em que as colunas s√£o separadas por v√≠rgulas. A fun√ß√£o read_tsv() importa arquivos texto em que as colunas s√£o separadas por tabula√ß√µes."
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html#importando-dados-de-arquivos-texto",
    "href": "content/manipulacao-dados-R/import-export.html#importando-dados-de-arquivos-texto",
    "title": "Importando/Exportando dados",
    "section": "1 Importando dados de arquivos texto",
    "text": "1 Importando dados de arquivos texto\nA fun√ß√£o read_delim() oferece mais controle sobre o tipo de delimitador de colunas (v√≠rgulas, tabula√ß√µes, ponto-e-v√≠rgula, entre outros) ou o identificador decimal (v√≠rgulas ou ponto).\nCarrege o pacote readr e importe o arquivo Reservatorios_Parana_parcial.csv dispon√≠vel no reposit√≥rio datasets do . √â poss√≠vel importar o arquivo diretamente do reposit√≥rio:\n\nlibrary(readr)\nres = read_delim(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n                  delim = ',',\n                  locale = locale(decimal_mark = '.',\n                                  encoding = 'latin1'))\n\n\n\n\n\n\n\nNota\n\n\n\nSe optar por fazer o download do arquivo, basta acessar pelo link (Reservatorios_Parana_parcial.csv), salv√°-lo em seu diret√≥rio de trabalho e importar com o comando:\n\nres = read_delim(file = \"Reservatorios_Parana_parcial.csv.csv\", delim = \",\")\n\n\n\nVerifique o objeto importado.\n\nres\n\n# A tibble: 31 √ó 11\n   Reservatorio Bacia  Fechamento   Area Trofia    pH Condutividade Alcalinidade\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n 1 Cavernoso    Iguacu       1965   2.9  Oligo‚Ä¶   7.4          33.1        140. \n 2 Curucaca     Iguacu       1982   2    Oligo‚Ä¶   7            32.4        126. \n 3 Foz do Areia Iguacu       1980 139    Oligo‚Ä¶   7.3          35.5         97  \n 4 Irai         Iguacu       2000  15    Eutr√É‚Ä¶   6.9          50.2          3.3\n 5 JMF          Iguacu       1970   0.45 Mesot‚Ä¶   7.3          40.2          3.7\n 6 Jordao       Iguacu       1996   3.4  Oligo‚Ä¶   7.1          23.7        153. \n 7 Passauna     Iguacu       1978  14    Oligo‚Ä¶   8.8         126.         526  \n 8 Piraquara    Iguacu       1979   3.3  Oligo‚Ä¶   7.1          22.8         50.7\n 9 Salto Caxias Iguacu       1998 124    Oligo‚Ä¶   7.3          39.6        106  \n10 Salto do Vau Iguacu       1959   2.9  Oligo‚Ä¶   6.5          23.2        279  \n# ‚Ñπ 21 more rows\n# ‚Ñπ 3 more variables: P.total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, CPUE &lt;dbl&gt;\n\n\nO objeto √© do tipo tibble com 31 linhas por 11 colunas. Uma tibble √© uma vers√£o moderna do data.frame que preserva aspectos eficazes para manipula√ß√£o, visualiza√ß√£o e transforma√ß√£o de dados.\n\nclass(res)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""
  },
  {
    "objectID": "content/manipulacao-dados-R/import-export.html#exportando-um-data-frame",
    "href": "content/manipulacao-dados-R/import-export.html#exportando-um-data-frame",
    "title": "Importando/Exportando dados",
    "section": "2 Exportando um data frame",
    "text": "2 Exportando um data frame\nA fun√ß√£o para exportar data frames no pacote readr √© write_delim() e outras fun√ß√µes an√°logas. Para exportar uma parte do data frame utiliza-se o comando:\n\nwrite_delim(res[1:10, 3:5],\n            file = \"Reservatorios_Parana_parcial.csv\", \n            delim = ',')"
  },
  {
    "objectID": "content/anova/anova-simples.html",
    "href": "content/anova/anova-simples.html",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nsource('scripts/anova-sim.r')\nA An√°lise de Vari√¢ncia (ANOVA) desenvolvida por R. A. Fisher aplica-se √† uma classe de desenho experimental em que a vari√°vel resposta \\(Y\\) √© cont√≠nua e a vari√°vel explanat√≥ria \\(X\\) √© categ√≥rica com \\(2\\) ou mais n√≠veis. A ANOVA nos permite testar a hip√≥tese de que duas ou mais m√©dias amostrais (\\(\\overline{Y}_i\\)) tenham sido obtidas de uma mesma popula√ß√£o estat√≠stica com m√©dia \\(\\mu\\). Alternativamente, podemos concluir que as m√©dias amostrais diferem umas das outras, de tal forma que devemos assumir que foram amostradas a partir de diferentes popula√ß√µes estat√≠sticas, nas quais ao menos um \\(\\mu_i\\) seja diferente dos demais. Iremos denominar estas duas possibilidades de hip√≥tese estat√≠sticas sobre a rela√ß√£o entre as m√©dias populacionais."
  },
  {
    "objectID": "content/anova/anova-simples.html#o-modelo-da-anova-e-as-hip√≥teses-estat√≠sticas",
    "href": "content/anova/anova-simples.html#o-modelo-da-anova-e-as-hip√≥teses-estat√≠sticas",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "1 O modelo da ANOVA e as hip√≥teses estat√≠sticas",
    "text": "1 O modelo da ANOVA e as hip√≥teses estat√≠sticas\nO modelo pode ser representado por:\n\\[Y_{ij} = \\mu + A_i + \\epsilon_{ij}\\]\nonde \\(Y_{ij}\\) √© a vari√°vel resposta associada √† observa√ß√£o \\(i\\) do tratamento \\(j\\), \\(\\mu\\) representa a m√©dia geral e \\(A_i\\) o efeito do tratamento \\(i\\). O termo \\(\\epsilon_{ij}\\) √© denominado de res√≠duo (ou erro) associado a cada observa√ß√£o, que assumimos ter distribui√ß√£o normal com m√©dia zero e vari√¢ncia constante.\n\\[\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\\]\n\n\n\n\n\n\nHip√≥teses estat√≠sticas no modelo de ANOVA\n\n\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 =.... = \\mu_k\\) (HIP√ìTESE NULA)\n\\(H_a\\): ao menos um par de m√©dias √© diferente (HIP√ìTESE ALTERNATIVA)\n\n\nA hip√≥tese nula (\\(H_0\\)) define a aus√™ncia de diferen√ßas entre as m√©dias populacionais enquanto a hip√≥tese alternativa (\\(H_a\\)) refere-se a qualquer possibilidade diferente de \\(H_0\\). Se temos exatamente dois n√≠veis em \\(X\\), a compara√ß√£o de m√©dias pode ser feita por meio de um teste \\(t\\). Por outro lado, quando temos mais de dois n√≠veis em \\(X\\), devemos utilizar o modelo de ANOVA."
  },
  {
    "objectID": "content/anova/anova-simples.html#parti√ß√£o-das-soma-dos-quadrados",
    "href": "content/anova/anova-simples.html#parti√ß√£o-das-soma-dos-quadrados",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "2 Parti√ß√£o das Soma dos Quadrados",
    "text": "2 Parti√ß√£o das Soma dos Quadrados\nAo representarmos a distribui√ß√£o de uma vari√°vel \\(Y\\) cont√≠nua em fun√ß√£o de uma vari√°vel \\(X\\) categ√≥rica, geralmente estamos interessados em determinar se os diferentes n√≠veis de \\(X\\) (diferentes grupos) t√™m m√©dias similares ou se ao menos um dos n√≠veis t√™m m√©dia diferente dos demais. Queremos uma medida que nos permita diferenciar situa√ß√µes como as apresentadas abaixo.\n\n\n\n\n\n\n\n\n\nNa figura \\(A\\) todos os grupos s√£o provenientes da mesma distribui√ß√£o e t√™m m√©dias aproximadamente iguais (\\(\\overline{Y}_A \\approx  \\overline{Y}_B \\approx \\overline{Y}_C \\approx \\overline{Y}_D\\)) e as diferen√ßas s√£o provinientes unicamente da variabilidade amostral. Na figura \\(B\\) o segundo grupo tem m√©dia mais elevada que os demais, enquanto na figura \\(C\\), todas as m√©dias parecem ser diferentes entre si (\\(\\overline{Y}_A \\ne  \\overline{Y}_B \\ne \\overline{Y}_C \\ne \\overline{Y}_D\\)).\nPara mensurar o grau de associa√ß√£o entre \\(Y\\) e \\(X\\) de modo a diferenciar as situa√ß√µes acima, vamos introduzir o processo de Parti√ß√£o da Soma dos Quadrados.\nSuponha a situ√ß√£o abaixo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota√ß√µes\n\n\n\n\nTemos \\(k = 3\\) grupos (A, B ou C) e para cada grupo \\(n =  5\\) observa√ß√µes. Denotamos por \\(n_{ij}\\) o n√∫mero de observa√ß√µes dentro de cada grupo, em que \\(i\\) √© a i-√©sima observa√ß√£o (\\(i = 1\\) a \\(5\\)) do j-√©simo grupo (\\(j = 1\\) a \\(3\\) - grupos A ao C). Neste exemplo, o n√∫mero de observa√ß√µes em cada grupo √© o mesmo (\\(n_1 = n_2 = n_3 = n\\)), de modo que o total de observa√ß√µes √© dado por:\n\n\\(N = k \\times n = n_1 + n_2 + n_3 = 15\\)\n\nA m√©dia de cada grupo ser√° denotada por \\(\\overline{Y}_j\\), que neste exemplo s√£o: \\(Y_1 = 20.64\\) (grupo A), \\(Y_2 = 28.68\\) (grupo B) e \\(Y_3 = 12.18\\) (grupo C).\nVamos denotar por \\(\\overline{\\overline{Y}}\\) a Grande M√©dia, isto √©, a m√©dia geral de todas as observa√ß√µes independente do grupo de origem.\n\n\\[\\overline{\\overline{Y}} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}\\frac{Y_{ij}}{N} = \\frac{\\overline{Y_1} + \\overline{Y_2} + \\overline{Y_3}}{3} = 20.5\\]\n\n\nPodemos agora observar estes elementos no gr√°fico de dispers√£o.\n\n\n\n\n\n\n\n\n\nEm seguida, precisamos calcular \\(3\\) quantias, a Soma dos Quadrados Totais (\\(SQ_{Total}\\)), a Soma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\) e a Soma dos Quadrados dos Res√≠duos \\(SQ_{Res}\\).\n\nSoma dos Quadrados Totais \\(SQ_{Total}\\): mede as diferen√ßas entre \\(Y_{ij}\\) e \\(\\overline{\\overline{Y}}\\). Temos nesta express√£o o somat√≥rio dos desvios ao quadrado de todas as observa√ß√µes com rela√ß√£o √† grande m√©dia independente do grupo de origem de cada observa√ß√£o.\n\n\\[SQ_{Total} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\): mede as diferen√ßas entre as m√©dias dos tratamentos \\(\\overline{Y}_j\\) e \\(\\overline{\\overline{Y}}\\), sendo portanto os desvios ao quadrado da m√©dia de cada tratamento subtra√≠da da grande m√©dia. \\(SQ_{Trat}\\) tamb√©m √© chamada de soma dos quadrados entre grupos ou entre tratamentos\n\n\\[SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Res√≠duos \\(SQ_{Res}\\): mede as diferen√ßas entre cada observa√ß√£o \\(Y_{ij}\\) e a m√©dia de seu pr√≥prio grupo \\(\\overline{Y}_{j}\\). \\(SQ_{Res}\\) tamb√©m √© chamada de soma dos quadrados dentro dos grupos ou dentro dos tratamentos\n\n\\[SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2\\]\n\n\n\n\n\n\nA caracter√≠stica aditiva das somas dos quadrados\n\n\n\nA parti√ß√£o da soma dos quadrados consiste em decompor a varia√ß√£o total do experimento em uma parcela atribu√≠da √† varia√ß√£o entre tratamentos e outra parcela da varia√ß√£o dentro dos tratamentos. Isto √© poss√≠vel pois as somas dos quadrados definidas acima podem ser expressas de forma aditiva como:\n\\[SQ_{Total} = SQ_{Trat} + SQ_{Res}\\]\nDeste modo, √© poss√≠vel demostrar que:\n\\(\\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(Y_{j} - \\overline{\\overline{Y}})^2 + \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{Y}_{j})^2\\)"
  },
  {
    "objectID": "content/anova/anova-simples.html#medindo-a-associa√ß√£o-entre-y-e-x",
    "href": "content/anova/anova-simples.html#medindo-a-associa√ß√£o-entre-y-e-x",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "3 Medindo a associa√ß√£o entre \\(Y\\) e \\(X\\)",
    "text": "3 Medindo a associa√ß√£o entre \\(Y\\) e \\(X\\)\nA caracter√≠stica aditiva das somas dos quadrados pode ser utilizada para mensurar o grau de depend√™ncia de \\(Y_{ij}\\) com respeito aos diferentes tratamentos. Compare as duas figuras abaixo:\n\n\n\n\n\n\n\n\n\nA soma dos quadrados dentro dos grupos √© a mesma nas duas figuras (\\(SQ_{Res} = 362.6\\)). No entanto, na figura da esquerda, em que as m√©dias dos tratamentos s√£o similares (e consequentemente pr√≥ximas √† grande m√©dia), a soma dos quadrados entre os tratamentos √© muito menor (\\(SQ_{Trat}^{esquerda} = 15.8\\)) que na figura da direita, em que as m√©dias dos tratamentos est√£o distantes entre si (\\(SQ_{Trat}^{direita} = 680.8\\)). √â desta forma que a parti√ß√£o das somas dos quadrados nos permite diferenciar situa√ß√µes em que: i - a m√©dia dos grupos depende dos n√≠veis do tratamento (figura da direita); de situa√ß√µes em que ii - a m√©dia n√£o depende dos n√≠veis do tratamento (figura da esquerda)."
  },
  {
    "objectID": "content/anova/anova-simples.html#quadrados-m√©dios-e-graus-de-liberdade",
    "href": "content/anova/anova-simples.html#quadrados-m√©dios-e-graus-de-liberdade",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "4 Quadrados m√©dios e graus de liberdade",
    "text": "4 Quadrados m√©dios e graus de liberdade\nPara que os somat√≥rios dos quadrados expressem uma medida de varia√ß√£o √© necess√°rio corrigi-los em fun√ß√£o dos graus de liberdade (\\(gl\\)), obtendo assim os Quadrados m√©dios conforme abaixo:\n\nQuadrado M√©dio Total (\\(QM_{Total}\\))\n\n\\[QM_{Total} = \\frac{SQ_{Total}}{gl_{Total}}\\]\nem que \\(gl_{Total} = N - 1\\)\n\nQuadrado M√©dio dos Tratamentos (\\(QM_{Trat}\\))\n\n\\[QM_{Trat} = \\frac{SQ_{Trat}}{gl_{Trat}}\\]\nem que \\(gl_{Trat} = k - 1\\)\n\nQuadrado M√©dio dos Res√≠duos (\\(QM_{Res}\\))\n\n\\[QM_{Res} = \\frac{SQ_{Res}}{gl_{Res}}\\]\nem que \\(gl_{Res} = N-k\\)\nAssim como a soma dos quadrados, os graus de liberdade tamb√©m t√™m caracter√≠stica aditiva.\n\\[gl_{Total} = gl_{Trat} + gl_{Res} = (k - 1) + (N - K) = N - 1\\]\nOs quadrados m√©dios que s√£o estimativas de vari√¢ncias. Compare por exemplo a express√£o do \\(QM_{Total}\\) com a f√≥rmula da vari√¢ncia amostral (\\(s^2\\)) e ver√° que excetuando mudan√ßas de nota√ß√£o, as express√µes s√£o essencialmente as mesmas."
  },
  {
    "objectID": "content/anova/anova-simples.html#estat√≠stica-f-e-teste-de-hip√≥teses",
    "href": "content/anova/anova-simples.html#estat√≠stica-f-e-teste-de-hip√≥teses",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "5 Estat√≠stica \\(F\\) e teste de hip√≥teses",
    "text": "5 Estat√≠stica \\(F\\) e teste de hip√≥teses\nUma vez que os quadrados m√©dios s√£o estimativas de vari√¢ncia, uma estat√≠stica de teste apropriada √©:\n\\[F_{calculado} = \\frac{QM_{Trat}}{QM_{Res}}\\]\nA estat√≠stica \\(F\\) (ou raz√£o-\\(F\\)) est√° associada √† distribui√ß√£o de probabilidades \\(F\\) e nos permite comparar a vari√¢ncia associada ao tratamento com a vari√¢ncia associada aos res√≠duos. Com o valor de \\(F_{calculado}\\), o teste de hip√≥teses √© poss√≠vel ap√≥s a defini√ß√£o do n√≠vel de signific√¢ncia \\(\\alpha\\).\n\n5.1 N√≠vel de signific√¢ncia\nAssim como discutimos nos testes \\(Z\\) e \\(t\\), o valor de \\(\\alpha\\) estabelece um limite de aceita√ß√£o para \\(H_0\\), isto √©, um limite a partir do qual a estat√≠stica do teste se torna t√£o extrema que nos leva a assumir que \\(H_0\\) √© improv√°vel, devendo portanto ser rejeitada em favor de \\(H_a\\). Este passo √© poss√≠vel pois o valor de \\(F_{calculado}\\) pode ser associado √† distribui√ß√£o \\(F\\) de probabilidades, o que nos permite calcular a probabilidade:\n\\[P(F_{calculado}) \\le \\alpha\\]\nPara facilitar a nota√ß√£o denominaremos \\(P(F_{calculado})\\) simplesmente de valor de \\(p\\) expresso em vermelho na figura abaixo:\n\n\n\n\n\n\nTomada de decis√£o na ANOVA\n\n\n\nSe \\(p &gt; \\alpha\\) ‚Äì&gt; ACEITAMOS \\(H_0\\)\nSe \\(p \\le \\alpha\\) ‚Äì&gt; REJEITAMOS \\(H_0\\) (e assumimos \\(H_a\\) como verdadeira)\n\n\n\n\n\n\n\n\n\n\n\nTradicionalmente utiliza-se \\(\\alpha = 0.05\\). Neste caso, \\(H_0\\) seria rejeitada somente de \\(p \\le 0.05\\). Em algumas situa√ß√µes podemos utilizar \\(\\alpha = 0.01\\), o que torna o experimento mais rigoroso, isto √©, menos propenso ao erro do tipo I."
  },
  {
    "objectID": "content/anova/anova-simples.html#um-exemplo-de-anova-os-n√≠veis-de-metais-pesados-afetam-a-diversidade-de-esp√©cies",
    "href": "content/anova/anova-simples.html#um-exemplo-de-anova-os-n√≠veis-de-metais-pesados-afetam-a-diversidade-de-esp√©cies",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "6 Um exemplo de ANOVA: os n√≠veis de metais pesados afetam a diversidade de esp√©cies?",
    "text": "6 Um exemplo de ANOVA: os n√≠veis de metais pesados afetam a diversidade de esp√©cies?\nImporte a base de dados medley.csv (dispon√≠vel tamb√©m em Chapter 10 - Single factor classification (ANOVA)) que avalia o impacto da presen√ßa de metais pesados na diversidade de esp√©cies de diatom√°cias em riachos (Medley e Clements (1998); Queen, Quinn, e Keough (2002); Logan (2011)).\n\nmedley = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/medley.csv\") |&gt; \n  mutate(STREAM = factor(STREAM),\n         ZINC = factor(ZINC, ordered = TRUE,\n                       levels = c(\"BACK\", \"LOW\", \"MED\", \"HIGH\")))\nvar_medley = colnames(medley)\nstream_levels = levels(medley$STREAM)\nn_stream = nlevels(medley$STREAM)\nzinc_levels = levels(medley$ZINC)\nn_zinc = nlevels(medley$ZINC)\n\n\nmedley |&gt; gt()\n\n\n\n\n\n\n\nSTREAM\nZINC\nDIVERSITY\n\n\n\n\nEagle\nBACK\n2.27\n\n\nEagle\nHIGH\n1.25\n\n\nEagle\nHIGH\n1.15\n\n\nEagle\nMED\n1.62\n\n\nBlue\nBACK\n1.70\n\n\nBlue\nHIGH\n0.63\n\n\nBlue\nBACK\n2.05\n\n\nBlue\nBACK\n1.98\n\n\nBlue\nHIGH\n1.04\n\n\nBlue\nMED\n2.19\n\n\nBlue\nMED\n2.10\n\n\nSnake\nBACK\n2.20\n\n\nSnake\nMED\n2.06\n\n\nSnake\nHIGH\n1.90\n\n\nSnake\nHIGH\n1.88\n\n\nSnake\nHIGH\n0.85\n\n\nArkan\nLOW\n1.40\n\n\nArkan\nLOW\n2.18\n\n\nArkan\nLOW\n1.83\n\n\nArkan\nLOW\n1.88\n\n\nArkan\nMED\n2.02\n\n\nArkan\nMED\n1.94\n\n\nArkan\nLOW\n2.10\n\n\nChalk\nLOW\n2.38\n\n\nChalk\nHIGH\n1.43\n\n\nChalk\nHIGH\n1.37\n\n\nChalk\nMED\n1.75\n\n\nChalk\nLOW\n2.83\n\n\nSplat\nBACK\n1.53\n\n\nSplat\nBACK\n0.76\n\n\nSplat\nMED\n0.80\n\n\nSplat\nLOW\n1.66\n\n\nSplat\nMED\n0.98\n\n\nSplat\nBACK\n1.89\n\n\n\n\n\n\n\nA coluna STREAM √© uma vari√°vel categ√≥rica contendo o nome dos \\(6\\) riachos amostrados (Arkan, Blue, Chalk, Eagle, Snake, Splat). A coluna ZINC √© uma vari√°vel categ√≥rica ordinal com \\(4\\) n√≠veis de concentra√ß√£o de zinco na √°gua (BACK &lt; LOW &lt; MED &lt; HIGH). O primeiro n√≠vel (BACK) √© o n√≠vel de refer√™ncia. Finalmente, a coluna DIVERSITY √© uma vari√°vel cont√≠nua que cont√©m a diversidade de diatom√°cieas medida pelo √≠ndice de Shannon em cada uma das 34 amostras.\nVamos nos concentrar nas vari√°veis DIVERSITY e ZINC. DIVERSITY ser√° a vari√°vel resposta. Dizemos que ZINC √© um tratamento, isto √©, uma condi√ß√£o experimental (ou observacional) sob a qual a vari√°vel dependente \\(Y\\) foi medida.\nPara verificarmos a distribui√ß√£o de diversidade para cada concentra√ß√£o de zinco vamos fazer um boxplot da vari√°vel DIVERSITY em fun√ß√£o de ZINC.\n\n\nC√≥digo\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\nVemos que a concentra√ß√£o HIGH aparenta ter menor diversidade que as demais concentral√ß√µes. A ANOVA nos permitir√° testar esta suposi√ß√£o.\n\n\n\n\n\n\nHip√≥pteses estat√≠sticas\n\n\n\n\\(H_0: \\mu_{BACK} = \\mu_{LOW} = \\mu_{MED}  = \\mu_{HIGH}\\)\n\\(H_a\\): ao menos um \\(\\mu\\) √© diferente\n\\(\\alpha = 0.05\\)\n\n\n\n6.1 Calculando a ANOVA\ni. Somat√≥rios dos quadrados\n\\(SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = 2.5666124\\)\n\\(SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2 = 6.5164111\\)\nii. Graus de liberdade\n\\(gl_{Trat} = k - 1 = 3\\)\n\\(gl_{Res} = N-k = 30\\)\niii. Quadrados m√©dios\n\\(QM_{Trat} = \\frac{SQ_{Trat}}{gl_{Trat}} = 0.8555375\\)\n\\(QM_{Res} = \\frac{SQ_{Res}}{gl_{Res}} = 0.2172137\\)\niv. Estat√≠stica \\(F\\)\n\\(F_{calculado} = \\frac{QM_{Trat}}{QM_{Res}} = 3.939\\)\n\n\n\n\n\n\nTabela da ANOVA**\n\n\n\nAs quantias acima s√£o tradicionalmente expressas em uma Tabela de ANOVA.\n\n\nC√≥digo\naov_ex = aov(DIVERSITY ~ ZINC, data = medley)\nanova_ex = anova(aov_ex)\n\n\n\n\n\n\nTabela¬†1: Tabela da ANOVA para a base de dados medley.\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\n3\n2.566612\n0.8555375\n3.93869\n0.01755956\n\n\n30\n6.516411\n0.2172137\nNA\nNA\n\n\n\n\n\n\n\n\n\n\nem que:\nDf: graus de liberdade\nSum Sq: soma dos quadrados\nMean Sq: quadrados m√©dios\nF value: valor de \\(F_{calculado}\\)\nPr(&gt;F): valor de p\nA primeira linha refere-se aos valores associados aos tratamentos e a segunda linha aos res√≠duos. Note que o c√¥mputo de \\(SQ_{Total}\\), \\(gl_{Total}\\) e \\(QM_{Total}\\) n√£o √© realmente necess√°rio.\n\n\nO valor de \\(p = 0.0175596\\) mostrado na Tabela¬†1 refere-se √† √°rea na distribui√ß√£o \\(F\\) que fica acima de \\(F_{calculado}\\) e que est√° representado em vermelho na Figura¬†1.\n\n\n\n\n\n\n\n\nFigura¬†1: Distribui√ß√£o F com indica√ß√£o do valor de p.\n\n\n\n\n\nAo verificar que \\(p \\le \\alpha\\), nossa conclus√£o deve ser de REJEITAR \\(H_0\\), pois \\(F_{calculado}\\) √© muito extremo para ser resultante da hip√≥tese nula. Neste caso, assumimos que a \\(H_a\\) √© mais condizente com a estrutura dos dados, de modo que os tratamentos devem ser provenientes de popula√ß√µes estat√≠sticas com diferentes m√©dias \\(\\mu\\)."
  },
  {
    "objectID": "content/anova/anova-simples.html#testes-a-posteriori-de-compara√ß√£o-de-m√©dias-o-teste-de-tukey",
    "href": "content/anova/anova-simples.html#testes-a-posteriori-de-compara√ß√£o-de-m√©dias-o-teste-de-tukey",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "7 Testes a posteriori de compara√ß√£o de m√©dias: o teste de Tukey",
    "text": "7 Testes a posteriori de compara√ß√£o de m√©dias: o teste de Tukey\nTendo rejeitado \\(H_0\\) conclu√≠mos que ao menos 1 par m√©dias √© diferente entre si. Nos resta saber quais pares s√£o estatisticamente diferentes, o que nos leva a buscar por um teste que permita fazer compara√ß√µes par-a-par. Os testes a posteriori s√£o uma alternativa.\nEntre os diferentes testes a posteriori na literatura discutiremos o teste de Tukey, em que o objetivo √© estabelecer uma Diferen√ßa Honesta Significativa (DHS) entre um dado par de m√©dias. Considerando a diferen√ßa entre um par de m√©dias e o erro padr√£o das diferen√ßas de m√©dias, a estat√≠stica do teste de Tukey √©:\n\\[q = \\frac{\\overline{Y}_1 - \\overline{Y}_2}{SE}\\]\nem que:\n\\[SE = \\sqrt{\\frac{QM_{Res}}{2}(\\frac{1}{n_1} + \\frac{1}{n_2})}\\]\nonde:\n\\(q\\): √© e estat√≠stica do teste\n\\(\\overline{Y}_1\\): √© a maior das m√©dias do par consideraddo;\n\\(\\overline{Y}_2\\): √© a menor das m√©dias do par consideraddo\n\\(QM_{Res}\\): √© quadrado m√©dio do res√≠duo obtido na ANOVA, e;\n\\(n_1\\), \\(n_2\\): os tamanhos amostrais de cada grupo envolvido na compara√ß√£o.\nO valor cr√≠tico de \\(q\\) pode ser obtido de uma tabela estat√≠stica da distribui√ß√£o de amplitude normalizada (studentized range q table). Para um dado \\(\\alpha\\), o valor desejado de \\(q\\) √© encontrado cruzando a linha contento o n√∫mero \\(k\\) de tratamentos do experimento com a linha contendo os graus de liberdade do res√≠duo (\\(gl_{Res}\\)). Veja um exemplo desta tabela no link: Studentized Range q Table.\nEm nosso exemplo, os valores de \\(q\\) entre os pares de m√©dias ser√£o:\n\nTukey_tab |&gt; \n  gt() |&gt; \n  cols_label(\n    combinacoes = \"Combina√ß√µes\",\n    diff = \"Diferen√ßa\",\n    n1 = \"n1\",\n    n2 = \"n2\",\n    se = \"Erro Padr√£o\",\n    q = \"Estat√≠stica q\",\n    H0 = \"Decis√£o\"\n  ) |&gt; \n  fmt_number(\n    columns = c(diff, se, q),\n    decimals = 3\n  ) |&gt; \n  tab_style(\n    style = cell_fill(color = \"orange\"),\n    locations = cells_body(\n      columns = H0,\n      rows = q &gt;= qc\n    )\n  ) |&gt; \n  tab_options(\n    table.width = \"100%\",\n    column_labels.font.weight = \"bold\"\n  )\n\n\n\n\n\n\n\nCombina√ß√µes\nDiferen√ßa\nn1\nn2\nErro Padr√£o\nEstat√≠stica q\nDecis√£o\n\n\n\n\nLOW-BACK\n0.235\n8\n8\n0.165\n1.426\nAceita H0\n\n\nMED-BACK\n0.080\n8\n8\n0.165\n0.484\nAceita H0\n\n\nHIGH-BACK\n0.520\n9\n8\n0.160\n3.246\nAceita H0\n\n\nMED-LOW\n0.315\n9\n8\n0.160\n1.965\nAceita H0\n\n\nHIGH-LOW\n0.755\n9\n8\n0.160\n4.713\nRejeita H0\n\n\nHIGH-MED\n0.440\n9\n9\n0.155\n2.832\nAceita H0\n\n\n\n\n\n\n\nO limite cr√≠tico para o valor de \\(q\\) tabelado √© \\(q_{0.95,30,4} = 3.845\\) (veja em: Studentized Range q Table), deste modo somente a compara√ß√£o entre HIGH-LOW sugere ter m√©dias significativamente diferentes."
  },
  {
    "objectID": "content/anova/anova-simples.html#ajustando-a-anova-no-r",
    "href": "content/anova/anova-simples.html#ajustando-a-anova-no-r",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "8 Ajustando a ANOVA no R",
    "text": "8 Ajustando a ANOVA no R\nA ANOVA no R pode ser feita com o comando aov.\n\najuste = aov(DIVERSITY ~ ZINC, data = medley)\najuste\n\nCall:\n   aov(formula = DIVERSITY ~ ZINC, data = medley)\n\nTerms:\n                    ZINC Residuals\nSum of Squares  2.566612  6.516411\nDeg. of Freedom        3        30\n\nResidual standard error: 0.4660619\nEstimated effects may be unbalanced\n\n\n\n\n\n\n\n\nF√≥rmula no R\n\n\n\nA nota√ß√£o de f√≥rmula no R √© escrita como: Y ~ Xonde l√™-se \\(Y\\) √© fun√ß√£o de \\(X\\).\n\n\nO comando acima fez os c√°lculos da ANOVA, isto √©, computou as somas dos quadrados, os graus de liberdade, os quadrados m√©dios, o \\(F_{calculado}\\) e o valor de \\(p\\). Para visualizarmos a tabela da ANOVA escrevemos:\n\nanova(ajuste)\n\nAnalysis of Variance Table\n\nResponse: DIVERSITY\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nZINC       3 2.5666 0.85554  3.9387 0.01756 *\nResiduals 30 6.5164 0.21721                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote que os resultados coincidem com o que apresentamos anteriormente. Como o valor de \\(p\\) foi menor que \\(\\alpha = 0.05\\), concluimos que a ANOVA foi significativa, isto √©, indicou que ao menos um par de m√©dias difere entre si. Podemos fazer o teste a posteriori de Tukey com o comando:\n\nalfa = 0.05\nTukeyHSD(ajuste, conf.level = 1-alfa)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = DIVERSITY ~ ZINC, data = medley)\n\n$ZINC\n                 diff        lwr         upr     p adj\nLOW-BACK   0.23500000 -0.3986367  0.86863665 0.7457444\nMED-BACK  -0.07972222 -0.6955064  0.53606192 0.9847376\nHIGH-BACK -0.51972222 -1.1355064  0.09606192 0.1218677\nMED-LOW   -0.31472222 -0.9305064  0.30106192 0.5153456\nHIGH-LOW  -0.75472222 -1.3705064 -0.13893808 0.0116543\nHIGH-MED  -0.44000000 -1.0373984  0.15739837 0.2095597\n\n\nO resultado apresenta todas as compara√ß√µes poss√≠veis entre os grupos, mostrando as diferen√ßas de m√©dias, seus intervalos de confian√ßa a \\(95\\%\\) e os valores de \\(p\\), indicando quais destas diferen√ßas s√£o significativas (\\(p \\le \\alpha\\)). Nvamente, estes resultados nos permitem concluir que somente o par HIGH-LOW difere entre si, pois p adj &lt; 0.05.\nO gr√°fico abaixo facilita a visualiza√ß√£o das compara√ß√µes, sobretudo em situa√ß√µes com muitos pares de m√©dias envolvidos:\n\nplot(TukeyHSD(ajuste))\n\n\n\n\n\n\n\n\nNeste gr√°fico, s√£o consideradas estatisticamente significativas as compara√ß√µes em que o intervalo de confian√ßa n√£o inclui o zero."
  },
  {
    "objectID": "content/anova/anova-simples.html#pressupostos-da-anova",
    "href": "content/anova/anova-simples.html#pressupostos-da-anova",
    "title": "An√°lise de vari√¢ncia de um fator",
    "section": "9 Pressupostos da ANOVA",
    "text": "9 Pressupostos da ANOVA\nOs pressupostos da ANOVA s√£o:\n\nAs observa√ß√µes s√£o independentes e;\nA vari√¢ncia dos res√≠duos √© homog√™nea e;\nOs res√≠duos t√™m distribui√ß√£o normal com m√©dia \\(0\\) e vari√¢ncia consante \\(\\sigma^2\\).\n\nVamos inicialmente testar o pressuposto de homogeneidade de vari√¢ncias com um teste \\(F\\).\n\nmedley |&gt; group_by(ZINC) |&gt; \n  summarise(Var = var(DIVERSITY)) |&gt; \n  gt()\n\n\n\n\n\n\n\nZINC\nVar\n\n\n\n\nBACK\n0.2354786\n\n\nLOW\n0.1980214\n\n\nMED\n0.2530194\n\n\nHIGH\n0.1822194\n\n\n\n\n\n\n\nNote que a maior vari√¢ncia √© \\(0.2530194\\) e a menor \\(0.1822194\\).\nO teste \\(F\\) consiste em dividir a maior vari√¢ncia pela menor:\n\nvmax = medley$DIVERSITY[medley$ZINC == \"MED\"]\nvmin = medley$DIVERSITY[medley$ZINC == \"HIGH\"]\nvar.test(vmax, vmin)\n\n\n    F test to compare two variances\n\ndata:  vmax and vmin\nF = 1.3885, num df = 8, denom df = 8, p-value = 0.6534\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3132103 6.1557698\nsample estimates:\nratio of variances \n          1.388543 \n\n\nA maior vari√¢ncia foi 1.39 vezes maior que a menor vari√¢ncia e o test F sugere que esta diferen√ßa √© n√£o-significativa a \\(5\\%\\) (\\(p &lt; 0.05\\)). Isto indica que as vari√¢ncias s√£o homog√™neas.\nA verifica√ß√£o visual de que as vari√¢ncias s√£o homog√™neas pode tamb√©m ser inspecionada pelo gr√°fico de res√≠duos:\n\nplot(rstudent(ajuste) ~ fitted(ajuste), pch = 16)\nabline(h = 0, col = 2)\n\n\n\n\n\n\n\n\nEm seguida avaliamos o histograma dos res√≠duos e aplicamos um teste de normalidade (ex. teste de Shapiro-Wilk) para verificar se o pressuposto de normalidade pode ser aceito.\n\nhist(rstudent(ajuste), breaks = 10)\n\n\n\n\n\n\n\nshapiro.test(rstudent(ajuste))\n\n\n    Shapiro-Wilk normality test\n\ndata:  rstudent(ajuste)\nW = 0.96696, p-value = 0.3828\n\n\nNeste caso, o valor de \\(p &gt; 0.05\\) indica n√£o haver desvio da normalidade."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html",
    "href": "content/distribuicao-normal/distr-norm.html",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')\nT√©cnicas de estat√≠stica descritiva nos permitem entender os padr√µes resultantes de fen√¥menos que j√° aconteceram, enquanto a infer√™ncia estat√≠stica nos fornece elementos para fazer predi√ß√µes sobre o que poder√° acontecer. A predi√ß√£o se torna poss√≠vel pelo uso de modelos probabil√≠sticos, entre os quais est√° a distribui√ß√£o normal de probabilidades.\nModelos probabil√≠sticos s√£o definidos por fun√ß√µes de probabilidade e as vari√°veis descritas por estes modelos s√£o denominadas de vari√°veis aleat√≥rias. Uma vari√°vel aleat√≥ria resulta de um experimento aleat√≥rio como i) medir a altura de uma pessoa; ii) tomar a temperatura em uma cidade; ii) medir a taxa de crescimento de uma bact√©ria; etc. A quest√£o relevante nestes experimentos √© que antes de serem realizados, n√£o temos certeza sobre qual ser√£o seus resultados.\nEmbora n√£o saibamos quais ser√£o os resultados de um experimento aleat√≥rio com exatid√£o, podemos nos basear em algum modelo probabilidades para prever a chance de um resultado observado estar dentro de determinados limites. Neste sentido, o papel de um modelo probabil√≠stico √©, delimitar a incerteza ao redor dos resultados poss√≠veis de um experimento aleat√≥rio.\nAo medir a altura de uma pessoa podemos supor que, possivelmente, o resultado ficar√° abaixo de \\(1,9\\) m. Supomos isto pois temos conhecimento de que a altura de maior parte das pessoas est√° abaixo deste limite. Se quisermos atribuir um valor de probabilidade a esta suposi√ß√£o devemos:\nNeste cap√≠tulo iremos discutir pela primeira vez o modelo de distribui√ß√£o normal e aprenderemos como encontrar estas probabilidades.\nImporte a base de dados altura2022.csv\nie = read_delim(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura2022.csv\")\nA distribui√ß√£o normal de probabilidades descreve uma curva em forma de sino tamb√©m chamada de distribui√ß√£o gaussiana. Um dos motivos que a tornaram central em estat√≠stica foi a percep√ß√£o de que o comportamento de muitos fen√¥menos naturais podem ser descritos adequadamente por este modelo te√≥rico. Veja por exemplo, o histograma de alturas de \\(110\\) estudantes de uma turma de Introdu√ß√£o a Estat√≠stica do curso de Bacharelado Interdisciplinar em Ci√™ncias do Mar (UNIFESP). A linha vermelha sobre este histograma representa a distribui√ß√£o normal te√≥rica. √Ä direita desta figura est√° um histograma da temperatura m√©dia anual em uma cidade americana, onde tamb√©m foi sobreposta uma curva normal te√≥rica. Embora estes dados descrevam fen√¥menos completamente distintos, a distribui√ß√£o normal se adequa razoavelmente bem aos dois histogramas.\nFigura¬†1: Altura (m) de alunos de um curso de estat√≠stica e temperatura m√©dia anual de uma cidade americana.\nO segundo motivo que torna a distribui√ß√£o normal uma das mais importantes em estat√≠stica ser√° nosso tema de estudo neste e nos pr√≥ximos cap√≠tulos, pois a distribui√ß√£o normal surge como o modelo esperado para a distribui√ß√£o das m√©dias amostrais sob determinadas condi√ß√µes, o que nos permite utilizar uma variedade de procedimentos anal√≠ticos no campo da infer√™ncia e testes de hip√≥tese."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#o-modelo-normal-de-probabilidades",
    "href": "content/distribuicao-normal/distr-norm.html#o-modelo-normal-de-probabilidades",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "1 O modelo normal de probabilidades",
    "text": "1 O modelo normal de probabilidades\nO modelo normal de probabilidades √© uma fun√ß√£o matem√°tica dada por:\n\\[f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}, x \\in \\mathbb{R} | -\\infty \\le y \\le +\\infty\\]\nA express√£o envolve as quantias \\(\\mu\\) e \\(\\sigma\\), definidas como os par√¢metros da distribui√ß√£o que representam respectivamente, sua m√©dia e o desvio padr√£o. Para dizer que uma vari√°vel aleat√≥ria \\(X\\) tem distribui√ß√£o normal por meio da express√£o:\n\\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma)\\)\nEsta express√£o diz de \\(X\\) √© normalmente distribu√≠da (\\(\\mathcal{N}\\)) e que esta distribui√ß√£o tem par√¢metros \\(\\mu\\) e \\(\\sigma\\).\nA m√©dia de uma distribui√ß√£o normal √© o ponto central da curva e o desvio padr√£o mede o espalhamento das observa√ß√µes ao redor de \\(\\mu\\). Em um fen√¥meno descrito por valores baixos de \\(\\sigma\\), a maioria das observa√ß√µes estar√° pr√≥xima a \\(\\mu\\), enquanto para valores altos de \\(\\sigma\\) as observa√ß√µes estar√£o mais distantes de \\(\\mu\\). Deste modo, podemos alterar o formato da distribui√ß√£o normal alterando seu par√¢metro de posi√ß√£o (i.e.¬†a m√©dia \\(\\mu\\)) e de dispers√£o (i.e.¬†o desvio padr√£o \\(\\sigma\\)).\n\n\n\n\n\n\n\n\nFigura¬†2: Distribui√ß√µes normais de probabilidade para diferentes combina√ß√µes de m√©dia e desvio padr√£o.\n\n\n\n\n\nSe as observa√ß√µes sobre um determinado fen√¥meno sugerem um padr√£o em forma de sino, podemos buscar a melhor combina√ß√£o de \\(\\mu\\) e \\(\\sigma\\) e descrever o fen√¥meno por meio de um modelo normal. Ao fazer isto, a distribui√ß√£o normal nos ajuda a calcular as probabilidade da ocorr√™ncia de eventos futuros estarem em diferentes faixas de valores. No caso das alturas dos alunos por exemplo, vemos que a probabilidade de um aluno ter mais de \\(2\\) metros ou menos de \\(1,5\\) metros √© extremamente baixa. Assumindo um modelo de distribui√ß√£o normal para a distribui√ß√£o de alturas, podemos utilizar o conjunto de dados para estimar os par√¢metros da popula√ß√£o e calcular quais seriam estas probabilidades.\n\n\n\n\n\n\nUm pouco de hist√≥ria\n\n\n\nAlguns atribuem a proposi√ß√£o deste modelo normal a Abraham de Moivre, um matem√°tico Franc√™s que chegou a a distribui√ß√£o normal como uma aproxima√ß√£o a distribui√ß√£o binomial em seu livro The Doctrine of Chances em \\(1718\\). A distribui√ß√£o normal de probabilidades √© sim√©trica, ou seja, os valores extremos s√£o igualmente representados acima e abaixo da regi√£o central (m√©dia). Voc√™ poder√° encontrar o termo bell curve em ingl√™s, devido √† sua forma de sino, ou ainda distribui√ß√£o gaussiana em homenagem a Carl Friedrich Gauss um dos mais importantes matem√°ticos do s√©culo XXI. Gauss lidou com a distribui√ß√£o normal quando desenvolveu a Teoria da distribui√ß√£o dos erros observacionais no contexto do M√©todo dos M√≠nimos Quadrados em \\(1823\\)."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#entendendo-a-fun√ß√£o-normal",
    "href": "content/distribuicao-normal/distr-norm.html#entendendo-a-fun√ß√£o-normal",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "2 Entendendo a fun√ß√£o normal",
    "text": "2 Entendendo a fun√ß√£o normal\nA fun√ß√£o \\(f(x) = \\frac{1}{\\sqrt(2\\pi\\sigma^2)}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\) √© uma fun√ß√£o de densidade de probabilidade. Antes de aplicar esta distribui√ß√£o para encontrar valores de probabilidade, vamos aprender simplesmente para descrever a fun√ß√µes de densidade assumindo valores particulares de \\(\\mu\\) e \\(\\sigma\\). Para isto, vamos tentar simular o histograma de alturas similar ao da Figura¬†1. Vamos assumir que a distribui√ß√£o de alturas tenha a seguinte media e desvio padr√£o:\n\\(\\mu = 1.7\\) metros\n\\(\\sigma = 0.09\\) metros\nPara uma determinada altura \\(x = 1.6\\) metros, a \\(f(x)\\) assume o valor:\n\\(f(1.6) = \\frac{1}{\\sqrt(2\\pi \\times0.09^2)}e^{-\\frac{1}{2}(\\frac{1.6 - 1.7}{0.09})^2} = 2.391\\)\nEste resultado corresponde ao ponto \\(y\\) no gr√°fico da distribui√ß√£o normal (Figura¬†3) em que \\(x = 1.6\\). Podemos encontar \\(f(x)\\) para quaisquer valores dentro dos reais \\(\\mathbb{R}\\) entre \\(-\\infty\\) e \\(+\\infty\\).\nAssim, se calcularmos \\(f(x)\\) para diferentes pontos em \\(x\\) teremos um esbo√ßo da fun√ß√£o de densidade normal. Na Figura¬†3, por exemplo, apresentamos \\(f(x)\\) para os valores:\n\\(X = 1.4, 1.45, 1.5, 1.55, 1.6, 1.65, 1.7, 1.75, 1.8, 1.85, 1.9, 1.95, 2\\)\nassumindo \\(\\mu = 1.7\\) e \\(\\sigma = 0.09\\)\n\n\n\n\n\n\n\n\nFigura¬†3: Pontos na distribui√ß√£o normal de densidade de probrabilidade.\n\n\n\n\n\n\n2.1 Calculando de \\(f(x)\\) no R: a fun√ß√£o dnorm()\nNo R, os resultados acima podem ser obtidos com a fun√ß√£o dnorm(), que fornece um modo simples para calcularmos \\(f(x)\\) na distribui√ß√£o normal. Nesta fun√ß√£o a letra ‚Äòd‚Äô vem de densidade da distribui√ß√£o normal.\nPara encontrar \\(f(x)\\) para um dado valor fazemos simplesmente:\n\nmu &lt;- 1.7\ndp &lt;- 0.11\ndnorm(1.5, mean = mu, sd = dp)\n\n[1] 0.6945048\n\n\nSe quisermos obter \\(f(x)\\) para m√∫ltiplos valores de \\(x\\) podemos fazer:\n\nx &lt;- c(1.4, 1.5, 1.6, 1.7)\ndnorm(x, mean = mu, sd = dp)\n\n[1] 0.0879777 0.6945048 2.3991470 3.6267480"
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#c√°lculo-de-probabilidade-com-a-fun√ß√£o-normal-de-densidade",
    "href": "content/distribuicao-normal/distr-norm.html#c√°lculo-de-probabilidade-com-a-fun√ß√£o-normal-de-densidade",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "3 C√°lculo de probabilidade com a fun√ß√£o normal de densidade",
    "text": "3 C√°lculo de probabilidade com a fun√ß√£o normal de densidade\nEncontrar a probabilidade de uma vari√°vel aleat√≥ria \\(X\\) estar dentro de uma deteminada faixa de valores significa fazer predi√ß√µes a respeito da probabilidade de ocorr√™ncia de uma observa√ß√£o futura. Por ser uma fun√ß√£o de probabilidade, a √°rea abaixo de \\(f(x)\\) na distribui√ß√£o normal √© igual a \\(1\\).\n\\[P(-\\infty \\le X \\le +\\infty) = \\int_{-\\infty}^{+\\infty}f(x) dx = 1\\]\nAssim, se desejamos obter probabilidade de uma vari√°vel estar dentro de um determinado limite, devemos calcular a √°rea abaixo da curva para este limite. Por exemplo, a probabilidade de uma observa√ß√£o em \\(X\\) estar entre \\(x_1\\) e \\(x_2\\) ser√°:\n\n\n\n\n\n\n\n\nFigura¬†4: Representa√ß√£o das probabilidades de um intervalo da distribui√ß√£o normal de densidade.\n\n\n\n\n\n\n3.1 Calculando probabilidades no R: a fun√ß√£o pnorm()\nUsando o R, a probabilidade de amostrarmos um aluno que tenha entre menos de \\(1.5\\) metros pode ser obtida por meio da fun√ß√£o pnorm:\n\nmu &lt;- 1.7\ndp &lt;- 0.11\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\n\n[1] 0.03451817\n\n\n\n\n\n\n\n\nArgumentos da fun√ß√£o:\n\n\n\nq: o valor de \\(x\\)\nmean: m√©dia \\(\\mu\\) da fun√ß√£o normal\nsd: desvio padr√£o \\(\\sigma\\) da fun√ß√£o normal\nlower.tail: se a fun√ß√£o ir√° retornar a probabilidade abaixo (TRUE) ou acima (FALSE) de q\nveja o menu de ajuda digitando ?pnorm no Console do R\n\n\nSe quisermos encontrar a probabilidade \\(P(X \\ge 1.5)\\) alteramos o par√¢metro lower.tail\n\npnorm(q = 1.5, mean = mu, sd = dp, lower.tail = FALSE)\n\n[1] 0.9654818\n\n\nSe desejamos obter a probabilidade de \\(x\\) estar entre \\(1.5\\)m e \\(1.7\\)m podemos fazer: \\[P(1.5 \\le X \\le 1.7) = P(X \\le 1.7) - P(X \\le 1.5)\\]\nNo R temos:\n\np1 &lt;- pnorm(q = 1.7, mean = mu, sd = dp, lower.tail = TRUE)\np2 &lt;- pnorm(q = 1.5, mean = mu, sd = dp, lower.tail = TRUE)\npfinal &lt;- p1 - p2\n\npfinal\n\n[1] 0.4654818\n\n\nou simplesmente:\n\ndiff(pnorm(q = c(1.7, 1.5),\n           mean = mu,\n           sd = dp,\n           lower.tail = TRUE)\n     )\n\n[1] -0.4654818\n\n\nAqui est√£o representados cada um dos intervalos calculados.\n\n\nC√≥digo\ndfc &lt;- data.frame(X = seq(0, sup, length.out = 10000)) |&gt;\n  dplyr::mutate(dx = dnorm(X, mean = mu, sd = dp))\n\ngc1 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &lt;= 1.7),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n    \"text\", x = 1.5, y = 3,\n    label = as.expression(bquote(P(X &lt;= 1.7) == .(round(p1, 3)))),\n    color = \"#eb4034\"\n  ) +\n  theme_classic()\n\ngc2 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &lt;= 1.5),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n    \"text\", x = 1.5, y = 3,\n    label = as.expression(bquote(P(X &lt;= 1.5) == .(round(p2, 3)))),\n    color = \"#eb4034\"\n  ) +\n  theme_classic()\n\ngc3 &lt;- ggplot(dfc, aes(x = X, y = dx)) +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = dp)) +\n  geom_area(\n    data = subset(dfc, X &gt;= 1.5 & X &lt;= 1.7),\n    fill = \"#eb4034\", color = NA, alpha = 0.5\n  ) +\n  scale_x_continuous(\n    name = \"X\",\n    limits = c(1.4, 2),\n    breaks = seq(1.4, 2, by = 0.05)\n  ) +\n  ylab(\"f(x)\") +\n  annotate(\n   \"text\",\n   x = 1.5, y = 3,\n   label = as.expression(\n      substitute(P(a &lt;= X * \",\" ~ X &lt;= b) == val,\n                  list(a = 1.5, b = 1.7, val = round(pfinal, 3)))\n   ),\n   color = \"#eb4034\"\n   ) +\n  theme_classic()\n\ngc1 / gc2 / gc3"
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#a-distribui√ß√£o-normal-padronizada",
    "href": "content/distribuicao-normal/distr-norm.html#a-distribui√ß√£o-normal-padronizada",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "4 A distribui√ß√£o normal padronizada",
    "text": "4 A distribui√ß√£o normal padronizada\nA integral para a fun√ß√£o normal √© dif√≠cil de ser calculada pois n√£o tem solu√ß√£o anal√≠tica. Isto era um problema para os cientistas at√© meados do s√©culo \\(XX\\) que precisavam calcular valores de probabilidades para diferentes combina√ß√µes de \\(\\mu\\) e \\(\\sigma\\). Naquele momento, a solu√ß√£o para facilitar a vida dos pesquisadores foi criar uma tabela descrevendo estas probabilidades em uma distribui√ß√£o normal padronizada, ou seja para valores particulares de \\(\\mu\\) e \\(\\sigma\\). Padronizar aqui, significa transfomar cada valor \\(x_i\\) de modo que as observa√ß√µes resultantes tenham m√©dia igual a \\(0\\) e desvio padr√£o igual a \\(1\\).\nEsta transforma√ß√£o √© apicada a cada observa√ß√£o \\(x_i\\), obtendo-sem um valor de \\(z_i\\) correspondente por meio da express√£o.\n\\[z_i = \\frac{x_i - \\mu}{\\sigma}\\]\nA transforma√ß√£o \\(Z\\) √© √∫til, pois ainda que seja dif√≠cil calcular as probabilidades para uma vari√°vel aleat√≥ria \\(X\\), ap√≥s a transforma√ß√£o teremos uma vari√°vel \\(Z\\) para a qual os valores de probabilidade est√£o tabelados. Deste modo, \\(Z\\) √© uma vari√°vel aleat√≥ria com \\(\\overline{z} = 0\\) e \\(s = 1\\) tal que:\n\\[Z \\sim \\mathcal{N}(0,\\,1)\\]\nAp√≥s a transforma√ß√£o \\(Z\\) nos exemplos sobre altura dos alunos e da temperatura mensal temos:\n\n\nC√≥digo\nie &lt;- ie |&gt; \n   mutate(ALTURA_z = (ALTURA - mean(ALTURA, na.rm = T))/sd(ALTURA, na.rm = T))\ntemp &lt;- temp |&gt; \n   mutate(tm_z = (tm - mean(tm, na.rm = T))/sd(tm, na.rm = T))\n\naltz_plt &lt;- ggplot(ie, aes(x = ALTURA_z)) +\n   geom_histogram(aes(y = after_stat(density)), \n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(ie$ALTURA_z, na.rm = T),\n                                          sd = sd(ie$ALTURA_z, na.rm = T))) +\n   labs(x = \"Distribui√ß√£o Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\ntempz_plt &lt;- ggplot(temp, aes(x = tm_z)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', \n                  color = 'black', bins = 10) +\n   stat_function(fun = dnorm, \n                 args = list(mean = mean(temp$tm_z, na.rm = T),\n                                          sd = sd(temp$tm_z, na.rm = T))) +\n   labs(x = \"Distribui√ß√£o Z\",\n        y = \"Frequencia relativa\") +\n   theme_classic()\n\n(alt_plt | temp_plt) / \n  (altz_plt | tempz_plt)\n\n\n\n\n\n\n\n\nFigura¬†5: Distribui√ß√£o das vari√°veis originais e ap√≥s a transforma√ß√£o Z.\n\n\n\n\n\n\n\n\n\n\n\nEscore Z\n\n\n\nO escore Z pode ser apresentado como uma medida de posi√ß√£o de uma observa√ß√£o na amostra (\\(z_i\\)) que representava uma medida relativa desta observa√ß√£o com rela√ßao √† m√©dia e ao desvio padr√£o do conjunto de dados. Por exemplo, um valor de \\(z_i = 2\\) significa que a observa√ß√£o original \\(x_i\\) est√° \\(2\\) desvios padr√µes acima de sua respectiva m√©dia \\(\\mu\\).\n\n\n\n4.1 Probabilidades em uma distribui√ß√£o normal padronizada\nNos dois exemplos anteriores, verifica-se que todas as observa√ß√µes est√£o situadas, aproximadamente, entre \\(z = -3\\) e \\(z = +3\\). De fato, a distribui√ß√£o normal padronizada ou distribui√ß√£o Z tem propriedades bem conhecidas. Como sua m√©dia √© \\(\\mu = 0\\) e seu desvio padr√£o √© \\(\\sigma = 1\\), a maior parte das observa√ß√µes fica limitada entre \\(z = -3\\) e \\(z = +3\\). Para ser exato, podemos descrever as probabilidades de uma observa√ß√£o estar dentro de alguns limites conhecidos. Por exemplo, \\(95\\%\\) das observa√ß√µes estar√° entre \\(z = -1.96\\) e \\(z = +1.96\\), isto √©,\n\\[P(-1.96 \\le Z \\le +1.96) = 0.95\\]\nDe forma similar, \\(90\\%\\) da √°rea central da curva se encontra entre \\(z = -1.64\\) e \\(z = +1.64\\). Estes e outros limites na distribui√ß√£o normal padronizada podem ser verificados na figura abaixo.\n\n\nC√≥digo\n# Ver fun√ß√£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\n\n\n\nFigura¬†6: √Åreas de probabilidade em uma distribui√ß√£o Normal Padronizada (Distribui√ß√£o Z).\n\n\n\n\n\nVamos exemplificar o uso da distribui√ß√£o \\(Z\\) no c√°lculo de probabilidades utilizando os dados de altura dos alunos. Para estes dados, iremos encontrar \\(P(X \\le 1.5)\\). Este procedimento consiste de:\n\n\nC√≥digo\nmu &lt;- 1.7\ndp &lt;- 0.11\nx &lt;- 1.5\nz_1.5 &lt;- (x - mu)/dp\n\n\n\nTransformar \\(x = 1.5\\) em \\(z_{1.5}\\) por meio de \\(z_{1.5} = \\frac{1.5 - 1.7}{0.11} = -1.818\\);\n\n\n\nC√≥digo\nmu &lt;- 1.7\ndp &lt;- 0.11\nx &lt;- 1.5\nz_1.5 &lt;- (x - mu)/dp\n\nz_1.5\n\n\n[1] -1.818182\n\n\n\nEncontrar encontrar \\(P(Z \\le z_{1.5}) = P(Z \\le -1.818) = 0.0345182\\).\n\n\n\nC√≥digo\npnorm(q = z_1.5, mean = 0, sd = 1, lower.tail = TRUE)\n\n\n[1] 0.03451817\n\n\nCompare este resultado com o obtido anteriormente para verificar que √© equivalente a \\(P(X \\le 1.5)\\).\n\n\n\n\n\n\nA transforma√ß√£o \\(Z\\)\n\n\n\nSuponha uma vari√°vel aleat√≥ria \\(X\\) nomalmente distribu√≠da conforme \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\). Desejamos encontrar \\(m\\) tal que:\n\\(P(X \\le m) = \\alpha\\)\n\n\\(\\alpha\\) aqui representa um valor de probabilidade qualquer determinada pela √°rea na distribui√ß√£o normal abaixo de \\(m\\).\n\nAo aplicar a transforma√ß√£o \\(Z\\) teremos:\n\\(P(\\frac{X - \\mu}{\\sigma} \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\ncomo \\(\\frac{X - \\mu}{\\sigma} = Z\\) temos que:\n\\(P(Z \\le \\frac{m - \\mu}{\\sigma}) = \\alpha\\)\nPor meio desta express√£o, voc√™ pode encontar \\(m\\) uma vez fornecido \\(\\alpha\\) ou encontrar \\(\\alpha\\), desde que seja fornecido \\(m\\).\nO mesmo vale se quisermos encontrar a probabilidade determinada por um intervalo definido de \\(m\\) at√© \\(n\\) (\\(m &lt; n\\)). Para isto fazemos:\n\\(P(m \\le X \\le n) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le \\frac{X - \\mu}{\\sigma} \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\\(P(\\frac{m - \\mu}{\\sigma} \\le Z \\le \\frac{n - \\mu}{\\sigma}) = \\alpha\\)\n\n\n\n\n4.2 Tabela \\(Z\\)\nAo utilizarmos um software estat√≠stico n√£o √© necess√°rio fazer esta transforma√ß√£o. A transforma√ß√£o \\(Z\\) era necess√°ria na aus√™ncia de ferramentas computacionais, ou seja, quando a √∫nica op√ß√£o era utilizarmos a Tabela \\(Z\\) para evitar c√°lculos tediosos considerando cada combina√ß√£o de \\(\\mu\\) e \\(\\sigma\\).\nA Tabela Z disponibiliza os valores de probabilidade para um grande n√∫mero de valores e √© apresentada na grande maioria dos livros de estat√≠stica.\nVoc√™ pode utilizar a Tabela \\(Z\\) para encontrar \\(P(X \\le 1.5)\\). Note que o valor transformado √© \\(z_{1.5} = -1.818\\). Este ser√° o valor que iremos buscar na tabela. Para isto:\n\nEncontre a p√°gina que oferece valores negativos, uma vez que \\(z_{1.5} &lt; 0\\);\nNa coluna 1 desta p√°gina (coluna z) encontre a linha -1.8 que refere-se √† unidade, e √† primeira casa decimal de \\(z_{1.5}\\);\nEncontre a coluna 0.02 (quarta coluna da tabela \\(Z\\)) que apresenta a segunda casa decimal de \\(z_{1.5}\\). Isto nos leva ao valor mais pr√≥ximo do calculado (\\(z_{1.5} = -1.818\\)).\nCruze a linha escolhida no item 3 com a coluna escolhida no item 4. Voc√™ ir√° encontrar o valor \\(0,0344\\). Este valor e a probabilidade de obtermos um valor de \\(z \\le 1.5\\) na distribui√ß√£o normal padronizada, ou seja, \\(P(Z \\le z_{1.5})\\). A diferen√ßa entre este valor e o encontrado com o R se deve unicamente ao limite de precis√£o na Tabela \\(Z\\)."
  },
  {
    "objectID": "content/distribuicao-normal/distr-norm.html#exerc√≠cios-resolvidos",
    "href": "content/distribuicao-normal/distr-norm.html#exerc√≠cios-resolvidos",
    "title": "O modelo de distribui√ß√£o normal",
    "section": "5 Exerc√≠cios resolvidos",
    "text": "5 Exerc√≠cios resolvidos\n\n5.1 Distribui√ß√£o de comprimento\nAs comunidades de peixes em riachos de cabeceira s√£o compostas por esp√©cies de pequeno porte. Rhamdioglanis transfasciatus √© uma destas esp√©cies, desconhecida do p√∫blico em geral, por√©m muito abundante em pequenos riachos bem preservados. Dados de captura sugerem que o tamanho dos indiv√≠duos pode ser razoavelmente bem descrito por um modelo de distribui√ß√£o normal.\nImporte a base de dados rhamdioglanis.csv\n\nrh &lt;- read_delim('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/rhamdioglanis.csv', delim = ';',\n                 locale = locale(decimal_mark = ','))\n\n\n\nC√≥digo\nggplot(rh, aes(x = Comprimento)) +\n   geom_histogram(aes(y = after_stat(density)),\n                  fill = 'dodgerblue4', color = 'black', bins = 15) +\n   stat_function(fun = dnorm, args = list(mean = mean(rh$Comprimento),\n                                          sd = sd(rh$Comprimento))) +\n   labs(x = 'Comprimento de Rhamdioglanis transfasciatus (cm)',\n        y = 'Densidade') +\n   theme_classic()\n\n\n\n\n\n\n\n\n\nSuponha o comprimento desta esp√©cie tenha uma distribui√ß√£o normal com \\(\\mu = 10\\) cm e \\(\\sigma = 3\\) cm. Encontre:\n\nA probabilidade de capturar um indiv√≠duo maior de 14 cm de comprimento, \\(P(X \\ge 14)\\).\nA probabilidade de capturar um indiv√≠duo menor de 5 cm de comprimento, \\(P(X \\le 5)\\).\nA probabilidade de encontrar um indiv√≠duo entre 5 e 14 cm, \\(P(5 \\le X \\le 14)\\).\nSe um trecho de riacho cont√©m 800 indiv√≠duos, quantos s√£o maiores que 14 cm de comprimento.\n\nRESOLU√á√ÉO\n\n\n\n\n\n\n\\(P(X \\ge 14)\\)\n\n\n\n\n\nVamos encontrar o respectivo valor de \\(Z\\) pela transforma√ß√£o\n\\(z_{14} = \\frac{14 - 10}{3} = 1.33\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(1.33\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(1.33\\). Cruzando linha e coluna encontramos o valor \\(0,9082\\). Note que este valor representa a √°rea abaixo de 1.33, isto √©, \\(P(Z \\le z_{14})\\). No entanto, queremos \\(P(Z \\ge z_{14})\\) que representa a √°rea da curva acima de \\(1.33\\). Para isto basta fazermos \\(1 - 0,9082\\).\nDeste modo, \\(P(Z \\ge z_{14}) = 1 - P(Z \\le z_{14}) = 1 - 0,9082 = 0.0918\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nii. \\(P(X \\le 5)\\)\n\n\n\n\n\n\\(z_{5} = \\frac{5 - 10}{3} = -1.67\\)\nNa tabela \\(Z\\) procuramos a linha que mostra a unidade e \\(1^a\\) casa decimal de \\(-1.67\\) e em seguida encontramos a coluna que representa a \\(2^a\\) casa decimal de \\(-1.67\\). Cruzando linha e coluna encontramos o valor \\(0,0475\\) que representa a √°rea desejada.\nDeste modo, \\(P(X \\le 5) = P(Z \\le z_{5}) = 0,0475\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niii. \\(P(5 \\le X \\le 14)\\)\n\n\n\n\n\nVamos subtrair as quantias \\(P(Z \\le 14) - P(Z \\le 5)\\)\nEstes valores j√° foram encontrados nos itens anteriores, de modo que basta fazermos:\n\\(P(5 \\le X \\le 14) = 0,9082 - 0,0475 = 0.8607\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv. Indiv√≠duos maiores que 14 cm de comprimento\n\n\n\n\n\nSe a propor√ß√£o de indiv√≠duos acima de 14 √© \\(P(X &gt; 14) = 0.0918\\) e a popula√ß√£o tem \\(N = 800\\) indiv√≠duos, teremos:\n\\(0.0918 \\times 800 = 73\\) indiv√≠duos maiores que 14 cm.\n\n\n\n\n\n\n\n\n\nRESOLU√á√ÉO no R\n\n\n\n\n\nO exerc√≠cio pode ser resolvido pelo R por meio da fun√ß√£o pnorm.\n\nmu &lt;- 10\nsigma &lt;- 3\nN &lt;- 800\nla &lt;- 14\nlb &lt;- 5\n\n\ni. \\(P(Z \\ge 14)\\)\n\npnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\n[1] 0.09121122\n\n\n\nii. \\(P(Z \\le 5)\\)\n\npnorm(q = lb, mean = mu, sd = sigma, lower.tail = TRUE)\n\n[1] 0.04779035\n\n\n\niii. \\(P(5 \\le X \\le 14)\\)\n\ndiff(\n   pnorm(q = c(lb, la),\n         mean = mu,\n         sd = sigma,\n         lower.tail = TRUE)\n   )\n\n[1] 0.8609984\n\n\n\niv. N√∫mero de indiv√≠duos maiores que \\(14\\) cm de comprimento\n\npg_la &lt;- pnorm(q = la, mean = mu, sd = sigma, lower.tail = FALSE)\n\nN * pg_la\n\n[1] 72.96898\n\n\n\n\n\n\n\n5.2 Intervalos em uma distribui√ß√£o normal\nSuponha vari√°vel aleat√≥ria \\(X\\) normalmente distribu√≠da conforme com \\(\\mu = 50\\) e \\(\\sigma = 10\\). Encontre:\n\nO valor de \\(a\\) tal que \\(P(X \\le a) = 0,10\\).\nO valor de \\(b\\) tal que \\(P(X \\ge b) = 0,85\\).\nO intervalo sim√©trico ao redor da m√©dia delimitado por \\(c\\) e \\(d\\) (\\(c &lt; d\\)), que cont√©m \\(95\\%\\) da √°rea sob a curva.\nO valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\nRESOLU√á√ÉO\nVeja que neste exerc√≠cio, foram oferecidos valores de probabilidades e solicitado que voc√™ obtivesse os limites em uma distribui√ß√£o normal espec√≠fica. Este processo √© oposto ao do excerc√≠cio anterior.\n\n\n\n\n\n\ni. O valor de \\(a\\)\n\n\n\n\n\nSe \\(P(X \\le a) = 0,10\\), a √°rea da curva abaixo de \\(a\\) √© \\(0,10\\). Procurando por este valor na tabela \\(Z\\) vemos que o valor mais pr√≥ximo √© \\(0,1003\\) que corresponde a um escore \\(z = -1,28\\). Vamos utilizar este valor para encontrar sua correspond√™ncia para a vari√°vel aleat√≥ria \\(X\\) que tem m√©dia \\(\\mu = 50\\) e desvio padr√£o \\(\\sigma = 10\\).\n\\(z = \\frac{a - \\mu}{\\sigma} :: -1,28 = \\frac{a - 50}{10}\\)\n\\(a = (-1,28 \\times 10) + 50 = 37.2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nii. O valor de \\(b\\)\n\n\n\n\n\nSe \\(P(X \\ge b) = 0,85\\), a √°rea abaixo de \\(b\\) que devemos encontrar na tabela \\(Z\\) √© \\(1 - 0,85 = 0.15\\). Vemos que o valor mais pr√≥ximo √© \\(0,1492\\) que corresponde a \\(z = -1,04\\). Ao utilizar este resultado na express√£o abaixo temos:\n\\(z = \\frac{b - \\mu}{\\sigma} :: -1,04 = \\frac{b - 50}{10}\\)\n\\(b = (-1,04 \\times 10) + 50 = 39.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO intervalo sim√©trico ao redor da m√©dia delimitado por \\(c\\) e \\(d\\) (\\(c &lt; d\\)), que cont√©m \\(95\\%\\) da √°rea sob a curva.\n\n\n\n\n\nSe entre \\(c\\) e \\(d\\) est√° \\(95\\%\\) da √°rea da curva, temos uma √°rea de \\(1 - 0,95 = 0,05\\) fora da curva. Como o intervalo √© sim√©trico, teremos \\(0,025\\) abaixo de \\(c\\) e \\(0,025\\) acima de \\(d\\).\nAo procurar na tabela \\(Z\\) por \\(0,025\\) encontraremos \\(z = -1,96\\) que equivale ena distribui√ß√£o de X a:\n\\(z = \\frac{c - \\mu}{\\sigma} :: -1,96 = \\frac{c - 50}{10}\\)\n\\(c = (-1,96 \\times 10) + 50 = 30.4\\)\nNovamente, como o intervalo √© sim√©trico e a dsitribui√ß√£o de \\(Z\\) √© centrada em zero, o ponto \\(d\\) ser√° de +\\(1,96\\) que resulta em:\n\\(z = \\frac{d - \\mu}{\\sigma} :: +1,96 = \\frac{d - 50}{10}\\)\n\\(d = (+1,96 \\times 10) + 50 = 69.6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niv. O valor de \\(e\\) tal que \\(P(50-e \\le X \\le 50+e) = 0.99\\)\n\n\n\n\n\nPodemos fazer aqui:\n\\(P(50-e \\le X \\le 50+e) = P(\\frac{50-e - \\mu}{\\sigma} \\le \\frac{X-\\mu}{\\sigma} \\le \\frac{50+e-\\mu}{\\sigma}) = 0.99\\)\ncomo \\(\\mu = 50\\) e \\(\\sigma = 10\\) temos:\n\\(P(\\frac{-e}{10} \\le Z \\le \\frac{e}{10}) = 0.90\\)\nComo a √°rea central ocupa \\(0,99\\) da distribui√ß√£o, restam \\(0,005\\) na cauda superior e \\(0,005\\) na cauda inferior:\n\n\n\n\n\n\n\n\n\nPara encontrar \\(-e\\) buscamos por \\(0,005\\) na tabela \\(Z\\) e encontramos \\(0,0051\\) como valor mais pr√≥ximo, referente a \\(z_{-e} = -2,57\\). Substituindo na equa√ß√£o temos:\n\\(\\frac{-e}{10} \\le -2,57 :: -e = -2,57 \\times 10 :: e = 25,7\\)\n*Note na figura acima que os limite das √°reas em azul s√£o:\n\\(\\mu - e = 50 - 25.7 = 24.3\\) e\n\\(\\mu - e = 50 + 25.7 = 75.7\\)\n\n\n\n\n\n\n\n\n\nRESOLU√á√ÉO no R\n\n\n\n\n\nO exerc√≠cio pode ser resolvido pelo R por meio da fun√ß√£o qnorm.\n\nEm qnorm, o ‚Äòq‚Äô vem de quantis da distribui√ß√£o normal.\n\n\nmu = 50\nsigma = 10\n\n(a &lt;- qnorm(p = 0.10, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 37.18448\n\n(b &lt;- qnorm(p = 1-0.85, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 39.63567\n\n(c &lt;- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = TRUE))\n\n[1] 30.40036\n\n(d &lt;- qnorm(p = (1-0.95)/2, mean = mu, sd = sigma, lower.tail = FALSE))\n\n[1] 69.59964\n\n(e &lt;- -qnorm(p = (1-0.99)/2, mean = mu, sd = sigma, lower.tail = TRUE) + 50)\n\n[1] 25.75829\n\n\n\n\n\n\n\n5.3 Quantos desvios padr√µes?\nSuponha uma vari√°vel aleat√≥ria normalmente distribu√≠da representada por \\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^2)\\), determine:\n\nO valor de \\(a\\) tal que \\(P(X &lt; a) = 0,20\\).\n\\(P(X \\le \\mu + 2\\sigma)\\).\nO valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\nRESOLU√á√ÉO\n\n\n\n\n\n\ni. O valor de \\(a\\) tal que \\(P(X &lt; a) = 0,20\\).\n\n\n\n\n\n\\(P(X &lt; a) = P(\\frac{X - \\mu}{\\sigma} &lt; \\frac{a - \\mu}{\\sigma}) = P(Z &lt; \\frac{a - \\mu}{\\sigma}) = 0,20\\)\nProcurando pelo valor de \\(z\\) que delimita \\(0,20\\) da √°rea abaixo de \\(a\\) encontramos por \\(z = -0,84\\), de modo que:\n\\(-0,84 = \\frac{a - \\mu}{\\sigma}\\)\n\\(a = \\mu -0,84\\sigma\\)\n\n\n\n\n\n\n\n\n\nii. \\(P(X \\le \\mu + 2\\sigma)\\)\n\n\n\n\n\nA express√£o \\(\\mu + 2\\sigma\\) nos diz que o limite de interesse est√° \\(2\\) desvios padr√µes acima de \\(\\mu\\). Ao procurar pelo valor de \\(z = 2,0\\) na tabela \\(Z\\), veremos que a probabilidade de interesse √© \\(P(X \\le \\mu + 2\\sigma) = 0,9772\\)\n\n\n\n\n\n\n\n\n\niii. O valor de \\(c\\) tal que \\(P(\\mu -c\\sigma \\le X \\le \\mu +c\\sigma) = 0.99\\)\n\n\n\n\n\nDesenvolvendo esta express√£o teremos\n\\(P(-c \\le \\frac{X - \\mu}{\\sigma} \\le +c) = P(-c \\le Z \\le +c) = 0.99\\)\nFora deste intervalo sim√©trico, teremos uma √°rea de \\(0,005\\) na cauda inferior e \\(0,005\\) na cauda superior da distribui√ß√£o \\(Z\\).\nAo procurar por \\(0,005\\) na tabela \\(Z\\) encontramos \\(z = -2,57\\), de modo que \\(c = 2,57\\).\n\n\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "",
    "text": "Bibliotecas utilizadas nesta se√ß√£o\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as st"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#simulando-uma-distribui√ß√£o-de-probabilidade-normal",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#simulando-uma-distribui√ß√£o-de-probabilidade-normal",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "1 Simulando uma distribui√ß√£o de probabilidade normal",
    "text": "1 Simulando uma distribui√ß√£o de probabilidade normal\nVamos utilizar nosso modelo te√≥rico de probabilidades (a distribui√ß√£o normal) para prever o que seria esperado para as frequ√™ncias relativas de alunos de diferentes alturas. Para isso precisamos calcular a probabilidade abaixo da curva para diferentes faixas de altura.\nEstritamente falando a equa√ß√£o da distribui√ß√£o normal abaixo:\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma} \\right)^2}, \\quad x \\in \\mathbb{R} \\mid -\\infty \\leq x \\leq +\\infty\n\\]\n√© a Fun√ß√£o de Densidade de Probabilidade (PDF) da distribui√ß√£o normal. Com base nesta equa√ß√£o, as probabilidades para intervalos de \\(X\\) s√£o obtidas por meio da Fun√ß√£o de Probabilidade Acumulada (CDF).\n\nmi = 170.94\nsigma = 6.86\n\nx = np.linspace(130, 210, 1000)\npdf = st.norm.pdf(x = x, loc = mi, scale = sigma)\n\ncdf = st.norm.cdf(x = x, loc = mi, scale = sigma)\n\nA distribui√ß√£o normal com m√©dia \\(X = 170.94\\) e \\(\\sigma = 6.86\\) est√£o representadas abaixo (PDF - Figura¬†2 (a); CDF - Figura¬†2 (b)).\nplt.plot(x, pdf)\nplt.xlabel('Alturas (cm)')\nplt.ylabel('PDF')\nplt.show()\n\nplt.plot(x, cdf)\nplt.xlabel('Alturas (cm)')\nplt.ylabel('CDF')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) Fun√ß√£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) Fun√ß√£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFigura¬†2: Distribui√ß√£o normal de probabilidade"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#obtendo-probabilidades-de-uma-distribui√ß√£o-normal",
    "href": "content/distribuicao-normal/distribuicao-normal-probabilidade.html#obtendo-probabilidades-de-uma-distribui√ß√£o-normal",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "2 Obtendo probabilidades de uma distribui√ß√£o normal",
    "text": "2 Obtendo probabilidades de uma distribui√ß√£o normal\n\n2.1 A probabilidade de \\(X\\) ser menor ou igual a \\(x_1\\): \\(P(X \\le x_1)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 160\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np = st.norm.cdf(x = x1, loc=mi, scale=sigma)\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = (x &lt;= x1), color='lightblue')\nplt.title(f'$P(X \\leq {x1})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p, p], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) Fun√ß√£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) Fun√ß√£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFigura¬†3: Distribui√ß√£o Normal de Probabilidades.\n\n\n\n\n\n2.2 A probabilidade de \\(X\\) ser maior ou igual a \\(x_1\\): \\(P(X \\ge x_1)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 180\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np = st.norm.cdf(x = x1, loc=mi, scale=sigma)\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = (x &gt;= x1), color='lightblue')\nplt.title(f'$P(X \\geq {x1})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p, p], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) Fun√ß√£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) Fun√ß√£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFigura¬†4: Distribui√ß√£o Normal de Probabilidades.\n\n\n\n\n\n2.3 A probabilidade de \\(X\\) estar entre \\(x_1\\) e \\(x_2\\): \\(P(x_1 \\le X \\le x_2)\\)\nmi = 170.94\nsigma = 6.86\nx1 = 160\nx2 = 180\n\nx = np.linspace(130, 210, 1000)\n\npdf_y = st.norm.pdf(x = x, loc = mi, scale = sigma)\ncdf_y = st.norm.cdf(x = x, loc = mi, scale = sigma)\np1 = st.norm.cdf(x = x1, loc=mi, scale=sigma)\np2 = st.norm.cdf(x = x2, loc=mi, scale=sigma)\np = p2 - p1\n\nplt.plot(x, pdf_y)\nplt.fill_between(x, pdf_y, where = ((x &gt;= x1) & (x &lt;= x2)), color='lightblue')\nplt.title(f'$P({x1} \\leq X \\leq {x2})$ = {np.round(p, 3)}')\nplt.show()\n\nplt.plot(x, cdf_y)\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.title(f'$F(X = {x1}$) = {np.round(p, 3)}')\nplt.title(f'$F(X = {x2}$) = {np.round(p, 3)}')\nplt.plot([x1, x1], [0, p1], color = 'red', linewidth = 3)\nplt.plot([130, x1], [p1, p1], color = 'red', linewidth = 3)\nplt.plot([x2, x2], [0, p2], color = 'red', linewidth = 3)\nplt.plot([130, x2], [p2, p2], color = 'red', linewidth = 3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(a) Fun√ß√£o de Densidade de Probabilidade (PDF)\n\n\n\n\n\n\n\n\n\n\n\n(b) Fun√ß√£o de Probabilidade Acumulada (CDF).\n\n\n\n\n\n\n\nFigura¬†5: Distribui√ß√£o Normal de Probabilidades.\n\n\n\n\n\n2.4 Representando \\(x_1\\) e \\(x_2\\) por \\(\\mu \\pm z\\sigma\\): \\(P(\\mu - z\\sigma \\le X \\le \\mu + z\\sigma)\\)\nObs.: \\(z\\) representa o n√∫mero de desvios padr√µes acima ou abaixo de \\(\\mu\\).\n\nmi = 170.94\nsigma = 6.86\nz = 1.96\nx1 = mi - z * sigma\nx2 = mi + z * sigma\n\nx = np.arange(130, 210, 0.001)\ny = st.norm.pdf(x = x, loc = mi, scale = sigma)\n\np1 = st.norm.cdf(x = x1, loc=mi, scale=sigma)\np2 = st.norm.cdf(x = x2, loc=mi, scale=sigma)\np = p2 - p1\n\nplt.plot(x, y)\nplt.fill_between(x, y, where = ((x &gt;= x1) & (x &lt;= x2)), color='lightblue')\nplt.title(f'P($\\mu - {z}\\sigma \\leq X \\leq \\mu + {z}\\sigma$) = {np.round(p, 3)}')\nplt.show()\n\n\n\n\n\n\n\nFigura¬†6: Distribui√ß√£o Normal de Probabilidades."
  },
  {
    "objectID": "content/multivariada-numerica/ordination.html",
    "href": "content/multivariada-numerica/ordination.html",
    "title": "M√©todos de ordena√ß√£o",
    "section": "",
    "text": "1 Classifica√ß√£o\n(Conte√∫do em constru√ß√£o)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#conte√∫do-da-aula",
    "href": "content/multivariada-numerica/intro-matrizes.html#conte√∫do-da-aula",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Conte√∫do da aula",
    "text": "Conte√∫do da aula\n\n\nDefini√ß√£o de matriz\nAdi√ß√£o de matrizes\nMultiplica√ß√£o por um escalar\nMultiplica√ß√£o de matrizes\nTransposta de uma matriz\n√Ålgebra de matrizes\nInversa de uma matriz\nInversa de uma matriz pelo m√©todo de Gauss-Jordan\nMatrizes elementares\nCadeias de Markov para Recifes de Coral"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#defini√ß√£o-de-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#defini√ß√£o-de-matriz",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Defini√ß√£o de matriz",
    "text": "Defini√ß√£o de matriz\n\\[A_{22} = \\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix};\nB_{33} = \\begin{bmatrix}\n5 & 6 & 7 \\\\\n8 & 9 & 10 \\\\\n11 & 12 & 13\n\\end{bmatrix}; C_{34} = \\begin{bmatrix}\n14 & 15 & 16 & 17 \\\\\n18 & 19 & 20 & 21 \\\\\n22 & 23 & 24 & 25\n\\end{bmatrix}\\]\n\nEstrutura geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\)\n\\[A_{mn} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#adi√ß√£o-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#adi√ß√£o-de-matrizes",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Adi√ß√£o de matrizes",
    "text": "Adi√ß√£o de matrizes\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}; B = \\begin{bmatrix}\n9 & 8 & 7 \\\\\n6 & 5 & 4 \\\\\n3 & 2 & 1\n\\end{bmatrix}\\)\n\n\\(A + B = \\begin{bmatrix}\n1 + 9 & 4 + 8 & 7 + 7 \\\\\n2 + 6 & 5 + 5 & 8 + 4 \\\\\n3 + 3 & 6 + 2 & 9 + 1\n\\end{bmatrix}\n= \\begin{bmatrix}\n10 & 12 & 14 \\\\\n8 & 10 & 12 \\\\\n6 & 8 & 10\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para duas matrizes \\(m \\times n\\), \\(A = [a_{ij}]\\) e \\(B = [b_{ij}]\\):\n\\[A + B = [a_{ij} + b_{ij}] = \\begin{bmatrix}\na_{11} + b_{11} & a_{12} + b_{12} & \\cdots & a_{1n} + b_{1n} \\\\\na_{21} + b_{21} & a_{22} + b_{22} & \\cdots & a_{2n} + b_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} + b_{m1} & a_{m2} + b_{m2} & \\cdots & a_{mn} + b_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-por-um-escalar",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-por-um-escalar",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Multiplica√ß√£o por um escalar",
    "text": "Multiplica√ß√£o por um escalar\n\n\n\nSeja \\(A\\) uma matriz \\(3 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}\\)\n\nA multiplica√ß√£o de \\(A\\) por um escalar \\(c = 3\\):\n\\(cA = 3 \\times \\begin{bmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{bmatrix}\n= \\begin{bmatrix}\n3 \\times 1 & 3 \\times 4 & 3 \\times 7 \\\\\n3 \\times 2 & 3 \\times 5 & 3 \\times 8 \\\\\n3 \\times 3 & 3 \\times 6 & 3 \\times 9\n\\end{bmatrix}\n= \\begin{bmatrix}\n3 & 12 & 21 \\\\\n6 & 15 & 24 \\\\\n9 & 18 & 27\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\) e um escalar \\(c\\):\n\\[cA = [c \\times a_{ij}] = \\begin{bmatrix}\nc \\times a_{11} & c \\times a_{12} & \\cdots & c \\times a_{1n} \\\\\nc\\times a_{21} & c \\times a_{22} & \\cdots & c \\times a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc \\times a_{m1} & c \\times a_{m2} & \\cdots & c \\times a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-de-matrizes",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Multiplica√ß√£o de matrizes",
    "text": "Multiplica√ß√£o de matrizes\n\n\n\nSeja \\(A\\) uma matriz \\(2 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\\)\ne \\(B\\) uma matriz \\(3 \\times 2\\):\n\\(B = \\begin{bmatrix}\n7 & 8 \\\\\n9 & 10 \\\\\n11 & 12\n\\end{bmatrix}\\)\n\nA multiplica√ß√£o de \\(A\\) por \\(B\\):\n\\(AB = \\begin{bmatrix}\n1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11 & 1 \\cdot 8 + 2 \\cdot 10 + 3 \\cdot 12 \\\\\n4 \\cdot 7 + 5 \\cdot 9 + 6 \\cdot 11 & 4 \\cdot 8 + 5 \\cdot 10 + 6 \\cdot 12\n\\end{bmatrix}\n= \\begin{bmatrix}\n58 & 64 \\\\\n139 & 154\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\), e uma matriz \\(n \\times p\\), \\(B = [b_{ij}]\\):\n\\[AB = [c_{ij}] = \\begin{bmatrix}\n\\sum_{k=1}^{n} a_{1k} b_{k1} & \\sum_{k=1}^{n} a_{1k} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{1k} b_{kp} \\\\\n\\sum_{k=1}^{n} a_{2k} b_{k1} & \\sum_{k=1}^{n} a_{2k} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{2k} b_{kp} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sum_{k=1}^{n} a_{mk} b_{k1} & \\sum_{k=1}^{n} a_{mk} b_{k2} & \\cdots & \\sum_{k=1}^{n} a_{mk} b_{kp}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-de-matrizes-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#multiplica√ß√£o-de-matrizes-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Multiplica√ß√£o de matrizes",
    "text": "Multiplica√ß√£o de matrizes\nPropriedades Alg√©bricas da Multiplica√ß√£o de Matrizes\n\nSejam \\(A\\), \\(B\\) e \\(C\\) matrizes (cujas ordens possibilitem que as opera√ß√µes indicadas sejam realizadas) e seja \\(k\\) um escalar. Ent√£o:\n\n\n\n\n\n\n\n\n\nPropriedade\nDescri√ß√£o\n\n\n\n\n1\n\\(A(BC) = (AB)C\\)\nAssociatividade\n\n\n2\n\\(A(B + C) = AB + AC\\)\nDistributiva √† esquerda\n\n\n3\n\\((A + B)C = AC + BC\\)\nDistributiva √† direita\n\n\n4\n\\(k(AB) = (kA)B = A(kB)\\)\n\n\n\n5\n\\(I_m A = A = A I_n\\) se \\(A\\) for \\(m \\times n\\)\nIdentidade da multiplica√ß√£o"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Transposta de uma matriz",
    "text": "Transposta de uma matriz\n\n\n\nSeja \\(A\\) uma matriz \\(2 \\times 3\\):\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\\)\n\nA transposta de \\(A\\) √© dada por \\(A^T = [a_{ij}]^T = [a_{ji}]\\):\n\\(A^T = \\begin{bmatrix}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{bmatrix}\\)\n\n\n\nEstrutura Geral: Para uma matriz \\(m \\times n\\), \\(A = [a_{ij}]\\):\n\n\n\\(A = [a_{ij}] = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\\)\n\n\\(A^T = [a_{ji}] = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{n1} \\\\\na_{12} & a_{22} & \\cdots & a_{n2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1m} & a_{2m} & \\cdots & a_{nm}\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#transposta-de-uma-matriz-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Transposta de uma matriz",
    "text": "Transposta de uma matriz\nPropriedades Alg√©bricas da Transposta de Matrizes\n\nSejam \\(A\\) e \\(B\\) matrizes (cujas ordens s√£o tais que as opera√ß√µes indicadas podem ser realizadas) e seja \\(k\\) um escalar. Ent√£o:\n\n\n\n\nPropriedade\n\n\n\n\n1\n\\((A^T)^T = A\\)\n\n\n2\n\\((A + B)^T = A^T + B^T\\)\n\n\n3\n\\((kA)^T = k(A^T)\\)\n\n\n4\n\\((AB)^T = B^T A^T\\)\n\n\n5\n\\((A^r)^T = (A^T)^r\\) para todos os inteiros \\(r\\) n√£o negativos"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#√°lgebra-de-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#√°lgebra-de-matrizes",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "√Ålgebra de matrizes",
    "text": "√Ålgebra de matrizes\nPropriedades Alg√©bricas da Adi√ß√£o de Matrizes e da Multiplica√ß√£o por Escalar\n\nSejam \\(A\\), \\(B\\) e \\(C\\) matrizes de mesma ordem, e \\(c\\) e \\(d\\) escalares. Ent√£o:\n\n\n\n\nPropriedade\nDescri√ß√£o\n\n\n\n\n1\n\\(A + B = B + A\\)\nComutatividade\n\n\n2\n\\((A + B) + C = A + (B + C)\\)\nAssociatividade\n\n\n3\n\\(A + O = A\\)\n\n\n\n4\n\\(A + (-A) = O\\)\n\n\n\n5\n\\(c(A + B) = cA + cB\\)\nDistributividade\n\n\n6\n\\((c + d)A = cA + dA\\)\nDistributividade\n\n\n7\n\\(c(dA) = (cd)A\\)\n\n\n\n8\n\\(1A = A\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#combina√ß√µes-lineares-em-matrizes",
    "href": "content/multivariada-numerica/intro-matrizes.html#combina√ß√µes-lineares-em-matrizes",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Combina√ß√µes lineares em matrizes",
    "text": "Combina√ß√µes lineares em matrizes\n\nEscrevendo a matriz \\(B = \\begin{bmatrix} 1 & 4 \\\\ 2 & 1 \\end{bmatrix}\\) como combina√ß√£o linear de \\(A_1 = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\\), \\(A_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\) e \\(A_3 = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1  \\end{bmatrix}\\)\ntemos\n\\[c_1A_1 + c_2A_2 + c_3A_3 = B\\]\n\\[c_1\\begin{bmatrix}\n0 & 1 \\\\\n-1 & 0\n\\end{bmatrix} +\nc_2\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} +\nc_3\\begin{bmatrix}\n1 & 1 \\\\\n1 & 1\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 4 \\\\\n2 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\nA combin√ß√£o linear pode ser resolvida pelo sistema:\n\\[\n\\begin{cases}\nc_2 + c_3 = 1 \\\\\nc_1 + c_3 = 4 \\\\\n-c_1 + c_3 = 2 \\\\\nc_2 + c_3 = 1\n\\end{cases}\n\\]\n\nQue tem solu√ß√£o:\n\\[c_1 = 1\\] \\[c_2 = -2\\] \\[c_3 = 3\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nSeja \\(A = \\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix}\\) e \\(A^{-1} = \\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix}\\)\n\nVerificamos que \\(A^{-1}\\) √© inversa de \\(A\\) pois:\n\\(AA^{-1} = \\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix} = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} = I\\)\ne\n\\(A^{-1}A = \\begin{bmatrix}\n\\frac{4}{5} & -\\frac{3}{5} \\\\\n-\\frac{1}{5} & \\frac{2}{5}\n\\end{bmatrix}\n\\begin{bmatrix}\n2 & 3 \\\\\n1 & 4\n\\end{bmatrix} = \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} = I\\)\n\n\n\n\n\n\n\n\n\nDefini√ß√£o\n\n\nSe \\(A\\) √© uma matriz \\(n \\times n\\), uma inversa de \\(A\\) √© uma matriz \\(n \\times n\\) \\(A^{-1}\\) que satisfaz:\n\\[AA^{-1} = I\\] e \\[A^{-1}A = I\\]\nsendo \\(I = I_n\\) a matriz identidade \\(n \\times n\\). Se existir uma matriz \\(A^{-1}\\) assim, diremos que \\(A\\) √© invert√≠vel."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\nEm cada exemplo, verifique se a matriz \\(B\\) √© inversa de \\(A\\)\n\n\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n-2 & 1 \\\\\n1.5 & -0.5\n\\end{bmatrix}\\)\n\n\n\n\\(A = \\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n3 & -5 \\\\\n-1 & 1\n\\end{bmatrix}\\)\n\n\n\n\n\n\n\\(A = \\begin{bmatrix}\n2 & 1 & 1 \\\\\n1 & 3 & 2 \\\\\n1 & 0 & 0\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n0 & 0 & 1 \\\\\n-2 & 1 & 3 \\\\\n3 & -1 & -5\n\\end{bmatrix}\\)\n\n\n\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n0 & 1 & 4 \\\\\n5 & 6 & 0\n\\end{bmatrix}\\) e \\(B = \\begin{bmatrix}\n4 & 2 & -2 \\\\\n-1 & 3 & 5 \\\\\n0 & 5 & 1\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-2",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-2",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nVerifique que \\(A = \\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\\) invert√≠vel e pode ser escrita por:\n\\(\\begin{bmatrix}\n2 & 5 \\\\\n1 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\nw & x \\\\\ny & z\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\\)\n\nQue resulta no sistema de equa√ß√µes:\n\\(\\begin{cases}\n2w + 5y = 1 \\\\\n2x + 5z = 0 \\\\\nw + 3y = 0 \\\\\nx + 3z = 1\n\\end{cases}\\)\n\n\n\n\nQue pode ser resolvido por:\n\\(\\left[ \\begin{array}{cccc|c}\n2 & 0 & 5 & 0 & 1\\\\\n0 & 2 & 0 & 5 & 0\\\\\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\n\\end{array} \\right]\\) \\(\\begin{array}{c}\nL_1 \\leftrightarrow L_3\\\\\nL_2 \\leftrightarrow L_4\\\\\n\\\\\n\\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\\\\\n2 & 0 & 5 & 0 & 1\\\\\n0 & 2 & 0 & 5 & 0\n\\end{array} \\right]\\) \\(\\begin{array}{c}\n\\\\\n\\\\\nL_3 - 2L_1 \\\\\nL_4 - 2L_2 \\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 3 & 0 & 0\\\\\n0 & 1 & 0 & 3 & 1\\\\\n0 & 0 & -1 & 0 & 1\\\\\n0 & 0 & 0 & -1 & -2\n\\end{array} \\right]\\) \\(\\begin{array}{c}\nL_1 + 3L_3 \\\\\nL_2 + 3L_4 \\\\\n-L_3 \\\\\n-L_4 \\\\\n\\end{array}\\)\n\\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 0 & 0 & 3\\\\\n0 & 1 & 0 & 0 & -5\\\\\n0 & 0 & 1 & 0 & -1\\\\\n0 & 0 & 0 & 1 & 2\n\\end{array} \\right]\\) \\(S = \\left[\\begin{array}{c}\n3 \\\\\n-5 \\\\\n-1 \\\\\n2 \\\\\n\\end{array} \\right]\\) Portanto: \\(A^{-1} = \\begin{bmatrix}\n3 & -5 \\\\\n-1 & 2\n\\end{bmatrix}\\)"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-3",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-3",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\nVerifique que \\(B = \\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix}\\) n√£o √© invert√≠vel e portanto n√£o pode ser escrita por:\n\\(\\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix}\n\\begin{bmatrix}\nw & x \\\\\ny & z\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\\)\n\nO sistema de equa√ß√µes lineares fica:\n\\(\\begin{cases}\nw + 2y = 1 \\\\\nx + 2z = 0 \\\\\n2w + 4y = 0 \\\\\n2x + 4z = 1\n\\end{cases}\\)\n\n\n\n\nQue pode ser representado por:\n\\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 2 & 0 & 1\\\\\n0 & 1 & 0 & 2 & 0\\\\\n2 & 0 & 4 & 0 & 0\\\\\n0 & 2 & 0 & 4 & 1\n\\end{array} \\right]\\) \\(\\begin{array}{c}\n\\\\\n\\\\\nL_3 - 2L_1 \\\\\nL_4 - 2L_2 \\\\\n\\end{array}\\) \\(\\left[ \\begin{array}{cccc|c}\n1 & 0 & 2 & 0 & 1\\\\\n0 & 1 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & -2\\\\\n0 & 0 & 0 & 0 & -1\n\\end{array} \\right]\\)\n\nA matriz na forma escalonada mostra que o sistema n√£o tem solu√ß√£o e portanto a matriz \\(B\\) n√£o √© invert√≠vel."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-4",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-4",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz",
    "text": "Inversa de uma matriz\n\n\n\n\n\n\n\nTeorema\n\n\nSe \\(A\\) √© uma matriz \\(n \\times n\\) invert√≠vel, o sistema de equa√ß√µes lineares dado por \\(A\\vec{x} = \\vec{b}\\) tem uma √∫nica solu√ß√£o \\(\\vec{x} = A^{-1}\\vec{b}\\) para cada \\(\\vec{b}\\) em \\(\\mathbb{R}^n\\).\n\n\n\n\n\n\n\n\n\n\n\nPropriedades\n\n\n\nSe \\(A\\) √© uma matriz invert√≠vel, ent√£o \\(A^{-1}\\) √© invert√≠vel e \\((A^{-1})^{-1} = A\\).\nSe \\(A\\) √© uma matriz invert√≠vel e \\(c\\) √© um escalar n√£o nulo, ent√£o \\(cA\\) √© uma matriz invert√≠vel e \\((cA)^{-1} = \\frac{1}{c}A^{-1}\\).\nSe \\(A\\) e \\(B\\) s√£o matrizes invert√≠veis de mesma ordem, ent√£o \\(AB\\) √© invert√≠vel e \\((AB)^{-1} = B^{-1}A^{-1}\\).\nSe \\(A\\) √© uma matriz invert√≠vel, ent√£o \\(A^T\\) √© invert√≠vel e \\((A^T)^{-1} = (A^{-1})^T\\).\nSe \\(A\\) √© uma matriz invert√≠vel, ent√£o, para todo inteiro n√£o negativo \\(n\\), a matriz \\(A^n\\) √© invert√≠vel e \\((A^n)^{-1} = (A^{-1})^n\\)."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-m√©todo-de-gauss-jordan",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-m√©todo-de-gauss-jordan",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz pelo m√©todo de Gauss-Jordan",
    "text": "Inversa de uma matriz pelo m√©todo de Gauss-Jordan\n\nPara encontrar a inversa de uma matriz \\(A\\) usando o m√©todo de Gauss-Jordan, seguimos os seguintes passos:\n\nForma√ß√£o da Matriz Aumentada:\n\n\nDada uma matriz \\(A\\) de ordem \\(n \\times n\\), formamos a matriz aumentada \\([A \\mid I]\\), onde \\(I\\) √© a matriz identidade de ordem \\(n \\times n\\).\n\n\nAplica√ß√£o de Opera√ß√µes Elementares:\n\n\nAplicamos opera√ß√µes elementares sobre as linhas da matriz aumentada \\([A \\mid I]\\) para transformar a parte esquerda (a matriz \\(A\\)) na matriz identidade \\(I\\).\n\n\nObten√ß√£o da Inversa:\n\n\nQuando a parte esquerda da matriz aumentada se transforma em \\(I\\), a parte direita ser√° a matriz inversa \\(A^{-1}\\). Ou seja, \\([I \\mid A^{-1}]\\)."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-m√©todo-de-gauss-jordan-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#inversa-de-uma-matriz-pelo-m√©todo-de-gauss-jordan-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Inversa de uma matriz pelo m√©todo de Gauss-Jordan",
    "text": "Inversa de uma matriz pelo m√©todo de Gauss-Jordan\n\nExemplo Pr√°tico\n\n\nConsidere a matriz \\(A = \\begin{bmatrix} 2 & 1 & 1 \\\\ 1 & 3 & 2 \\\\ 1 & 0 & 0 \\end{bmatrix}\\).\n\nQue tem a matriz aumentada \\([A \\mid I]\\):\n\\[\\left[\\begin{array}{ccc|ccc}\n   2 & 1 & 1 & 1 & 0 & 0 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   1 & 0 & 0 & 0 & 0 & 1\n   \\end{array}\\right]\\]\n\n\n\n\nAplique opera√ß√µes elementares para transformar a parte esquerda em \\(I\\):\n\\(\\left[\\begin{array}{ccc|ccc}\n   2 & 1 & 1 & 1 & 0 & 0 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   1 & 0 & 0 & 0 & 0 & 1\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   L_1 \\leftrightarrow L_3\\\\\n   \\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   1 & 3 & 2 & 0 & 1 & 0 \\\\\n   2 & 1 & 1 & 1 & 0 & 0\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 - L_1\\\\\n   L_3 - 2L_1\\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 3 & 2 & 0 & 1 & -1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 \\leftrightarrow L_3\\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 3 & 2 & 0 & 1 & -1\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   \\\\\n   L_3 - 3L_2\\\\\n   \\end{array}\\)\n\\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 0 & -1 & -3 & 1 & 5\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   \\\\\n   -L_3\\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 1 & 1 & 0 & -2 \\\\\n   0 & 0 & 1 & 3 & -1 & -5\n   \\end{array}\\right]\\) \\(\\begin{array}{c}\n   \\\\\n   L_2 - L_3\\\\\n   \\\\\n   \\end{array}\\) \\(\\left[\\begin{array}{ccc|ccc}\n   1 & 0 & 0 & 0 & 0 & 1 \\\\\n   0 & 1 & 0 & -2 & 1 & 3 \\\\\n   0 & 0 & 1 & 3 & -1 & -5\n   \\end{array}\\right]\\)\n\n\\[A^{-1} = \\begin{bmatrix}\n   0  &  0 &  1 \\\\\n   -2 &  1 &  3 \\\\\n   3  & -1 & -5\n   \\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#matrizes-elementares",
    "href": "content/multivariada-numerica/intro-matrizes.html#matrizes-elementares",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Matrizes Elementares",
    "text": "Matrizes Elementares\n\nDefini√ß√£o:\nMatrizes elementares s√£o aquelas obtidas atrav√©s de opera√ß√µes elementares realizadas sobre a matriz identidade. Elas desempenham um papel fundamental na solu√ß√£o de sistemas lineares e na obten√ß√£o da inversa de uma matriz.\nExemplos de Opera√ß√µes Elementares:\n\nTroca de Linhas: Exemplo: Trocar a linha 1 pela linha 2.\n\\[E = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\\]\nMultiplica√ß√£o de uma Linha por um Escalar: Exemplo: Multiplicar a linha 1 por um escalar \\(k\\).\n\\[E = \\begin{bmatrix} k & 0 \\\\ 0 & 1 \\end{bmatrix}\\]\nAdi√ß√£o de M√∫ltiplos de Linhas: Exemplo: Adicionar a linha 2 multiplicada por um escalar \\(k\\) √† linha 1.\n\\[E = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de Matrizes Elementares para Calcular a Inversa",
    "text": "Exemplo de Matrizes Elementares para Calcular a Inversa\n\n\n\nConsidere a matriz \\(A = \\begin{bmatrix} 2 & 1 & 1 \\\\ 1 & 3 & 2 \\\\ 1 & 0 & 0 \\end{bmatrix}\\).\n\nQue foi resolvida no exemplo anterior pela sequ√™ncia de opera√ß√µes elementares:\n\n\\(L_1 \\leftrightarrow L_3\\)\n\\(L_2 \\rightarrow L_2 - L_1\\); \\(L_3 \\rightarrow L_3 - 2L_1\\)\n\\(L_2 \\leftrightarrow L_3\\)\n\\(L_3 \\rightarrow L_3 - 3L_2\\)\n\\(L_3 \\rightarrow -L_3\\)\n\\(L_2 \\rightarrow L_2 - L_3\\)\n\n\n\n\n\n\n\n\nTroca de \\(L_1\\) e \\(L_3\\):\n\\[E_1 = \\begin{bmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{bmatrix}\\]\n\\(L_2 \\rightarrow L_2 - L_1\\); \\(L_3 \\rightarrow L_3 - 2L_1\\):\n\\[E_2 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n-1 & 1 & 0 \\\\\n-2 & 0 & 1\n\\end{bmatrix}\\]\nTroca de \\(L_2\\) e \\(L_3\\):\n\\[E_3 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{bmatrix}\\]\n\n\n\n\\(L_3 \\rightarrow L_3 - 3L_2\\):\n\\[E_4 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & -3 & 1\n\\end{bmatrix}\\]\nMultiplica√ß√£o de \\(L_3\\) por \\(-1\\):\n\\[E_5 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & -1\n\\end{bmatrix}\\]\n\\(L_2 \\rightarrow L_2 - L_3\\):\n\\[E_6 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & -1 \\\\\n0 & 0 & 1\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-matrizes-elementares-para-calcular-a-inversa-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de Matrizes Elementares para Calcular a Inversa",
    "text": "Exemplo de Matrizes Elementares para Calcular a Inversa\n\nEstabelecidas as matrizes elementares \\(E_1\\) a \\(E_6\\), tem-se a seguinte rela√ß√£o:\n\\[E_6 \\times E_5 \\times E_4 \\times E_3 \\times E_2 \\times E_1 \\times A = I\\]\nE consequentemente:\n\\[E_1^{-1} \\times E_2^{-1} \\times E_3^{-1} \\times E_4^{-1} \\times E_5^{-1} \\times E_6^{-1} = A\\]\n\n\n\n\n\n\n\n\n\nO Teorema Fundamental das Matrizes Invert√≠veis - vers√£o 1\n\n\nSeja \\(A\\) uma matriz \\(n \\times n\\). As seguintes afirma√ß√µes s√£o equivalentes:\n\n\\(A\\) √© invert√≠vel.\n\\(A\\vec{x} = \\vec{b}\\) tem uma √∫nica solu√ß√£o para cada \\(\\vec{b}\\) em \\(\\mathbb{R}^n\\).\n\\(A\\vec{x} = 0\\) tem apenas a solu√ß√£o trivial.\nA forma escalonada reduzida de \\(A\\) √© \\(I_n\\).\n\\(A\\) √© um produto de matrizes elementares."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral\n\nProblema\nOs recifes de coral enfrentam v√°rias amea√ßas ambientais, como branqueamento, acidifica√ß√£o dos oceanos e destrui√ß√£o f√≠sica. Essas amea√ßas podem ser modeladas usando uma Cadeia de Markov para entender a probabilidade de um recife estar em um certo estado de sa√∫de ao longo do tempo.\nEstados\nDefinimos tr√™s estados poss√≠veis para a sa√∫de de um recife de coral:\n\nS1: Saud√°vel\nS2: Moderadamente Degradado\nS3: Severamente Degradado\n\nMatriz de Transi√ß√£o\nA matriz de transi√ß√£o de estados, \\(P\\), representa as probabilidades de transi√ß√£o entre os estados de sa√∫de de um recife de coral de um per√≠odo para o outro.\n\\[P = \\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix}\\]\nCada elemento \\(P_{ij}\\) na matriz representa a probabilidade de transi√ß√£o do estado \\(j\\) na coluna para o estado \\(i\\) na linha. Por exemplo, \\(P_{12} = 0.2\\) indica que h√° uma probabilidade de 20% de um recife saud√°vel (\\(S1\\)) passar para o estado moderadamente degradado (\\(S2\\)) no pr√≥ximo per√≠odo."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-1",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-1",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral\n\nEstado inicial\nVamos considerar que inicialmente no tempo \\(t_0\\) 80% dos recifes est√£o saud√°veis, 15% est√£o moderadamente degradados e 5% est√£o severamente degradados. Isso pode ser representado pelo vetor de estado inicial:\n\\[\\vec{v_0} = \\begin{bmatrix}\n0.8 \\\\\n0.15 \\\\\n0.05\n\\end{bmatrix}\\]\nEstado em \\(t + 1\\)\nPara determinar o estado dos recifes ap√≥s um per√≠odo de tempo \\(t_1\\), multiplicamos o vetor de estado inicial pela matriz de transi√ß√£o:\n\\[\n\\vec{v_1} = P \\times \\vec{v_0} = \\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix} \\times \\begin{bmatrix}\n0.8 \\\\\n0.15 \\\\\n0.05\n\\end{bmatrix} = \\begin{bmatrix}\n0.61 \\\\\n0.25 \\\\\n0.14\n\\end{bmatrix}\n\\]\nIsso significa que, ap√≥s um per√≠odo, 61% dos recifes estar√£o saud√°veis, 25% estar√£o moderadamente degradados e 14% estar√£o severamente degradados."
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-2",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-2",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral\n\nEstado Estacion√°rio\nO estado estacion√°rio √© um vetor de probabilidades que representa a distribui√ß√£o dos estados de um sistema em equil√≠brio, onde as probabilidades de estar em cada estado n√£o mudam com o tempo. Para uma cadeia de Markov, isso ocorre quando o vetor de estado n√£o muda ap√≥s uma multiplica√ß√£o pela matriz de transi√ß√£o.\nSe \\(\\vec{v_{ss}}\\) √© um vetor de estado estacion√°rio e \\(P\\) √© a matriz de transi√ß√£o, ent√£o:\n\\[\n\\vec{v_{ss}} = P \\times \\vec{v_{ss}}\n\\]\nPortanto, precisamos resolver o sistema de equa√ß√µes:\n\\[\n\\begin{bmatrix}\n0.7 & 0.3 & 0.1 \\\\\n0.2 & 0.5 & 0.3 \\\\\n0.1 & 0.2 & 0.6\n\\end{bmatrix} \\times \\begin{bmatrix}\n\\pi_1 \\\\\n\\pi_2 \\\\\n\\pi_3\n\\end{bmatrix} = \\begin{bmatrix}\n\\pi_1 \\\\\n\\pi_2 \\\\\n\\pi_3\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-3",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-3",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral\n\nResolu√ß√£o do Sistema\n\n\nH√° ainda uma condi√ß√£o adicional de que a soma das probabilidades em \\(\\vec{v_t}\\) seja 1:\n\\[\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\]\n\nQue gera e sistema de equa√ß√µes:\n\\[\n\\begin{cases}\n0.7\\pi_1 + 0.3\\pi_2 + 0.1\\pi_3 = \\pi_1 \\\\\n0.2\\pi_1 + 0.5\\pi_2 + 0.3\\pi_3 = \\pi_2 \\\\\n0.1\\pi_1 + 0.2\\pi_2 + 0.6\\pi_3 = \\pi_3 \\\\\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\end{cases}\n\\]\n\n\n\n\n\n\nO pode ser reorganizado como:\n\\[\n\\begin{cases}\n-3\\pi_1 + 3\\pi_2 + \\pi_3 = 0 \\\\\n2\\pi_1 - 5\\pi_2 + 3\\pi_3 = 0 \\\\\n\\pi_1 + 2\\pi_2 - 4\\pi_3 = 0 \\\\\n\\pi_1 + \\pi_2 + \\pi_3 = 1\n\\end{cases}\n\\]\n\nE tem solu√ß√£o:\n\\[\n\\vec{v_{ss}} = \\begin{bmatrix} \\frac{7}{17} \\\\ \\frac{11}{34} \\\\ \\frac{9}{34} \\end{bmatrix} ~ \\sim \\begin{bmatrix}\n0.4117 \\\\\n0.3235 \\\\\n0.2647\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\n\nResolu√ßao completa\n\n\nFa√ßa o download da RESOLU√á√ÉO COMPLETA"
  },
  {
    "objectID": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-4",
    "href": "content/multivariada-numerica/intro-matrizes.html#exemplo-de-aplica√ß√£o-cadeias-de-markov-para-recifes-de-coral-4",
    "title": "Introdu√ß√£o √† √Ålgebra de Matrizes",
    "section": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral",
    "text": "Exemplo de aplica√ß√£o: Cadeias de Markov para Recifes de Coral\n\nInterpreta√ß√£o do vetor de Estado Estacion√°rio\nNo longo prazo, a distribui√ß√£o das probabilidades entre os estados √©:\n\n\\(\\pi_1 = \\frac{7}{17} ~ \\sim 0.4117\\)\n\\(\\pi_2 = \\frac{11}{34} ~ \\sim 0.3235\\)\n\\(\\pi_3 = \\frac{9}{34} ~ \\sim 0.2647\\)\n\n\n\n\n\n\n\n\n\nConclus√£o\n\n\nA exist√™ncia de um vetor estacion√°rio indica que, independentemente do estado inicial, a cadeia de Markov converge para essa distribui√ß√£o de probabilidade quando o sistema est√° em equil√≠brio.\nPortanto, mantendo as condi√ß√µes atuais que resultam na matriz de transi√ß√£o vigente, espera-se que, a longo prazo, aproximadamente 41,18% do recife de coral permanecer√° em condi√ß√µes Saud√°veis, 32,35% estar√° Moderadamente Degradado e 26,47% ser√° Severamente Degradado.\n\n\n\n\n\n\n\n\nBICT Mar - Unifesp ¬∑ Ecologia Num√©rica"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html",
    "href": "content/regressao-linear/regressao-linear-multipla.html",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(patchwork)\nlibrary(gt)"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#abund√¢ncia-de-aves-em-fragmentos-de-floresta",
    "href": "content/regressao-linear/regressao-linear-multipla.html#abund√¢ncia-de-aves-em-fragmentos-de-floresta",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "1 Abund√¢ncia de aves em fragmentos de floresta",
    "text": "1 Abund√¢ncia de aves em fragmentos de floresta\nLoyn (1987) conduziu um estudo para entender quais caracter√≠sticas do habitat estavam relacionadas √† abund√¢ncia de aves da floresta (acesse o artigo aqui). Para isso, ele selecionou 56 fragmentos de floresta no sudeste de Victoria, Austr√°lia, e registrou a abund√¢ncia de aves da floresta (ABUND) em cada fragmento como vari√°vel de resposta.\nAs vari√°veis preditoras registradas para cada fragmento inclu√≠ram:\n\n√Årea do fragmento (ha): AREA\nDist√¢ncia ao fragmento mais pr√≥ximo (km): DIST\nDist√¢ncia ao fragmento maior mais pr√≥ximo (km):LDIST\nN√∫mero de anos desde que o fragmento foi isolado por desmatamento (anos):YR.ISOL\n√çndice de hist√≥rico de pastagem, de 1 (leve) a 5 (pesado):GRAZE\nAltitude m√©dia (m):ALT\n\nInicialmente, vamos nos concentrar nas vari√°veis YR.ISOL, GRAZE e ALT.\nImporte a base de dados loyn.csv\n\nloyn = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/loyn.csv\")\n\nhead(loyn) |&gt; gt()\n\n\n\n\n\n\n\nABUND\nAREA\nYR.ISOL\nDIST\nLDIST\nGRAZE\nALT\n\n\n\n\n5.3\n0.1\n1968\n39\n39\n2\n160\n\n\n2.0\n0.5\n1920\n234\n234\n5\n60\n\n\n1.5\n0.5\n1900\n104\n311\n5\n140\n\n\n17.1\n1.0\n1966\n66\n66\n3\n160\n\n\n13.8\n1.0\n1918\n246\n246\n5\n140\n\n\n14.1\n1.0\n1965\n234\n285\n3\n130"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#gr√°ficos-de-dispers√£o-entre-abund-e-cada-uma-das-demais-vari√°veis-preditoras",
    "href": "content/regressao-linear/regressao-linear-multipla.html#gr√°ficos-de-dispers√£o-entre-abund-e-cada-uma-das-demais-vari√°veis-preditoras",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "2 Gr√°ficos de dispers√£o entre ABUND e cada uma das demais vari√°veis preditoras",
    "text": "2 Gr√°ficos de dispers√£o entre ABUND e cada uma das demais vari√°veis preditoras\n\nplt_gr &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = GRAZE) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\nplt_al &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = ALT) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\nplt_yr &lt;- ggplot(loyn) +\n  aes(y = ABUND, x = YR.ISOL) +\n  geom_point() +\n  geom_smooth(se = FALSE, span = 1)\n\n\nplt_gr + plt_al + plt_yr"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#multicolinearidade-as-vari√°veis-preditoras-s√£o-correlacionadas-entre-si",
    "href": "content/regressao-linear/regressao-linear-multipla.html#multicolinearidade-as-vari√°veis-preditoras-s√£o-correlacionadas-entre-si",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "3 Multicolinearidade: as vari√°veis preditoras s√£o correlacionadas entre si?",
    "text": "3 Multicolinearidade: as vari√°veis preditoras s√£o correlacionadas entre si?\n\nggpairs(loyn |&gt; select(GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nAs vari√°veis ALT versus GRAZE e GRAZE versus YR.ISOL parecem ter um grau de correla√ß√£o moderado entre si."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#o-modelo-de-regress√£o-m√∫ltipla",
    "href": "content/regressao-linear/regressao-linear-multipla.html#o-modelo-de-regress√£o-m√∫ltipla",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "4 O modelo de regress√£o m√∫ltipla",
    "text": "4 O modelo de regress√£o m√∫ltipla\nO modelo de regress√£o linear m√∫ltipla √© dado por:\n\\[ABUND_i = \\beta_0 + \\beta_1 ALT_i + \\beta_2 YR.ISIOL_i + \\epsilon_i\\]\nNo R pode ser ajustado por:\n\nmfull &lt;- lm(ABUND ~ ALT + YR.ISOL, data  = loyn)\nmfull\n\n\nCall:\nlm(formula = ABUND ~ ALT + YR.ISOL, data = loyn)\n\nCoefficients:\n(Intercept)          ALT      YR.ISOL  \n -348.47698      0.07006      0.18348  \n\n\nO resumo do modelo pode ser visto com a fun√ß√£o summary\n\nsummary(mfull)\n\n\nCall:\nlm(formula = ABUND ~ ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.9745  -6.4690   0.6168   7.4408  24.0155 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -348.47698   93.73407  -3.718 0.000486 ***\nALT            0.07006    0.02852   2.457 0.017329 *  \nYR.ISOL        0.18348    0.04852   3.781 0.000398 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.953 on 53 degrees of freedom\nMultiple R-squared:  0.3297,    Adjusted R-squared:  0.3044 \nF-statistic: 13.03 on 2 and 53 DF,  p-value: 2.49e-05"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#hip√≥tese-nula-e-compara√ß√£o-de-modelos",
    "href": "content/regressao-linear/regressao-linear-multipla.html#hip√≥tese-nula-e-compara√ß√£o-de-modelos",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "5 Hip√≥tese nula e compara√ß√£o de modelos",
    "text": "5 Hip√≥tese nula e compara√ß√£o de modelos\nA hip√≥tese nula (\\(H_0\\)) b√°sica que podemos testar ao ajustar um modelo de regress√£o linear m√∫ltipla √© que todas as inclina√ß√µes de regress√£o parciais s√£o iguais a zero, ou seja, \\(H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_j = 0\\). Neste exemplo, \\(H_0\\) √© que o coeficiente de inclina√ß√£o dos n√≠veis de pastagem e os anos de isolamento do fragmento sejam ambos iguais a zero e, consequentemente, n√£o t√™m influ√™ncia sobre a abund√¢ncia.\nTestamos a hip√≥tese nula com a ANOVA na regress√£o m√∫ltipla, que divide a varia√ß√£o total de \\(Y\\) em dois componentes: a varia√ß√£o explicada pela regress√£o linear com \\(X_1\\), \\(X_2\\), \\(\\cdots\\), \\(X_j\\) e a varia√ß√£o residual.\nSe \\(H_0\\) for verdadeira, tanto o quadrado m√©dio da regress√£o \\(QM_{Regress√£o}\\) quanto o quadrado m√©dio do res√≠duo (\\(QM_{Res√≠duo}\\)) estimar√£o \\(\\sigma^2\\), e a raz√£o \\(F\\) entre eles ser√° igual a 1. Se \\(H_0\\) for falsa, pelo menos uma das inclina√ß√µes de regress√£o parciais n√£o ser√° igual a zero e \\(QM_{Regress√£o}\\) estimar√° \\(\\sigma^2\\) mais um termo \\(QM_{Regress√£o}\\) o que representa essas inclina√ß√µes de regress√£o parciais. Portanto, a raz√£o \\(F = \\frac{QM_{Regress√£o}}{QM_{Regress√£o}} &gt; 1\\). Neste caso, a decis√£o de aceitar \\(H_0\\) √© feita pela compara√ß√£o do \\(F\\) calculado com a distribui√ß√£o \\(F\\) apropriada, da mesma forma que fazemos com a regress√£o linear simples ou com a An√°lise de Vari√¢ncia.\nO resultado da raz√£o \\(F\\) aparece no comando summary, que no exemplo acima √© F = 13.035, com valor de p = 2.5^{-5}.\nTamb√©m podemos testar as hip√≥teses nulas sobre cada coeficiente de regress√£o parcial, ou seja, de que qualquer \\(\\beta_1\\) seja igual a zero. Para isto, podemos usar a estrat√©gia de compara√ß√£o de modelos em que o modelo completo (aquele com todas as vari√°veis) √© comparado com o modelo reduzido (aquele sem a vari√°vel \\(X_1\\) de interesse).\nPara testar o efeito da altitude, por exemplo, o modelo reduzido √©:\n\\(ABUND_i = \\beta_0 + \\beta_2 YR.ISIOL_i + \\epsilon_i\\)\nO modelo completo tem soma dos quadrados (\\(SQ\\)) maior que o modelo reduzido. Para comparar o ganho extra que o modelo completo tem sobre o modelo reduzido podemos fazer:\n\\(SS_{extra} = SS_{Regress√£o_{completo}} - SS_{Regress√£o_{reduzido}}\\)\nEm seguida, calculamos o quadrado m√©dio extra como \\(QM_{extra} = \\frac{SS_{extra}}{gl}\\) e usamos o teste \\(F\\) como:\n\\(F = \\frac{QM_{extra}}{QM_{Res√≠duo_{completo}}}\\)\nO mesmo pode ser feito para a vari√°vel \\(YR.ISOL\\).\nNo R, podemos testar os efeitos dos coeficientes parciais de regress√£o com o comando drop1.\n\ndrop1(mfull, test = 'F')\n\nSingle term deletions\n\nModel:\nABUND ~ ALT + YR.ISOL\n        Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;               4248.3 248.42                      \nALT      1    483.79 4732.1 252.46  6.0355 0.0173292 *  \nYR.ISOL  1   1146.10 5394.4 259.80 14.2982 0.0003979 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVemos aqui que os dois componentes (ALT e YR.ISOL) adicionam uma varia√ß√£o explicada significativa, isto √©, para os dois coeficientes \\(p \\le 0,005\\).\nNote que o teste o teste F de compara√ß√£o de modelos foi equivalente ao teste \\(t\\) aplicado a cada coeficiente e que pode ser visto no resultado da fun√ß√£o summary, sendo \\(F = t^2\\). No entanto, a estrat√©gia de compara√ß√£o de modelos apresentada aqui permite a compara√ß√£o n√£o somente de coeficientes isolados, mas de qualquer combina√ß√£o espec√≠fica dos coeficientes em compara√ß√£o com o modelo completo."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#coeficiente-de-determina√ß√£o-r2",
    "href": "content/regressao-linear/regressao-linear-multipla.html#coeficiente-de-determina√ß√£o-r2",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "6 Coeficiente de determina√ß√£o (\\(R^2\\))",
    "text": "6 Coeficiente de determina√ß√£o (\\(R^2\\))\nNa regress√£o m√∫ltipla, o coeficiente de determina√ß√£o \\(R^2\\) mede a propor√ß√£o da variabilidade total da vari√°vel resposta que √© explicada pelas vari√°veis preditoras. No entanto, \\(R^2\\) tende a aumentar √† medida que mais preditores s√£o adicionados ao modelo, mesmo que n√£o sejam significativos. Para corrigir essa infla√ß√£o, utilizamos o coeficiente de determina√ß√£o ajustado (\\(R^2_{ajustado}\\)), que ajusta o \\(R^2\\) considerando o n√∫mero de preditores no modelo e o tamanho da amostra. O \\(R^2_{ajustado}\\) penaliza a adi√ß√£o de preditores irrelevantes, proporcionando uma avalia√ß√£o mais precisa da qualidade do ajuste do modelo e pode ser obtido pela express√£o:\n\\(R^2_{ajustado} = 1 - \\frac{(1-R^2)(n-1)}{n-k-1}\\)\nNo resultado da fun√ß√£o summary vemos que o \\(R^2 = 0.33\\) e o \\(R^2_{ajustado} = 0.304\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#pressupostos-da-regress√£o-linear-m√∫ltipla",
    "href": "content/regressao-linear/regressao-linear-multipla.html#pressupostos-da-regress√£o-linear-m√∫ltipla",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "7 Pressupostos da regress√£o linear m√∫ltipla",
    "text": "7 Pressupostos da regress√£o linear m√∫ltipla\n\n7.1 Normalidade dos res√≠duos\n\nloyn &lt;- loyn |&gt; \n  mutate(rst = rstudent(mfull),\n         yaj = fitted(mfull))\n\n\nggplot(loyn) +\n  aes(x = rst, y = after_stat(density)) +\n  geom_histogram(bins = 10, density = TRUE, color = 'white') +\n  geom_density(color = 'darkblue', linewidth = 2)\n\n\n\n\n\n\n\n\n\nshapiro.test(loyn$rst)\n\n\n    Shapiro-Wilk normality test\n\ndata:  loyn$rst\nW = 0.97409, p-value = 0.2687\n\n\n\n\n7.2 Gr√°fico de res√≠duos\n\nggplot(loyn) +\n  aes(x = yaj, y = rst) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\")\n\n\n\n\n\n\n\n\n\n\n7.3 √çndice de Alavancagem (Leverage)\n\ninfl &lt;- influence.measures(mfull)$infmat |&gt; \n  as.data.frame()\n\nggplot(infl) +\n  aes(y = hat, x = 1:nrow(infl)) +\n  geom_point() +\n  ylab('Leverage')\n\n\n\n\n\n\n\n\n\n\n7.4 √çndice de Alavancagem de Cook (Dcook)\nO √≠ndice de alavancagem de Cook √© uma medida que combina a magnitude do efeito de alavancagem de uma observa√ß√£o com o quanto essa observa√ß√£o influencia a estimativa dos coeficientes de regress√£o. Uma observa√ß√£o com \\(D_{Cook} &gt; 1\\) √© frequentemente considerada influente e devem ser examinada para avaliar seu impacto no modelo.\nPara obter o √≠ndice de alavancagem de Cook em R:\n\nggplot(infl) +\n  aes(y = cook.d, x = 1:nrow(infl)) +\n  geom_point() +\n  ylab('Dist√¢ncia de Cook')"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#outros-dign√≥sticos",
    "href": "content/regressao-linear/regressao-linear-multipla.html#outros-dign√≥sticos",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "8 Outros dign√≥sticos",
    "text": "8 Outros dign√≥sticos\n\n8.1 Res√≠duos versus vari√°veis preditoras\n\nggplot(loyn) +\n  aes(x = ALT, y = rst) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(loyn) +\n  aes(x = YR.ISOL, y = rst) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n8.2 Res√≠duos dos modelos reduzidos versus vari√°veis preditoras\nNeste gr√°ficos, ajustamos os modelos reduzidos excluindo uma vari√°vel preditora por vez e plotamos os res√≠duos deste modelo com a vari√°vel preditora exclu√≠da. Uma tend√™ncia neste gr√°fico indica que a inclus√£o da vari√°vel no modelo ajudaria a reduzir a varia√ß√£o residual.\n\nmpalt &lt;- lm(ABUND ~ YR.ISOL, data  = loyn) # Modelo reduzido sem ALT\nplot(rstudent(mpalt) ~ loyn$ALT)\nabline(lm(rstudent(mpalt) ~ loyn$ALT))\n\n\n\n\n\n\n\n\n\nmpisol &lt;- lm(ABUND ~ ALT, data  = loyn) # Modelo reduzido sem YR.ISOL\nplot(rstudent(mpisol) ~ loyn$YR.ISOL)\nabline(lm(rstudent(mpisol) ~ loyn$YR.ISOL))"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#mais-sobre-multicolinearidade",
    "href": "content/regressao-linear/regressao-linear-multipla.html#mais-sobre-multicolinearidade",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "9 Mais sobre multicolinearidade",
    "text": "9 Mais sobre multicolinearidade\nVari√°veis preditoras correlacionadas entre si caracteriza a multicolinearidade. Quando severa, a multicolinearidade pode afetar a estimativa dos par√¢metros da regress√£o, pois pequenas altera√ß√µes nos dados ou inclus√£o/remo√ß√£o de vari√°veis podem causar grandes mudan√ßas nos coeficientes estimados da regress√£o. Al√©m disso, a presen√ßa de multicolinearidade pode inflar os erros padr√µes dos coeficientes de regress√£o, resultando em um modelo globalmente significativo, mas com coeficientes individuais que n√£o s√£o estatisticamente diferentes de zero.\nAvaliar uma matriz de correla√ß√£o entre pares de vari√°veis preditoras pode ser a primeira e mais simples forma de explorar a presen√ßa de colinearidade. Outra forma √© avaliar a toler√¢ncia de cada vari√°vel preditora \\(X_j\\) por meio de \\(1 - R^2_j\\), em que \\(R^2_j\\) √© o coeficiente de determina√ß√£o do modelo em que \\(X_j\\) √© relacionada √†s demais \\(1 - p\\) vari√°veis preditoras. Geralmente, esta toler√¢ncia √© expressa na forma do √≠ndice de infla√ß√£o da varia√ß√£o (variance inflation factor - \\(VIF\\)) para cada vari√°vel preditora, em que:\n\\[VIF_j =\\frac{1}{1 - R^2_j}\\]\nValores elevados indicam que a presen√ßa de colinearidade devido a vari√°vel \\(X_j\\). Diferente n√≠veis de corte s√£o propostos como indicadores da presen√ßa de multicolinearidade \\(VIF &gt; 5\\), \\(VIF &gt; 10\\) ou \\(VIF &gt; 20\\)\nTodos os coeficientes \\(VIF_j\\) podem ser encontrados em uma √∫nica opera√ß√£o calculando a inversa da matriz de correla√ß√£o, \\(\\mathbb{R^{1}}\\) entre as vari√°veis de interesse. Os elementos diagonais dessa matriz inversa s√£o os coeficientes \\(VIF_j\\). Vimos que GRAZE era correlacionada com ALT e com YR.ISOL. Os ceoficientes \\(VIF\\) para estas vari√°veis podem ser obtidos por:\n\nvif &lt;- loyn |&gt; \n  select(GRAZE, ALT, YR.ISOL) |&gt; \n  cor() |&gt; \n  solve() |&gt; \n  diag()\n\nvif\n\n   GRAZE      ALT  YR.ISOL \n1.904799 1.200372 1.679995 \n\n\nO \\(VIF\\) para GRAZE √© maior que os demais, por√©m longe do limite \\(VIF &gt; 5\\). Vejamos entretanto o que ocorre com o modelo para abund√¢ncia se inserimos estas tr√™s vari√°veis:\n\nmfull2 &lt;- lm(ABUND ~ GRAZE + ALT + YR.ISOL, data = loyn)\nsummary(mfull2)\n\n\nCall:\nlm(formula = ABUND ~ GRAZE + ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\nALT           0.03285    0.02679   1.226 0.225618    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\n\nNote que agora, somente GRAZE aparece com coeficiente estat√≠sticamente diferente de \\(0\\) e \\(R^2_{ajustado}\\) aumenta de 0.304 para 0.459"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-multipla.html#tranforma√ß√µes",
    "href": "content/regressao-linear/regressao-linear-multipla.html#tranforma√ß√µes",
    "title": "Regress√£o linear m√∫ltipla",
    "section": "10 Tranforma√ß√µes",
    "text": "10 Tranforma√ß√µes\nTransforma√ß√µes podem frequentemente ser eficazes se a distribui√ß√£o em situa√ß√µes em que as vari√°veis preditoras apresentem distribui√ß√µes assim√©tricas. Vamos incluir a AREA no modelo de regress√£o. Vejamos os graficos de disper√ß√£o entre as vari√°veis preditoras.\n\nggpairs(loyn |&gt; select(AREA, GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nH√° uma rela√ß√£o fortemente assim√©trica da vari√°vel √°rea, em que poucos framentos s√£o muito maiores. Vejamos as associa√ß√µes par a par utilizando a transfoma√ß√£o \\(log(AREA)\\)\n\nloyn$lAREA &lt;- log(loyn$AREA)\nggpairs(loyn |&gt; select(lAREA, GRAZE, ALT, YR.ISOL))\n\n\n\n\n\n\n\n\nA transforma√ß√£o resolveu o problema da assimetria.\nVamos ajustar agora o modelo de regress√£o:\n\nmfull3 &lt;- lm(ABUND ~ lAREA + GRAZE + ALT + YR.ISOL, data = loyn)\nsummary(mfull3)\n\n\nCall:\nlm(formula = ABUND ~ lAREA + GRAZE + ALT + YR.ISOL, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.4245  -3.3341   0.6227   2.6759  15.3290 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -141.88574   86.23728  -1.645   0.1061    \nlAREA          3.07303    0.55118   5.575 9.41e-07 ***\nGRAZE         -1.60127    0.90538  -1.769   0.0829 .  \nALT            0.02586    0.02136   1.210   0.2317    \nYR.ISOL        0.07991    0.04323   1.848   0.0703 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.283 on 51 degrees of freedom\nMultiple R-squared:  0.6823,    Adjusted R-squared:  0.6574 \nF-statistic: 27.39 on 4 and 51 DF,  p-value: 3.671e-12\n\n\nO resultado indica que somente o \\(log(AREA)\\) seja importante para predizer a abund√¢ncia. Entretanto, lembre-se que havia uma certo padr√£o de colinearidade entre GRAZE, ALT a YR.ISOL. Teste retirar uma a uma estas vari√°veis do modelo e avalie os resultados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "",
    "text": "Objetivos\n\n\n\nNeste tutorial, vamos implementar o M√©todo dos M√≠nimos Quadrados (MMQ) em Python para ajustar um modelo de regress√£o polinomial de segundo grau.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\beta_2\\) da equa√ß√£o \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#introdu√ß√£o",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#introdu√ß√£o",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "",
    "text": "Objetivos\n\n\n\nNeste tutorial, vamos implementar o M√©todo dos M√≠nimos Quadrados (MMQ) em Python para ajustar um modelo de regress√£o polinomial de segundo grau.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\beta_2\\) da equa√ß√£o \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#importando-as-bibliotecas",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#importando-as-bibliotecas",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "2 üõ†Ô∏è Importando as Bibliotecas",
    "text": "2 üõ†Ô∏è Importando as Bibliotecas\nVamos come√ßar importando as bibliotecas necess√°rias:\n\nimport pandas as pd           # Para manipula√ß√£o de dados\nimport matplotlib.pyplot as plt  # Para cria√ß√£o e manipula√ß√£o gr√°fica\nimport seaborn as sns        # Para cria√ß√£o e manipula√ß√£o gr√°fica\nimport numpy as np           # Para opera√ß√µes matem√°ticas e matriciais"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#inserindo-os-dados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#inserindo-os-dados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "3 üìä Inserindo os Dados",
    "text": "3 üìä Inserindo os Dados\nVamos trabalhar com dados que apresentam uma rela√ß√£o quadr√°tica. Ao inv√©s de digitarmos os dados diretamente \\(y\\) e \\(x\\) como listas, iremos ler os dados a partir de um arquivo que est√° dispon√≠vel no link regressao_polinomial_exemplo. O arquivo esta no formato .csv em que cada coluna √© separada por uma v√≠rgula, um tipo de formata√ß√£o muito comum.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regressao_polinomial_exemplo.csv')\n\nUtilizando a fun√ß√£o read_csv() da bilbioteca Pandas, os dados foram importados no formato de data frame, basicamento uma estrutura de dados em linhas e colunas, em que as colunas s√£o denominadas de atributos.\n\nprint(df)\n\n   x   y\n0  0   5\n1  1   2\n2  2  10\n3  3   8\n4  4  15\n5  5  35"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-os-dados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-os-dados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "4 üìà Visualizando os Dados",
    "text": "4 üìà Visualizando os Dados\nAntes de ajustar o modelo, vamos visualizar nossos dados:\n\n# Criando the gr√°fico de dispers√£o\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data = df, x = 'x', y = 'y', color = '#0072B2', s=120, label='Dados observados')\n\n# Configurando o gr√°fico\nplt.title('Gr√°fico de Dispers√£o dos Dados', fontsize=14, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nüìù Observa√ß√£o 1: Aparentemente, um modelo polinomial de segundo grau pode oferecer um ajuste melhor a estes dados do que a regress√£o linear simples. Nosso objetivo ser√° explorar esse modelo e, ao final, compar√°-lo com o modelo linear.\nüìù Observa√ß√£o 2: Como importamos os dados diretamente de um arquivo .csv para o objeto df, utilizamos a fun√ß√£o scatterplot da biblioteca Seaborn para plotar o gr√°fico de dispers√£o entre as vari√°veis \\(y\\) e \\(x\\)."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#implementando-o-mmq-polinomial---passo-a-passo",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#implementando-o-mmq-polinomial---passo-a-passo",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "5 üßÆ Implementando o MMQ Polinomial - Passo a Passo",
    "text": "5 üßÆ Implementando o MMQ Polinomial - Passo a Passo\n\n5.1 Criando os Vetores Base\nPara o modelo polinomial \\(\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2\\), precisamos dos vetores:\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_2 = \\begin{bmatrix} x_1^2 \\\\ x_2^2 \\\\ \\vdots \\\\ x_n^2 \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# N√∫mero de observa√ß√µes\nn = len(df['x'])\n\n# Vetor f0: vetor de 1's (para o intercepto Œ≤‚ÇÄ)\nf0 = [1] * n\n\n# Vetor f1: valores de x (para o coeficiente linear Œ≤‚ÇÅ)\nf1 = df['x'].copy()\n\n# Vetor f2: valores de x¬≤ (para o coeficiente quadr√°tico Œ≤‚ÇÇ)\nf2 = np.array(df['x'])**2  # Eleva cada elemento de x ao quadrado\n\nVisualizando os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{f}_2\\).\n\nprint(\"Vetor f0 (intercepto):\", f0)\nprint(\"Vetor f1 (termo linear):\", f1)\nprint(\"Vetor f2 (termo quadr√°tico):\", f2)\n\nVetor f0 (intercepto): [1, 1, 1, 1, 1, 1]\nVetor f1 (termo linear): 0    0\n1    1\n2    2\n3    3\n4    4\n5    5\nName: x, dtype: int64\nVetor f2 (termo quadr√°tico): [ 0  1  4  9 16 25]\n\n\n\n\n5.2 Construindo as Matrizes X e Y\nAgora vamos montar as matrizes do sistema polinomial:\n\\[X = \\begin{bmatrix} \\vec{f}_0 & \\vec{f}_1 & \\vec{f}_2 \\end{bmatrix} = \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ 1 & x_2 & x_2^2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x_n^2 \\end{bmatrix} \\quad \\text{e} \\quad Y = \\begin{bmatrix} \\vec{y} \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# Matriz X: combinando f0, f1 e f2 em colunas\nX = np.column_stack((f0, f1, f2))\n\n# Matriz Y: transformando y em matriz com n linhas e 1 coluna\nY = np.array(df['y']).reshape(n, 1)\n\n\n\n5.3 Resolvendo o Sistema Normal\nCalculamos os coeficientes usando a mesma f√≥rmula:\n\\[B = (X^T X)^{-1} X^T Y\\]\n\n# Calculando X transposta vezes X\nXTX = X.T @ X  # X.T √© a transposta de X\n# Calculando X transposta vezes Y\nXTY = X.T @ Y\n# Calculando a matriz inversa (X^T X)^(-1)\nXTX_inv = np.linalg.inv(XTX)  # Inversa de X^T X\n# Coeficientes de regress√£o\nB = XTX_inv @ XTY\n\n\n\n\n\n\n\nInterpreta√ß√£o\n\n\n\n\n\\(\\beta_0\\) (intercepto): valor de y quando x = 0\n\\(\\beta_1\\) (coeficiente linear): relacionado √† taxa de varia√ß√£o linear\n\\(\\beta_2\\) (coeficiente quadr√°tico): relacionado √† curvatura da par√°bola\n\nSe \\(\\beta_2 &gt; 0\\): par√°bola com concavidade para cima\nSe \\(\\beta_2 &lt; 0\\): par√°bola com concavidade para baixo\n\n\n\n\n\n\n5.4 Obtendo os Valores Ajustados de y\nTendo obtido os coeficientes de regress√£o, os valores ajustados de y (\\(\\hat{y}\\)) podem ser obtido pela multiplica√ß√£o matricial:\n\\[F = XB = \\begin{bmatrix} 1 & x_1 & x^2_1 \\\\ 1 & x_2 & x^2_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_n & x^2_n \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{bmatrix}\\]\nObs.: denominamos \\(F\\) a matriz de valores ajustados de \\(y\\).\n\n# Valores ajustados (preditos)\nF = X @ B\n\n\n\n5.5 Avaliando a Qualidade do Ajuste\n\n5.5.1 Calculando a Soma dos Quadrados dos Res√≠duos (\\(SQ_{res}\\))\n\\(SQ_{res}\\) pode ser obtida pela multiplica√ß√£o matricial:\n\\[SQ_{res} = \\boldsymbol{e}^T \\boldsymbol{e}\\]\nEm que \\(\\boldsymbol{e}\\) √© a matriz coluna dos res√≠duos obtida pela diferen√ßa entre os valores observados e ajustados de \\(y\\):\n\\[\\boldsymbol{e} = Y - F = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\]\n\n# Res√≠duos: diferen√ßa entre valores observados e ajustados\ne = Y - F\n\n# Soma dos Quadrados dos Res√≠duos\nSQres = (e.T @ e)[0, 0]\n\n\n\n5.5.2 Calculando a Soma dos Quadrados Totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser obtida pela multiplica√ß√£o matricial:\n\\[SQ_{tot} = \\boldsymbol{D}^T \\boldsymbol{D}\\]\nEm que \\(\\boldsymbol{D}\\) √© a matriz coluna dos desvios da m√©dis obtida pela diferen√ßa entre os valores observados de \\(y\\) e a m√©dia de \\(\\overline{y}\\):\n\\[\\boldsymbol{D} = Y - \\overline{Y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\overline{y} \\\\ \\overline{y} \\\\ \\vdots \\\\ \\overline{y} \\end{bmatrix} = \\begin{bmatrix} d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_n \\end{bmatrix}\\]\n\n# Soma dos Quadrados Total\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\n\n\n5.5.3 Calculando o coeficiente de determina√ß√£o \\(R^2\\):\nO \\(R^2\\) √© dado pela express√£o:\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]\n\n# Coeficiente de Determina√ß√£o R¬≤\nR2 = 1 - (SQres / SQtot)\n\n\nVisualizando os resultados:\n\nprint(\"üìä Medidas de Qualidade do Ajuste:\")\nprint(f\"Soma dos Quadrados dos Res√≠duos (SQres): {SQres:.4f}\")\nprint(f\"Soma dos Quadrados Total (SQtot): {SQtot:.4f}\")\nprint(f\"Coeficiente de Determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\n\nüìä Medidas de Qualidade do Ajuste:\nSoma dos Quadrados dos Res√≠duos (SQres): 59.2643\nSoma dos Quadrados Total (SQtot): 705.5000\nCoeficiente de Determina√ß√£o (R¬≤): 0.9160\nPorcentagem da varia√ß√£o explicada: 91.60%"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-o-resultado-final",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#visualizando-o-resultado-final",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "6 üìä Visualizando o Resultado Final",
    "text": "6 üìä Visualizando o Resultado Final\nVamos plotar os dados originais junto com a curva ajustada:\nCriando uma linha cont√≠nua para \\(\\hat{y}\\)\n\n# Criando pontos para desenhar a curva suave\nx_curva = np.linspace(min(df['x']), max(df['x']), 100)\ny_curva = B[0, 0] + B[1, 0] * x_curva + B[2, 0] * x_curva**2\n\n\n# Criando o gr√°fico final\nplt.figure(figsize=(8, 6))\n\n# Pontos observados\nsns.scatterplot(data = df, x = 'x', y = 'y', \n                color = '#0072B2', s=120,\n                label=f'Dados observados (n={n})')\n\n# Valores ajustados\nplt.scatter(df['x'], F[:,0], \n           color='#000000', marker='*', s=120, \n           label='Valores ajustados')\n\n# Curva ajustada\nplt.plot(x_curva, y_curva, \n         color='#D55E00', \n         label=fr'Curva ajustada: $\\hat{{y}} = {B[0,0]:.3f} {B[1,0]:.3f}x + {B[2,0]:.3f}x^2$')\n\n# Configura√ß√µes do gr√°fico\nplt.title(f'Regress√£o Polinomial (2¬∫ grau) - MMQ\\nR¬≤ = {R2:.4f}', \n          fontsize=15, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-dos-resultados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-dos-resultados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "7 üéØ Resumo dos Resultados",
    "text": "7 üéØ Resumo dos Resultados\n\nprint(\"=\"*60)\nprint(\"         RESUMO DA REGRESS√ÉO POLINOMIAL\")\nprint(\"=\"*60)\nprint(f\"Equa√ß√£o ajustada: y = {B[0,0]:.4f} {B[1,0]:.4f}x + {B[2,0]:.4f}x¬≤\")\nprint(f\"Coeficiente de determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\nprint(\"=\"*60)\n\n============================================================\n         RESUMO DA REGRESS√ÉO POLINOMIAL\n============================================================\nEqua√ß√£o ajustada: y = 5.7500 -4.5679x + 1.9821x¬≤\nCoeficiente de determina√ß√£o (R¬≤): 0.9160\nPorcentagem da varia√ß√£o explicada: 91.60%\n============================================================"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#compara√ß√£o-linear-vs-polinomial",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#compara√ß√£o-linear-vs-polinomial",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "8 üîç Compara√ß√£o: Linear vs Polinomial",
    "text": "8 üîç Compara√ß√£o: Linear vs Polinomial\nVamos comparar o ajuste linear e polinomial para os mesmos dados:\n\n# Ajuste LINEAR para compara√ß√£o\nX_linear = np.column_stack((f0, f1))  # Apenas f0 e f1\nB_linear = np.linalg.inv(X_linear.T @ X_linear) @ (X_linear.T @ Y)\n\n# R¬≤ do modelo linear\nF_linear = X_linear @ B_linear\nresiduos_linear = Y - F_linear\nSQres_linear = (residuos_linear.T @ residuos_linear)[0, 0]\nR2_linear = 1 - (SQres_linear / SQtot)\n\nprint(\"üìä Compara√ß√£o dos Modelos:\")\nprint(\"-\" * 40)\nprint(f\"Modelo Linear:     R¬≤ = {R2_linear:.4f}\")\nprint(f\"Modelo Polinomial: R¬≤ = {R2:.4f}\")\nprint(f\"Melhoria no R¬≤:    {R2 - R2_linear:.4f}\")\n\nüìä Compara√ß√£o dos Modelos:\n----------------------------------------\nModelo Linear:     R¬≤ = 0.7081\nModelo Polinomial: R¬≤ = 0.9160\nMelhoria no R¬≤:    0.2079\n\n\nGr√°ficos de dispers√£o\n\nx_vals = df[\"x\"].to_numpy()\n\ny_linear = B_linear[0, 0] + B_linear[1, 0] * x_vals\n\n# Gr√°fico comparativo\nplt.figure(figsize=(8, 6))\n\n# plt.subplot(1, 2, 1)\nsns.scatterplot(data = df, x = 'x', y = 'y', s=100, color = '#0072B2', label='Dados observados')\nplt.plot(x_vals, y_linear, color='#D55E00', label=f'Modelo Linear\\nR¬≤ = {R2_linear:.4f}')\nplt.plot(x_curva, y_curva, color='#009E73', label=f'Modelo Polinomial\\nR¬≤ = {R2:.4f}')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True, alpha=0.3)\nplt.legend()\n\n# plt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-do-c√≥digo-modelo-polinomial",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#resumo-do-c√≥digo-modelo-polinomial",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "9 üßæ Resumo do C√≥digo (modelo polinomial)",
    "text": "9 üßæ Resumo do C√≥digo (modelo polinomial)\n\nInser√ß√£o dos Dados\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regressao_polinomial_exemplo.csv')\n\n\nDefini√ß√£o das matrizes do sistema\n\n\nn = len(df['x'])\nf0 = [1] * n\nf1 = df['x'].copy()\nf2 = np.array(df['x'])**2\n\nX = np.column_stack((f0, f1, f2))\nY = np.array(df['y']).reshape(n, 1)\n\n\nC√°lculo dos coeficientes\n\n\nXTX = X.T @ X\nXTY = X.T @ Y\nXTX_inv = np.linalg.inv(XTX)\nB = XTX_inv @ XTY\n\n\nQualidade do ajuste\n\n\nY_ajustado = X @ B\ne = Y - Y_ajustado\nSQres = (e.T @ e)[0, 0]\n\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\nR2 = 1 - (SQres / SQtot)"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#exerc√≠cio-pr√°tico",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#exerc√≠cio-pr√°tico",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "10 üöÄ Exerc√≠cio Pr√°tico",
    "text": "10 üöÄ Exerc√≠cio Pr√°tico\nTeste o c√≥digo com novos dados:\n\n# Experimente com estes dados (padr√£o quadr√°tico diferente):\ndf_novo = pd.DataFrame({\n  'x_novo': [1, 2, 3, 4, 5, 6, 7],\n  'y_novo': [30, 12, 18, 9, 7, 8, 6]\n})\n\nprint(df_novo)\n\n# Quest√µes para investigar:\n# 1. Qual √© o R¬≤ do modelo polinomial para estes dados?\n# 2. O coeficiente Œ≤‚ÇÇ √© positivo ou negativo? O que isso significa?\n# 3. Compare com o modelo linear - qual √© a diferen√ßa no R¬≤?\n\n# Implemente todo o processo do MMQ polinomial com os novos dados\n# Dica: voc√™ pode copiar e adaptar o c√≥digo acima!\n\n   x_novo  y_novo\n0       1      30\n1       2      12\n2       3      18\n3       4       9\n4       5       7\n5       6       8\n6       7       6"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#conceitos-importantes-revisados",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#conceitos-importantes-revisados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "11 üí° Conceitos Importantes Revisados",
    "text": "11 üí° Conceitos Importantes Revisados\n\nRegress√£o Polinomial: Extens√£o da regress√£o linear para rela√ß√µes curvas\nMatriz de Design: Agora com tr√™s colunas: \\([1, x, x^2]\\)\nInterpreta√ß√£o dos Coeficientes: Cada coeficiente tem significado espec√≠fico\nCompara√ß√£o de Modelos: Uso do \\(R^2\\) para avaliar qual modelo √© melhor"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-polinomial.html#pr√≥ximos-passos",
    "href": "content/regressao-linear/mmq-regressao-polinomial.html#pr√≥ximos-passos",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial",
    "section": "12 üîó Pr√≥ximos Passos",
    "text": "12 üîó Pr√≥ximos Passos\n\nExperimente com polin√¥mios de grau maior (\\(x^3\\), \\(x^4\\), etc.)\nInvestigue o conceito de overfitting com graus muito altos"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html",
    "href": "content/funcoes-modelos/funcoes-potencia.html",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#pacotes-e-bibliotecas",
    "href": "content/funcoes-modelos/funcoes-potencia.html#pacotes-e-bibliotecas",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#defini√ß√£o-e-tipos-de-fun√ß√µes-pot√™ncias",
    "href": "content/funcoes-modelos/funcoes-potencia.html#defini√ß√£o-e-tipos-de-fun√ß√µes-pot√™ncias",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "2 Defini√ß√£o e Tipos de Fun√ß√µes Pot√™ncias",
    "text": "2 Defini√ß√£o e Tipos de Fun√ß√µes Pot√™ncias\nUma fun√ß√£o pot√™ncia √© definida como uma fun√ß√£o da forma \\(f(x) = x^k\\), em que \\(k\\) √© uma constante.\nO valor da constante \\(k\\) determina a classifica√ß√£o da fun√ß√£o pot√™ncia:\n\nMon√¥mio: para \\(k = n\\), onde \\(n\\) √© um inteiro positivo. Exemplos - \\(f(x) = x^2\\) ou \\(f(x) = x^3\\).\nFun√ß√£o raiz: para \\(k = 1/n\\), onde \\(n\\) √© um inteiro positivo. Exemplos - \\(f(x) = x^{1/2}\\) (raiz quadrada) ou \\(f(x) = x^{1/3}\\) (raiz c√∫bica).\nFun√ß√£o rec√≠proca: para \\(k = -1\\). Ou seja, \\(f(x) = x^{-1} = 1/x\\).\n\n\n2.1 Definindo e Visualizando Fun√ß√µes Pot√™ncias em Python\nVamos usar o Python para definir e plotar exemplos de cada tipo de fun√ß√£o pot√™ncia. Isso nos ajudar√° a entender suas caracter√≠sticas visuais.\n\n# Definindo a fun√ß√£o pot√™ncia em python\ndef potencia(x, n):\n    \"\"\"Fun√ß√£o pot√™ncia: f(x) = x^k.\"\"\"\n    return x**n\n\nUtilizando a fun√ß√£o criada.\n\n# Gerando um intervalo de valores para x para plotagem\n# Come√ßamos de 0.1 para evitar divis√£o por zero na fun√ß√£o rec√≠proca.\nx_values = np.linspace(0.1, 5, 400) \n# x_values\n\n\n# Gerando valores de y\ny_values = potencia(x_values, 2)\n# y_values\n\n\n# Criando tr√™s gr√°ficos lado a lado com diferentes valores de k\n# Criando os subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 3))\n\n# Primeiro gr√°fico: f(x) = x¬≤\nax1.plot(x_values, potencia(x_values, 2), label='f(x) = x¬≤')\nax1.set_title('Mon√¥mio')\nax1.set_xlabel('x')\nax1.set_ylabel('f(x)')\nax1.legend()\nax1.grid(True)\n\n# Segundo gr√°fico: f(x) = x^(1/2)\nax2.plot(x_values, potencia(x_values, 1/2), label='f(x) = x^(1/2)')\nax2.set_title('Fun√ß√£o Raiz')\nax2.set_xlabel('x')\nax2.set_ylabel('f(x)')\nax2.legend()\nax2.grid(True)\n\n# Terceiro gr√°fico: f(x) = x‚Åª¬π\nax3.plot(x_values, potencia(x_values, -1), label='f(x) = x‚Åª¬π')\nax3.set_title('Fun√ß√£o Rec√≠proca')\nax3.set_xlabel('x')\nax3.set_ylabel('f(x)')\nax3.legend()\nax3.grid(True)\n\n# Ajustando o layout e salvando a figura\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#exemplo-da-rela√ß√£o-esp√©cie-√°rea",
    "href": "content/funcoes-modelos/funcoes-potencia.html#exemplo-da-rela√ß√£o-esp√©cie-√°rea",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "3 Exemplo da Rela√ß√£o Esp√©cie-√Årea",
    "text": "3 Exemplo da Rela√ß√£o Esp√©cie-√Årea\nA fun√ß√£o pot√™ncia √© amplamente utilizada em ecologia para modelar fen√¥menos no mundo real. Um exemplo √© a rela√ß√£o entre o n√∫mero de esp√©cies (\\(S\\)) e a √°rea de uma regi√£o (\\(A\\)). A rela√ß√£o entre \\(S\\) e \\(A\\) √© geralmente modelada por:\n\\[S(A) = cA^k\\]\nEm que \\(c\\) e \\(k\\) s√£o coeficientes que precisam ser determinados a partir de dados observados.\nConsidere a tabela de dados que mostra valores de √°rea (A) e riqueza de esp√©cies (S):\n\n\n\nObserva√ß√£o\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\nA (km¬≤)\n0,25\n0,5\n1\n2\n4\n7,9\n15,9\n31,6\n63\n\n\nS\n6\n10\n13\n14\n17\n19\n22\n24\n28\n\n\n\nPodemos observar esta rela√ß√£o em Python como segue:\n\n3.1 Definindo a tabela de dados\n\n# Dados da tabela\ndata = {\n    'A': [0.25, 0.5, 1, 2, 4, 7.9, 15.9, 31.6, 63],\n    'S': [6, 10, 13, 14, 17, 19, 22, 24, 28]\n}\ndf = pd.DataFrame(data)\n\n\n\n3.2 Visualizando o gr√°fico de dispers√£o\n\nplt.figure(figsize=(8, 5))\nplt.scatter(df['A'], df['S'], label='Dados Observados')\nplt.title('Diagrama de Dispers√£o: Rela√ß√£o Esp√©cie-√Årea')\nplt.xlabel('√Årea (km¬≤)')\nplt.ylabel('N√∫mero de Esp√©cies')\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#m√©todo-dos-m√≠nimos-quadrados-mmq-para-o-modelo-de-regress√£o-pot√™ncia",
    "href": "content/funcoes-modelos/funcoes-potencia.html#m√©todo-dos-m√≠nimos-quadrados-mmq-para-o-modelo-de-regress√£o-pot√™ncia",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "4 M√©todo dos M√≠nimos Quadrados (MMQ) para o Modelo de Regress√£o Pot√™ncia",
    "text": "4 M√©todo dos M√≠nimos Quadrados (MMQ) para o Modelo de Regress√£o Pot√™ncia\nPodemos utilizar o MMQ para encontrar os coeficientes da rela√ß√£o de pot√™ncia. Para isso precisamos antes linearizar a rela√ß√£o, aplicando o logaritmo em ambos os lados da equa√ß√£o.\n\n\n\n\n\n\nLinearizando a rela√ß√£o pot√™ncia\n\n\n\n\nComece com a equa√ß√£o original: \\[S = cA^k\\]\nAplique o logaritmo (de qualquer base) nos dois lados: \\[\\log(S) = \\log(cA^k)\\]\nUse a propriedade do logaritmo do produto \\(\\log(xy) = \\log(x) + \\log(y)\\): \\[\\log(S) = \\log(c) + \\log(A^k)\\]\nUse a propriedade do logaritmo da pot√™ncia \\(\\log(x^p) = p\\log(x)\\): \\[\\log(S) = \\log(c) + k\\log(A)\\]\n\nAo final, obtemos uma equa√ß√£o linear na forma \\(y = a + bx\\), onde:\n\n\\(y = \\log(S)\\)\n\\(x = \\log(A)\\)\nO coeficiente angular √© \\(b = k\\)\nO intercepto linear (onde a reta cruza o eixo y) √© \\(a = \\log(c)\\)\n\n\n\nAp√≥s a lineariza√ß√£o, os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{y}\\), s√£o definidos como segue:\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} \\log(x_1) \\\\ \\log(x_2) \\\\ \\vdots \\\\ \\log(x_n) \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} \\log(y_1) \\\\ \\log(y_2) \\\\ \\vdots \\\\ \\log(y_n) \\end{bmatrix}\\]\nA partir da√≠, definimos as matrizes \\(X\\) e \\(Y\\) como no modelo linear simples e seguimos com as mesmas opera√ß√µes matriciais.\nVamos criar uma fun√ß√£o em python que implementa o MMQ:\n\n\n\n\n\n\nFun√ß√£o em python para MMQ\n\n\n\n\ndef mmq(x, y):\n    \"\"\"\n    Calcula os coeficientes (B) e o R¬≤ de uma regress√£o linear simples.\n\n    Args:\n        x (list ou np.ndarray): Os valores da vari√°vel independente.\n        y (list ou np.ndarray): Os valores da vari√°vel dependente.\n\n    Returns:\n        tuple: Uma tupla contendo a matriz de coeficientes B e o valor de R¬≤.\n    \"\"\"\n    # 1. Defini√ß√£o das matrizes do sistema\n    n = len(x)\n    # Converte para array numpy para garantir a funcionalidade\n    x_array = np.array(x)\n    f0 = np.ones(n)\n    f1 = x_array.copy()\n\n    X = np.column_stack((f0, f1))\n    Y = np.array(y).reshape(n, 1)\n\n    # 2. C√°lculo dos coeficientes\n    XTX = X.T @ X\n    XTY = X.T @ Y\n    XTX_inv = np.linalg.inv(XTX)\n    B = XTX_inv @ XTY\n    \n    return B\n\n\n\nDefinida a fun√ß√£o mmq basta utilizarmos com um conjunto de dados de entrada.\n\n# Ajustando o modelo esp√©cie-√°rea\nB_ea = mmq(np.log(df['A']), np.log(df['S']))\nB_ea\n\narray([[2.4039032 ],\n       [0.24475497]])\n\n\n\n4.1 Visualizando os coeficientes ajustados\n\nc = np.exp(B_ea[0])\nk = B_ea[1]\n\nprint('c: ', c)\nprint('k: ', k)\n\nc:  [11.06628617]\nk:  [0.24475497]\n\n\nO modelo de regress√£o pot√™ncia para a riqueza de esp√©cies, com base nos dados fornecidos, foi determinado como\n\\[S(A) = 11.066A^{0.244}\\]\nOs valores de \\(c\\) e \\(k\\) foram, respectivamente, \\(11.066\\) e \\(0.244\\)."
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#visualizando-o-ajuste-da-curva-de-regress√£o-pot√™ncia",
    "href": "content/funcoes-modelos/funcoes-potencia.html#visualizando-o-ajuste-da-curva-de-regress√£o-pot√™ncia",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "5 Visualizando o Ajuste da Curva de Regress√£o Pot√™ncia",
    "text": "5 Visualizando o Ajuste da Curva de Regress√£o Pot√™ncia\nPodemos criar uma nova fun√ß√£o que permitir√° encontrar os valores ajustados para o modelo pot√™ncia a partir dos coeficientes da regress√£o obtidos.\n\ndef S_modelo(novo_x, c, k):\n    y_fit = c * novo_x ** k\n    return y_fit\n\n\n5.1 Gerando novos valores de x\n\nA_values = np.linspace(np.min(df['A']), np.max(df['A']), 400) \nS_fit = S_modelo(A_values, c, k)\n\n\n\n5.2 Plotanto o gr√°fico\n\n# Plotar os dados e o modelo ajustado\nplt.figure(figsize=(8, 5))\nplt.scatter(df['A'], df['S'], label='Dados Observados')\nplt.plot(A_values, S_fit, color='red', label=f'Modelo Ajustado: S(A) = {c[0]:.3f}A^{k[0]:.3f}')\nplt.title('Modelo de Regress√£o Pot√™ncia Ajustado para Rela√ß√£o Esp√©cie-√Årea')\nplt.xlabel('√Årea (km¬≤)')\nplt.ylabel('N√∫mero de Esp√©cies')\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "content/funcoes-modelos/funcoes-potencia.html#estimativas-e-previs√µes-com-o-modelo",
    "href": "content/funcoes-modelos/funcoes-potencia.html#estimativas-e-previs√µes-com-o-modelo",
    "title": "Explorando Fun√ß√µes Pot√™ncias com Python",
    "section": "6 Estimativas e Previs√µes com o Modelo",
    "text": "6 Estimativas e Previs√µes com o Modelo\nCom o modelo, podemos estimar a riqueza de esp√©cies para √°reas espec√≠ficas.\n\n# Estimando a riqueza de esp√©cies para √°reas espec√≠ficas\nS_10km2 = S_modelo(10, c, k)\nS_70km2 = S_modelo(70, c, k)\n\nprint(f\"Riqueza estimada para uma √°rea de 10 km¬≤: {S_10km2[0]:.3f} ‚âà {round(S_10km2[0])} esp√©cies\")\nprint(f\"Riqueza predita para uma √°rea de 70 km¬≤: {S_70km2[0]:.3f} ‚âà {round(S_70km2[0])} esp√©cies\")\n\nRiqueza estimada para uma √°rea de 10 km¬≤: 19.443 ‚âà 19 esp√©cies\nRiqueza predita para uma √°rea de 70 km¬≤: 31.304 ‚âà 31 esp√©cies\n\n\n\n6.1 Determina√ß√£o da √Årea para Exceder uma Riqueza Espec√≠fica\nO modelo tamb√©m permite determinar qual √°rea m√≠nima √© necess√°ria para que a riqueza de esp√©cies exceda um certo valor. Por exemplo, para exceder 35 esp√©cies, o c√°lculo √©;\n\\[A &gt; \\left( \\frac{35}{c} \\right)^{1/k}\\]\n\n\n\n\n\n\nDeterminando a √°rea m√≠nima para exceder uma riqueza espec√≠fica\n\n\n\n\nComece com a equa√ß√£o original: \\[S = cA^k\\]\nEstabele√ßa a desigualdade para exceder o valor alvo: \\[cA^k &gt; S_{\\text{alvo}}\\]\nDivida ambos os lados por \\(c\\) (como \\(c &gt; 0\\), a desigualdade se mant√©m): \\[A^k &gt; \\frac{S_{\\text{alvo}}}{c}\\]\nAplique a raiz \\(k\\)-√©sima em ambos os lados (como \\(k &gt; 0\\), a desigualdade se mant√©m): \\[A &gt; \\left( \\frac{S_{\\text{alvo}}}{c} \\right)^{1/k}\\]\n\n\n\n\n\n6.2 Resolvendo a Desigualdade\n\n# Riqueza de esp√©cies alvo\ntarget_species = 35\n\n# Calculando a √°rea necess√°ria\narea_necessaria = (target_species / c)**(1/k)\n\nprint(f\"Para a riqueza exceder {target_species} esp√©cies:\")\nprint(f\"√Årea deve ser maior que aproximadamente {area_necessaria[0]:.3f} km¬≤.\")\n\nPara a riqueza exceder 35 esp√©cies:\n√Årea deve ser maior que aproximadamente 110.441 km¬≤."
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html",
    "href": "content/estatistica-descritiva/varquant.html",
    "title": "Descrevendo vari√°veis quantitativas",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nVari√°veis quantitativas podem ser discretas ou cont√≠nuas. A descri√ß√£o dos padr√µes de distribui√ß√£o para esses tipos de vari√°veis √© feita utilizando tabelas (frequ√™ncia e frequ√™ncia acumulada) e gr√°ficos (histogramas ou gr√°ficos de frequ√™ncia acumulada)."
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html#tabelas-de-frequ√™ncia-para-vari√°veis-quantitativas",
    "href": "content/estatistica-descritiva/varquant.html#tabelas-de-frequ√™ncia-para-vari√°veis-quantitativas",
    "title": "Descrevendo vari√°veis quantitativas",
    "section": "1 Tabelas de frequ√™ncia para vari√°veis quantitativas",
    "text": "1 Tabelas de frequ√™ncia para vari√°veis quantitativas\nA constru√ß√£o de tabelas de frequ√™ncias para vari√°veis quantitativas necessita que agrupemos as observa√ß√µes em faixas de valores. Veja as observa√ß√µes abaixo por exemplo:\n\\(X =\\) {2.66, 3.72, 5.73, 9.08, 2.02, 8.98, 9.45, 6.61, 6.29, 0.62}\nPodemos agrup√°-las nas seguintes faixas de valores:\n(0,2], (2,4], (4,6], (6,8], (8,10]\nEstas faixas de valores s√£o denominadas de intervalos de classe. Se alocadas nestes intervalos, as observa√ß√µes ficam:\n\nX &lt;- c(2.66, 3.72, 5.73, 9.08, 2.02, 8.98, 9.45, 6.61, 6.29, 0.62)\nClasses &lt;- cut(X, seq(0, 10, by = 2))\n\ndf &lt;- data.frame(X, Classes)\n\ndf |&gt; \n  gt()\n\n\n\n\n\n\n\nX\nClasses\n\n\n\n\n2.66\n(2,4]\n\n\n3.72\n(2,4]\n\n\n5.73\n(4,6]\n\n\n9.08\n(8,10]\n\n\n2.02\n(2,4]\n\n\n8.98\n(8,10]\n\n\n9.45\n(8,10]\n\n\n6.61\n(6,8]\n\n\n6.29\n(6,8]\n\n\n0.62\n(0,2]\n\n\n\n\n\n\n\nUma tabela de frequ√™ncia para estas observa√ß√µes √© constru√≠da contando o n√∫mero de observa√ß√µes por intervalo de classes. Neste caso:\n\ndf |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,2]\n1\n\n\n(2,4]\n3\n\n\n(4,6]\n1\n\n\n(6,8]\n2\n\n\n(8,10]\n3\n\n\n\n\n\n\n\nNa coluna Frequencia, temos o n√∫mero de observa√ß√µes da vari√°vel X para cada um dos intervalos de classe.\n\n1.1 Alterando o tamanho dos intervalos de classe\nNo exemplo anterior, definimos os limites dos intervalos de classe de 2 em 2 unidades. Poder√≠amos ter escolhido outros tamanhos, por exemplo, de 4 em 4. Neste caso ter√≠amos:\n\nClasses &lt;- cut(X, seq(0, 12, by = 4))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,4]\n4\n\n\n(4,8]\n3\n\n\n(8,12]\n3\n\n\n\n\n\n\n\nNote que ao escolhermos o tamanho dos intervalos de classe, estamos criando a vari√°vel qualitativa ordinal Classes, a partir do agrupamento das observa√ß√µes em X. Neste sentido, n√£o h√° um √∫nico tamanho correto para os intervalos de classe. O objetivo √© encontrar um tamanho que permita evidenciar os padr√µes de distribui√ß√£o da vari√°vel sem perdermos muitos detalhes.\nPoder√≠amos escolher um tamanho muito grande, de 5 em 5. Neste caso, ter√≠amos somente 2 grupos.\n\nClasses &lt;- cut(X, seq(0, 10, by = 5))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,5]\n4\n\n\n(5,10]\n6\n\n\n\n\n\n\n\nPor outro lado, poder√≠amos escolher um tamanho muito pequeno, por exemplo, de 1 em 1.\n\nClasses &lt;- cut(X, seq(0, 10, by = 1))\ndata.frame(X, Classes) |&gt; \n  group_by(Classes) |&gt; \n  summarise(Frequencia = n()) |&gt; \n  gt()\n\n\n\n\n\n\n\nClasses\nFrequencia\n\n\n\n\n(0,1]\n1\n\n\n(2,3]\n2\n\n\n(3,4]\n1\n\n\n(5,6]\n1\n\n\n(6,7]\n2\n\n\n(8,9]\n1\n\n\n(9,10]\n2\n\n\n\n\n\n\n\nNas duas situa√ß√µes, n√£o √© poss√≠vel evidenciar os padr√µes de distribui√ß√£o da vari√°vel X. Na primeira, perdemos muita informa√ß√£o agrupando as observa√ß√µes em somente duas faixas e, na √∫ltima, perdemos a capacidade de visualizar os padr√µes de distribui√ß√£o de X.\n\n\n1.2 Tabela de frequ√™ncia para a CPUE\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nNo objeto res, temos 8 vari√°veis quantitativas: Fechamento, Area, pH, Condutividade, Alcalinidade, P.total, Riqueza, CPUE. Vamos verificar como fica uma tabela de frequ√™ncias para a vari√°vel CPUE, que expressa a captura em \\(kg\\) de peixes em cada reservat√≥rio. Inicialmente, vamos selecionar somente esta coluna da tabela e visualiz√°-la em ordem crescente.\n\nsort(res$CPUE)\n\n [1]  2.05  2.43  4.01  4.71  5.60  5.95  6.29  7.35  7.51  7.75  7.95  9.22\n[13]  9.40 11.59 11.73 11.74 12.55 13.04 13.12 13.67 13.72 13.86 16.10 16.50\n[25] 17.95 20.83 20.92 21.82 24.88 28.73 30.76\n\n\nVemos que o menor valor √© 2.05 \\(kg\\) e o maior 30.76 \\(kg\\). Assumindo que temos 31 observa√ß√µes, vamos criar um intervalo de classes de 5 em 5 unidades. Para isso, criaremos a vari√°vel cl_cpue, que ser√° uma sequ√™ncia de \\(0\\) a \\(35\\), com tamanho \\(5\\). Os valores nesta sequ√™ncia s√£o os limites de classe.\n\ncl_cpue &lt;- seq(from = 0, to = 35, by = 5)\ncl_cpue\n\n[1]  0  5 10 15 20 25 30 35\n\n\nUtilizaremos os limites de classe para gerar uma nova coluna, delimitando os intervalos a que cada observa√ß√£o pertence. Para isso, utilizaremos a fun√ß√£o cut.\n\ntab_cpue &lt;- res |&gt; \n  select(CPUE) |&gt; \n  mutate(int_cpue = cut(CPUE, breaks = cl_cpue))\n\nE veremos a tabela em ordem crescente de classes para facilitar a identifica√ß√£o de padr√µes.\n\ntab_cpue |&gt; \n  arrange(CPUE) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE\nint_cpue\n\n\n\n\n2.05\n(0,5]\n\n\n2.43\n(0,5]\n\n\n4.01\n(0,5]\n\n\n4.71\n(0,5]\n\n\n5.60\n(5,10]\n\n\n5.95\n(5,10]\n\n\n6.29\n(5,10]\n\n\n7.35\n(5,10]\n\n\n7.51\n(5,10]\n\n\n7.75\n(5,10]\n\n\n7.95\n(5,10]\n\n\n9.22\n(5,10]\n\n\n9.40\n(5,10]\n\n\n11.59\n(10,15]\n\n\n11.73\n(10,15]\n\n\n11.74\n(10,15]\n\n\n12.55\n(10,15]\n\n\n13.04\n(10,15]\n\n\n13.12\n(10,15]\n\n\n13.67\n(10,15]\n\n\n13.72\n(10,15]\n\n\n13.86\n(10,15]\n\n\n16.10\n(15,20]\n\n\n16.50\n(15,20]\n\n\n17.95\n(15,20]\n\n\n20.83\n(20,25]\n\n\n20.92\n(20,25]\n\n\n21.82\n(20,25]\n\n\n24.88\n(20,25]\n\n\n28.73\n(25,30]\n\n\n30.76\n(30,35]\n\n\n\n\n\n\n\nA nova tabela tab_cpue tem agora duas colunas: os valores num√©ricos de CPUE e os valores transformados em intervalos de classe, int_cpue. √â com esta √∫ltima que montaremos a tabela de frequ√™ncia.\n\nfre_cpue &lt;- tab_cpue |&gt; \n  group_by(int_cpue) |&gt; \n  summarise(Frequencia = n())\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\n\n\n\n\n(0,5]\n4\n\n\n(5,10]\n9\n\n\n(10,15]\n9\n\n\n(15,20]\n3\n\n\n(20,25]\n4\n\n\n(25,30]\n1\n\n\n(30,35]\n1\n\n\n\n\n\n\n\nE, em seguida, de frequ√™ncia relativa:\n\nfre_cpue &lt;- fre_cpue |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\nFreq_relativa\n\n\n\n\n(0,5]\n4\n0.12903226\n\n\n(5,10]\n9\n0.29032258\n\n\n(10,15]\n9\n0.29032258\n\n\n(15,20]\n3\n0.09677419\n\n\n(20,25]\n4\n0.12903226\n\n\n(25,30]\n1\n0.03225806\n\n\n(30,35]\n1\n0.03225806\n\n\n\n\n\n\n\nVeja que os intervalos de (5,10] e (10,15] cont√™m o maior n√∫mero de observa√ß√µes, cerca de 29% cada um, e que acima de \\(25\\) \\(kg\\) temos somente duas observa√ß√µes.\n\n\n1.3 Tabela de frequ√™ncia acumulada\nOutra forma de representar o padr√£o de distribui√ß√£o para uma vari√°vel quantitativa √© apresent√°-la em uma tabela de frequ√™ncia acumulada. Fazemos isso somando de forma cumulativa as observa√ß√µes em cada classe de intervalo e criando duas colunas adicionais de frequ√™ncia acumulada e de frequ√™ncia relativa acumulada.\n\nfre_cpue &lt;- fre_cpue |&gt; \n  mutate(F_acumulada = cumsum(Frequencia),\n         FR_acumulada = cumsum(Freq_relativa))\n\nfre_cpue |&gt; \n  gt()\n\n\n\n\n\n\n\nint_cpue\nFrequencia\nFreq_relativa\nF_acumulada\nFR_acumulada\n\n\n\n\n(0,5]\n4\n0.12903226\n4\n0.1290323\n\n\n(5,10]\n9\n0.29032258\n13\n0.4193548\n\n\n(10,15]\n9\n0.29032258\n22\n0.7096774\n\n\n(15,20]\n3\n0.09677419\n25\n0.8064516\n\n\n(20,25]\n4\n0.12903226\n29\n0.9354839\n\n\n(25,30]\n1\n0.03225806\n30\n0.9677419\n\n\n(30,35]\n1\n0.03225806\n31\n1.0000000\n\n\n\n\n\n\n\nVeja agora que a √∫ltima linha da coluna de frequ√™ncia acumulada √© igual ao n√∫mero de observa√ß√µes total e que a da frequ√™ncia relativa acumulada √© igual a 1."
  },
  {
    "objectID": "content/estatistica-descritiva/varquant.html#representa√ß√£o-gr√°fica-histogramas",
    "href": "content/estatistica-descritiva/varquant.html#representa√ß√£o-gr√°fica-histogramas",
    "title": "Descrevendo vari√°veis quantitativas",
    "section": "2 Representa√ß√£o gr√°fica: histogramas",
    "text": "2 Representa√ß√£o gr√°fica: histogramas\nHistogramas s√£o representa√ß√µes das tabelas de frequ√™ncia e de frequ√™ncia relativa. Um histograma da coluna CPUE pode ser feito com o comando:\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nOs intervalos de classe foram escolhidos automaticamente pela fun√ß√£o geom_histogram. Se quisermos ter o controle sobre estes intervalos, podemos adicionar o argumento breaks e a sequ√™ncia com os limites de classe que criamos anteriormente:\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram(breaks = cl_cpue)\n\n\n\n\n\n\n\n\nA formata√ß√£o do histograma acima pode ser melhorada de diversas formas, por exemplo:\n\nggplot(res, aes(x = CPUE, label = after_stat(count))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'Frequ√™ncia') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nModificamos a cor do preenchimento (fill = 'darkblue'), e identificamos as barras individualmente tra√ßando uma linha branca entre elas (color = 'white');\nReescrevemos o r√≥tulo dos eixos \\(x\\) e \\(y\\) (labs());\nIdentificamos as frequ√™ncias em cada barra individualmente com o argumento label = after_stat(count) e a fun√ß√£o geom_text;\nModificamos o tema do gr√°fico para obter uma altera√ß√£o geral na apar√™ncia da figura. Existem diversos outros temas poss√≠veis que podem ser vistos aqui.\n\nUm histograma com a frequ√™ncia relativa pode ser obtido com:\n\nggplot(res, aes(x = CPUE,\n                y = after_stat(count)/sum(after_stat(count)),\n                label = round(after_stat(count)/sum(after_stat(count)), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'Frequ√™ncia relativa') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\nAqui fizemos duas mudan√ßas: + Inserimos o argumento y = after_stat(count)/sum(after_stat(count)) para dizer que as barras em \\(y\\) devem mostrar a contagem do n√∫mero de observa√ß√µes em cada intervalo dividido pelo total; + Modificamos o argumento label = round(after_stat(count)/sum(after_stat(count)), 2) de modo que tamb√©m mostre a frequ√™ncia relativa, utilizando a fun√ß√£o round.\n\n2.1 Representando frequ√™ncias acumuladas\nA √∫nica modifica√ß√£o neste caso ser√° identificarmos o eixo \\(y\\) por sua contagem acumulada: y = cumsum(after_stat(count)).\n\nggplot(res, aes(x = CPUE,\n                y = cumsum(after_stat(count)),\n                label = round(cumsum(after_stat(count)), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'Frequ√™ncia acumulada') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()\n\n\n\n\n\n\n\n\nPara fazer o mesmo mostrando as frequ√™ncias relativas, fazemos:\n\nggplot(res, aes(x = CPUE,\n                y = cumsum(after_stat(count)/sum(after_stat(count))),\n                label = round(cumsum(after_stat(count)/sum(after_stat(count))), 2))) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue', color = 'white') +\n  labs(x = 'Captura em kg', y = 'Frequ√™ncia acumulada relativa') +\n  geom_text(stat = \"bin\", size = 6, vjust = 1.5, color = 'white',\n            breaks = cl_cpue) +\n  theme_classic()"
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html",
    "href": "content/estatistica-descritiva/quartis.html",
    "title": "Medidas de posi√ß√£o: quartis",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/assimetria-ggplot.r')\nA m√©dia, mediana, moda e ponto m√©dio s√£o um tipo de medidas de posi√ß√£o que indicam uma posi√ß√£o particular, isto √©, a posi√ß√£o central ao redor da qual os dados est√£o dispersos. Existem, no entanto, outras medidas de posi√ß√£o como quartis, comumente utilizadas na descri√ß√£o, an√°lise e interpreta√ß√£o de dados.\nOs quartis de uma distribui√ß√£o de valores s√£o obtidos ap√≥s ordenarmos os dados em ordem crescente e, em seguida, agrup√°-los em partes iguais, contendo cada uma 25% do n√∫mero total de observa√ß√µes. Se temos 20 observa√ß√µes, cada parte conter√°, portanto, cinco observa√ß√µes, \\(20 \\times 0.25 = 5\\). Os quartis s√£o as posi√ß√µes num√©ricas que dividem estas partes.\nOs quartis podem ser indicados por \\(Q_1\\), \\(Q_2\\) e \\(Q_3\\), conforme a figura abaixo.\nOs quartis que veremos aqui s√£o medidas emp√≠ricas dos limites indicados na figura acima. Calculamos estes limites a partir de uma amostra de tamanho \\(n\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#c√°lculo-dos-quartis-na-posi√ß√£o-j",
    "href": "content/estatistica-descritiva/quartis.html#c√°lculo-dos-quartis-na-posi√ß√£o-j",
    "title": "Medidas de posi√ß√£o: quartis",
    "section": "1 C√°lculo dos quartis na posi√ß√£o \\(j\\)",
    "text": "1 C√°lculo dos quartis na posi√ß√£o \\(j\\)\nExistem diferentes algoritmos poss√≠veis para o c√°lculo dos quartis. Veremos um deles. Para isso, siga os passos abaixo:\n\nReorganize \\(X\\) em ordem crescente de \\(k = 1\\) a \\(k = n\\). Seja \\(n\\) o n√∫mero de observa√ß√µes em \\(X\\), teremos, portanto, \\(X_k\\) como o valor observado na posi√ß√£o \\(k\\) em ordem crescente. Deste modo, para \\(k = 1\\), teremos \\(X_1\\) como o menor valor, e para \\(k = n\\), teremos \\(X_n\\) como o maior valor.\nCalcule\n\n\\[L = \\frac{j \\times (n+1)}{4};\\]\n\nDefina \\(k\\) como o maior n√∫mero inteiro abaixo de \\(L\\);\nCalcule\n\n\\[Q_j = X_k + (L - k) \\times (X_{k+1}-X_k);\\]\n\n\\(Q_j\\) ser√° um elemento entre \\(X_k\\) e \\(X_{k+1}\\). Se \\(X_k\\) for um n√∫mero inteiro, \\(Q_j = X_k\\).\n\nExemplo para o c√°lculo de \\(Q_1\\)\n\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\nnX &lt;- length(X)\n\nConsidere a vari√°vel \\(X\\) com \\(n =\\) 20 observa√ß√µes.\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\n\nsX &lt;- sort(X)\n\nj1 &lt;- 1\nL1 &lt;- j1 * (nX + 1) / 4\nk1 &lt;- floor(L1)\nQ1 &lt;- sX[k1] + (L1 - k1) * (sX[k1+1] - sX[k1])\n\nj2 &lt;- 2\nL2 &lt;- j2 * (nX + 1) / 4\nk2 &lt;- floor(L2)\nQ2 &lt;- sX[k2] + (L2 - k2) * (sX[k2+1] - sX[k2])\n\nj3 &lt;- 3\nL3 &lt;- j3 * (nX + 1) / 4\nk3 &lt;- floor(L3)\nQ3 &lt;- sX[k3] + (L3 - k3) * (sX[k3+1] - sX[k3])\n\n\nOrganize em ordem crescente para determinar os valores de \\(X\\) nas posi√ß√µes \\(k\\).\n\n\nPosicao_k &lt;- paste(1:length(X), \"a Posi√ß√£o\", sep = \"\")\ndf &lt;- tibble(`Posi√ß√£o k` = Posicao_k, `X ordenado` = sX)\n\ndf |&gt; \n  gt()\n\n\n\n\n\n\n\nPosi√ß√£o k\nX ordenado\n\n\n\n\n1a Posi√ß√£o\n5.6\n\n\n2a Posi√ß√£o\n8.3\n\n\n3a Posi√ß√£o\n8.4\n\n\n4a Posi√ß√£o\n8.7\n\n\n5a Posi√ß√£o\n8.8\n\n\n6a Posi√ß√£o\n9.4\n\n\n7a Posi√ß√£o\n9.9\n\n\n8a Posi√ß√£o\n10.0\n\n\n9a Posi√ß√£o\n10.4\n\n\n10a Posi√ß√£o\n10.7\n\n\n11a Posi√ß√£o\n10.8\n\n\n12a Posi√ß√£o\n11.0\n\n\n13a Posi√ß√£o\n11.2\n\n\n14a Posi√ß√£o\n11.2\n\n\n15a Posi√ß√£o\n11.5\n\n\n16a Posi√ß√£o\n11.6\n\n\n17a Posi√ß√£o\n11.9\n\n\n18a Posi√ß√£o\n12.2\n\n\n19a Posi√ß√£o\n13.0\n\n\n20a Posi√ß√£o\n13.2\n\n\n\n\n\n\n\n\nPara \\(j = 1\\) (\\(Q_1\\)), calcule:\n\n\\(L = \\frac{1 \\times (20+1)}{4} = 5.25\\);\n\nDefina \\(k\\) como o maior n√∫mero inteiro abaixo de \\(L\\). Portanto, se \\(L = 5.25\\), \\(k = 5\\).\nNote que a observa√ß√£o correspondente √† \\(k = 5\\) (5\\(^a\\) posi√ß√£o) √© 8.8, enquanto a observa√ß√£o correspondente √† \\(k = 6\\) (6\\(^a\\) posi√ß√£o) √© 9.4. Deste modo, calcule\n\n\\(Q_1 = 8.8 + (5.25 - 5) \\times (9.4 - 8.8) = 8.95\\).\nVemos ent√£o que, para a vari√°vel \\(X\\) em quest√£o, o primeiro quartil √©:\n\\(Q_1 = 8.95\\)\nExerc√≠cio: Calcule agora os valores correspondentes a \\(Q_2\\) e \\(Q_3\\) e verifique que os resultados s√£o: \\(Q_2 = 10.75\\) e \\(Q_3 = 11.575\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#c√°lculo-dos-quartis-no-r",
    "href": "content/estatistica-descritiva/quartis.html#c√°lculo-dos-quartis-no-r",
    "title": "Medidas de posi√ß√£o: quartis",
    "section": "2 C√°lculo dos quartis no R",
    "text": "2 C√°lculo dos quartis no R\nPodemos programar a sequ√™ncia de fun√ß√µes acima utilizando o R:\n\nX &lt;- c(8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, \n       13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2)\n\n# Ordenando X em ordem crescente\nsX &lt;- sort(X, decreasing = FALSE)\n# Encontrando o n√∫mero de observa√ß√µes em X\nn &lt;- length(X) \n# Encontrando os quartis (Q1, Q2 e Q3)\nj &lt;- c(1, 2, 3)\nL &lt;- j * (n + 1) / 4\nk &lt;- floor(L)\nQ &lt;- sX[k] + (L - k) * (sX[k+1] - sX[k])\nnames(Q) &lt;- c('Q1', 'Q2', 'Q3')\n\n# Visualizando os quartis\nQ\n\n    Q1     Q2     Q3 \n 8.950 10.750 11.575 \n\n\nEntretanto, existe uma fun√ß√£o no R denominada quantile, que pode ser utilizada da seguinte forma:\n\nquantile(X, probs = c(0.25, 0.50, 0.75))\n\n   25%    50%    75% \n 9.250 10.750 11.525 \n\n\n\n\n\n\n\n\nObserva√ß√µes\n\n\n\n\nLembre que o quartil \\(Q_1\\) delimita a posi√ß√£o \\(25\\%\\), \\(Q_2\\) delimita a posi√ß√£o \\(50\\%\\) (\\(=\\) mediana) e \\(Q_3\\) delimita a posi√ß√£o \\(75\\%\\). Por este motivo, utilizamos o argumento probs = c(0.25, 0.50, 0.75). Assim, a fun√ß√£o quantile √© mais geral que a rotina passada anteriormente, pois permite o c√°lculo para qualquer posi√ß√£o entre os quantis \\(0\\%\\) e \\(100\\%\\).\nNote tamb√©m que os resultados foram ligeiramente diferentes, uma vez que existem diferentes algoritmos para o c√°lculo dos quartis. A fun√ß√£o quantile permite a escolha entre \\(9\\) algoritmos diferentes e, por padr√£o, utiliza o type = 7. O passo-a-passo que mostramos corresponde ao type = 6. Voc√™ pode verificar que, ao digitar o comando abaixo, os resultados ser√£o os mesmos que calculamos manualmente.\n\n\nquantile(X, probs = c(0.25, 0.50, 0.75), type = 6)\n\n   25%    50%    75% \n 8.950 10.750 11.575 \n\n\n\nEssas diferen√ßas diminuem √† medida que o tamanho amostral aumenta.\nFinalmente, os quartis discutidos aqui s√£o casos particulares de limites mais gerais denominados quantis, que indicam uma posi√ß√£o espec√≠fica na distribui√ß√£o. Por exemplo, o limite \\(Q_1\\) poderia ser chamado de Quantil \\(0,25\\). Assim, podemos encontrar qualquer posi√ß√£o, como o quantil \\(0,10\\) que delimita os \\(10\\%\\) menores valores.\nNo c√°lculo dos quantis para um limite \\(p\\) qualquer (\\(0 \\le p \\le 1\\)), a √∫nica mudan√ßa no algoritmo apresentado est√° na obten√ß√£o de \\(L\\) (passo 2), que √© feita como:\n\n\\[L = p \\times (n+1)\\]"
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#obtendo-os-quartis-a-partir-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/quartis.html#obtendo-os-quartis-a-partir-de-uma-tabela-de-dados",
    "title": "Medidas de posi√ß√£o: quartis",
    "section": "3 Obtendo os quartis a partir de uma tabela de dados",
    "text": "3 Obtendo os quartis a partir de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUsaremos a fun√ß√£o summarise para obter os quartis para a vari√°vel CPUE.\n\nres |&gt; \n  reframe(Quartis = quantile(CPUE, probs = c(0.25, 0.50, 0.75)),\n          Limites = c('25%', '50%', '75%')) |&gt; \n  gt()\n\n\n\n\n\n\n\nQuartis\nLimites\n\n\n\n\n7.43\n25%\n\n\n11.74\n50%\n\n\n16.30\n75%"
  },
  {
    "objectID": "content/estatistica-descritiva/quartis.html#boxplots-uma-representa√ß√£o-gr√°fica-dos-quartis",
    "href": "content/estatistica-descritiva/quartis.html#boxplots-uma-representa√ß√£o-gr√°fica-dos-quartis",
    "title": "Medidas de posi√ß√£o: quartis",
    "section": "4 Boxplots: uma representa√ß√£o gr√°fica dos quartis",
    "text": "4 Boxplots: uma representa√ß√£o gr√°fica dos quartis\nOs quartis de uma distribui√ß√£o nos ajudam a entender o formato de uma distribui√ß√£o. Uma das formas amplamente estabelecidas de represent√°-los graficamente √© por meio de um boxplot. Para a vari√°vel acima, o boxplot ser√°:\n\n\nC√≥digo\ndf &lt;- data.frame(X)\nPX &lt;- quantile(X, probs = c(0, 0.25, 0.50, 0.75, 1))\nLegX &lt;- c(\"M√≠nimo\", \"Q1\", \"Q2 = Mediana\", \"Q3\", \"M√°ximo\")\nggplot(df, aes(y = X)) +\n  geom_boxplot(fill = 'lightblue', coef = 10) +\n  annotate(geom = 'text', x = .8, y = PX - 0.3,\n           label = LegX) +\n  annotate(geom = 'segment', \n           x = 0.5, xend = 1.23,\n           y = PX, yend = PX,\n           arrow = arrow(ends = 'first')) +\n  scale_y_continuous(breaks = 5:14) +\n  theme_classic() +\n  theme(axis.title = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n\n\n\n\n\n\n\nFigura¬†2: Divis√£o em quartis de um boxplot\n\n\n\n\n\nEm um boxplot, a linha central representa a Mediana ou \\(2^o\\) quartil (\\(Q_2\\)), e os limites da caixa s√£o o \\(1^o\\) e \\(3^o\\) quartis, respectivamente \\(Q_1\\) e \\(Q_3\\). As extremidades geralmente s√£o os pontos m√°ximo e m√≠nimo da distribui√ß√£o.\nExiste uma rela√ß√£o entre os histogramas e os boxplots. Ambos podem ser utilizados para avaliar o grau de assimetria de uma distribui√ß√£o, como apresentado abaixo. Em uma distribui√ß√£o sim√©trica, a caixa do boxplot tende a se concentrar no meio da distribui√ß√£o. J√° em distribui√ß√µes assim√©tricas, a caixa tende a ficar deslocada √† esquerda ou √† direita (Figura¬†3).\n\n\nC√≥digo\n# Ver fun√ß√£o completa no arquivo 'scripts/assimetria-ggplot.r'\nassimetria_ggplot(fig = 'bh')\n\n\n\n\n\n\n\n\nFigura¬†3: Padr√£o de assimetria representado por meio de histogramas e boxplots."
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html",
    "href": "content/estatistica-descritiva/varqualit.html",
    "title": "Descrevendo vari√°veis qualitativas",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nVari√°veis qualitativas podem ser categ√≥ricas n√£o ordenadas ou categ√≥ricas ordenadas. A descri√ß√£o de vari√°veis desta natureza se d√° por meio da contagem e da representa√ß√£o dos n√≠veis destas vari√°veis por meio da contagem total, pelos valores relativos ou percentuais.\nImporte a base de dados Reservatorios_Parana_parcial.csv.\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"UTF-8\")\n)\nNa tabela, temos 3 vari√°veis categ√≥ricas: Reservatorio, Bacia e Trofia. A primeira identifica cada reservat√≥rio pelo seu nome. A segunda √© uma vari√°vel categ√≥rica n√£o ordenada (n√≠vel de mensura√ß√£o nominal) e a terceira uma vari√°vel categ√≥rica ordenada (n√≠vel de mensura√ß√£o ordinal)."
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#representa√ß√£o-em-tabelas-de-frequ√™ncia",
    "href": "content/estatistica-descritiva/varqualit.html#representa√ß√£o-em-tabelas-de-frequ√™ncia",
    "title": "Descrevendo vari√°veis qualitativas",
    "section": "1 Representa√ß√£o em tabelas de frequ√™ncia",
    "text": "1 Representa√ß√£o em tabelas de frequ√™ncia\nSe uma vari√°vel √© descrita no n√≠vel de mensura√ß√£o nominal, como √© o caso de Bacia, podemos obter a frequ√™ncia com que cada um dos n√≠veis aparece na vari√°vel. Essa contagem pode ser obtida por meio de uma tabela de frequ√™ncias.\n\nfbacia &lt;- res |&gt; \n  group_by(Bacia) |&gt; \n  summarise(Frequencia = n())\n\nfbacia |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\n\n\n\n\nIguacu\n13\n\n\nIvai\n2\n\n\nLitoranea\n4\n\n\nParanapanema\n7\n\n\nPiriqui\n2\n\n\nTibagi\n3\n\n\n\n\n\n\n\nO resultado mostra que existem 13 reservat√≥rios na tabela pertencentes √† bacia do rio Iguacu, 2 √† bacia do rio Ivai e assim por diante. Confira estas contagens na base de dados.\nAs linhas da tabela est√£o organizadas em ordem alfab√©tica. Para facilitar a visualiza√ß√£o, podemos orden√°-las de modo decrescente como fun√ß√£o do n√∫mero de reservat√≥rios por bacia.\n\nfbacia &lt;- fbacia |&gt; \n  arrange(desc(Frequencia))\n\nfbacia |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\n\n\n\n\nIguacu\n13\n\n\nParanapanema\n7\n\n\nLitoranea\n4\n\n\nTibagi\n3\n\n\nIvai\n2\n\n\nPiriqui\n2\n\n\n\n\n\n\n\nPodemos olhar tamb√©m para a frequ√™ncia relativa do n√∫mero de reservat√≥rios por bacia.\n\nfbacia_rel &lt;- fbacia |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nfbacia_rel |&gt; \n  gt()\n\n\n\n\n\n\n\nBacia\nFrequencia\nFreq_relativa\n\n\n\n\nIguacu\n13\n0.41935484\n\n\nParanapanema\n7\n0.22580645\n\n\nLitoranea\n4\n0.12903226\n\n\nTibagi\n3\n0.09677419\n\n\nIvai\n2\n0.06451613\n\n\nPiriqui\n2\n0.06451613\n\n\n\n\n\n\n\nA caracter√≠stica da frequ√™ncia relativa √© que o somat√≥rio da coluna deve ser igual a 1, enquanto a frequ√™ncia num√©rica tem o somat√≥rio igual ao n√∫mero de linhas na tabela.\n\nfbacia_rel |&gt; \n  summarise_if(is.numeric, sum) |&gt; \n  gt()\n\n\n\n\n\n\n\nFrequencia\nFreq_relativa\n\n\n\n\n31\n1"
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#tabelas-de-frequ√™ncia-para-vari√°veis-categ√≥ricas-ordenadas",
    "href": "content/estatistica-descritiva/varqualit.html#tabelas-de-frequ√™ncia-para-vari√°veis-categ√≥ricas-ordenadas",
    "title": "Descrevendo vari√°veis qualitativas",
    "section": "2 Tabelas de frequ√™ncia para vari√°veis categ√≥ricas ordenadas",
    "text": "2 Tabelas de frequ√™ncia para vari√°veis categ√≥ricas ordenadas\nA caracter√≠stica da vari√°vel Trofia difere da anterior unicamente por ser uma vari√°vel categ√≥rica ordenada que, no caso, expressa o grau de eutrofiza√ß√£o dos reservat√≥rios. Neste sentido, a √∫nica mudan√ßa na representa√ß√£o da vari√°vel se deve ao fato de que existe uma sequ√™ncia natural para representar os n√≠veis. Podemos indicar que uma determinada vari√°vel √© categ√≥rica ordenada fazendo uma pequena altera√ß√£o na base de dados.\nSe montarmos uma tabela de frequ√™ncia da vari√°vel Trofia, teremos as linhas organizadas em ordem alfab√©tica:\n\nftrofia &lt;- res |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nEutr√≥fico\n2\n\n\nMesotr√≥fico\n3\n\n\nOligotr√≥fico\n24\n\n\nNA\n2\n\n\n\n\n\n\n\nSe desejarmos que as colunas apare√ßam como fun√ß√£o do n√≠vel de eutrofiza√ß√£o, devemos primeiro transformar a vari√°vel Trofia em um fator ordenado, que √© o modo como o R interpreta uma vari√°vel categ√≥rica ordenada.\nInicialmente, use o comando abaixo para verificar que o R entende a vari√°vel Trofia como um character (&lt;chr&gt;).\n\nglimpse(res)\n\nRows: 31\nColumns: 11\n$ Reservatorio  &lt;chr&gt; \"Cavernoso\", \"Curucaca\", \"Foz do Areia\", \"Irai\", \"JMF\", ‚Ä¶\n$ Bacia         &lt;chr&gt; \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguac‚Ä¶\n$ Fechamento    &lt;dbl&gt; 1965, 1982, 1980, 2000, 1970, 1996, 1978, 1979, 1998, 19‚Ä¶\n$ Area          &lt;dbl&gt; 2.90, 2.00, 139.00, 15.00, 0.45, 3.40, 14.00, 3.30, 124.‚Ä¶\n$ Trofia        &lt;chr&gt; \"Oligotr√≥fico\", \"Oligotr√≥fico\", \"Oligotr√≥fico\", \"Eutr√≥fi‚Ä¶\n$ pH            &lt;dbl&gt; 7.4, 7.0, 7.3, 6.9, 7.3, 7.1, 8.8, 7.1, 7.3, 6.5, 8.6, 9‚Ä¶\n$ Condutividade &lt;dbl&gt; 33.1, 32.4, 35.5, 50.2, 40.2, 23.7, 125.6, 22.8, 39.6, 2‚Ä¶\n$ Alcalinidade  &lt;dbl&gt; 139.80, 125.70, 97.00, 3.30, 3.70, 152.70, 526.00, 50.67‚Ä¶\n$ P.total       &lt;dbl&gt; 7.8, 4.7, 14.3, 53.4, 41.2, 3.3, 15.2, 4.5, 12.1, 11.0, ‚Ä¶\n$ Riqueza       &lt;dbl&gt; 18, 16, 19, 12, 18, 17, 11, 8, 21, 8, 24, 21, 22, 15, 10‚Ä¶\n$ CPUE          &lt;dbl&gt; 9.22, 28.73, 11.59, 30.76, 5.95, 7.75, 7.51, 4.01, 20.83‚Ä¶\n\n\nIremos transformar esta vari√°vel para que o R a interprete como uma vari√°vel categ√≥rica ordenada.\n\nres &lt;- res |&gt; \n  mutate(Trofia = factor(Trofia, ordered = TRUE, \n                         levels = c(\"Oligotr√≥fico\", \n                                    \"Mesotr√≥fico\", \n                                    \"Eutr√≥fico\")))\n\nAp√≥s aplicarmos este comando, vemos que agora o R reconhece esta vari√°vel como do tipo &lt;ord&gt;:\n\nglimpse(res)\n\nRows: 31\nColumns: 11\n$ Reservatorio  &lt;chr&gt; \"Cavernoso\", \"Curucaca\", \"Foz do Areia\", \"Irai\", \"JMF\", ‚Ä¶\n$ Bacia         &lt;chr&gt; \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguacu\", \"Iguac‚Ä¶\n$ Fechamento    &lt;dbl&gt; 1965, 1982, 1980, 2000, 1970, 1996, 1978, 1979, 1998, 19‚Ä¶\n$ Area          &lt;dbl&gt; 2.90, 2.00, 139.00, 15.00, 0.45, 3.40, 14.00, 3.30, 124.‚Ä¶\n$ Trofia        &lt;ord&gt; Oligotr√≥fico, Oligotr√≥fico, Oligotr√≥fico, Eutr√≥fico, Mes‚Ä¶\n$ pH            &lt;dbl&gt; 7.4, 7.0, 7.3, 6.9, 7.3, 7.1, 8.8, 7.1, 7.3, 6.5, 8.6, 9‚Ä¶\n$ Condutividade &lt;dbl&gt; 33.1, 32.4, 35.5, 50.2, 40.2, 23.7, 125.6, 22.8, 39.6, 2‚Ä¶\n$ Alcalinidade  &lt;dbl&gt; 139.80, 125.70, 97.00, 3.30, 3.70, 152.70, 526.00, 50.67‚Ä¶\n$ P.total       &lt;dbl&gt; 7.8, 4.7, 14.3, 53.4, 41.2, 3.3, 15.2, 4.5, 12.1, 11.0, ‚Ä¶\n$ Riqueza       &lt;dbl&gt; 18, 16, 19, 12, 18, 17, 11, 8, 21, 8, 24, 21, 22, 15, 10‚Ä¶\n$ CPUE          &lt;dbl&gt; 9.22, 28.73, 11.59, 30.76, 5.95, 7.75, 7.51, 4.01, 20.83‚Ä¶\n\n\nE se fizermos:\n\nres$Trofia\n\n [1] Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Eutr√≥fico    Mesotr√≥fico \n [6] Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico\n[11] Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Mesotr√≥fico \n[16] Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico Mesotr√≥fico  Oligotr√≥fico\n[21] Oligotr√≥fico Oligotr√≥fico Oligotr√≥fico &lt;NA&gt;         Oligotr√≥fico\n[26] Oligotr√≥fico Eutr√≥fico    Oligotr√≥fico Oligotr√≥fico &lt;NA&gt;        \n[31] Oligotr√≥fico\nLevels: Oligotr√≥fico &lt; Mesotr√≥fico &lt; Eutr√≥fico\n\n\nTemos agora a indica√ß√£o de que h√° uma ordena√ß√£o sequencial nos n√≠veis de trofia em que Oligotr√≥fico &lt; Mesotr√≥fico &lt; Eutr√≥fico.\nA partir de agora, se extrairmos uma tabela de frequ√™ncia relativa, as linhas ser√£o apresentadas na ordem pr√©-definida.\n\nftrofia &lt;- res |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nOligotr√≥fico\n24\n\n\nMesotr√≥fico\n3\n\n\nEutr√≥fico\n2\n\n\nNA\n2\n\n\n\n\n\n\n\nNa tabela acima, a √∫ltima linha aparece vazia, pois h√° casos sem informa√ß√£o, isto √©, com dados faltantes que s√£o representados por NA. Caso voc√™ n√£o queira representar os dados faltantes, √© poss√≠vel utilizar a fun√ß√£o drop_na() para excluir estas linhas.\n\nftrofia &lt;- res |&gt; \n  drop_na(Trofia) |&gt; \n  group_by(Trofia) |&gt; \n  summarise(Frequencia = n())\n\nftrofia |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\n\n\n\n\nOligotr√≥fico\n24\n\n\nMesotr√≥fico\n3\n\n\nEutr√≥fico\n2\n\n\n\n\n\n\n\nPodemos adicionar uma coluna de frequ√™ncia relativa como fizemos anteriormente.\n\nftrofia_rel &lt;- ftrofia |&gt; \n  mutate(Freq_relativa = Frequencia / sum(Frequencia))\n\nftrofia_rel |&gt; \n  gt()\n\n\n\n\n\n\n\nTrofia\nFrequencia\nFreq_relativa\n\n\n\n\nOligotr√≥fico\n24\n0.82758621\n\n\nMesotr√≥fico\n3\n0.10344828\n\n\nEutr√≥fico\n2\n0.06896552"
  },
  {
    "objectID": "content/estatistica-descritiva/varqualit.html#representa√ß√£o-gr√°fica",
    "href": "content/estatistica-descritiva/varqualit.html#representa√ß√£o-gr√°fica",
    "title": "Descrevendo vari√°veis qualitativas",
    "section": "3 Representa√ß√£o gr√°fica",
    "text": "3 Representa√ß√£o gr√°fica\nVari√°veis categ√≥ricas n√£o ordenadas ou ordenadas podem ser representadas por gr√°ficos de barras.\n\n\n\n\n\n\nO pacote ggplot2\n\n\n\nUtilizaremos o pacote ggplot2 para representar graficamente as vari√°veis. O ggplot2 √© instalado e habilitado juntamente com o tidyverse, de modo que neste momento voc√™ j√° o tem habilitado em sua sess√£o do R.\nPara uma r√°pida explica√ß√£o do ggplot2, veja aqui. Para uma explica√ß√£o detalhada, veja o site oficial (ggplot2){target=‚Äú_blank‚Äù} e o livro ggplot2: Elegant Graphics for Data Analysis.\n\n\n\n3.1 Criando um gr√°fico no ggplot2\nUm gr√°fico no ggplot2 √© feito em camadas que devem ter minimamente:\n\nA defini√ß√£o da tabela de dados;\nA est√©tica gr√°fica indicando quais vari√°veis ser√£o representadas e suas posi√ß√µes no gr√°fico;\nO formato da representa√ß√£o por meio de geometrias gr√°ficas (ex. gr√°ficos de pontos, linhas, barras, etc.).\n\nEsta abordagem permite que tenhamos um m√©todo consistente para construir diferentes tipos de gr√°ficos.\nGr√°fico de frequ√™ncia\nUm gr√°fico de barras da vari√°vel Bacia ficaria:\n\nggplot(data = res) + # define tabela de dados\n  aes(x = Bacia) +   # define a est√©tica gr√°fica\n  geom_bar()         # define a geometria gr√°fica\n\n\n\n\n\n\n\n\nVamos entender o comando:\n\nggplot(res): define a tabela de dados que ser√° utilizada.\naes(x = Bacia): define que o eixo x deste gr√°fico dever√° conter os n√≠veis da vari√°vel Bacia.\ngeom_bar(): define o tipo gr√°fico, que no ggplot2 √© denominado de geometria gr√°fica.\n\nEstes argumentos devem ser inseridos sequencialmente separados pelo s√≠mbolo +.\nO argumento geom_bar() espera como argumento uma vari√°vel qualitativa em um dos eixos. Por padr√£o, a fun√ß√£o far√° a contagem dos n√≠veis dentro da vari√°vel e representar√° no eixo y.\nPoder√≠amos ter feito o mesmo gr√°fico de barras indicando que a vari√°vel Bacia seria representada no eixo y, o que resultaria em um gr√°fico de barras invertido conforme abaixo:\n\nggplot(data = res) +\n  aes(y = Bacia) +\n  geom_bar()\n\n\n\n\n\n\n\n\nA est√©tica gr√°fica (aes()) n√£o precisa estar em uma linha separada. Tamb√©m n√£o √© obrigat√≥rio escrevermos data = res. De fato, √© mais comum escrevermos esta sequ√™ncia de argumentos como:\n\nggplot(res, mapping = aes(x = Bacia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nou simplesmente:\n\nggplot(res, aes(x = Bacia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\no que ir√° gerar os mesmos resultados.\nFinalmente, poder√≠amos organizar as barras em ordem decrescente como fizemos com as tabelas de frequ√™ncia, utilizando a fun√ß√£o fct_infreq():\n\nggplot(res, aes(x = fct_infreq(Bacia))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nou em ordem crescente, revertendo o comando anterior com a fun√ß√£o fct_rev().\n\nggplot(res, aes(x = fct_rev(fct_infreq(Bacia)))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nFormatando a figura\nPara tornar a figura mais autoexplicativa, podemos adicionar camadas identificando os eixos e fornecendo t√≠tulo, subt√≠tulo e outras informa√ß√µes:\n\nggplot(res, aes(x = Bacia)) +\n  geom_bar() +\n  labs(\n    title = \"Reservat√≥rios do Estado do Paran√°\",\n    subtitle = \"Reservat√≥rios por bacia hidrogr√°fica\",\n    caption = \"Dados obtidos do livro: Biocenoses em Reservat√≥rios\",\n    x = \"Bacia hidrogr√°fica\",\n    y = \"Frequ√™ncia\"\n  )\n\n\n\n\n\n\n\n\nGr√°fico de frequ√™ncia relativa\nUtilizando o ggplot2, √© simples construir um gr√°fico de frequ√™ncia relativa.\n\nggplot(res, aes(x = Bacia, y = after_stat(prop), group = 1)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nVeja que para isso transformamos as contagens em propor√ß√µes. Se quisermos transformar em percentuais, ent√£o:\n\nggplot(res, aes(x = Bacia, y = after_stat(prop), group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\n\nOutras op√ß√µes para construir um gr√°fico de barras\nAs figuras que acabamos de fazer apresentam, de modo gr√°fico, as mesmas informa√ß√µes das tabelas de frequ√™ncia vistas no in√≠cio do cap√≠tulo sem que fosse necess√°rio construir a tabela de frequ√™ncia, pois o comando geom_bar() j√° realiza esta contagem.\nEntretanto, caso j√° tiv√©ssemos a tabela de frequ√™ncia, tamb√©m poder√≠amos utiliz√°-la diretamente. No in√≠cio do cap√≠tulo, constru√≠mos a tabela fbacia_rel, onde t√≠nhamos 3 colunas: Bacia, Frequencia, Freq_relativa.\nPodemos construir gr√°ficos de barras das tabelas Frequencia ou Freq_relativa da seguinte forma:\n\nggplot(fbacia_rel, aes(x = Bacia, y = Frequencia)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\ne\n\nggplot(fbacia_rel, aes(x = Bacia, y = Freq_relativa)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nPara utilizar diretamente uma tabela de frequ√™ncias, devemos oferecer a vari√°vel do eixo x, do eixo y e, no comando geom_bar(), adicionar o argumento stat = \"identity\". Feito isso, o comando utiliza diretamente os n√∫meros dispon√≠veis em cada linha da coluna Frequencia.\n\nGr√°fico de frequ√™ncia para vari√°veis categ√≥ricas ordenadas\nPara vari√°veis categ√≥ricas ordenadas, valem os mesmos comandos apresentados acima. Usamos a fun√ß√£o geom_bar() para construir os gr√°ficos de barras. A diferen√ßa √© que, antes da constru√ß√£o, √© necess√°rio que a vari√°vel em quest√£o tenha sido transformada para um fator ordenado.\nLembrando o que fizemos no in√≠cio do cap√≠tulo, esta transforma√ß√£o pode ser feita para a vari√°vel Trofia com os comandos:\n\nres &lt;- res |&gt; \n  mutate(Trofia = factor(Trofia, ordered = TRUE, \n                         levels = c(\"Oligotr√≥fico\", \n                                    \"Mesotr√≥fico\", \n                                    \"Eutr√≥fico\")))\n\nFeito isso, o comando geom_bar() vai organizar os n√≠veis de acordo com a sequ√™ncia definida:\n\nggplot(res, aes(x = Trofia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nE caso seja necess√°rio retirar reservat√≥rios com dados faltantes em Trofia, podemos fazer:\n\nres |&gt; \n  drop_na(Trofia) |&gt; \n  ggplot(aes(x = Trofia)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPr√©-processamento do data-frame para o ggplot2\n\n\n\nNo comando acima, a tabela de dados n√£o foi inserida dentro do comando ggplot(). Ela foi inicialmente processada para remo√ß√£o de NAs com a fun√ß√£o drop_na() e o operador |&gt; foi utilizado para inserir o resultado do processamento no ggplot(). Esta √© outra maneira de combinar capacidade de processamento de dados no R com a representa√ß√£o gr√°fica do pacote ggplot2."
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "",
    "text": "Utilize este roteiro de atividades para consolidar os conceitos apresentados na primeira aula sobre descri√ß√£o e visualiza√ß√£o de dados com Python.\nCrie um novo arquivo no Google Colab e execute cada exerc√≠cio em uma ou mais c√©lular. Teste e observe os resultados antes de prosseguir para o pr√≥ximo.\nAproveite para experimentar varia√ß√µes dos c√≥digos apresentados para garantir que tenha entendido a atividade.\nCaso encontre dificuldades, revise o material da aula correspondente ao t√≥pico em quest√£o.\nMantenha o notebook organizado com coment√°rios explicativos sobre o que cada c√≥digo faz e suas principais descobertas."
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#orienta√ß√µes-gerais",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#orienta√ß√µes-gerais",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "",
    "text": "Utilize este roteiro de atividades para consolidar os conceitos apresentados na primeira aula sobre descri√ß√£o e visualiza√ß√£o de dados com Python.\nCrie um novo arquivo no Google Colab e execute cada exerc√≠cio em uma ou mais c√©lular. Teste e observe os resultados antes de prosseguir para o pr√≥ximo.\nAproveite para experimentar varia√ß√µes dos c√≥digos apresentados para garantir que tenha entendido a atividade.\nCaso encontre dificuldades, revise o material da aula correspondente ao t√≥pico em quest√£o.\nMantenha o notebook organizado com coment√°rios explicativos sobre o que cada c√≥digo faz e suas principais descobertas."
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#prepara√ß√£o",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#prepara√ß√£o",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "2 Prepara√ß√£o",
    "text": "2 Prepara√ß√£o\nAntes de come√ßar, importe os pacotes necess√°rios e carregue os dados que ser√£o utilizados:\n\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom seaborn import load_dataset\n\n# Carregando iris\niris = sns.load_dataset('iris')\ntips = sns.load_dataset('tips')"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-1-opera√ß√µes-b√°sicas-e-estruturas-de-dados",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-1-opera√ß√µes-b√°sicas-e-estruturas-de-dados",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "3 Parte 1: Opera√ß√µes B√°sicas e Estruturas de Dados",
    "text": "3 Parte 1: Opera√ß√µes B√°sicas e Estruturas de Dados\n\n3.1 Exerc√≠cio 1.1 - Opera√ß√µes Aritm√©ticas\n\nCalcule as seguintes opera√ß√µes:\n\n15 + 8\n25 * 3\n100 / 7 (divis√£o comum)\n100 // 7 (divis√£o inteira)\n100 % 7 (resto da divis√£o)\n2**8 (potencia√ß√£o)\n\nUse as fun√ß√µes matem√°ticas para calcular:\n\nLogaritmo natural de 50\nLogaritmo base 10 de 1000\nRaiz quadrada de 64\nSeno de œÄ/4 (use math.pi)\n\n\n\n\n3.2 Exerc√≠cio 1.2 - Vari√°veis e Atribui√ß√µes\n\nCrie uma vari√°vel altura com valor 1.75\nCrie uma vari√°vel peso com valor 70\nCalcule o IMC (peso / altura¬≤) e armazene em uma vari√°vel imc\nVerifique o resultado\n\n\n\n3.3 Exerc√≠cio 1.3 - Listas e Arrays\n\nCrie uma lista com as idades: [23, 34, 45, 28, 31, 29]\nConverta essa lista em um array NumPy\nMultiplique todos os valores por 2 usando a lista e depois usando o array\nCompare os resultados obtidos\n\n\n\n3.4 Exerc√≠cio 1.4 - Sequ√™ncias\n\nCrie uma sequ√™ncia de n√∫meros de 1 a 20 usando range()\nCrie um array com 7 valores igualmente espa√ßados entre 0 e 100 usando np.linspace()\nRepita o n√∫mero 5 dez vezes usando np.repeat()"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-2-explorando-os-dados---dataset-iris",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-2-explorando-os-dados---dataset-iris",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "4 Parte 2: Explorando os Dados - Dataset Iris",
    "text": "4 Parte 2: Explorando os Dados - Dataset Iris\n\n4.1 Exerc√≠cio 2.1 - Primeiras Explora√ß√µes\n\nVisualize as primeiras 10 linhas do dataset iris\nVerifique as dimens√µes do dataset (shape)\nExamine os tipos de dados de cada coluna\nVerifique se h√° valores ausentes no dataset. Se houver, exclua este valores.\n\n\n\n4.2 Exerc√≠cio 2.2 - Sele√ß√£o e Filtragem\n\nSelecione apenas a coluna ‚Äòsepal length (cm)‚Äô\nSelecione as colunas ‚Äòpetal length (cm)‚Äô e ‚Äòpetal width (cm)‚Äô simultaneamente\nSelecione as linhas de 20 a 30\nFiltre apenas as observa√ß√µes da esp√©cie ‚Äòsetosa‚Äô\nFiltre as observa√ß√µes onde ‚Äòpetal length (cm)‚Äô &gt; 4.0"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-3-estat√≠stica-descritiva---dataset-tips",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-3-estat√≠stica-descritiva---dataset-tips",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "5 Parte 3: Estat√≠stica Descritiva - Dataset Tips",
    "text": "5 Parte 3: Estat√≠stica Descritiva - Dataset Tips\n\n5.1 Exerc√≠cio 3.1 - Vari√°veis Qualitativas\n\nCalcule a frequ√™ncia absoluta da vari√°vel ‚Äòday‚Äô (dia da semana)\nCalcule a frequ√™ncia relativa da vari√°vel ‚Äòtime‚Äô (almo√ßo/jantar)\nCrie um gr√°fico de barras para a vari√°vel ‚Äòsmoker‚Äô\n\n\n\n5.2 Exerc√≠cio 3.2 - Vari√°veis Quantitativas\n\nGere um resumo descritivo completo da vari√°vel ‚Äòtotal_bill‚Äô\nCalcule separadamente a m√©dia, mediana e desvio padr√£o de ‚Äòtip‚Äô\nCrie um histograma da vari√°vel ‚Äòtotal_bill‚Äô com 8 intervalos\nCrie um boxplot da vari√°vel ‚Äòtip‚Äô\n\n\n\n5.3 Exerc√≠cio 3.3 - Quartis e Medidas de Posi√ß√£o\n\nCalcule os quartis (25%, 50%, 75%) da vari√°vel ‚Äòtotal_bill‚Äô\nIdentifique qual √© o valor do percentil 90 da vari√°vel ‚Äòtip‚Äô\n\n\n\n5.4 Exerc√≠cio 3.4 - Padroniza√ß√£o (Z-score)\n\nCalcule o Z-score da vari√°vel ‚Äòtotal_bill‚Äô\nAdicione esta nova vari√°vel ao dataset como ‚Äòzscore_bill‚Äô\nVerifique que a m√©dia do Z-score √© aproximadamente 0 e o desvio padr√£o √© 1\nCrie dois histogramas lado a lado: um da vari√°vel original e outro do Z-score"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-4-medidas-de-associa√ß√£o",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#parte-4-medidas-de-associa√ß√£o",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "6 Parte 4: Medidas de Associa√ß√£o",
    "text": "6 Parte 4: Medidas de Associa√ß√£o\n\n6.1 Exerc√≠cio 4.1 - Associa√ß√£o entre Vari√°veis Qualitativas (Dataset Tips)\n\nCrie uma tabela de conting√™ncia entre ‚Äòday‚Äô e ‚Äòtime‚Äô\nCalcule as frequ√™ncias relativas por linha (marginal por linha)\nCalcule as frequ√™ncias relativas por coluna (marginal por coluna)\nCrie um gr√°fico de barras agrupadas mostrando a rela√ß√£o entre ‚Äòday‚Äô e ‚Äòsmoker‚Äô\n\n\n\n6.2 Exerc√≠cio 4.2 - Associa√ß√£o entre Vari√°veis Quantitativas (Dataset Iris)\n\nCrie um gr√°fico de dispers√£o entre ‚Äòsepal length (cm)‚Äô e ‚Äòpetal length (cm)‚Äô\nCalcule a covari√¢ncia entre essas duas vari√°veis\nCalcule a correla√ß√£o entre essas duas vari√°veis\n\n\n\n6.3 Exerc√≠cio 4.3 - Associa√ß√£o entre Vari√°vel Quantitativa e Qualitativa\nCom dataset Tips:\n\nCalcule a m√©dia de ‚Äòtip‚Äô por categoria de ‚Äòtime‚Äô (almo√ßo/jantar)\nCrie um boxplot de ‚Äòtotal_bill‚Äô por ‚Äòday‚Äô\nFa√ßa um gr√°fico de pontos (pointplot) mostrando a m√©dia de ‚Äòtip‚Äô por ‚Äòsmoker‚Äô com barras de erro Com dataset Iris:\nCalcule um resumo descritivo de ‚Äòpetal width (cm)‚Äô por esp√©cie\nCrie boxplots de ‚Äòsepal width (cm)‚Äô por esp√©cie\n\n\n\n6.4 Exerc√≠cio 4.4 - An√°lises Multivariadas\n\nDataset Tips: Crie um gr√°fico de dispers√£o de ‚Äòtotal_bill‚Äô vs ‚Äòtip‚Äô, colorindo os pontos por ‚Äòsmoker‚Äô\nDataset Iris: Fa√ßa um pairplot das vari√°veis quantitativas, colorindo por esp√©cie"
  },
  {
    "objectID": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#desafios-extras",
    "href": "content/manipulacao-dados-python/roteiro-atividades-descricao-dados.html#desafios-extras",
    "title": "Roteiro de Atividades - Ci√™ncias de Dados",
    "section": "7 Desafios Extras",
    "text": "7 Desafios Extras\n\n7.1 Desafio 1\nUsando o dataset Tips, investigue se existe diferen√ßa no comportamento de gorjeta entre fumantes e n√£o fumantes em diferentes dias da semana. Use tabelas de conting√™ncia e gr√°ficos apropriados.\n\n\n7.2 Desafio 2\nNo dataset Iris, identifique qual esp√©cie possui a maior variabilidade nas medidas. Compare os coeficientes de varia√ß√£o (desvio padr√£o / m√©dia) de cada medida para cada esp√©cie.\n\n\n7.3 Desafio 3\nCrie uma nova vari√°vel no dataset Tips chamada ‚Äòtip_rate‚Äô que represente a porcentagem de gorjeta em rela√ß√£o √† conta total. Analise essa nova vari√°vel descritivamente e investigue sua rela√ß√£o com outras vari√°veis do dataset."
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "",
    "text": "Neste tutorial, vamos explorar como trabalhar com estruturas de dados tabulares em Python usando a biblioteca Pandas. Utilizaremos o dataset de [pinguins de Palmer](https://allisonhorst.github.io/palmerpenguins/index.html}{target=‚Äú_blank‚Äù} como exemplo pr√°tico."
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#pacotes-necess√°rios",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#pacotes-necess√°rios",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "1 Pacotes necess√°rios",
    "text": "1 Pacotes necess√°rios\n\nimport pandas as pd\n# pip install palmerpenguins\nfrom palmerpenguins import load_penguins\n\n\n\n\n\n\n\nInstala√ß√£o de palmerpenguins\n\n\n\nO dataset palmerpenguins pode ser instalado com: pip install palmerpenguins"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#carregando-os-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#carregando-os-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "2 Carregando os dados",
    "text": "2 Carregando os dados\n\npenguins = load_penguins()"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#explorando-a-estrutura-dos-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#explorando-a-estrutura-dos-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "3 Explorando a estrutura dos dados",
    "text": "3 Explorando a estrutura dos dados\n\n3.1 Dimens√µes do DataFrame\n\npenguins.shape  # (n√∫mero de linhas, n√∫mero de colunas)\n\n(344, 8)\n\n\n\n\n3.2 Primeiras observa√ß√µes\n\npenguins.head()  # Mostra as primeiras 5 linhas\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n3.3 Tipos de dados\n\npenguins.dtypes  # Mostra o tipo de cada coluna\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-colunas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-colunas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "4 Selecionando colunas",
    "text": "4 Selecionando colunas\n\n4.1 Sele√ß√£o de uma coluna\n\npenguins['species']  # Retorna uma Series\n\n0         Adelie\n1         Adelie\n2         Adelie\n3         Adelie\n4         Adelie\n         ...    \n339    Chinstrap\n340    Chinstrap\n341    Chinstrap\n342    Chinstrap\n343    Chinstrap\nName: species, Length: 344, dtype: object\n\n\n\n\n4.2 Sele√ß√£o de m√∫ltiplas colunas\n\npenguins[['species', 'island', 'body_mass_g']]  # Retorna um DataFrame\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\n\n\n1\nAdelie\nTorgersen\n3800.0\n\n\n2\nAdelie\nTorgersen\n3250.0\n\n\n3\nAdelie\nTorgersen\nNaN\n\n\n4\nAdelie\nTorgersen\n3450.0\n\n\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n4000.0\n\n\n340\nChinstrap\nDream\n3400.0\n\n\n341\nChinstrap\nDream\n3775.0\n\n\n342\nChinstrap\nDream\n4100.0\n\n\n343\nChinstrap\nDream\n3775.0\n\n\n\n\n344 rows √ó 3 columns\n\n\n\n\n\n\n\n\n\nDica\n\n\n\nDiferen√ßa importante:\n- df['coluna'] retorna uma Series (uma dimens√£o)\n- df[['coluna']] retorna um DataFrame (duas dimens√µes)"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-linhas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#selecionando-linhas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "5 Selecionando linhas",
    "text": "5 Selecionando linhas\n\n5.1 Sele√ß√£o por √≠ndice num√©rico\n\npenguins.iloc[0]     # Primeira linha (√≠ndice 0)\npenguins.iloc[10]    # 11¬™ linha (√≠ndice 10)\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            37.8\nbill_depth_mm             17.1\nflipper_length_mm        186.0\nbody_mass_g             3300.0\nsex                        NaN\nyear                      2007\nName: 10, dtype: object\n\n\n\n\n5.2 Sele√ß√£o de m√∫ltiplas linhas\n\npenguins.iloc[0:5]   # Linhas 0 a 4 (5 n√£o inclu√≠do)\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#sele√ß√£o-combinada-linhas-e-colunas",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#sele√ß√£o-combinada-linhas-e-colunas",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "6 Sele√ß√£o combinada: linhas e colunas",
    "text": "6 Sele√ß√£o combinada: linhas e colunas\n\npenguins.iloc[0:5, 0:3]  # Linhas 0-4, colunas 0-2\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n\n\n1\nAdelie\nTorgersen\n39.5\n\n\n2\nAdelie\nTorgersen\n40.3\n\n\n3\nAdelie\nTorgersen\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nIndexa√ß√£o em Python:\n- √çndices come√ßam em 0\n- Intervalos [inicio:fim] n√£o incluem o valor fim\n- 0:5 significa √≠ndices 0, 1, 2, 3, 4"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#filtragem-de-dados",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#filtragem-de-dados",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "7 Filtragem de dados",
    "text": "7 Filtragem de dados\n\n7.1 Filtro simples\n\nfiltro = penguins['species'] == 'Adelie'\nfiltro  # Retorna uma Series de True/False\n\n0       True\n1       True\n2       True\n3       True\n4       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: species, Length: 344, dtype: bool\n\n\n\npenguins[filtro]  # Retorna apenas as linhas onde filtro √© True\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n147\nAdelie\nDream\n36.6\n18.4\n184.0\n3475.0\nfemale\n2009\n\n\n148\nAdelie\nDream\n36.0\n17.8\n195.0\n3450.0\nfemale\n2009\n\n\n149\nAdelie\nDream\n37.8\n18.1\n193.0\n3750.0\nmale\n2009\n\n\n150\nAdelie\nDream\n36.0\n17.1\n187.0\n3700.0\nfemale\n2009\n\n\n151\nAdelie\nDream\n41.5\n18.5\n201.0\n4000.0\nmale\n2009\n\n\n\n\n152 rows √ó 8 columns\n\n\n\n\n\n7.2 M√∫ltiplas condi√ß√µes\nPara combinar condi√ß√µes, usamos operadores l√≥gicos:\n\n& para E (AND)\n| para OU (OR)\n~ para N√ÉO (NOT)\n\n\nfiltro2 = (penguins['species'] == 'Adelie') & (penguins['island'] == 'Torgersen')\nfiltro2\n\n0       True\n1       True\n2       True\n3       True\n4       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nLength: 344, dtype: bool\n\n\n\npenguins[filtro2]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007\n\n\n10\nAdelie\nTorgersen\n37.8\n17.1\n186.0\n3300.0\nNaN\n2007\n\n\n11\nAdelie\nTorgersen\n37.8\n17.3\n180.0\n3700.0\nNaN\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n13\nAdelie\nTorgersen\n38.6\n21.2\n191.0\n3800.0\nmale\n2007\n\n\n14\nAdelie\nTorgersen\n34.6\n21.1\n198.0\n4400.0\nmale\n2007\n\n\n15\nAdelie\nTorgersen\n36.6\n17.8\n185.0\n3700.0\nfemale\n2007\n\n\n16\nAdelie\nTorgersen\n38.7\n19.0\n195.0\n3450.0\nfemale\n2007\n\n\n17\nAdelie\nTorgersen\n42.5\n20.7\n197.0\n4500.0\nmale\n2007\n\n\n18\nAdelie\nTorgersen\n34.4\n18.4\n184.0\n3325.0\nfemale\n2007\n\n\n19\nAdelie\nTorgersen\n46.0\n21.5\n194.0\n4200.0\nmale\n2007\n\n\n68\nAdelie\nTorgersen\n35.9\n16.6\n190.0\n3050.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n70\nAdelie\nTorgersen\n33.5\n19.0\n190.0\n3600.0\nfemale\n2008\n\n\n71\nAdelie\nTorgersen\n39.7\n18.4\n190.0\n3900.0\nmale\n2008\n\n\n72\nAdelie\nTorgersen\n39.6\n17.2\n196.0\n3550.0\nfemale\n2008\n\n\n73\nAdelie\nTorgersen\n45.8\n18.9\n197.0\n4150.0\nmale\n2008\n\n\n74\nAdelie\nTorgersen\n35.5\n17.5\n190.0\n3700.0\nfemale\n2008\n\n\n75\nAdelie\nTorgersen\n42.8\n18.5\n195.0\n4250.0\nmale\n2008\n\n\n76\nAdelie\nTorgersen\n40.9\n16.8\n191.0\n3700.0\nfemale\n2008\n\n\n77\nAdelie\nTorgersen\n37.2\n19.4\n184.0\n3900.0\nmale\n2008\n\n\n78\nAdelie\nTorgersen\n36.2\n16.1\n187.0\n3550.0\nfemale\n2008\n\n\n79\nAdelie\nTorgersen\n42.1\n19.1\n195.0\n4000.0\nmale\n2008\n\n\n80\nAdelie\nTorgersen\n34.6\n17.2\n189.0\n3200.0\nfemale\n2008\n\n\n81\nAdelie\nTorgersen\n42.9\n17.6\n196.0\n4700.0\nmale\n2008\n\n\n82\nAdelie\nTorgersen\n36.7\n18.8\n187.0\n3800.0\nfemale\n2008\n\n\n83\nAdelie\nTorgersen\n35.1\n19.4\n193.0\n4200.0\nmale\n2008\n\n\n116\nAdelie\nTorgersen\n38.6\n17.0\n188.0\n2900.0\nfemale\n2009\n\n\n117\nAdelie\nTorgersen\n37.3\n20.5\n199.0\n3775.0\nmale\n2009\n\n\n118\nAdelie\nTorgersen\n35.7\n17.0\n189.0\n3350.0\nfemale\n2009\n\n\n119\nAdelie\nTorgersen\n41.1\n18.6\n189.0\n3325.0\nmale\n2009\n\n\n120\nAdelie\nTorgersen\n36.2\n17.2\n187.0\n3150.0\nfemale\n2009\n\n\n121\nAdelie\nTorgersen\n37.7\n19.8\n198.0\n3500.0\nmale\n2009\n\n\n122\nAdelie\nTorgersen\n40.2\n17.0\n176.0\n3450.0\nfemale\n2009\n\n\n123\nAdelie\nTorgersen\n41.4\n18.5\n202.0\n3875.0\nmale\n2009\n\n\n124\nAdelie\nTorgersen\n35.2\n15.9\n186.0\n3050.0\nfemale\n2009\n\n\n125\nAdelie\nTorgersen\n40.6\n19.0\n199.0\n4000.0\nmale\n2009\n\n\n126\nAdelie\nTorgersen\n38.8\n17.6\n191.0\n3275.0\nfemale\n2009\n\n\n127\nAdelie\nTorgersen\n41.5\n18.3\n195.0\n4300.0\nmale\n2009\n\n\n128\nAdelie\nTorgersen\n39.0\n17.1\n191.0\n3050.0\nfemale\n2009\n\n\n129\nAdelie\nTorgersen\n44.1\n18.0\n210.0\n4000.0\nmale\n2009\n\n\n130\nAdelie\nTorgersen\n38.5\n17.9\n190.0\n3325.0\nfemale\n2009\n\n\n131\nAdelie\nTorgersen\n43.1\n19.2\n197.0\n3500.0\nmale\n2009\n\n\n\n\n\n\n\n\npenguins[filtro2].shape  # Quantas linhas atendem aos crit√©rios\n\n(52, 8)\n\n\n\n\n\n\n\n\nAviso\n\n\n\nPar√™nteses s√£o obrigat√≥rios ao combinar condi√ß√µes:\n- ‚úÖ (condi√ß√£o1) & (condi√ß√£o2)\n- ‚ùå condi√ß√£o1 & condi√ß√£o2"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#tratando-dados-ausentes",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#tratando-dados-ausentes",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "8 Tratando dados ausentes",
    "text": "8 Tratando dados ausentes\n\n8.1 Identificando valores ausentes\n\npenguins.isnull().sum(axis=1)  # Valores ausentes por linha\n\n0      0\n1      0\n2      0\n3      5\n4      0\n      ..\n339    0\n340    0\n341    0\n342    0\n343    0\nLength: 344, dtype: int64\n\n\n\npenguins.isnull().sum(axis=0)  # Valores ausentes por coluna\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\n\n\n8.2 Removendo valores ausentes\n\npenguins2 = penguins.dropna()  # Remove todas as linhas com valores ausentes\npenguins2.isnull().sum(axis=0)  # Verifica se ainda h√° valores ausentes\n\nspecies              0\nisland               0\nbill_length_mm       0\nbill_depth_mm        0\nflipper_length_mm    0\nbody_mass_g          0\nsex                  0\nyear                 0\ndtype: int64"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#m√©todos-√∫teis-para-explora√ß√£o",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#m√©todos-√∫teis-para-explora√ß√£o",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "9 M√©todos √∫teis para explora√ß√£o",
    "text": "9 M√©todos √∫teis para explora√ß√£o\n\n9.1 Informa√ß√µes gerais\n\npenguins.info()          # Informa√ß√µes gerais sobre o DataFrame\npenguins.describe()      # Estat√≠sticas descritivas para colunas num√©ricas\npenguins['species'].unique()        # Valores √∫nicos em uma coluna\npenguins['species'].value_counts()  # Contagem de cada valor √∫nico\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nspecies\nAdelie       152\nGentoo       124\nChinstrap     68\nName: count, dtype: int64\n\n\n\n\n9.2 Verifica√ß√£o de dados\n\npenguins.shape           # Dimens√µes\npenguins.columns         # Nomes das colunas\npenguins.index           # √çndices das linhas\n\nRangeIndex(start=0, stop=344, step=1)"
  },
  {
    "objectID": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#exemplos-pr√°ticos",
    "href": "content/manipulacao-dados-python/02-estrutura-tipo-python.html#exemplos-pr√°ticos",
    "title": "Estrutura e Tipos de Dados em Python",
    "section": "10 Exemplos pr√°ticos",
    "text": "10 Exemplos pr√°ticos\n\n10.1 Filtros complexos\n\n# Pinguins Adelie com massa corporal &gt; 4000g\nfiltro_complexo = (penguins['species'] == 'Adelie') & (penguins['body_mass_g'] &gt; 4000)\npenguins_grandes = penguins[filtro_complexo]\nprint(f\"Encontrados {len(penguins_grandes)} pinguins Adelie com massa &gt; 4000g\")\n\nEncontrados 35 pinguins Adelie com massa &gt; 4000g\n\n\n\n\n10.2 Sele√ß√£o espec√≠fica\n\n# Primeiros 10 pinguins, apenas esp√©cie e massa corporal\npenguins.iloc[0:10][['species', 'body_mass_g']]\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\n\n\n\n\n0\nAdelie\n3750.0\n\n\n1\nAdelie\n3800.0\n\n\n2\nAdelie\n3250.0\n\n\n3\nAdelie\nNaN\n\n\n4\nAdelie\n3450.0\n\n\n5\nAdelie\n3650.0\n\n\n6\nAdelie\n3625.0\n\n\n7\nAdelie\n4675.0\n\n\n8\nAdelie\n3475.0\n\n\n9\nAdelie\n4250.0\n\n\n\n\n\n\n\n\n\n10.3 Combinando opera√ß√µes\n\n# Pinguins da ilha Biscoe, removendo valores ausentes, apenas colunas num√©ricas\nresultado = (penguins[penguins['island'] == 'Biscoe']\n            .dropna()\n            [['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']])\nresultado.shape\n\n(163, 4)"
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#prepara√ß√£o-inicial",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#prepara√ß√£o-inicial",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "1 üõ†Ô∏è Prepara√ß√£o Inicial",
    "text": "1 üõ†Ô∏è Prepara√ß√£o Inicial\nVamos importar as bibliotecas necess√°rias:\n\nfrom google.colab import drive  # Permite que o Google Colab leia seu Google Drive\nimport pandas as pd  # An√°lise e manipula√ß√£o de dados"
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-1-montando-o-google-drive-no-colab",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-1-montando-o-google-drive-no-colab",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "2 üîó Etapa 1: Montando o Google Drive no Colab",
    "text": "2 üîó Etapa 1: Montando o Google Drive no Colab\nO primeiro passo √© montar seu Google Drive, dentro do Google Colab. Isto pode ser feito com o comando drive.mount(). No exemplo abaixo, vamos pedir que as pasats de seu Google Dive sejam inclu√≠das em uma estrutura de pastas dentro do caminho \"/content/drive\".\n\n# Montar o Google Drive (vai solicitar permiss√£o)\ndrive.mount(\"/content/drive\")\n\nAp√≥s executar este comando, voc√™ ver√° um link de autoriza√ß√£o de acesso ao Google Drive pelo Google Colab. Permita todos os acessos.\n\n2.1 ‚úÖ Verificando os arquivos e pastas\nVoc√™ agora ser√° capaz de navegar pela estrutura de pastas do seu Drive. Por exemplo, voc√™ pode verificar se seu arquivo est√° realmente salvo com o comando !ls.\n\n# Listando arquivos e subpastas na pasta raiz do Drive\n!ls \"/content/drive/MyDrive/MyDrive/Projetos/Dados\""
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-2-localizando-seu-arquivo-csv",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-2-localizando-seu-arquivo-csv",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "3 üìÅ Etapa 2: Localizando seu Arquivo CSV",
    "text": "3 üìÅ Etapa 2: Localizando seu Arquivo CSV\nCaso seu arquivo arquivo_exemplo.csv esteja listado na pasta acima, crie um objeto que conter√° todo o caminho at√© o arquivo:\n\ncaminho_arquivo = \"/content/drive/MyDrive/Projetos/Dados/arquivo_exemplo.csv\""
  },
  {
    "objectID": "content/manipulacao-dados-python/importa-dados-python.html#etapa-3-lendo-o-csv-com-pandas",
    "href": "content/manipulacao-dados-python/importa-dados-python.html#etapa-3-lendo-o-csv-com-pandas",
    "title": "Importando data frames a partir de arquivos CSV",
    "section": "4 üìä Etapa 3: Lendo o CSV com pandas",
    "text": "4 üìä Etapa 3: Lendo o CSV com pandas\nLeia o arquivo com a fun√ß√£o read_csv() do pandas e salve-o em um data frame.\n\n# Lendo o CSV\ndf = pd.read_csv(caminho_arquivo)\n\n# Verique se os dados foram importados corretamente\nprint(df)\n\nPronto!! Ap√≥s verificar se a importa√ß√£o foi feita corretamente, voc√™ pode utilizar o data frame no restante do c√≥digo"
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html",
    "href": "content/inferencia-estatistica/int-conf.html",
    "title": "Estimando a m√©dia populacional",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')"
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html#estima√ß√£o-pontual-e-estima√ß√£o-intervalar",
    "href": "content/inferencia-estatistica/int-conf.html#estima√ß√£o-pontual-e-estima√ß√£o-intervalar",
    "title": "Estimando a m√©dia populacional",
    "section": "1 Estima√ß√£o pontual e estima√ß√£o intervalar",
    "text": "1 Estima√ß√£o pontual e estima√ß√£o intervalar\nA m√©dia \\(\\overline{X}\\) obtida a partir de uma determinada amostra varia em fun√ß√£o das caracter√≠sticas das unidades amostrais que foram selecionadas. Portanto, \\(\\overline{X}\\) n√£o ser√° igual √† m√©dia \\(\\mu\\). No entanto, o TLC nos garante que a distribui√ß√£o esperada das m√©dias amostrais ter√° uma distribui√ß√£o normal e que a m√©dia das m√©dias (\\(\\mu_{\\overline{X}}\\)) ser√° igual a \\(\\mu\\). Vimos ainda que o desvio padr√£o da distribui√ß√£o das m√©dias amostrais (conhecido como erro padr√£o - \\(\\sigma_{\\overline{X}}\\)) depender√° do tamanho da amostra \\(n\\), de acordo com a express√£o:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nUma vez que n√£o conhecemos \\(\\mu\\), temos que estim√°-lo a partir da amostra. Neste caso, \\(\\overline{X}\\) ser√° nossa melhor estimativa da m√©dia populacional. Dizemos que \\(\\overline{X}\\) √© o estimador pontual de \\(\\mu\\).\nComo \\(\\overline{X}\\) varia em fun√ß√£o de nossa amostra particular, devemos obter al√©m da estimativa pontual, uma estimativa intervalar que nos √© fornecida pelo intervalo de confian√ßa.\n\n1.1 Intervalo de confian√ßa\n\n\n\n\n\n\nIntervalo de confian√ßa: defini√ß√£o\n\n\n\n√â o intervalo de valores associado a um determinado n√≠vel de signific√¢ncia (\\(\\alpha\\)). Quando dizemos que um intervalo foi calculado a um n√≠vel de confian√ßa de \\(95\\%\\) (\\(1 - \\alpha\\)), estamos dizendo que a probabilidade do IC conter o valor da m√©dia populacional \\(\\mu\\) √© de \\(95\\%\\).\n\n\nO IC √© calculado por:\n\\[IC_{1-\\alpha} = \\mu \\pm z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO valor de \\(z_{\\alpha/2}\\) √© o valor do √≠ndice \\(z\\) associado ao n√≠vel de confian√ßa desejado.\nSe desejamos definir o intervalo de confian√ßa a 95% precisamos garantir que haja uma probabilidade de 95% de que a m√©dia amostral esteja ao redor da m√©dia populacional. Deste modo, o limite deve excluir 2.5% da por√ß√£o superior e 2.5% da por√ß√£o inferior da curva. Para isto, definimos \\(z_{\\alpha/2} = 1.96\\), sendo \\(\\alpha\\) fixado em 0.05.\n\nO valor \\(z_{\\alpha/2} = 1.96\\) foi retirado da Tabela \\(Z\\) como o m√≥dulo do valor de \\(z\\) que delimida uma √°rea inferior igual a \\(0.025\\).\n\nSe queremos um n√≠vel de confian√ßa diferente, basta ajustar o valor de \\(\\alpha\\). Por exemplo, se queremos um n√≠vel de signific√¢ncia a 99%, fixamos \\(\\alpha\\) em \\(0.01\\) e portanto \\(z = 2.58\\). Da mesma forma, o \\(IC_{90\\%}\\) poder√° ser obtido com \\(\\alpha = 0.10\\) e consequentemente \\(z = 1.64\\). Estes e outros limites descrevem as probabilidades em uma distribui√ß√£o normal padronizada, que podem ser obtidos com o uso da maioria dos softwares estat√≠sticos, al√©m de estarem incluso na Tabela Z, encontrada na grande maioria dos livros de estat√≠stica b√°sica.\n\n\nC√≥digo\n# Ver fun√ß√£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg(xlabels = c(-4:4))\n\n\n\n\n\n\n\n\nFigura¬†1: √Åreas de probabilidade em uma distribui√ß√£o Normal Padronizada (Distribui√ß√£o Z).\n\n\n\n\n\nPara o c√°lculo do intervalo de confian√ßa, assumimos que as m√©dias amostrais seguem uma distribui√ß√£o normal com m√©dia \\(\\mu\\) e desvio padr√£o \\(\\frac{\\sigma}{\\sqrt{n}}\\). Ao fazer isso, estamos aplicando o Teorema Central do Limite (TCL). Geralmente, n√£o temos os valores de \\(\\mu\\) e \\(\\sigma\\), por isso utilizamos os valores de \\(\\overline{X}\\) e \\(s\\), calculados a partir de nossa amostra. Quando o tamanho das amostras √© grande (\\(n \\geq 30\\)), √© aceit√°vel utilizar o valor de \\(z_{\\alpha/2}\\). Assim::\n\\[IC_{1-\\alpha} = \\overline{X} \\pm z_{\\alpha/2} \\times \\frac{s}{\\sqrt{n}}\\]\n\n1.1.1 Distribui√ßao \\(t\\) de Student: \\(\\mu\\) e \\(\\sigma\\) desconhecidos\nQuando n√£o conhecemos \\(\\mu\\) e \\(\\sigma\\) e as amostras s√£o pequenas (ex. \\(n&lt;30\\)), a dsitribui√ß√£o normal n√£o √© a melhor aproxima√ß√£o para o comportamento das m√©dias amostrais. Nestes casos, substitu√≠mos a distribui√ß√£o de \\(z\\) pela Distribui√ß√£o \\(t\\) de Student, sendo o intervalo de confian√ßa obtido por:\n\\[IC_{1-\\alpha} = \\overline{X} \\pm t_{\\alpha/2, gl} \\times \\frac{s}{\\sqrt{n}}\\]\nEm que \\(\\alpha\\) continua sendo o n√≠vel de signific√¢ncia e \\(gl\\) √© definido como os graus de liberdade. Neste caso, os graus de liberdade s√£o dados por:\n\\[gl = n-1\\]\nO formato da distribui√ß√£o \\(t\\) de student n√£o √© constante. √Ä medida que o tamanho amostral aumenta, o formado da distribui√ß√£o \\(t\\) converge para a distribui√ß√£o normal. Isto faz com que na pr√°tica raremente se utiliza a distribui√ß√£o \\(Z\\), substituindo-a pela distribui√ß√£o \\(t\\) de Student.\n\n\n\n\n\n\n\n\nFigura¬†2: Fun√ß√£o de densidade de t para diferentes graus de liberdade.\n\n\n\n\n\nPara amostras pequenas (\\(n = 2\\)) o formato da distribui√ß√£o de \\(t\\) √© distinto da distribui√ß√£o normal. No entanto, para tamanhos amostrais maiores (\\(n = 30\\)) as o formato da distribui√ß√£o \\(t\\) tende a a convergir para o mesmo formato a distribui√ß√£o normal. Esta caracter√≠stica implica que a √°rea a partir de um determinado limite \\(t_i\\) n√£o √© constante como na distribui√ß√£o normal, mas depende do tamanho da amostra, como pode ser visto abaixo.\n\n\n\n\n\n\n\n\nFigura¬†3: Fun√ß√£o de densidade de t para diferentes graus de liberdade."
  },
  {
    "objectID": "content/inferencia-estatistica/int-conf.html#introdu√ß√£o-√†-sufici√™ncia-amostral",
    "href": "content/inferencia-estatistica/int-conf.html#introdu√ß√£o-√†-sufici√™ncia-amostral",
    "title": "Estimando a m√©dia populacional",
    "section": "2 Introdu√ß√£o √† sufici√™ncia amostral",
    "text": "2 Introdu√ß√£o √† sufici√™ncia amostral\nUma decis√£o central ao planejamento de um experimento √© quanto recurso (ex. tempo, dinheiro, m√£o de obra) devem ser investidos para se obter boas estimativas dos par√¢metros populacionais. Por boas estimativas, entendemos amostras precisas, ou seja, que podem ser definida por amostras com baixo erro padr√£o e acuradas, que em m√©dia apontem para o verdadeiro valor do par√¢metro. Neste caso, uma das primeiras quest√µes a ser feita √© ‚ÄúQual tamanho amostral aplicar em meu estudo?‚Äù.\nVimos que aumentar o tamanho amostral resulta em estimativas mais precisas, isto √© com menor erro padr√£o. Portanto, um bom delineamento amostral √© aquele que permita, a um custo m√≠nimo, obter estimativas com a precis√£o desejada. Uma pesquisa que resulte em estimativas demasiadamente imprecisas pode se mostrar in√∫til. O que dizer por exemplo, se um estudo conclui que o comprimento m√©dios de uma esp√©cie de pescado √© de \\(35\\) cm com uma incerteza a \\(95\\%\\) entre \\(15\\) e \\(55\\) cm? Uma estimativa com tal n√≠vel de imprecis√£o n√£o ter√° qualquer implica√ß√£o pr√°tica.\nPor outro lado, partir de um determinado tamanho amostral o ganho em precis√£o torna-se m√≠nimo. Isto significa que amostras demasiadamente grandes podem ter um custo muto alto por√©m n√£o serem capazes aumentar de forma relevante a precis√£o do experimento.\nVeja o que ocorre com o erro padr√£o de uma amostra √† medida que aumenta o tamanho \\(n\\).\n\n\n\n\n\n\n\n\nFigura¬†4: Efeito do aumento do tamanho amostral n sobre o erro padr√£o da m√©dia.\n\n\n\n\n\nNeste exemplo, para amostras de tamanho 1, \\(\\sigma_{\\overline{X}} = 4\\). Se tivermos agora amostras de tamanho 10, \\(\\sigma_{\\overline{X}} = 1.2\\), uma redu√ß√£o de mais de 50%. No entanto aumentarmos o tamanho amostral para 50 o erro padr√£o cai somente de \\(1,2\\) para \\(0,56\\). Isto significa que a partir de determinado ponto (neste exemplo a partir de \\(10\\) ou \\(20\\) amostras), a redu√ß√£o no erro padr√£o torna-se m√≠nima. Neste momento podemos podemos refletir sobre o custo de continuar aumentando o tamanho amostral para obter um ganho cada vez menor em precis√£o.\nPara encontrarmos o tamanho amostral desejado, devemos decidir sobre dois pontos: i - que n√≠vel de acur√°cia desejado, ou seja, qu√£o distante do valor real (m√©dia populacional) queremos que nossa esimativa esteja; e ii - qual o n√≠vel de confian√ßa do resultado, ou seja, com que precis√£o queremos fazer esta estimativa.\n\n2.1 N√≠vel de acur√°cia desejado (margem de erro) e n√≠vel de confian√ßa na estimativa\nO n√≠vel de acur√°cia desejado √© comumente conhecido com margem de Erro (E), definida como diferen√ßa m√°xima prov√°vel (com probabilidade \\(1-\\alpha\\)) entre a m√©dia amostral e a m√©dia populacional.\nA margem de erro para a m√©dia amostral pode ser obtida por (compare esta express√£o com a do intervalo de confian√ßa):\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nO n√≠vel de confian√ßa na estimativa nos garante que nossa estimativa estar√° dentro da margem de erro assumida com probabilidade \\(1-\\alpha\\). Como vimos acima, valores t√≠picos para o n√≠vel de confian√ßa s√£o \\(99\\%\\), \\(95\\%\\) e \\(90\\%\\).\nUma representa√ß√£o esquem√°tica do erro amostral e do n√≠vel de confian√ßa na distribui√ß√£o de \\(z\\) pode ser vista abaixo:\n\n\n\n\n\n\n\n\nFigura¬†5: Erro amostra e n√≠vel de confian√ßa na distribui√ß√£o Z.\n\n\n\n\n\nA defini√ß√£o da margem de erro e do n√≠vel de confian√ßa depende de estimativas pr√©vias dos par√¢metros populacionais \\(\\mu\\) e \\(\\sigma\\). Estas estimativas podem ser obtidas na literatura, buscando estudos similares, ou por meio de um projeto piloto. Em um experimento piloto, o pesquisador ir√° conduzir seu plano de amostragem com um tamanho m√≠nimo, justamente para avaliar a efici√™ncia metodol√≥gica, adequabilidade dos resultados e prever o esfor√ßo amostral adequado. As informa√ß√µes de um pequeno estudo piloto, se bem aproveitadas, podem evitar erros simples de delineamento, al√©m de invariavelmente, permitir economia de recusros e consequentemente ganho em qualidade.\n\n\n2.2 Determinando o tamanho de uma amostra\nPodemos voltar a nossa quest√£o anterior sobre Qual tamanho amostral aplicar em meu estudo?. Esta quest√£o pode ser reformulada como:\n\nQual tamanho amostral aplicar para obter uma estimativa de \\(\\mu\\) que possua uma margem de erro \\(E\\) e nivel de confian√ßa \\(1-\\alpha\\) pr√©-determinados.\n\nIniciando com a f√≥rmula da margem de erro:\n\\[E = z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\]\nisolamos a vari√°vel \\(n\\) para obter:\n\\[n = (\\frac{ z_{\\alpha/2} \\times \\sigma}{E})^2\\]\nNovamente, uma vez que n√£o conhecemos o desvio padr√£o populacional \\(\\sigma\\) podemos substitu√≠-lo pelo desvio padr√£o (\\(s\\)) de um experimento piloto ou estim√°-lo a partir da literatura.\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html",
    "href": "content/visualizacao-dados/grafico-ggplot2.html",
    "title": "Gr√°ficos em camadas",
    "section": "",
    "text": "O pacote ggplot2 no R √© baseado na gram√°tica de gr√°ficos (Grammar of Graphics), que permite a constru√ß√£o de visualiza√ß√µes de dados de maneira declarativa. Com ele, √© poss√≠vel criar uma ampla variedade de gr√°ficos, desde simples gr√°ficos de barras e dispers√£o at√© complexas visualiza√ß√µes com m√∫ltiplas camadas e facetas. O ggplot2 facilita a personaliza√ß√£o detalhada dos gr√°ficos, incluindo temas, cores e anota√ß√µes, tornando-o uma escolha popular entre estat√≠sticos, cientistas de dados e analistas para comunicar informa√ß√µes de maneira clara e eficiente.\nO ggplot2 gera gr√°ficos a partir das colunas de um data frame, o que significa que o dom√≠nio de ferramentas de transforma√ß√£o de data frames √© fundamental para a cria√ß√£o de visualiza√ß√µes eficazes. Cada elemento do gr√°fico, como eixos, pontos, linhas e barras, √© mapeado a partir das vari√°veis presentes no data frame. Isso permite grande flexibilidade na representa√ß√£o gr√°fica.\nA estrutura em camadas do ggplot2 fornece uma base coesa e flex√≠vel para a codifica√ß√£o de gr√°ficos. Por exemplo, √© poss√≠vel come√ßar com uma camada base que define o sistema de coordenadas e os eixos, adicionar uma camada de pontos para criar um gr√°fico de dispers√£o, e ent√£o sobrepor camadas adicionais para ajustar a est√©tica, adicionar linhas de tend√™ncia, ou incluir etiquetas. Essa abordagem em camadas facilita a personaliza√ß√£o e a atualiza√ß√£o dos gr√°ficos, tornando o processo de cria√ß√£o de visualiza√ß√µes complexas mais organizado e intuitivo. Isso n√£o s√≥ melhora a clareza e a legibilidade do c√≥digo, mas tamb√©m promove uma maior capacidade de experimenta√ß√£o e explora√ß√£o dos dados, permitindo que analistas e pesquisadores ajustem e aprimorem suas visualiza√ß√µes de forma eficiente.\nAqui faremos uma introdu√ß√£o aos elementos princiais do ggplot2. Para saber mais verifique as refer√™ncias abaixo:\nInstale o pacote gglot2 e carregue-o com os demais pacotes utilizados nessa se√ß√£o. O pacote ser√° adicionado para compor m√∫ltiplos gr√°ficos em uma mesma figura.\ninstall.packages(\"ggplot2\")\ninstall.packages(\"patchwork\")\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#histogramas",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#histogramas",
    "title": "Gr√°ficos em camadas",
    "section": "1 Histogramas",
    "text": "1 Histogramas\nFa√ßa um histograma dos dados de vaz√£o da tabela HubbardBrook.csv (datasets).\n\nhbrook &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook.csv\")\nhbrook\n\n# A tibble: 62 √ó 4\n    Year Treatment   Flow Precipitation\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n 1  1958 Deforested  645.         1168.\n 2  1959 Deforested 1012.         1483.\n 3  1960 Deforested  825.         1321.\n 4  1961 Deforested  470.          980.\n 5  1962 Deforested  777.         1232.\n 6  1963 Deforested  774.         1139.\n 7  1964 Deforested  712.         1175.\n 8  1965 Deforested  599.         1115.\n 9  1966 Deforested 1189.         1222.\n10  1967 Deforested 1132.         1315.\n# ‚Ñπ 52 more rows\n\n\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\")\n\n\n\n\n\n\n\n\nO comando acima cont√©m duas camadas, separadas pelo s√≠mbolo +, que indica o fim de uma camada e o in√≠cio de outra. No ggplot2, cada camada adiciona ou formata um elemento do gr√°fico. A ordem das camadas geralmente n√£o importa, mas organiz√°-las bem facilita a leitura do c√≥digo. No exemplo, temos:\n\nFun√ß√£o ggplot(): Define a estrutura b√°sica do gr√°fico. O argumento data = especifica o data frame que cont√©m os dados. O argumento mapping = define a est√©tica do gr√°fico definida pela fun√ß√£o aes(x = Flow), indicando que o eixo \\(x\\) representar√° a vari√°vel Flow.\nFun√ß√£o geom_histogram(): Define a geometria do gr√°fico, aqui um histograma. A cor da borda √© definida por color = \"blue\" e o preenchimento por fill = \"lightblue\".\n\nFormata√ß√µes adicionais:\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\") +\n  labs(title = \"Histograma de vaz√£o\", \n       x = bquote(Vazao (m^3/s)),\n       y = \"Contagem\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nUm t√≠tulo foi inserido, os nomes para os eixos \\(x\\) e \\(y\\) foram definidos e o t√≠tulo foi centralizado por theme(plot.title = element_text(hjust = 0.5)).\nO histograma anterior, combina dados de vaz√£o anual na bacia Deforested e Reference, identificadas pela vari√°vel Treatment. Para verificar histogramas separados de acordo com os n√≠veis desta vari√°vel podemos usar a fun√ß√£o facet_grid()\n\nggplot(data = hbrook, mapping = aes(x = Flow)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\") +\n  labs(title = \"Histograma de vaz√£o\", \n       x = bquote(Vazao (m^3/s)),\n       y = \"Contagem\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_grid(rows = vars(Treatment))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutras geometrias gr√°ficas\n\n\n\nAl√©m dos histogramas, existem muitas outras geometrias gr√°ficas do tipo geom_NOME(). Algumas das mais utilizadas s√£o: geom_abline(), geom_bar(), geom_boxplot(), geom_line(), geom_point(), geom_smooth(), geom_text(), entre muitas outras."
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#boxplots",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#boxplots",
    "title": "Gr√°ficos em camadas",
    "section": "2 Boxplots",
    "text": "2 Boxplots\nA princ√≠pio, a distribui√ß√£o das vaz√µes n√£o s√£o muito diferentes entre os tratamentos. Um boxplot pode ser utilizado para visualizar estas distribui√ß√µes.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Treatment)) +\n  geom_boxplot() +\n  labs(y = bquote(Vazao (m^3/s)),\n       x = \"\")\n\n\n\n\n\n\n\n\nO boxplot exige que sejam definidas uma vari√°vel cont√≠nua, neste caso Flow em \\(y\\) como fun√ß√£o de uma vari√°vel categ√≥rica, neste caso Treatment em \\(x\\)."
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#gr√°fico-de-dispers√£o",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#gr√°fico-de-dispers√£o",
    "title": "Gr√°ficos em camadas",
    "section": "3 Gr√°fico de dispers√£o",
    "text": "3 Gr√°fico de dispers√£o\nPara verificar a rela√ß√£o entre vaz√£o e precipita√ß√£o, pode-se plotar um gr√°fico de dispers√£o entre Flow e Precipitation.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Precipitation)) +\n  geom_point(shape = 21) +\n  labs(y = bquote(Vaz√£o (m^3/s)),\n       x = bquote(Precipita√ß√£o (m^3/ano)))\n\n\n\n\n\n\n\n\nO Treatment pode ser adicinado a esta figura como cores diferentes.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, \n                     x = Precipitation, \n                     fill = Treatment)) +\n  geom_point(shape = 21, size = 3) +\n  labs(y = bquote(Vaz√£o (m^3/s)),\n       x = bquote(Precipita√ß√£o (m^3/ano))) +\n  guides(fill=guide_legend(title=\"Estado da √°rea\")) +\n  scale_fill_manual(values = c(\"blue\", \"green\"))"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#s√©ries-temporais",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#s√©ries-temporais",
    "title": "Gr√°ficos em camadas",
    "section": "4 S√©ries temporais",
    "text": "4 S√©ries temporais\nO operador pipe pode ser combinado com a fun√ß√£o ggplot() para filtrar as bacia Deforested e representar a vaz√£o em uma s√©rie temporal.\n\nhbrook |&gt;  \n  filter(Treatment == \"Deforested\") |&gt;  \n  ggplot(mapping = aes(y = Flow, x = Year)) +\n    geom_line() +\n    labs(y = bquote(Vaz√£o (m^3/s)),\n         x = \"Ano\")\n\n\n\n\n\n\n\n\nPodem ser vistas as s√©ries temporais para os dois tratamentos, representando-os em figuras diferentes.\n\nggplot(data = hbrook, mapping = aes(y = Flow, x = Year)) +\n  geom_line() +\n  labs(y = bquote(Vaz√£o (m^3/s)),\n       x = \"Ano\") +\n  facet_grid(rows = vars(Treatment))\n\n\n\n\n\n\n\n\nOu na mesma figura em cores diferentes.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, x = Year, color = Treatment)) +\n  geom_line() +\n  labs(y = bquote(Vaz√£o (m^3/s)),\n       x = \"Ano\") +\n  scale_color_manual(values = c(\"blue\", \"green\"))\n\n\n\n\n\n\n\n\nO desmatamento da bacia Deforested ocorreu em \\(1965\\), e interven√ß√µes para impedir o desenvolvimento da vegeta√ß√£o foram realizadas at√© \\(1970\\). Esse intervalo pode ser representado por um ret√¢ngulo no gr√°fico.\n\nggplot(data = hbrook, \n       mapping = aes(y = Flow, x = Year, color = Treatment)) +\n  geom_line() +\n  labs(y = bquote(Vaz√£o (m^3/s)),\n       x = \"Ano\") +\n  scale_color_manual(values = c(\"blue\", \"green\")) +\n  scale_x_continuous(breaks = seq(1955, 1990, by = 5)) +\n  annotate(\"rect\", \n           xmin = 1965, xmax = 1970, \n           ymin = -Inf, ymax = Inf, \n           alpha = 0.2, fill = \"red\") +\n  theme_test()\n\n\n\n\n\n\n\n\nComo as vaz√µes foram mensuradas nos mesmos anos, √© poss√≠vel calcular a diferen√ßa de vaz√£o entre os tratamentos e representar essas diferen√ßas graficamente.\n\nhbrook_largo &lt;- hbrook |&gt;\n  select(-Precipitation) |&gt;\n  pivot_wider(names_from = Treatment, values_from = Flow) |&gt; \n  mutate(diffDR = Deforested - Reference)\nhbrook_largo\n\n# A tibble: 31 √ó 4\n    Year Deforested Reference diffDR\n   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1  1958       645.      567.   77.8\n 2  1959      1012.      918.   93.8\n 3  1960       825.      752.   73.2\n 4  1961       470.      436.   33.8\n 5  1962       777.      699.   78.0\n 6  1963       774.      663.  111. \n 7  1964       712.      630.   81.7\n 8  1965       599.      547.   52.2\n 9  1966      1189.      727.  463. \n10  1967      1132.      781.  351. \n# ‚Ñπ 21 more rows\n\n\n\nggplot(data = hbrook_largo, \n       mapping = aes(y = diffDR, x = Year)) +\n  geom_line() +\n  geom_point(shape = 19) +\n  labs(y = bquote(Diferen√ßa~de~Vaz√£o (m^3/s)),\n       x = \"Ano\") +\n  scale_x_continuous(breaks = seq(1955, 1990, by = 5)) +\n  annotate(\"rect\", \n           xmin = 1965, xmax = 1970, \n           ymin = -Inf, ymax = Inf, \n           alpha = 0.2, fill = \"red\") +\n  theme_test()"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#gr√°fico-de-barras",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#gr√°fico-de-barras",
    "title": "Gr√°ficos em camadas",
    "section": "5 Gr√°fico de barras",
    "text": "5 Gr√°fico de barras\nSer√° criada uma vari√°vel categ√≥rica Vazao_cat contendo os n√≠veis Extrema (se Flow &gt;= 1000 m^3/s) e Normal caso contr√°rio. Em seguida, ser√° contado o n√∫mero de observa√ß√µes com vaz√£o extrema.\n\nextremo &lt;- 1000\n\nhbrook2 &lt;- hbrook  |&gt;\n  mutate(Vazao_cat = if_else(Flow &gt;= extremo, \n                             true = \"Extrema\", \n                             false = \"Normal\"))\n\nggplot(data = hbrook2, mapping = aes(x = Vazao_cat)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nSe a vari√°vel estiver no eixo \\(y\\), aes(y = Vazao_cat), o gr√°fico ser√° desenhado na horizontal.\n\nggplot(data = hbrook2, mapping = aes(y = Vazao_cat)) +\n  geom_bar()"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#temas-no-ggplot2",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#temas-no-ggplot2",
    "title": "Gr√°ficos em camadas",
    "section": "6 Temas no ggplot2",
    "text": "6 Temas no ggplot2\nO ggplot2 oferece uma s√©rie de temas pr√©-formatados para facilitar a personaliza√ß√£o dos gr√°ficos. Para aplicar um tema, basta adicionar uma camada com o nome do tema desejado usando theme_NOME(). Veja um exemplo com o tema theme_classic():\n\nggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\n\n\n\n\n\n\n\nOs temas b√°sicos dispon√≠veis no ggplot2 incluem:\n\n\nC√≥digo\ng1 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_grey() +\n  labs(title = \"theme_grey()\")\n\ng2 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_gray() +\n  labs(title = \"theme_gray()\")\n\ng3 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_bw() +\n  labs(title = \"theme_bw()\")\n\ng4 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_linedraw() +\n  labs(title = \"theme_linedraw()\")\n\ng5 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_light() +\n  labs(title = \"theme_light()\")\n\ng6 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_dark() +\n  labs(title = \"theme_dark()\")\n\ng7 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"theme_minimal()\")\n\ng8 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic() +\n  labs(title = \"theme_classic()\")\n\ng9 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_void() +\n  labs(title = \"theme_void()\")\n\ng10 &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_test() +\n  labs(title = \"theme_test()\")\n\n\n\n\nC√≥digo\ngcol1 &lt;- g1 / g2 / g3 / g4 / g5\ngcol2 &lt;- g6 / g7 / g8 / g9 / g10\n\ngcol1 | gcol2"
  },
  {
    "objectID": "content/visualizacao-dados/grafico-ggplot2.html#salvando-uma-figura-gerada-pelo-gglot2.",
    "href": "content/visualizacao-dados/grafico-ggplot2.html#salvando-uma-figura-gerada-pelo-gglot2.",
    "title": "Gr√°ficos em camadas",
    "section": "7 Salvando uma figura gerada pelo gglot2.",
    "text": "7 Salvando uma figura gerada pelo gglot2.\nPara salvar um gr√°fico gerado com ggplot2, utiliza-se a fun√ß√£o ggsave(). Veja o exemplo abaixo:\n\nggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\nggsave(filename = \"Exemplo_ggsave.png\", \n       width = 20, height = 20, units = \"cm\")  \n\nPor padr√£o, a fun√ß√£o ggsave() salva o √∫ltimo gr√°fico criado. Caso seja necess√°rio salvar um gr√°fico espec√≠fico, pode-se usar o argumento plot = objeto_grafico.\n\nobjeto_grafico &lt;- ggplot(hbrook, mapping = aes(x = Year, y = Flow, color = Treatment)) +\n  geom_line() +\n  theme_classic()\n\nggsave(filename = \"objeto_grafico_plt.png\", \n       plot = objeto_grafico,\n       device = \"png\",\n       width = 20, \n       height = 20,\n       units = \"cm\",\n       dpi = 480)"
  },
  {
    "objectID": "content/teste-hipoteses/teste-variancia.html",
    "href": "content/teste-hipoteses/teste-variancia.html",
    "title": "Comparando vari√¢ncias",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas no cap√≠tulo\n\n\n\n\n\n\nlibrary(gt)\nlibrary(tidyverse)\nlibrary(patchwork)\nA mesma l√≥gica para testar uma hip√≥tese sobre a m√©dia populacional \\(\\mu\\) pode ser utilizada para testar uma hip√≥tese sobre a vari√¢ncia populacional \\(\\sigma^2\\). Veja o exemplo a seguir.\nA Tabela¬†1 √© proviniente de um estudo em que foi analizada a riqueza de esp√©cies da macro-fauna da zona entre-mar√©s em nove praias costa da Holanda. Neste exemplo vamos usar as praias 5 e 8.\nC√≥digo\nRIKZ &lt;- read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/RIKZ.csv')\n\nS &lt;- RIKZ |&gt; \n  subset(Beach == 5 | Beach == 8) |&gt; \n  select(Richness, Beach)\n\nS |&gt; \n  gt() |&gt; \n  cols_width(\n    Richness ~ px(150),\n    Beach ~ px(150)\n  )\n\n\n\n\nTabela¬†1: Riqueza da macro-fauna em duas praias da costa Holandesa. Dados completos no arquivo ‚ÄúRIKZ‚Äù do pacote ‚ÄúAED‚Äù.\n\n\n\n\n\n\n\n\n\nRichness\nBeach\n\n\n\n\n3\n5\n\n\n22\n5\n\n\n6\n5\n\n\n0\n5\n\n\n6\n5\n\n\n3\n8\n\n\n5\n8\n\n\n7\n8\n\n\n5\n8\n\n\n0\n8\nPodemos nos perguntar se em uma praia a riqueza de esp√©cies varia mais que na outra, ou seja, se em uma das praias amostras difere uma das outras em maior grau que na outra praia. Neste caso, estamos interessados em testar as vari√¢ncias, n√£o as m√©dias. Para testarmos a homogeneidade de vari√¢ncias entre as praias podemos estabelecer as seguintes hip√≥teses:\n1. Estabelcer as hip√≥teses estat√≠sticas\n\\(H_0: \\sigma^2_5 = \\sigma^2_8\\)\n\\(H_a: \\sigma^2_5 \\ne \\sigma^2_8\\)\nA hip√≥tese nula \\(H_0\\) estabelece aqui que as vari√¢ncias populacionais na praia 1 (\\(\\sigma^2_5\\)) seja igual a vari√¢ncia populacional da praia 2 (\\(\\sigma^2_8\\)), enquento \\(H_a\\) estabelece que s√£o diferentes.\n2. Definir o n√≠vel de signific√¢ncia\nNeste caso podemos estabelecer \\(\\alpha = 0,05\\) como de costume.\n3. Definir a estat√≠stica do teste\nExistem v√°rias formas poss√≠veis de testar a homogeneidade de vari√¢ncias, a mais simples √© o teste de raz√£o de vari√¢ncias que tem como estat√≠stica:\n\\[F = \\frac{s^2_{maior}}{s^2_{menor}}\\]\nem que \\(s^2_{maior}\\) √© a maior vari√¢ncia amostral e \\(s^2_{menor}\\) √© a menor vari√¢ncia amostral.\n4. Calcular a estat√≠stica do teste \\(F_{calc}\\)\nC√≥digo\nS_var = S |&gt; \n  group_by(Beach) |&gt; \n  summarise(Variancias = var(Richness),\n            n = n())\nsmax = max(S_var[,2])\nsmin = min(S_var[,2])\nn1 = as.numeric(S_var[1,3])\nn2 = as.numeric(S_var[2,3])\n\nFcalc = smax/smin\np = pf(Fcalc, df1 = n1-1, df2 = n2-1, lower.tail = FALSE)\nNeste exemplo, as vari√¢ncias amostrais s√£o:\nPraia 5: \\(s^2_{1} = 72.8\\) e,\nPraia 8: \\(s^2_{2} = 7\\)\nO \\(F_{calc}\\) fica:\n\\[F_{calc} = \\frac{72.8}{7} = 10.4\\] mostrando de a vari√¢ncia na praia 5 √© \\(10.4\\) vezes maior que na praia 8.\n5. Calcular o valor de p para a distribui√ß√£o estat√≠stica apropriada\nNo teste de hip√≥tese para uma m√©dia a distribui√ß√£o estat√≠stica apropriada para a estat√≠stica \\(Z\\) era a distribuiu√ß√£o normal padronizada. No caso do teste de raz√£o de vari√¢ncias, a distribui√ß√£o apropriada √© chamada de ditribui√ß√£o \\(F\\), que tem um formato assim√©trico √† direita. Em nosso exemplo, o valor de \\(p = 0.022\\).\nFigura¬†1: Distribui√ß√£o F de Fisher para 4 graus de liberdade no numerador e 4 graus de liberdade no denominador.\nO formato da distribui√ß√£o F varia em fun√ß√£o dos graus de liberdade do numerador e do denominador. Para este exemplo, os graus de liberdade do numerador e denominador s√£o calculados como \\(gl = n-1\\). Como foram tomadas 5 amostras em cada uma das praias, \\(gl_{numerador} = gl_{denominador} = n-1 = 4\\).\nTomada de decis√£o sobre \\(H_0\\)\nAssumindo que o valor de \\(p = 0.022\\) √© menor que o n√≠vel de signific√¢ncia adotado \\(\\alpha = 0,05\\), rejeitamos \\(H_0\\) e conclu√≠mos que a distribui√ß√£o da riqueza de esp√©cies na praia 5 √© mais heterog√™nea que na praia 8."
  },
  {
    "objectID": "content/teste-hipoteses/teste-variancia.html#teste-de-raz√£o-de-vari√¢ncias-no-r",
    "href": "content/teste-hipoteses/teste-variancia.html#teste-de-raz√£o-de-vari√¢ncias-no-r",
    "title": "Comparando vari√¢ncias",
    "section": "1 Teste de raz√£o de vari√¢ncias no R",
    "text": "1 Teste de raz√£o de vari√¢ncias no R\nOs c√°lculos acima podem ser replicados no R com o comando var.test().\n\nvar.test(Richness ~ Beach, data = S, alternative = 'greater')\n\n\n    F test to compare two variances\n\ndata:  Richness by Beach\nF = 10.4, num df = 4, denom df = 4, p-value = 0.02173\nalternative hypothesis: true ratio of variances is greater than 1\n95 percent confidence interval:\n 1.627993      Inf\nsample estimates:\nratio of variances \n              10.4 \n\n\n\n\n\n\n\n\nDistribui√ß√£o \\(F\\) para outros graus de liberdade\n\n\n\n\n\n\n\n\n\n\n\nFigura¬†2: Distribui√ß√£o F de Fisher para diferentes combina√ß√µes de graus de liberdade no numerador e denominador."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html",
    "href": "content/teste-hipoteses/teste-t.html",
    "title": "Comparando m√©dias: teste t de Student",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas no cap√≠tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nO modelo normal de probabilidades n√£o √© a melhor aproxima√ß√£o para a distribui√ß√£o das m√©dias amostrais quando n√£o conhecemos \\(\\mu\\) e \\(\\sigma\\) e/ou quando o tamanho amostral \\(n\\) √© pequeno. Nesta situa√ß√£o, a distribui√ß√£o t de Student √© mais apropriada para o c√°lculo do intervalo de confian√ßa. Da mesma forma, o teste \\(Z\\) assume que a distribui√ß√£o das m√©dias amostrais √© normalmente distribu√≠da e que a vari√¢ncia populacional \\(\\sigma\\) seja conhecida, uma informa√ß√£o que n√£o temos na pr√°tica cient√≠fica.\nO teste t de Student √© utilizado em substitui√ß√£o ao teste \\(Z\\) quando \\(\\sigma\\) √© desconhecido e/ou o tamanho amostral √© pequeno. A l√≥gica do teste √© a mesma apresentada discutida no teste \\(Z\\), por√©m estabelece que a distribui√ß√£o das m√©dias amostrais √© melhor descrita pela distribui√ß√£o \\(t\\) e n√£o pela distribui√ß√£o normal."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#teste-t-para-uma-m√©dia-populacional",
    "href": "content/teste-hipoteses/teste-t.html#teste-t-para-uma-m√©dia-populacional",
    "title": "Comparando m√©dias: teste t de Student",
    "section": "1 Teste t para uma m√©dia populacional",
    "text": "1 Teste t para uma m√©dia populacional\nConsidere um exemplo simples. Dados do Banco Central do Brasil dizem que moedas de \\(R\\$ 0,10\\) da segunda gera√ß√£o pesam 4.8 gramas. Voc√™ tem \\(8\\) moedas no bolso e resolve testar essa afirma√ß√£o pesando cada moeda. Os pesos obtidos s√£o: \\(X = 5.1, 5, 4.8, 5, 5, 4.9, 4.9, 4.7\\).\nInicialmente, devemos estabelecer nossa hip√≥tese nula (\\(H_0\\)), nossa hip√≥tese alternativa (\\(H_a\\)) e o n√≠vel se signific√¢ncia \\(\\alpha\\). Iremos estabelecer \\(\\alpha = 0,05\\) e as hip√≥teses como:\n\\(H_0: \\mu = 4.8\\) gramas\n\\(H_a: \\mu \\ne 4.8\\) gramas\nComo n√£o conhecemos \\(\\sigma\\) e temos uma amostra pequena, a posi√ß√£o das m√©dias amostrais seguir√° uma distribui√ß√£o \\(t\\) de Student e a estat√≠stica do teste ser√°:\n\\[t = \\frac{\\overline{X} - \\mu}{s_{\\overline{X}}}\\]\nsendo o erro padr√£o amostral obtido por:\n\\[s_{\\overline{X}} = \\frac{s}{\\sqrt{n}}\\]\nO c√°lculo de \\(t\\) √© muito similar ao escore \\(Z\\). No entanto, substitu√≠mos \\(\\sigma\\) por \\(s\\). As distribui√ß√µes de \\(t\\) e de \\(Z\\) s√£o muito similares. Entretanto, para amostras pequenas e quando \\(\\sigma\\) √© desconhecido, a curva de \\(t\\) nos fornece uma melhor estimativa das probabilidades associadas a distribui√ß√£o das m√©dias amostrais.\nPara este exemplo, temos uma amostra de tamanho \\(n = 8\\) com m√©dia \\(\\overline{X} = 4.925\\)g e desvio padr√£o \\(s = 0.13\\)g. O valor de \\(t\\) pode ser calculado por:\n\\[t_{c} = \\frac{\\overline{X} - \\mu}{s_{\\overline{X}}} = \\frac{\\overline{X} - \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{4.925  - 4.8}{\\frac{0.13}{\\sqrt{8}}} = 2.76\\]\nAssim como fizemos para a distribui√ß√£o \\(Z\\), devemos encontrar a probabilidade de obtermos um valor t√£o ou maior que o m√≥dulo de \\(t_c\\). Na figura abaixo, nosso resultado fica:\n\n\n\n\n\n\n\n\nFigura¬†2: Valor de p associado ao resultado do teste t.\n\n\n\n\n\nA probabilidade de encontrarmos um valor de \\(t_c\\) t√£o ou mais extremo segundo a hip√≥tese nula foi de \\(p = 0.028\\). Uma vez que este valor √© menor que o n√≠vel cr√≠tico \\(\\alpha = 0,05\\), conclu√≠mos que existe evid√™ncia suficiente para rejeitar \\(H_0\\) e aceitar a hip√≥tese alternativa de que as moedas de \\(10\\) centavos n√£o prov√©m de uma popula√ß√£o estat√≠stica com \\(\\mu = 4,8\\) gramas. Nossa conclus√£o √© portanto, que as moedas de \\(R\\$ 0,10\\) s√£o mais pesadas que \\(4,8\\) gramas.\n\n\n\n\n\n\nTerste t no R\n\n\n\n\nt.test(X, mu = 4.8)\n\n\n    One Sample t-test\n\ndata:  X\nt = 2.7584, df = 7, p-value = 0.02816\nalternative hypothesis: true mean is not equal to 4.8\n95 percent confidence interval:\n 4.817844 5.032156\nsample estimates:\nmean of x \n    4.925 \n\n\n\nNos comandos acima, \\(X\\) √© a amostra e o argumento mu representa a expectativa sobre a m√©dia populacional segundo \\(H_0\\). Como resultados temos:\n\na indica√ß√£o de que fizemos um teste \\(t\\) para uma amostra: One Sample t-test;\no valor de \\(t\\) calculado: t = 2.7584;\nos graus de liberdade: df = 8 - 1 = 7; e\no valor de p = 0.028.\n\nA sa√≠da da fun√ß√£o apresenta ainda o valor da m√©dia amostral (\\(\\overline{X} = 4.925\\)) e o intervalo de confian√ßa a \\(95\\%\\) (4.817844 - 5.032156)."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#graus-de-liberdade",
    "href": "content/teste-hipoteses/teste-t.html#graus-de-liberdade",
    "title": "Comparando m√©dias: teste t de Student",
    "section": "2 Graus de liberdade",
    "text": "2 Graus de liberdade\nA distribui√ß√£o \\(t\\) como v√°rias outras distribui√ß√µes amostrais utilizadas em infer√™ncia estat√≠stica, muda seu formato em fun√ß√£o do que chamamos de graus de liberdade (\\(gl\\)). Os graus de liberdade t√™m rela√ß√£o com o tamanho amostral. No caso do teste \\(t\\) para \\(1\\) amostra, esta rela√ß√£o √© simplesmente: \\(gl = n-1\\).\n√Ä medida que os graus de liberdade aumentam, o formato da distribui√ß√£o \\(t\\) se assemelha ao formato da distribui√ß√£o Normal padronizada. De fato, para graus de liberdades altos (ex. \\(n \\ge 30\\)), os formatos das distribui√ß√µes \\(Z\\) e \\(t\\) s√£o praticamente indistingu√≠veis. Na pr√°tica, isto faz que as distribui√ß√£o \\(Z\\) raramente seja utilizada.\n\n\n\n\n\n\n\n\nFigura¬†3: Fun√ß√£o de densidade de t para diferentes graus de liberdade."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#probabilidades-no-teste-t-de-student-a-tabela-t",
    "href": "content/teste-hipoteses/teste-t.html#probabilidades-no-teste-t-de-student-a-tabela-t",
    "title": "Comparando m√©dias: teste t de Student",
    "section": "3 Probabilidades no teste \\(t\\) de Student: a tabela \\(t\\)",
    "text": "3 Probabilidades no teste \\(t\\) de Student: a tabela \\(t\\)\nA rejei√ß√£o uo aceita√ß√£o da hip√≥tese nula em um teste \\(t\\) pode ser feita por meio da obten√ß√£o do valor de p ou pela compara√ß√£o do \\(t\\) calculado com valores cr√≠ticos de refer√™ncia para determinado n√≠vel de signific√¢ncia. O primeiro caso foi o que apresentamos acima e depende de um software estat√≠stico para obtermos valores exatos de \\(p\\). O segundo caso, pode ser feito com aux√≠lio da Tabela \\(t\\), em que limites cr√≠ticos de \\(t\\) s√£o disponibilizados para diferentes n√≠veis de signific√¢ncia e graus de liberdade.\nAtualmente, o uso da tabela \\(t\\) t√™m finalidade em grande parte did√°tica e, por este motivo, vamos apresent√°-lo aqui rapidamente. No entanto, fora da sala de aula, o teste \\(t\\) ser√° invariavelmente conduzido por meio de um software estat√≠stico este m√©todo que permitir√° a obten√ß√£o do valor exato de \\(p\\).\nNa Tabela t, a primeira coluna mostra os graus de liberdade de \\(1\\) a \\(120\\). O cabe√ßalho da tabela de \\(90\\%\\) a \\(0,1\\%\\) mostra a √°rea na distribui√ß√£o de \\(t\\) nas caldas inferior e superior.\nVamos retornar ao exemplo da moedas de \\(R\\$0,10\\) para exemplificar sua utiliza√ß√£o. Neste exemplo a tinhamos \\(8\\) (\\(gl = 7\\) graus de liberdade) e o teste foi feito com \\(\\alpha =0,05\\). Se buscarmos na linha \\(gl = 7\\) e a coluna \\(5\\%\\) (\\(\\alpha = 0,05\\)), encontraremos o valor \\(t = 2,3646\\). Este √© o chamado \\(t\\) cr√≠tico (\\(t_{cr√≠tico}\\)). Acima deste valor e abaixo de sua contraparte negativa temos exatamente \\(5\\%\\) da √°rea na disribui√ß√£o \\(t\\). Deste modo, qualquer valor calulado maior que \\(t_{cr√≠tico}\\) estar√° mais para a extremidade da distribui√ß√£o e consequentemente estar√° associado a menores valores de probabilidade. Neste sentido:\n\n\\(t_{calculado} \\ge t_{cr√≠tico}\\) leva a rejei√ß√£o de \\(H_0\\)\n\n\n\\(t_{calculado} &lt; t_{cr√≠tico}\\) leva a aceita√ß√£o de \\(H_0\\)\n\nO resultado do teste estat√≠stico em nosso exemplo foi \\(t_c = 2.76\\) que √© maior que \\(2,3646\\). Isto nos leva √† mesma decis√£o anterior (rejeitar \\(H_0\\)), ainda que por meio da tabela \\(t\\) n√£o tenhamos o valor exato de probabilidade."
  },
  {
    "objectID": "content/teste-hipoteses/teste-t.html#teste-t-para-compara√ß√£o-de-duas-m√©dias-independentes",
    "href": "content/teste-hipoteses/teste-t.html#teste-t-para-compara√ß√£o-de-duas-m√©dias-independentes",
    "title": "Comparando m√©dias: teste t de Student",
    "section": "4 Teste t para compara√ß√£o de duas m√©dias independentes",
    "text": "4 Teste t para compara√ß√£o de duas m√©dias independentes\nO que vimos no teste \\(t\\) para uma amostra pode ser facilmente extendido para testarmos a diferen√ßas entre duas amostras.\nOs dados abaixo mostram o tempo de coagula√ß√£o sangu√≠nea (em minutos) em ratos machos adultos tratados com dois tipos de drogas, retirado do livro Biostatistical Analysis (Zar 2010), pp.¬†130-134.\n\n\nC√≥digo\nra &lt;- data.frame(Droga = factor(c(rep(\"Droga A\", 6), rep(\"Droga B\",7))),\n                Tempo = c(8.8, 8.4, 7.9, 8.7, 9.1, 9.6, \n                          9.9, 9.0, 11.1, 9.6, 8.7, 10.4, 9.5))\n\n\n\n\n\n\nTabela¬†1: Tempo de coagula√ß√£o sangu√≠nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\n\n\n\n\nDroga\nTempo\n\n\n\n\nDroga A\n8.80\n\n\nDroga A\n8.40\n\n\nDroga A\n7.90\n\n\nDroga A\n8.70\n\n\nDroga A\n9.10\n\n\nDroga A\n9.60\n\n\nDroga B\n9.90\n\n\nDroga B\n9.00\n\n\nDroga B\n11.10\n\n\nDroga B\n9.60\n\n\nDroga B\n8.70\n\n\nDroga B\n10.40\n\n\nDroga B\n9.50\n\n\n\n\n\n\n\n\n\n\nNosso objetivo √© testar se as duas drogas resultam, em m√©dia, no mesmo tempo de coagula√ß√£o. Inicialmente, vamos fazer um gr√°fico de dispers√£o para verificar a distribui√ß√£o do tempo de coagula√ß√£o para cada droga.\n\n\nC√≥digo\nggplot(ra, aes(y = Tempo, x = Droga)) +\n  geom_boxplot() +\n  geom_point(col = 2, size = 3) +\n  labs(y = 'Tempo de coalgula√ß√£o (min)', x = '') +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nFigura¬†4: Distribui√ß√£o do tempo de coagula√ß√£o sangu√≠nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\nAs m√©dias, desvios padr√µes e tamanhos amostrais de cada grupo s√£o:\n\n\nC√≥digo\nra_m = ra |&gt; \n    group_by(Droga) |&gt; \n    summarize('Tempo m√©dio' = round(mean(Tempo),2), \n              Desvio = round(sd(Tempo),2), n = n() )\n\nra_m |&gt; \n  gt()\n\n\n\n\nTabela¬†2: Tempo de coagula√ß√£o sangu√≠nea (em minutos) para dois tipos de drogas.\n\n\n\n\n\n\n\n\n\nDroga\nTempo m√©dio\nDesvio\nn\n\n\n\n\nDroga A\n8.75\n0.58\n6\n\n\nDroga B\n9.74\n0.82\n7\n\n\n\n\n\n\n\n\n\n\nPara testarmos se as m√©dias dos grupos prov√©m de popula√ß√µes estat√≠sticas com diferentes \\(\\mu's\\) devemos estabelecer nosso n√≠vel de signific√¢ncia (por exemplo \\(\\alpha = 0.05\\)) as hipoteses estat√≠sticas:\n\\(H_0: \\mu_A = \\mu_B\\) gramas\n\\(H_a: \\mu_A \\ne \\mu_B\\) gramas\n\n\n\n\n\n\nTeste de homogeneidade de vari√¢ncias\n\n\n\nUm dos pressupostos do teste t que apresentaremos a frente √© de que as popula√ß√µes que ser√£o comparadas t√™m a mesma vari√¢ncia \\(\\sigma^2\\). Devemos portanto testar o pressuposto de homogeneidade de vari√¢ncias que pode ser realizado com o teste de raz√£o de vari√¢ncias.\nNo R fazemos o teste de homogeneidade de vari√¢ncias com o comando abaixo.\n\nvar.test(ra$Tempo ~ ra$Droga)\n\n\n    F test to compare two variances\n\ndata:  ra$Tempo by ra$Droga\nF = 0.50633, num df = 5, denom df = 6, p-value = 0.4722\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.08456359 3.53301988\nsample estimates:\nratio of variances \n           0.50633 \n\n\nNo teste acima, \\(F_{calculado} = 0.51\\) e \\(p = 0.472\\). Assumindo um \\(\\alpha = 0,05\\), conclu√≠mos que n√£o h√° evid√™ncias para rejeitar a hip√≥tese de homogeneidade e que assumimos que as duas popula√ß√µes t√™m a mesma vari√¢ncia. Deste modo podemos continuar com o teste t.\n\n\nO teste t para duas amostras √© calculado por:\n\\[t = \\frac{(\\overline{X_A} - \\mu_A) - (\\overline{X_B} - \\mu_B)}{s_{\\overline{X_A}-\\overline{X_B}}}\\]\nAssumindo a hipotese nula em que \\(\\mu_A = \\mu_B\\) a express√£o fica\n\\[t = \\frac{\\overline{X_A} - \\overline{X_B}}{s_{\\overline{X_A}-\\overline{X_B}}}\\]\nem que a quantia \\(s_{\\overline{X_A}-\\overline{X_B}}\\) √© calculada por:\n\\[s_{\\overline{X_A}-\\overline{X_B}} = \\sqrt{\\frac{s^2_{p}}{n_1} + \\frac{s^2_{p}}{n_2}}\\]\n\\(s_p\\) √© denominada de vari√¢ncia conjunta calculada por\n\\[s^2_p = \\frac{(n_1 - 1) \\times s^2_1 + (n_2 - 1) \\times s^2_2}{(n_1 - 1) + (n_2 - 1)}\\]\nPara este exemplo,\n\\(s_p = 0.52\\)\ne\n\\(s_{\\overline{X_A}-\\overline{X_B}} =  0.4\\)\nO valor de t calculado √©:\n\\(t_c =  -2.476\\)\nNa distribui√ß√£o t, a probabilidade de encontrar valores t√£o ou mais extremos que 2.476 √© de \\(p = 0.031\\).\nPortanto:\n\\(P(|t| \\ge 2.476) \\le 0.05\\)\nUma vez que a probabilidade associada ao valor de \\(t\\) √© menor que o n√≠vel de signific√¢ncia, rejeitamos \\(H_0\\) e assumimos que os tempos m√©dios de coagula√ß√£o s√£o diferentes. Ao avaliar as m√©dia amostrais \\(\\overline{X}_A\\) e \\(\\overline{X}_B\\), conclu√≠mos que a droga \\(A\\) resulta, em m√©dia, em tempos menores de coagula√ß√£o.\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "topics/estatistica-descritiva.html",
    "href": "topics/estatistica-descritiva.html",
    "title": "Estat√≠stica Descritiva",
    "section": "",
    "text": "Descrevendo vari√°veis qualitativas\n\n\n\n\n\n\nR\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nVari√°veis qualitativas\n\n\nVisualiza√ß√£o de dados\n\n\n\nDescri√ß√£o de vari√°veis qualitativas, incluindo tabelas de frequ√™ncia, gr√°ficos de barras e considera√ß√µes sobre vari√°veis ordinais.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescrevendo vari√°veis quantitativas\n\n\n\n\n\n\nR\n\n\nCi√™ncia de dados\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nVari√°veis quantitativas\n\n\nDistribui√ß√£o de frequ√™ncia\n\n\n\nExplora√ß√£o de vari√°veis quantitativas por meio de tabelas de frequ√™ncia, histogramas e gr√°ficos de frequ√™ncia acumulada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de tend√™ncia central\n\n\n\n\n\n\nR\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nTend√™ncia central\n\n\nDistribui√ß√£o de dados\n\n\n\nDiscuss√£o das principais medidas de tend√™ncia central (m√©dia, mediana, moda) e sua interpreta√ß√£o em diferentes distribui√ß√µes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de varia√ß√£o\n\n\n\n\n\n\nR\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nVariabilidade de dados\n\n\nAn√°lise de dispers√£o\n\n\n\nApresenta√ß√£o das medidas de varia√ß√£o, como vari√¢ncia, desvio padr√£o, coeficiente de varia√ß√£o e amplitude, com exemplos pr√°ticos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de posi√ß√£o: quartis\n\n\n\n\n\n\nR\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nVariabilidade de dados\n\n\nAn√°lise de dispers√£o\n\n\n\nC√°lculo e interpreta√ß√£o de quartis para an√°lise de distribui√ß√£o, ressaltando faixas de varia√ß√£o e valores at√≠picos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de posi√ß√£o: transforma√ß√£o Z\n\n\n\n\n\n\nR\n\n\nAn√°lise de dados\n\n\nEstat√≠stica descritiva\n\n\nPadroniza√ß√£o de dados\n\n\n√çndice Z\n\n\n\nTransforma√ß√£o Z para padronizar distribui√ß√µes, facilitando compara√ß√µes entre diferentes escalas de medida.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/teste-hipoteses.html",
    "href": "topics/teste-hipoteses.html",
    "title": "Teste de Hip√≥teses",
    "section": "",
    "text": "Introdu√ß√£o ao teste de hip√≥teses\n\n\n\n\n\nApresenta√ß√£o do teste de hip√≥teses, defini√ß√µes de hip√≥teses nula e alternativa, erros do tipo I/II e valor de p.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparando vari√¢ncias\n\n\n\n\n\nM√©todos de compara√ß√£o de vari√¢ncias, incluindo o teste F e o teste de Levene.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparando m√©dias: teste t de Student\n\n\n\n\n\nTeste t de Student para compara√ß√£o de m√©dias, abrangendo uma amostra, grupos independentes e medidas pareadas.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/visualizacao-dados.html",
    "href": "topics/visualizacao-dados.html",
    "title": "Visualiza√ß√£o de Dados",
    "section": "",
    "text": "(B√°sico da) Visualiza√ß√£o gr√°fica\n\n\n\n\n\n\nR\n\n\nPrograma√ß√£o\n\n\nGr√°ficos em R\n\n\nVisualiza√ß√£o de dados\n\n\n\nIntrodu√ß√£o √† cria√ß√£o de gr√°ficos em R: gr√°ficos de barras, histogramas, boxplots, dispers√£o e exporta√ß√£o de figuras.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGr√°ficos em camadas\n\n\n\n\n\n\nCi√™ncia de dados\n\n\nR\n\n\nTidyverse\n\n\nVisualiza√ß√£o gr√°fica\n\n\n\nCria√ß√£o de gr√°ficos em camadas com ggplot2, incluindo histogramas, boxplots e gr√°ficos de dispers√£o.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/amostragem.html",
    "href": "topics/amostragem.html",
    "title": "Amostragem",
    "section": "",
    "text": "Descrevendo popula√ß√µes e amostras\n\n\n\n\n\nDescreve popula√ß√µes e amostras, abordando a distin√ß√£o entre par√¢metros populacionais e estimadores amostrais.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmostrando uma popula√ß√£o estat√≠stica\n\n\n\n\n\nM√©todos de amostragem aleat√≥ria simples, estratificada e sistem√°tica, destacando o erro amostral e a acur√°cia das estimativas.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/estrutura-dados.html",
    "href": "topics/estrutura-dados.html",
    "title": "Estrutura de Dados",
    "section": "",
    "text": "Estrutura e tipos de dados\n\n\n\n\n\n\nR\n\n\nEstrutura de dados\n\n\nTipos de dados\n\n\nAn√°lise de dados\n\n\n\nDescri√ß√£o de diferentes estruturas de dados e tipos de vari√°veis, com foco em n√≠veis de mensura√ß√£o e tratamento de valores ausentes em tabelas.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/manipulacao-dados-python.html",
    "href": "topics/manipulacao-dados-python.html",
    "title": "Introdu√ß√£o e Manipula√ß√£o de Dados em Python",
    "section": "",
    "text": "Introdu√ß√£o ao Python: Estrutura da Linguagem\n\n\n\n\n\nEstrutura da linguagem Python, incluindo opera√ß√µes b√°sicas, tipos de objetos (listas, arrays, strings, dicion√°rios) e sintaxe principal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstrutura e Tipos de Dados em Python\n\n\n\n\n\nManipula√ß√£o de DataFrames em Python usando Pandas, incluindo sele√ß√£o de linhas e colunas, filtragem de dados e tratamento de valores ausentes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstat√≠stica Descritiva e Visualiza√ß√£o com Python\n\n\n\n\n\nAn√°lise descritiva de dados usando Python com Pandas e Matplotlib, incluindo medidas de tend√™ncia central, dispers√£o e visualiza√ß√µes b√°sicas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python\n\n\n\n\n\nAn√°lise de associa√ß√µes entre vari√°veis usando Python com Pandas, Matplotlib e Seaborn, incluindo tabelas de conting√™ncia, correla√ß√£o e visualiza√ß√µes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportando data frames a partir de arquivos CSV\n\n\nMontar o Google Drive no Colab e importar dados de arquivos CSV usando pandas\n\n\n\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/intro-bayes.html",
    "href": "topics/intro-bayes.html",
    "title": "Introdu√ß√£o √† Infer√™ncia Bayesiana",
    "section": "",
    "text": "Contando possibilidades\n\n\nEvid√™ncias sobre uma hip√≥tese\n\n\nIntrodu√ß√£o √† contagem de possibilidades na abordagem bayesiana. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe contagens a probabilidades\n\n\nA distribui√ß√£o a posteriori\n\n\nTransi√ß√£o de contagens para probabilidades sob uma perspectiva bayesiana. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstruindo um modelo bayesiano\n\n\nVerossimilhan√ßa e distribui√ß√£o a priori\n\n\nConstru√ß√£o de um modelo bayesiano, enfatizando a formula√ß√£o de distribui√ß√µes a priori e posterior. Baseado em Statistical Rethinking (McElreath 2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfer√™ncia Bayesiana Binomial\n\n\nEstimando \\(p\\) via aproxima√ß√£o por Grid\n\n\nIntrodu√ß√£o ao conceito de aproxima√ß√£o por grid na abordagem bayesiana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfer√™ncia Bayesiana Binomial com PyMC\n\n\nEstimando \\(p\\) usando modelagem probabil√≠stica\n\n\nIntrodu√ß√£o √† modelagem probabil√≠stica na abordagem bayesiana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo Normal Bayesiano\n\n\nModelando Dados Cont√≠nuos no PyMC - distribui√ß√µes a priori\n\n\nIntrodu√ß√£o √† modelagem Bayesiana de dados cont√≠nuos, incluindo escolha das priores e checagens preditivas.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente\n\nRefer√™ncias\n\nMcElreath, Richard. 2018. Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman; Hall/CRC."
  },
  {
    "objectID": "topics/glms.html",
    "href": "topics/glms.html",
    "title": "Modelos Lineares Generalizados",
    "section": "",
    "text": "Modelos Lineares Generalizados (GLMs)\n\n\n\n\n\n\nModelagem\n\n\nGLM\n\n\nRegress√£o\n\n\n\nIntrodu√ß√£o aos GLMs, incluindo Regress√£o Log√≠stica e Poisson.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/manipulacao-dados-R.html",
    "href": "topics/manipulacao-dados-R.html",
    "title": "Manipula√ß√£o de Dados em R",
    "section": "",
    "text": "Os pacotes em tidyverse\n\n\n\n\n\n\nCi√™ncia de dados\n\n\nR\n\n\nTidyverse\n\n\n\nPacotes do tidyverse para importa√ß√£o, organiza√ß√£o, transforma√ß√£o e visualiza√ß√£o de dados em R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportando/Exportando dados\n\n\n\n\n\n\nCi√™ncia de dados\n\n\nR\n\n\nTidyverse\n\n\nImporta√ß√£o e exporta√ß√£o de dados\n\n\n\nT√©cnicas de importa√ß√£o e exporta√ß√£o de dados com o pacote readr do Tidyverse, para diversos formatos de arquivo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperadores pipe\n\n\n\n\n\n\nCi√™ncia de dados\n\n\nR\n\n\nTidyverse\n\n\nTransforma√ß√£o de dados\n\n\n\nUso de operadores pipe para encadear fun√ß√µes e simplificar fluxos de dados em R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforma√ß√£o de Dados\n\n\n\n\n\n\nCi√™ncia de dados\n\n\nR\n\n\nTidyverse\n\n\nTransforma√ß√£o de dados\n\n\n\nManipula√ß√£o e transforma√ß√£o de dados com as fun√ß√µes principais do Tidyverse, incluindo dplyr e tidyr.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/inferencia-estatistica.html",
    "href": "topics/inferencia-estatistica.html",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "",
    "text": "Distribui√ß√£o das m√©dias amostrais\n\n\n\n\n\nExposi√ß√£o do teorema central do limite, enfatizando a distribui√ß√£o das m√©dias amostrais e sua import√¢ncia em infer√™ncia estat√≠stica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimando a m√©dia populacional\n\n\n\n\n\nConstru√ß√£o e interpreta√ß√£o de intervalos de confian√ßa para estimar a m√©dia populacional, incluindo a distribui√ß√£o t de Student.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/distribuicao-normal.html",
    "href": "topics/distribuicao-normal.html",
    "title": "A Distribui√ß√£o Normal",
    "section": "",
    "text": "O modelo de distribui√ß√£o normal\n\n\n\n\n\nIntrodu√ß√£o √† distribui√ß√£o normal, suas caracter√≠sticas e aplica√ß√µes no contexto da infer√™ncia estat√≠stica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO modelo da distribui√ß√£o normal\n\n\nUm modelo para a distribui√ß√£o de alturas\n\n\nApresenta o modelo matem√°tico da distribui√ß√£o normal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nO modelo da distribui√ß√£o normal\n\n\nFun√ß√£o de densidade e fun√ß√£o de probabilidade acumulada\n\n\nExplora a distribui√ß√£o normal para extrair probabilidades\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/anova.html",
    "href": "topics/anova.html",
    "title": "An√°lise de vari√¢ncia",
    "section": "",
    "text": "An√°lise de vari√¢ncia de um fator\n\n\n\n\n\nAvalia√ß√£o de uma √∫nica fonte de varia√ß√£o, parti√ß√£o da soma de quadrados e aplica√ß√£o do teste F.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/funcoes-modelos.html",
    "href": "topics/funcoes-modelos.html",
    "title": "Fun√ß√µes e modelos",
    "section": "",
    "text": "Explorando Fun√ß√µes Pot√™ncias com Python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/fundamentos-probabilidade.html",
    "href": "topics/fundamentos-probabilidade.html",
    "title": "Fundamentos de Probabilidades",
    "section": "",
    "text": "Espa√ßo de possibilidades de um experimento\n\n\n\n\n\n\nProbabilidade\n\n\nEspa√ßo amostral\n\n\nEventos\n\n\nExperimento aleat√≥rio\n\n\n\nEspa√ßo de possibilidades de um experimento aleat√≥rio, abordando a defini√ß√£o de evento e probabilidade.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombinando as probabilidades de eventos\n\n\n\n\n\n\nProbabilidade\n\n\nEventos complexos\n\n\nDiagrama de Venn\n\n\nDiagrama de √°rvore\n\n\n\nCombina√ß√£o de probabilidades de eventos, utilizando diagramas de Venn e √°rvores para representar uni√µes e interse√ß√µes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilidade condicional e independ√™ncia\n\n\n\n\n\n\nProbabilidade condicional\n\n\nEventos dependentes\n\n\nTeorema de Bayes\n\n\nDiagrama de √°rvore\n\n\n\nExplora√ß√£o da probabilidade condicional e independ√™ncia, com aplica√ß√µes do Teorema de Bayes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeorema de Bayes\n\n\n\n\n\n\nTeorema de Bayes\n\n\nProbabilidade condicional\n\n\nEventos dependentes\n\n\n\nApresenta√ß√£o do Teorema de Bayes e sua aplica√ß√£o no c√°lculo de probabilidades condicionais.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/multivariada-numerica.html",
    "href": "topics/multivariada-numerica.html",
    "title": "T√≥picos Avan√ßados em Ci√™ncia de Dados e An√°lise Multivariada",
    "section": "",
    "text": "Introdu√ß√£o √† √Ålgebra de Matrizes\n\n\n\n\n\nOpera√ß√µes b√°sicas e √°lgebra matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEcologia Funcional: aplica√ß√£o da √°lgebra matricial\n\n\n\n\n\n\nProduto escalar\n\n\n√Çngulo entre vetores\n\n\nMultiplica√ß√£o matricial\n\n\nMatriz transposta\n\n\nMatriz sim√©trica\n\n\n\nC√°lculo da similaridade funcional entre esp√©cies de peixes usando √°lgebra matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgrupamento (Clustering)\n\n\n\n\n\n\nDendrograma\n\n\nK-means\n\n\n√Årvore de Regress√£o Multivariada\n\n\n\nIntrodu√ß√£o aos m√©todos de agrupamento hier√°rquico e n√£o hier√°rquico.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©todos de ordena√ß√£o\n\n\n\n\n\n\nOrdenal√ß√£o\n\n\n\nIntrodu√ß√£o aos m√©todos de ordena√ß√£o: PCA, PCoA, CA, NMDS.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/introducao-r.html",
    "href": "topics/introducao-r.html",
    "title": "Introdu√ß√£o ao R",
    "section": "",
    "text": "Estrutura da linguagem\n\n\n\n\n\n\nR\n\n\nPrograma√ß√£o\n\n\n\nEstrutura da linguagem R, incluindo opera√ß√µes b√°sicas, tipos de objetos (vetores, data frames, matrizes, listas) e sintaxe principal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(B√°sico da) Manipula√ß√£o de data frames\n\n\n\n\n\n\nR\n\n\nPrograma√ß√£o\n\n\nManipula√ß√£o de dados\n\n\nData frames\n\n\n\nPrinc√≠pios de manipula√ß√£o de data frames no R: importa√ß√£o, sele√ß√£o de linhas e colunas e cria√ß√£o de vari√°veis.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/modelos-regressao-bayes.html",
    "href": "topics/modelos-regressao-bayes.html",
    "title": "Modelos de Regress√£o Bayesianos",
    "section": "",
    "text": "Regress√£o Linear Bayesiana\n\n\nEscolha das priores, checagem preditivas e infer√™ncia a posteriori.\n\n\nRegress√£o linear bayesiana ‚Äî altura em adultos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFluxo de Trabalho na Modelagem Bayesiana\n\n\nDo modelo linear √† distribui√ß√£o a posteriori\n\n\n\nInfer√™ncia bayesiana\n\n\nModelagem estat√≠stica\n\n\nBambi\n\n\nPyMC\n\n\nFluxo de trabalho\n\n\nDistribui√ß√µes a priori\n\n\nInfer√™ncia a posteriori\n\n\n\nExplorando o fluxo de trabalho bayesiano em modelos de regress√£o linear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplorando Modelos de Regress√£o Bayesiana\n\n\nDos modelos lineares a respostas generalizadas e estruturas hier√°rquicas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelos Estat√≠sticos e Modelos Cient√≠ficos\n\n\nComplexidade Tecnol√≥gica em Ilhas da Oceania\n\n\nTr√™s estrat√©gias para modelar a rela√ß√£o entre tamanho populacional e n√∫mero de ferramentas\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/regressao-linear.html",
    "href": "topics/regressao-linear.html",
    "title": "Modelos de Regress√£o",
    "section": "",
    "text": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples\n\n\nRepresenta√ß√£o Vetorial e Matricial\n\n\nM√©todo dos m√≠nimos quadrados na Regress√£o linear simples por meio da representa√ß√£o vetorial e matricial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples\n\n\nImplementa√ß√£o em Python usando √Ålgebra Matricial\n\n\nTutorial pr√°tico para implementar o m√©todo dos m√≠nimos quadrados em Python, aplicando os conceitos de √°lgebra linear e estat√≠stica b√°sica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©todo dos M√≠nimos Quadrados na Regress√£o Polinomial\n\n\nImplementa√ß√£o em Python usando √Ålgebra Matricial\n\n\nTutorial pr√°tico para implementar o m√©todo dos m√≠nimos quadrados em Python para modelos polinomiais, aplicando os conceitos de √°lgebra linear e estat√≠stica b√°sica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegress√£o linear simples\n\n\n\n\n\nIntrodu√ß√£o √† regress√£o linear simples, incluindo ANOVA da regress√£o, coeficiente de determina√ß√£o e diagn√≥sticos b√°sicos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegress√£o linear m√∫ltipla\n\n\n\n\n\nRegress√£o linear m√∫ltipla, discutindo sele√ß√£o de vari√°veis, pressupostos e diagn√≥sticos de adequa√ß√£o do modelo.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "topics/medidas-associacao.html",
    "href": "topics/medidas-associacao.html",
    "title": "Medidas de Associa√ß√£o",
    "section": "",
    "text": "Associa√ß√£o entre duas vari√°veis qualitativas\n\n\n\n\n\n\nEstat√≠stica\n\n\nAn√°lise qualitativa\n\n\nTabelas de conting√™ncia\n\n\nMedidas de associa√ß√£o\n\n\n\nAn√°lise da associa√ß√£o entre vari√°veis qualitativas, uso de tabelas de conting√™ncia e estat√≠sticas de associa√ß√£o.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssocia√ß√£o entre duas vari√°veis quantitativas\n\n\n\n\n\n\nEstat√≠stica\n\n\nAn√°lise quantitativa\n\n\nCovari√¢ncia\n\n\nCorrela√ß√£o\n\n\nMedidas de associa√ß√£o\n\n\n\nAn√°lise da associa√ß√£o entre vari√°veis quantitativas, com destaque para covari√¢ncia e correla√ß√£o de Pearson.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssocia√ß√£o entre vari√°veis quantitativas e qualitativas\n\n\n\n\n\n\nEstat√≠stica\n\n\nANOVA\n\n\nAn√°lise quantitativa\n\n\nAn√°lise qualitativa\n\n\nMedidas de associa√ß√£o\n\n\n\nAn√°lise da rela√ß√£o entre vari√°veis quantitativas e categ√≥ricas, considerando parti√ß√£o da soma de quadrados e coeficientes de determina√ß√£o.\n\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "",
    "text": "Nenhum item correspondente"
  },
  {
    "objectID": "index.html#fundamentos-computacionais",
    "href": "index.html#fundamentos-computacionais",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "",
    "text": "Nenhum item correspondente"
  },
  {
    "objectID": "index.html#estat√≠stica-descritiva-e-an√°lise-explorat√≥ria",
    "href": "index.html#estat√≠stica-descritiva-e-an√°lise-explorat√≥ria",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "Estat√≠stica Descritiva e An√°lise Explorat√≥ria",
    "text": "Estat√≠stica Descritiva e An√°lise Explorat√≥ria\n\n\n\n\n\n\n\n\n\n\nEstrutura de Dados\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstat√≠stica Descritiva\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedidas de Associa√ß√£o\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#fundamentos-te√≥ricos",
    "href": "index.html#fundamentos-te√≥ricos",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "Fundamentos Te√≥ricos",
    "text": "Fundamentos Te√≥ricos\n\n\n\n\n\n\n\n\n\n\nFundamentos de Probabilidades\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Distribui√ß√£o Normal\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmostragem\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfer√™ncia Estat√≠stica\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeste de Hip√≥teses\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#modelos-lineares",
    "href": "index.html#modelos-lineares",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "Modelos Lineares",
    "text": "Modelos Lineares\n\n\n\n\n\n\n\n\n\n\nAn√°lise de vari√¢ncia\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de Regress√£o\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelos Lineares Generalizados\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#infer√™ncia-bayesiana",
    "href": "index.html#infer√™ncia-bayesiana",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "Infer√™ncia Bayesiana",
    "text": "Infer√™ncia Bayesiana\n\n\n\n\n\n\n\n\n\n\nIntrodu√ß√£o √† Infer√™ncia Bayesiana\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelos de Regress√£o Bayesianos\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#an√°lise-multivariada-e-ecologia-num√©rica",
    "href": "index.html#an√°lise-multivariada-e-ecologia-num√©rica",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "An√°lise Multivariada e Ecologia Num√©rica",
    "text": "An√°lise Multivariada e Ecologia Num√©rica\n\n\n\n\n\n\n\n\n\n\nT√≥picos Avan√ßados em Ci√™ncia de Dados e An√°lise Multivariada\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "index.html#fun√ß√µes-e-modelos",
    "href": "index.html#fun√ß√µes-e-modelos",
    "title": "Modelagem Estat√≠stica e An√°lise de Dados",
    "section": "Fun√ß√µes e Modelos",
    "text": "Fun√ß√µes e Modelos\n\n\n\n\n\n\n\n\n\n\nFun√ß√µes e modelos\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html",
    "href": "content/teste-hipoteses/intro-testehipot.html",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nUm dos objetivos centrais em estat√≠stica √© fazer infer√™ncias v√°lidas para a popula√ß√£o examinando as caracter√≠sticas de uma amostra. Considere as afirma√ß√µes abaixo:\nTodas estas afirma√ß√µes s√£o na realidade hip√≥teses, sobre um ou mais par√¢metros de uma popula√ß√£o estat√≠stica que podem ser testadas por meio de experimentos adequados. A experimenta√ß√£o nos permite tirar conclus√µes sobre determitada hip√≥tese com base na amostra. Mais especificamente, queremos saber se os dados em m√£os nos permitem ou n√£o refutar uma hip√≥tese inicial. Portanto, se desejamos fazer uma infer√™ncia sobre um par√¢metro da popula√ß√£o estat√≠stica (ex.: sua m√©dia \\(\\mu\\)), devemos iniciar com uma afirma√ß√£o sobre a posi√ß√£o deste par√¢metro, que denominamos de hip√≥tese nula (\\(H_0\\))."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#probabilidade-e-teste-de-hip√≥teses",
    "href": "content/teste-hipoteses/intro-testehipot.html#probabilidade-e-teste-de-hip√≥teses",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "1 Probabilidade e teste de hip√≥teses",
    "text": "1 Probabilidade e teste de hip√≥teses\nA m√©dia \\(\\overline{X}\\) de uma amostra ser√° nossa melhor evid√™ncia a respeito de \\(\\mu\\). Tendo este valor, podemos nos perguntar:\n\nO valor obtido de \\(\\overline{X}\\) √© condizente com o esperado segundo \\(H_0\\)?\n\nCaso \\(\\overline{X}\\) esteja muito pr√≥ximo a \\(\\mu\\), n√£o h√° evid√™ncias para rejeitar \\(H_0\\). Por outro lado, um valor de \\(\\overline{X}\\) muito distante de \\(\\mu\\) ir√° colocar em d√∫vida a afirma√ß√£o estabelecida em \\(H_0\\). O ponto relevante aqui √© decidirmos qu√£o distante de \\(\\mu\\) deve estar \\(\\overline{X}\\) para que rejeitemos \\(H_0\\)? Esta resposta poder√° ser respondida somente com o aux√≠lio de um modelo probabil√≠stico aplicado ao experimento em quest√£o.\nSeja \\(H_0\\) verdadeira, √© esperado que a probabilidade de \\(\\overline{X}\\) estar pr√≥ximo a \\(\\mu\\) √© alta. Portanto, uma pergunta melhor formulada seria:\n\nSendo \\(H_0\\) verdadeira, qual √© a probabilidade de que uma determinada m√©dia amostral \\(\\overline{X}\\) esteja t√£o ou mais distante de \\(\\mu\\) quanto o observado em nossa amostra particular?\n\n\n1.1 Um modelo de distribui√ß√£o das m√©dias amostrais para testar \\(H_0\\)\nA pergunta feita acima √© de natureza probabil√≠stica, de modo que para respond√™-la iremos precisar estabelecer um modelo probabil√≠stico para a distribui√ß√£o das m√©dias amostrais. De acordo com o que temos discutido at√© este ponto, Teorema Central do Limite (TCL) estabelece que a distribui√ß√£o normal √© um bom modelo neste situa√ß√£o.\nDesta forma, para um \\(H_0\\) verdadeiro, seria esperado que a distribui√ß√£o das m√©dias amostrais resultantes de um procedimento experimental tivesse o formato de um distribui√ß√£o normal, centrada em \\(110\\) mm. Segundo o TCL, a distribui√ß√£o seria centrada em \\(\\mu\\) e o desvio padr√£o seria definido pelo erro padr√£o da m√©dia, isto √©, \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\nDigamos ainda que o modelo clim√°tico estabele√ßa que desvio padr√£o para a quantidade de chuva seja \\(\\sigma = 30\\). Neste caso, o erro padr√£o seria de \\(\\sigma_{\\mu} = \\frac{30}{\\sqrt{n}}\\).\nFeito isto, temos em m√£os o modelo probabil√≠stico que, aliado a uma amostra particular, nos permitir√° concluir se h√° evid√™ncias para rejeitar \\(H_0\\) em favor de \\(H_a\\).\n\n\n1.2 Definindo o limite de rejei√ß√£o para \\(H_0\\): nivel de signific√¢ncia \\(\\alpha\\)\nSegundo a distribui√ß√£o normal, a probabilidade do valor observado \\(\\overline{X}\\) estar t√£o ou mais distante de \\(\\mu\\) na distribui√ß√£o \\(Z\\) √© calculando por:\n\\[z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\overline{X}}}\\]\nO valor de \\(z\\) calculado √© chamado de estatitica do teste. Com o uso da Tabela \\(Z\\), esta estat√≠stica ser√° utilizada para encontrar:\n\\[P(Z \\ge z) = P(\\overline{X} \\ge \\mu)\\] A probabilidade \\(P(Z \\ge z)\\) √© encontrada na distribui√ß√£o normal padronizada em que \\(Z \\sim \\mathcal{N}(0,\\,\\frac{\\sigma}{\\sqrt{n}})\\) e como nossa pergunta se refere √† dist√¢ncia entre \\(\\overline{X}\\) e \\(\\mu\\), devemos encontar tamb√©m \\(P(Z \\le -z)\\), de modo que a probabilidade que nos interessa √© denominada de valor de p de um teste de hip√≥teses:\n\\[p = P(Z \\ge |z|)\\]\nO valor de \\(p\\) √© a √°rea destacada em vermelho da distribui√ß√£o normal padronizada:\n\n\n\n\n\n\n\n\nFigura¬†1: Representa√ß√£o da √°rea de rejei√ß√£o na distribui√ß√£o Z.\n\n\n\n\n\nA √°rea destacada em vermelho diminui conforme \\(\\overline{X}\\) se distancia de \\(\\mu\\) e aumenta se \\(\\overline{X}\\) est√° pr√≥ximo a \\(\\mu\\).\n\n\n\n\n\n\nO valor de p e n√≠vel de signific√¢ncia\n\n\n\nMede a probabilidade de encontrarmos \\(\\overline{X}\\) t√£o ou mais distante de \\(\\mu\\), assumindo que \\(H_0\\) seja verdadeira. Se \\(p\\) for muito pequeno, a probabilidade de que \\(\\overline{X}\\) seja condizente com \\(H_0\\) diminui. Neste caso dizemos que √© improv√°vel que \\(\\overline{X}\\) seja proviniente de \\(H_0\\), o que nos leva levando a rejeitar a hip√≥tese nula em favor de \\(H_a\\).\nA decis√£o de rejeitar \\(H_0\\) depende do limite de rejei√ß√£o \\(\\alpha\\), tamb√©m chamado de nivel cr√≠tico ou n√≠vel de signific√¢ncia. A definir o valor de \\(\\alpha\\), a conclus√£o de um teste estat√≠stico se d√° por (Figura¬†2):\n\nSe \\(p &gt; \\alpha\\) ‚Äì&gt; ACEITAMOS \\(H_0\\), \\(\\overline{X}\\) est√° pr√≥ximo de \\(\\mu\\)\nSe \\(p \\le \\alpha\\) ‚Äì&gt; REJEITAMOS \\(H_0\\), \\(\\overline{X}\\) est√° distante de \\(\\mu\\). A assumimos \\(H_a\\) como verdadeira.\n\n\n\n\n\n\n\n\n\nFigura¬†2: Efeito do n√≠vel de significancia sobre a √°rea de rejei√ß√£o em um teste de hip√≥tese."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#exemplificando-um-teste-de-hip√≥teses-o-teste-z",
    "href": "content/teste-hipoteses/intro-testehipot.html#exemplificando-um-teste-de-hip√≥teses-o-teste-z",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "2 Exemplificando um teste de hip√≥teses: o teste \\(Z\\)",
    "text": "2 Exemplificando um teste de hip√≥teses: o teste \\(Z\\)\n\n\n\n\n\n\nDescri√ß√£o do problema\n\n\n\nDigamos que o n√∫mero de batimentos card√≠acos por minuto de um adulto em repouso tenha m√©dia \\(\\mu = 65\\) e desvio padr√£o \\(\\sigma = 9\\). Voc√™ imagina que o sedentarismo altera o batimento m√©dio de um adulto.\n\n\n\nHip√≥teses estat√≠ticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\ne 65\\) batimentos por minuto\n\nLimite de rejei√ß√£o: determinamos o n√≠vel de signific√¢ncia (\\(\\alpha\\)) do teste como \\(\\alpha = 0,05\\).\n\n\nIMPORTANTE: O n√≠vel de signific√¢ncia \\(\\alpha\\) deve ser determinado antes da tomada de dados.\n\n\nExperimento: selecionamos uma amostra aleat√≥ria selecionando ao acaso \\(n = 15\\) pessoas de h√°bito sedent√°rio e medimos seus batimentos card√≠acos. Os resultados s√£o:\n\nAmostra: 65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66\nque nos d√° uma m√©dia amostral de:\n\\(\\overline{X} = \\frac{\\sum{X_i}}{n} = \\frac{65+73+56+71+69+69+68+59+73+68+69+64+67+64+66}{15} = 66.73\\) batimentos por minuto;\ne um erro padr√£o de:\n\\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{9}{3.87} = 2.32\\)\n\nTeste de hip√≥teses: com estes resultados encontramos o valor correspondente de Z.\n\n\\(z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\mu}} = \\frac{66.73 - 65}{2.32} = 0.75\\)\ne utilizando a Tabela Z , encontramos a probabilidade de obtermos valores t√£o ou mais extremos que \\(-0.75\\) e \\(+0.75\\).\n\n\n\n\n\n\n\n\nFigura¬†3: √Årea de rejei√ß√£o para z = 0,75.\n\n\n\n\n\nCom isto, a probabilidade de encontarmos valores t√£o ou mais extermos que \\(\\overline{X} = 66.73\\) foi calculada em \\(0.227 + 0.227 =\\) 0.453.\nNeste exemplo, a estat√≠stica do teste foi \\(z = 0.75\\) o a probabilidade associada \\(p = 0.453\\).\n\n\n\n\n\n\nTeste Z no R\n\n\n\n\nX &lt;- c(65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66)\nXm &lt;- mean(X)\npnorm(q = Xm, mean = 65, sd = 9/sqrt(15), lower.tail = FALSE) * 2\n\n[1] 0.4557231"
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#tomada-de-decis√£o-sobre-h_0-n√≠vel-de-signific√¢ncia",
    "href": "content/teste-hipoteses/intro-testehipot.html#tomada-de-decis√£o-sobre-h_0-n√≠vel-de-signific√¢ncia",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "3 Tomada de decis√£o sobre \\(H_0\\): n√≠vel de signific√¢ncia",
    "text": "3 Tomada de decis√£o sobre \\(H_0\\): n√≠vel de signific√¢ncia\nNo exemplo anterior, obtivemos \\(p =\\) 0.453. Isto significa que:\n\nsendo \\(H_0\\) verdadeira, existe uma probabilidade igual a \\(0.453\\) de que a m√©dia de uma amostra com \\(n = 15\\) esteja t√£o ou mais distante de \\(\\mu = 65\\) como observado neste experimento.\n\nSe aceitarmos que esta probabilidade √© alta, ent√£o n√£o h√° motivo para buscar por outras explica√ß√µes. Por outro lado, se concluirmos que esta probabilidade √© baixa, estamos dizendo que resultado obtido √© improv√°vel segundo a hip√≥tese nula. Neste caso, devemos recorrer √† hip√≥tese alternativa para explicar o fen√¥meno.\nPara decidir se a probabilidade obtida √© alta ou baixa, devemos compar√°-la ao n√≠vel de signific√¢ncia \\(\\alpha\\) pr√©-estabelecido. \\(H_0\\) ser√° aceita somente se a probabilidade encontrada for maior que \\(\\alpha\\). Por outro lado, se nossa probabilidade for menor ou igual a \\(\\alpha\\), considerarmos os resultados improv√°veis segundo a hip√≥tese nula e rejeitamos \\(H_0\\) em favor de \\(H_a\\).\nUm n√≠vel cr√≠tico comumente utilizado √© \\(\\alpha = 0.05\\). No exemplo acima a probabilidade foi de 0.453, um valor muito acima de \\(0.05\\). Dizemos portanto, que a m√©dia amostral \\(\\overline{X}\\) n√£o est√° t√£o distante do \\(\\mu\\) a ponto de rejeitarmos \\(H_0\\).\n\nConcluimos que, neste exemplo, \\(\\overline{X} = 66.73\\) n√£o nos fornece evid√™ncia suficiente para rejeitar \\(H_0\\)."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#erros-de-decis√£o-em-um-teste-de-hip√≥teses",
    "href": "content/teste-hipoteses/intro-testehipot.html#erros-de-decis√£o-em-um-teste-de-hip√≥teses",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "4 Erros de decis√£o em um teste de hip√≥teses",
    "text": "4 Erros de decis√£o em um teste de hip√≥teses\nA interpreta√ß√£o da probabilidade final esta associada √† situa√ß√£o em que \\(H_0\\) seja verdadeira.\nIsto nos leva perguntar: o que esperar caso \\(H_0\\) seja falsa?\nComo n√£o sabemos de fato, de \\(H_0\\) √© verdadeira ou n√£o, a tomada de decis√£o sobre um resultado de um teste estat√≠stico pode nos levar √†s seguintes situa√ß√µes:\n\n\n\nTabela¬†1: Erros de decis√£o em um teste de hip√≥testes\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\) Verdadeira\n\\(H_0\\) Falsa\n\n\n\n\n\\(H_0\\) √© rejeitada\n\\(\\alpha\\) (\\(\\textbf{Erro Tipo I}\\))\nDecis√£o correta (\\(1-\\beta\\))\n\n\n\\(H_0\\) √© aceita\nDecis√£o correta (\\(1-\\alpha\\))\n\\(\\beta\\) (\\(\\textbf{Erro Tipo II}\\))\n\n\n\n\n\n\nA Tabela¬†1 nos mostra os tipos de erros aos quais estamos sujeitos ao realizar um teste de hip√≥tese. Podemos rejeitar \\(H_0\\), ainda que ela seja verdadeira. O nivel de signific√¢ncia adotado, estabele que a probabilidade disto acontecer √© \\(\\alpha\\). Se rejeitarmos \\(H_0\\) quando ela √© verdadeira, estaremos incorrendo em um erro de decis√£o que denominamos de Erro Tipo I. Consequentemente, temos uma probabilidade de \\(1 - \\alpha\\) de aceitar corretamente \\(H_0\\) quando ela √© verdadeira. Estabelecer um \\(\\alpha = 0,05\\) nos garante que iremos incorrer no erro do tipo I em somente \\(5\\%\\) das vezes que o experimento for realizado.\nUm outra situa√ß√£o ocorre quando aceitamos erroneamente a hip√≥tese nula que √© falsa, incorrendo no Erro Tipo II. O erro do tipo II tem probabilidade \\(\\beta\\) de acontecer. O complementar desta probabilidade (\\(1-\\beta\\)) √© denominado de Poder do Teste. Um teste poderoso √© portanto, aquele que tem elevada probabilidade de rejeitar \\(H_0\\) quando ela √© falsa.\nAs figuras abaixo representam as distribui√ß√µes das m√©dias amostrais e os erros do tipos I e II quando o \\(H_0\\) √© verdadeira (\\(\\mu_a = \\mu\\)) e quando \\(H_0\\) √© falsa (\\(\\mu_a &gt; \\mu\\)).\n\n\n\n\n\n\n\n\nFigura¬†4: Rela√ß√£o entre o erro tipo I (\\(\\alpha\\)) e o erro tipos II (\\(\\beta\\)), ao aceitar ou rejeitar \\(H_0\\).\n\n\n\n\n\nIdealmente em um teste estat√≠stico, seria interessante reduzir ao m√°ximo os erros do tipo I e II. Ao reduzirmos o erro do tipo I, diminuindo \\(\\alpha\\) teremos um teste mais rigoroso que raramente iria errar ao rejeitar um \\(H_0\\) verdadeiro (Figura A). Entretanto, este teste tamb√©m raramente iria rejeitar \\(H_0\\) ainda que ele seja falso (Figura B). Consequentemente, ao diminuir o valor de \\(\\alpha\\) ficamos menos propensos a cometer o erro do tipo I, por√©m mais propensos a incorrer no erro tipo II, isto √©, n√£o rejeitar uma \\(H_0\\) falsa.\nDadas estas caracter√≠sticas, o √∫nico modo que reduzir os dois tipos de erros simultaneamente √© aumentando o tamanho amostral \\(n\\) pois, neste caso, reduzimos o erro padr√£o (\\(\\sigma_{\\overline{X}}\\)) e consequentemente a sobreposi√ß√£o entre as duas curvas acima."
  },
  {
    "objectID": "content/teste-hipoteses/intro-testehipot.html#estabelecendo-a-hip√≥tese-alternativa-testes-bilaterais-vs-unilaterais",
    "href": "content/teste-hipoteses/intro-testehipot.html#estabelecendo-a-hip√≥tese-alternativa-testes-bilaterais-vs-unilaterais",
    "title": "Introdu√ß√£o ao teste de hip√≥teses",
    "section": "5 Estabelecendo a hip√≥tese alternativa: testes bilaterais vs unilaterais",
    "text": "5 Estabelecendo a hip√≥tese alternativa: testes bilaterais vs unilaterais\nA hip√≥tese alternativa estabelece nossa expectativa para a explica√ß√£o dos resultados de um experimento no caso de \\(H_0\\) ser falsa. Os testes que descrevemos acima s√£o chamados testes bilaterais ou bicaudais. Isto significa que sendo \\(H_0\\) falsa, podemos esperar que a m√©dia populacional esteja tanto acima quanto abaixo de \\(\\mu\\). Existem situa√ß√µes, no entanto, para as quais j√° temos uma expectativa a priori com base no conhecimento pr√©vio sobre o fen√™meno estudado.\nVoltemos ao exemplo sobre a frequ√™ncia card√≠aca. Sabemos que o sedentarismo, tende a elevar a frequ√™ncia card√≠aca em repouso. Deste modo, o problema poderia ser estabelecido da seguinte forma.\n\n\n\n\n\n\nDescri√ß√£o do problema\n\n\n\nDigamos que o n√∫mero de batimentos card√≠acos por minuto de um adulto em repouso tenha m√©dia \\(\\mu = 65\\) e desvio padr√£o \\(\\sigma = 9\\). A literatura sugere que o sedentarismo aumenta o batimento m√©dio de um adulto.\n\n\nO problema agora estabelece que no caso de rejei√ß√£o de \\(H_0\\), a frequ√™ncia card√≠aca deveia ser maior que 65 batimentos por minuto. Deste modo teremos como hip√≥teses estat√≠sticas:\n\nHip√≥teses estat√≠ticas:\n\n\\(H_0: \\mu = 65\\) batimentos por minuto\n\\(H_a: \\mu \\gt 65\\) batimentos por minuto\nA mudan√ßa aqui est√° em \\(H_a\\) que estabelece que na hip√≥tese de rejei√ß√£o de \\(H_0\\), esperamos somente que a frequencia card√≠aca aumente.\nEsta modifica√ß√£o na constru√ß√£o das hip√≥teses estat√≠sticas tem implica√ß√£o na defini√ß√£o do limite de rejei√ß√£o.\n\nLimite de rejei√ß√£o: se definimos \\(\\alpha = 0,05\\), e \\(H_a: \\mu \\gt 65\\), temos que a √°rea de rejei√ß√£o ser√° expressa acima de 65 batimentos por minuto.\n\n\n\n\n\n\n\n\n\nFigura¬†5: √Årea de rejei√ß√£o em um teste unilateral com \\(\\alpha = 0,05\\).\n\n\n\n\n\nNote portanto, que a diferen√ßa entre um teste bilateral e um teste unilateral est√° na defini√ß√£o d√° √°rea que expressa a zona de rejei√ß√£o, \\(\\alpha\\) para \\(H_0\\). Nos teste bilaterais, a √°rea de rejei√ß√£o √© distribu√≠da acima e abaixo de \\(\\mu\\) (Figura¬†2), enquanto nos teste unilaterais, a √°rea estar√° toda acima ou abaixo de \\(\\mu\\), a depender do que foi estabelecido em \\(H_a\\) (Figura¬†5).\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html",
    "href": "content/estrutura-dados/estrutura-tipo.html",
    "title": "Estrutura e tipos de dados",
    "section": "",
    "text": "Neste t√≥pico exploramos os conceitos fundamentais de estrutura e tipos de dados, focando na organiza√ß√£o de unidades amostrais e descritores em tabelas de dados. Tamb√©m discutiremos diferentes tipos de vari√°veis, suas transforma√ß√µes e como lidar com valores ausentes (NA) em tabelas de dados. Para ilustrar esses conceitos, usaremos a tabela penguins_raw do pacote palmerpenguins em R, fornecendo tanto explica√ß√µes te√≥ricas quanto exemplos pr√°ticos de c√≥digo em R."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#palmer-penguins-dataset",
    "href": "content/estrutura-dados/estrutura-tipo.html#palmer-penguins-dataset",
    "title": "Estrutura e tipos de dados",
    "section": "1 Palmer Penguins dataset",
    "text": "1 Palmer Penguins dataset\nA tabela penguins_raw inclui observa√ß√µes de nidifica√ß√£o, dados de morfometria e tamanho dos pinguins e medidas de is√≥topos de amostras de sangue de pinguins adultos das esp√©cies Ad√©lie (Pygoscelis adeliae), Chinstrap (Pygoscelis antarctica) e Gentoo (Pygoscelis papua).\n\ndata(penguins_raw)\npenguins_raw |&gt; \n  head() |&gt;\n  gt()\n\n\n\nTabela¬†1: Primeiras linhas da tabela penguins_raw.\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n2007-11-11\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n2007-11-11\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n2007-11-16\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n2007-11-16\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n2007-11-16\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n2007-11-16\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n\n\n\nA tabela penguins_raw cont√©m 344 linhas e 17 colunas, cada uma representando diferentes aspectos dos dados coletados sobre os pinguins. Cada linha representa uma unidade amostral (UA) e cada coluna representa uma vari√°vel (VAR) que descreve um atributo espec√≠fico da unidade amostral (Tabela¬†2).\n\n\n\nTabela¬†2: Descri√ß√£o dos atributos da tabela penguins_raw.\n\n\n\n\n\n\n\n\n\n\nVari√°vel\nTipo\nDescri√ß√£o\n\n\n\n\nstudyName\nCateg√≥rica\nExpedi√ß√£o de amostragem de onde os dados foram coletados, gerados, etc.\n\n\nSample Number\nQuantitativa Discreta\nUm n√∫mero inteiro indicando a sequ√™ncia cont√≠nua de numera√ß√£o para cada amostra\n\n\nSpecies\nCateg√≥rica\nUma string de caracteres indicando a esp√©cie de pinguim\n\n\nRegion\nCateg√≥rica\nUma string de caracteres indicando a regi√£o da grade de amostragem Palmer LTER\n\n\nIsland\nCateg√≥rica\nUma string de caracteres indicando a ilha perto da Esta√ß√£o Palmer onde as amostras foram coletadas\n\n\nStage\nCateg√≥rica\nUma string de caracteres indicando o est√°gio reprodutivo no momento da amostragem\n\n\nIndividual ID\nCateg√≥rica\nUma string de caracteres indicando o ID √∫nico para cada indiv√≠duo no conjunto de dados\n\n\nClutch Completion\nCateg√≥rica\nUma string de caracteres indicando se o ninho estudado foi observado com uma ninhada completa, ou seja, 2 ovos\n\n\nDate Egg\nCateg√≥rica Ordinal\nUma data indicando a data em que o ninho estudado foi observado com 1 ovo (amostrado)\n\n\nCulmen Length\nQuantitativa Cont√≠nua\nUm n√∫mero indicando o comprimento da crista dorsal do bico de um p√°ssaro (mil√≠metros)\n\n\nCulmen Depth\nQuantitativa Cont√≠nua\nUm n√∫mero indicando a profundidade da crista dorsal do bico de um p√°ssaro (mil√≠metros)\n\n\nFlipper Length\nQuantitativa Discreta\nUm n√∫mero inteiro indicando o comprimento da nadadeira do pinguim (mil√≠metros)\n\n\nBody Mass\nQuantitativa Discreta\nUm n√∫mero inteiro indicando a massa corporal do pinguim (gramas)\n\n\nSex\nCateg√≥rica\nUma string de caracteres indicando o sexo do animal\n\n\nDelta 15 N\nQuantitativa Cont√≠nua\nUm n√∫mero indicando a medida da raz√£o dos is√≥topos est√°veis 15N:14N\n\n\nDelta 13 C\nQuantitativa Cont√≠nua\nUm n√∫mero indicando a medida da raz√£o dos is√≥topos est√°veis 13C:12C\n\n\nComments\nCateg√≥rica\nUma string de caracteres com texto fornecendo informa√ß√µes adicionais relevantes para os dados"
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#unidades-amostrais-e-descritores-formato-geral",
    "href": "content/estrutura-dados/estrutura-tipo.html#unidades-amostrais-e-descritores-formato-geral",
    "title": "Estrutura e tipos de dados",
    "section": "2 Unidades amostrais e descritores: formato geral",
    "text": "2 Unidades amostrais e descritores: formato geral\nA tabela Tabela¬†1 est√° organizada no formato em que cada linha representa uma unidade amostral (UA) e cada coluna representa uma vari√°vel (VA). As vari√°veis s√£o os descritores ou atributos que descrevem as caracter√≠sticas de cada unidade amostral.\n\n\n\n\nTabela¬†3: Estrutura geral de uma base de dados. As linhas representam as unidades amostrais (ou observa√ß√µes) e as colunas representam as vari√°veis (ou atributos).\n\n\n\n\n\n\n\n\n\nID\nVA 1\nVA 2\nVA 3\nVA 4\nVA 5\nVA 6\nVA 7\n\n\n\n\nUA 1\n\n\n\n\n\n\n\n\n\nUA 2\n\n\n\n\n\n\n\n\n\nUA 3\n\n\n\n\n\n\n\n\n\nUA 4\n\n\n\n\n\n\n\n\n\nUA 5\n\n\n\n\n\n\n\n\n\nUA 6\n\n\n\n\n\n\n\n\n\nUA 7\n\n\n\n\n\n\n\n\n\nUA 8\n\n\n\n\n\n\n\n\n\nUA 9\n\n\n\n\n\n\n\n\n\nUA 10"
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#dados-ausentes",
    "href": "content/estrutura-dados/estrutura-tipo.html#dados-ausentes",
    "title": "Estrutura e tipos de dados",
    "section": "3 Dados ausentes",
    "text": "3 Dados ausentes\nValores n√£o preenchidos s√£o comuns em conjuntos de dados. Na tabela penguins_raw, diversas colunas apresentam dados ausentes, indicados como NA. A seguir, s√£o apresentadas algumas estrat√©gias para lidar com esses dados faltantes:\n\nRemover valores faltantes: Exclua linhas com dados ausentes usando a fun√ß√£o drop_na().\n\n\npenguins_limpo &lt;- drop_na(penguins_raw)\n\nnrow(penguins_limpo)\n\n[1] 34\n\n\nRestaram apenas 344 linhas na tabela, o que indica a necessidade de avaliar cuidadosamente quais colunas ter√£o seus valores NA removidos. Para isso, √© √∫til verificar a quantidade de dados ausentes em cada coluna. Observando a tabela Tabela¬†1, nota-se que a maioria dos dados ausentes est√° na vari√°vel Comments. Como essa coluna n√£o ser√° inclu√≠da nas an√°lises, os valores ausentes nela n√£o precisam ser removidos. Podemos, portanto, excluir as linhas que cont√™m NA em outras colunas, preservando apenas a coluna Comments.\n\npenguins_limpo &lt;- penguins_raw |&gt; \n  drop_na(-Comments)\n\nnrow(penguins_limpo)\n\n[1] 324\n\n\nAgora, restaram 344 linhas na tabela. A remo√ß√£o de linhas deve ser feita com cautela, avaliando caso a caso. Como alternativa, pode-se considerar a imputa√ß√£o de valores para as c√©lulas ausentes, o que pode permitir a preserva√ß√£o de mais dados para an√°lise.\n\nInserir valores faltantes: Preencha valores faltantes usando m√©todos estat√≠sticos, como substitui√ß√£o pela m√©dia.\n\n\npenguins_lpch &lt;- penguins_raw |&gt; \n  mutate(`Culmen Length (mm)` = if_else(\n    is.na(`Culmen Length (mm)`),\n    mean(`Culmen Length (mm)`, na.rm = TRUE),\n    `Culmen Length (mm)`\n  ))\n\nNeste caso, os valores ausentes foram substitu√≠dos pela m√©dia aritm√©tica da vari√°vel Culmen Length (mm).\n\n\n\n\n\n\nT√©cnicas Avan√ßadas de Imputa√ß√£o\n\n\n\nUma alternativa √† substitui√ß√£o pela m√©dia simples √© a imputa√ß√£o m√∫ltipla, que pode utilizar agrupamentos mais detalhados (por exemplo, por esp√©cie e ilha) e considerar a associa√ß√£o com outras vari√°veis da tabela. Outra op√ß√£o √© empregar m√©todos mais sofisticados, como o k-Nearest Neighbors (kNN)."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#tipos-de-dados",
    "href": "content/estrutura-dados/estrutura-tipo.html#tipos-de-dados",
    "title": "Estrutura e tipos de dados",
    "section": "4 Tipos de dados",
    "text": "4 Tipos de dados\nUma tabela de dados pode ser composta por vari√°veis quantitativas ou qualitativas.\n\nVari√°veis qualitativas\nS√£o vari√°veis n√£o-num√©ricas como categorias ou r√≥tulos. Dentre as vari√°veis qualitativas temos aquelas do tipo categ√≥ricas n√£o-ordenadas e do tipo categ√≥ricas ordenadas.\nVari√°vel categ√≥rica n√£o-ordenada: a vari√°vel Island classifica cada penguim de acordo com a ilha em que foi registrado. Os n√≠veis da vari√°vel Island s√£o: Torgersen, Biscoe, Dream. A vari√°vel √© do tipo categ√≥rica n√£o-ordenada, pois os n√≠veis n√£o possuem qualquer rela√ß√£o de ordena√ß√£o natural entre si.\n\n\nVari√°veis quantitativas\nS√£o vari√°veis num√©ricas que tamb√©m podem ser sub-divididas em dois grupos: discretas e cont√≠nuas.\n\nVari√°veis quantitativas discretas: envolvem quantias enumer√°veis. Na tabela penguins_raw n√£o h√° nenhum exemplo deste tipo de vari√°vel, mas exemplos podem ser a contagem de barcos que saem para pescar em um determinado dia, o n√∫mero de peixes de um cardume o n√∫mero de ovos no ninho de ave.\nVari√°veis quantitativas cont√≠nuas: envolvem quantias n√£o-enumer√°veis como a vaz√£o em \\(m^3/seg\\) que verte de uma cachoeira, o volume de chuva em um determinado dia, altura da mar√© ou a velocidade do vento. O limite de precis√£o que utilizamos para represent√°-las depende basicamente da capacidade de mensura√ß√£o dos aparelhos dispon√≠veis. Na tabela penguins_raw existem diversos exemplos deste tipo de vari√°vel como\n\nEm nosso exemplo, temos diversas vari√°veis deste tipo como Culmen Length, Culmen Depth, Flipper Length, Body Mass, Delta 15 N e Delta 13 C.\n\n\n\n\n\n\nTransformando vari√°veis\n\n\n\nSempre √© poss√≠vel transformar vari√°veis quantitativas em qualitativas. Se temos uma vari√°vel medindo o comprimento de peixes desembarcados em cent√≠metros (vari√°vel quantitativa), √© poss√≠vel express√°-la de forma categ√≥rica em peixes grandes e peixes pequenos (vari√°vel qualitativa). Por outro lado, se tivermos somente a informa√ß√£o de que um peixe √© grande ou pequeno, n√£o podemos recuperar as quantias num√©ricas originais. Ao transformar uma vari√°vel de quantitativa em qualitativa, algumas propriedades s√£o perdidas."
  },
  {
    "objectID": "content/estrutura-dados/estrutura-tipo.html#n√≠veis-de-mensura√ß√£o",
    "href": "content/estrutura-dados/estrutura-tipo.html#n√≠veis-de-mensura√ß√£o",
    "title": "Estrutura e tipos de dados",
    "section": "5 N√≠veis de mensura√ß√£o",
    "text": "5 N√≠veis de mensura√ß√£o\nPodemos organizar uma vari√°vel a partir de seu n√≠vel de mensura√ß√£o (Figura¬†1), dado em: nominal, ordinal, intervalar e raz√£o.\nN√≠vel nominal: √© caracter√≠stico de vari√°veis que possuem n√≠veis n√£o ordenaveis. Ex. cor, grupo taxon√¥mico, nomes de cidades, etc.\n\nN√≠vel ordinal: √© aquele em que os n√≠veis podem ser ordenados, embora n√£o seja poss√≠vel quantificar as diferen√ßas entre dois n√≠veis. Ex. i - Ordem de chegada de maratonistas em uma competi√ß√£o (\\(1^o\\),\\(2^o\\),\\(3^o\\),\\(\\cdots\\)). ii - Condi√ß√£o de saneamento das cidades (√≥timo, bom, ruim, p√©ssimo). iii - Condi√ß√£o de saneamento das praias da baixada santista (pr√≥prio, impr√≥rpio). No n√≠vel ordinal podemos ordenar os elementos por√©m n√£o podemos quantificar as diferen√ßas entre eles.\nN√≠vel intervalar: √© aquele em que al√©m ser poss√≠vel ordenar, √© poss√≠vel quantificar as diferen√ßas entre duas observa√ß√µes. No entanto, n√£o h√° um ponto inicial natural, ou seja, um ponto zero que indique aus√™ncia da quantia. Ex. i ‚Äì Temperatura: \\(0^oC\\) n√£o indica aus√™ncia de temperatura, assim como \\(10^oC\\) n√£o √© duas vezes mais quente que \\(5^oC\\). Essas caracter√≠sticas s√£o somente uma conven√ß√£o relacionada √† escala de mensura√ß√£o da temperatura. ii - Ano do calend√°rio: o ano zero √© uma conven√ß√£o do calend√°rio, n√£o significa aus√™ncia de tempo.\nN√≠vel de raz√£o: √© como o intervalar, por√©m existe um ponto zero natural. Peso igual a \\(0\\) kg indica aus√™ncia de peso e dez quilogramas √© duas vezes mais pesado que \\(5\\) kg. O mesmo vale para comprimento, dist√¢ncia, velocidade, n√∫mero de ovos.\n\n\n\n\n\n\n\n\nFigura¬†1: Tipos de vari√°veis e n√≠veis de mensura√ß√£o.\n\n\n\n\nA depender do n√≠vel de mensura√ß√£o, algumas opera√ß√µes matem√°ticas podem ou n√£o fazer sentido. Por exemplo, se uma esp√©cie tem \\(N_A = 100\\) indiv√≠duos na regi√£o A e \\(N_B = 200\\) na regi√£o B, a segunda regi√£o √© duas vezes mais populosa pois \\(\\frac{N_B}{N_A} = 2\\). Por outro lado, se a temperatura na regi√£o A √© de \\(T_A = 10^oC\\) enquanto na B √© de \\(T_B = 20^oC\\) n√£o faz sentido fazer \\(\\frac{T_B}{T_A} = 2\\) e dizer que B seja duas vezes mais quente que A. Ainda que matematicamente a opera√ß√£o seja poss√≠vel nos dois exemplos, no √∫ltimo sua interpreta√ß√£o f√≠sica n√£o tem sentido.\n\n\n\n\n\n\nTipos de dados vs n√≠veis de mensura√ß√£o\n\n\n\nExiste uma rela√ß√£o entre tipo de dados e n√≠vel de mensura√ß√£o. Os n√≠veis nominal e ordinal de mensura√ß√£o se referem a vari√°veis qualitativas n√£o-ordenadas e qualitativas ordenadas respectivamente. J√° os n√≠veis intervalar e raz√£o se referem a vari√°veis quantitativas, podendo ser discretas ou cont√≠nuas."
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html",
    "href": "content/visualizacao-dados/graficos-r.html",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "",
    "text": "A visualiza√ß√£o gr√°fica consiste em representar visualmente os padr√µes de distribui√ß√£o de uma vari√°vel ou a associa√ß√£o entre duas ou mais vari√°veis. Os tipos de gr√°ficos utilizados dependem do tipo de vari√°vel (categ√≥rica ou num√©rica) e do n√∫mero de vari√°veis envolvidas. Temos gr√°ficos univariados para uma √∫nica vari√°vel, gr√°ficos bivariados para associa√ß√£o entre duas vari√°veis e gr√°ficos multivariados para mais de duas vari√°veis.\nAs fun√ß√µes gr√°ficas discutidas nesta se√ß√£o est√£o dispon√≠veis no pacote graphics, que vem instalado por padr√£o no R, n√£o sendo necess√°rio instalar pacotes adicionais. Essas fun√ß√µes oferecem elevado controle sobre elementos gr√°ficos (fontes, tamanhos, cores), mas podem ser complexas para criar figuras elaboradas. Apesar de muitas nomenclaturas serem compat√≠veis para o controle de eixos, t√≠tulos e tamanhos de fonte, os argumentos nem sempre s√£o coesos entre os diferentes tipos de gr√°ficos, o que pode dificultar o aprendizado. No entanto, essas fun√ß√µes fornecem uma base s√≥lida sobre a estrutura gr√°fica no R, permitindo resolver rapidamente muitas situa√ß√µes do dia a dia da an√°lise explorat√≥ria."
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#doubs-river-dataset",
    "href": "content/visualizacao-dados/graficos-r.html#doubs-river-dataset",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "1 Doubs river dataset",
    "text": "1 Doubs river dataset\nPara demonstrar algumas ferramentas gr√°ficas, ser√° utilizado o conjunto de dados Doubs River data, dispon√≠vel no pacote ade4 (Dray, Dufour, e Thioulouse 2015). Esse conjunto de dados foi apresentado na se√ß√£o anterior sobre manipula√ß√£o de data frames, onde foi importado o arquivo dbenv.csv. Agora, ser√° usado o conjunto de dados completo.\nO conjunto de dados do Rio Doubs (Verneaux 1973) consiste de amostras sequenciais da cabeceira √† foz do rio, em condi√ß√µes que variam de √°guas bem oxigenadas e oligotr√≥ficas a √°guas eutr√≥ficas e desprovidas de oxig√™nio. O conjunto de dados √© uma lista com quatro data frames:\n\n$env: data frame com vari√°veis ambientais relacionadas √† hidrologia, geomorfologia e qu√≠mica do\n$fish: data frame com abund√¢ncias das esp√©cies de peixes capturadas nos locais de amostragem.\n$xy: data frame com coordenadas geogr√°ficas de cada ponto de amostragem.\n$species: data frame com os nomes cient√≠ficos, populares em franc√™s e ingl√™s, e c√≥digos abreviados das esp√©cies capturadas.\n\n\n1.1 Instalando o pacote ade4 e carregando os dados\n\nInstale o pacote ade4:\n\n\ninstall.packages(\"ade4\")\n\n\nCarregue o pacote:\n\n\nlibrary(ade4)\n\n\nHabilite o conjunto de dados doubs\n\n\ndata(doubs)\n\n\nConfira se consiste de uma lista:\n\n\nclass(doubs)\nstr(doubs)\n\n\nLeia a descri√ß√£o do conjunto de dados para conchec√™-lo melhor.\n\n\n?doubs\n\n\nExtraia os dados ambientais para um novo data.frame:\n\n\nambiente &lt;- doubs$env\n\n\nAdicione a este data frame uma nova vari√°vel categ√≥rica denominada secao com quatro n√≠veis (Borcard, Gillet, e Legendre 2018).\n\n\nambiente$secao &lt;- c(rep(\"Se√ß√£o 1\", 16), rep(\"Se√ß√£o 4\", 14))\nambiente$secao[c(5,9,17)] &lt;- \"Se√ß√£o 2\"\nambiente$secao[23:25] &lt;- \"Se√ß√£o 3\"\nambiente$secao &lt;- factor(ambiente$secao)\n\n\nAdicione outra vari√°vel categ√≥rica, indicando tr√™s n√≠veis de satura√ß√£o de oxig√™nio em cada ponto.\n\n\nambiente$saturacao &lt;- cut(ambiente$oxy, breaks = c(0, 80, 109, 124), \n           labels = c(\"Pobre\", \"M√©dio\", \"Saturado\"))\nhead(ambiente, 10)\n\n   dfs alt   slo  flo pH har pho nit amm oxy bdo   secao saturacao\n1    3 934 6.176   84 79  45   1  20   0 122  27 Se√ß√£o 1  Saturado\n2   22 932 3.434  100 80  40   2  20  10 103  19 Se√ß√£o 1     M√©dio\n3  102 914 3.638  180 83  52   5  22   5 105  35 Se√ß√£o 1     M√©dio\n4  185 854 3.497  253 80  72  10  21   0 110  13 Se√ß√£o 1  Saturado\n5  215 849 3.178  264 81  84  38  52  20  80  62 Se√ß√£o 2     Pobre\n6  324 846 3.497  286 79  60  20  15   0 102  53 Se√ß√£o 1     M√©dio\n7  268 841 4.205  400 81  88   7  15   0 111  22 Se√ß√£o 1  Saturado\n8  491 792 3.258  130 81  94  20  41  12  70  81 Se√ß√£o 1     Pobre\n9  705 752 2.565  480 80  90  30  82  12  72  52 Se√ß√£o 2     Pobre\n10 990 617 4.605 1000 77  82   6  75   1 100  43 Se√ß√£o 1     M√©dio"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#descrevendo-os-padr√µes-de-uma-vari√°vel",
    "href": "content/visualizacao-dados/graficos-r.html#descrevendo-os-padr√µes-de-uma-vari√°vel",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "2 Descrevendo os padr√µes de uma vari√°vel",
    "text": "2 Descrevendo os padr√µes de uma vari√°vel\n\n2.1 Gr√°fico de barras\nUm gr√°fico de barras √© utilizado para verificar a contagem de cada n√≠vel de uma vari√°vel categ√≥rica. Fa√ßa um gr√°fico de barras para a vari√°vel saturacao.\nInicialmente, monte uma tabela de frequencia:\n\ntab1 &lt;- table(ambiente$saturacao)\ntab1\n\n\n   Pobre    M√©dio Saturado \n       8       14        8 \n\n\nEm seguida represente-a em um gr√°fico de barras:\n\nbarplot(tab1)\n\n\n\n\n\n\n\n\nAdicionando elementos de formata√ß√£o gr√°fica:\n\nbarplot(tab1,\n        main = \"Concentra√ß√£o de oxig√™nio\",\n        ylab = \"Frequ√™ncia\",\n        ylim = c(0, 18), col = \"black\")\nbox()\n\n\n\n\n\n\n\n\n\n\n2.2 Histograma\nUm histograma descreve o padr√£o de distribui√ß√£o de uma vari√°vel quantitativa a partir da divis√£o desta vari√°vel em intervalos de classe.\nO histograma abaixo para a coluna oxy expressa a satura√ß√£o de oxig√™nio (mg/l \\(\\times\\) 10).\n\nhist(ambiente$oxy)\n\n\n\n\n\n\n\n\n\n\nNo histograma, o intervalo de classes determina o formato exato do gr√°fico. No exemplo acima, a escolha foi feita automaticamente. No entanto, √© poss√≠vel definir o intervalo desejado com o argumento breaks:\n\nclasses &lt;- seq(40, 140, by = 20)\nhist(ambiente$oxy, breaks = classes)\n\n\n\n\n\n\n\n\nA divis√£o foi feita em intervalos de tamanho 20, iniciando em 40 e terminando em 140. A escolha deve ser a que evidencie da melhor forma poss√≠vel o padr√£o de distribui√ß√£o da vari√°vel.\n\n\n2.3 Boxplot\nBoxplots oferecem um resumo gr√°fico da distribui√ß√£o de uma vari√°vel quantitativa. Abaixo est√° representada a vari√°vel oxy.\n\nboxplot(ambiente$oxy)\n\n\n\n\n\n\n\n\nA linha do meio representa a mediana da vari√°vel, enquanto os limites das caixas representam o \\(1^o\\) e \\(3^o\\) quartis e as linhas externas representam os pontos m√≠nimo e m√°ximo. Estes limites podem ser obtidos com o comando:\n\nquantile(ambiente$oxy, probs = c(0, 0.25, 0.5, 0.75, 1))\n\n    0%    25%    50%    75%   100% \n 41.00  80.25 102.00 109.00 124.00"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#associa√ß√£o-entre-duas-vari√°veis",
    "href": "content/visualizacao-dados/graficos-r.html#associa√ß√£o-entre-duas-vari√°veis",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "3 Associa√ß√£o entre duas vari√°veis",
    "text": "3 Associa√ß√£o entre duas vari√°veis\n\n3.1 Gr√°fico de barras\nUm gr√°fico de barras pode combinar duas vari√°veis categ√≥ricas como secao e saturacao. Inicialmente, monta-se uma tabela de frequ√™ncia, combinandos as contagens para cada n√≠vel das vari√°veis.\n\ntab2 &lt;- table(ambiente[,c(\"secao\", \"saturacao\")])\ntab2\n\n         saturacao\nsecao     Pobre M√©dio Saturado\n  Se√ß√£o 1     1     5        8\n  Se√ß√£o 2     2     1        0\n  Se√ß√£o 3     3     0        0\n  Se√ß√£o 4     2     8        0\n\n\nNeste caso, √© poss√≠vel representar estas contagens de diferentes formas:\n\nlayout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE))\nbarplot(tab2, legend = TRUE)\nbarplot(tab2, legend = TRUE, beside = TRUE)\nbarplot(t(tab2), legend = TRUE)\nbarplot(t(tab2), legend = TRUE, beside = TRUE)\n\n\n\n\n\n\n\n\n\nA fun√ß√£o layout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE)) organiza o espa√ßo gr√°fico em um formato matricial com 2 linhas por 2 colunas, permitindo a inser√ß√£o de 4 figuras. O argumento byrow = TRUE define que as figuras ser√£o adicionais linha-a-linha.\nA fun√ß√£o t() transp√µe a tabela, o que consequentemente altera a refer√™ncia da figura. No primeiro caso, a concentra√ß√£o de oxig√™nio √© a vari√°vel principal e, no segundo caso, s√£o as se√ß√µes.\nO argumento beside = TRUE faz com que as barras apare√ßam lado-a-lado e beside = FALSE resulta em cada barra representa a vari√°vel principal subdividida nos n√≠veis da vari√°vel secubd√°ria.\nEm todos os gr√°ficos foi adicionada uma legenda.\n\nAdiocionando elementos de formata√ß√£o:\n\ncores &lt;- 1:4\nlimy1 &lt;- c(0, 17)\nlimy2 &lt;- c(0, 16)\nlegenda &lt;- list(cex = 0.8)\n\nlayout(mat = matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE))\nbarplot(tab2, legend = TRUE, col = cores, ylim = limy1, \n        args.legend = legenda)\nbox()\nbarplot(tab2, legend = TRUE, beside = TRUE, col = cores, \n        ylim = limy1, args.legend = legenda)\nbox()\nbarplot(t(tab2), legend = TRUE, col = cores, ylim = limy2, \n        args.legend = legenda)\nbox()\nbarplot(t(tab2), legend = TRUE, beside = TRUE, col = cores, \n        ylim = limy2, args.legend = legenda)\nbox()\n\n\n\n\n\n\n\n\n\n\n3.2 Boxplot\nO boxplot tamb√©m pode ser utilizado para representar uma vari√°vel \\(X_1\\) para diferentes n√≠veis de uma vari√°vel categ√≥rica \\(X_2\\), por exemplo oxy para cada n√≠vel de secao.\n\nboxplot(oxy ~ secao, data = ambiente)\n\n\n\n\n\n\n\n\nOs pontos associados √† Se√ß√£o 1 t√™m maiores concentra√ß√µes de oxig√™nio (mediana = 110.5) e que os pontos associados √† Se√ß√£o 3 (mediana = 52).\nNa fun√ß√£o boxplot foi utilizada a representa√ß√£o de f√≥rmula no R (y ~ x) em que a vari√°vel no eixo y depende de x. Esta nota√ß√£o √© amplamente utilizada em modelos estat√≠sticos (ex. regress√£o linear, e an√°lise de vari√¢ncia, etc.).\n\nAo inv√©s de acessar a vari√°vel por ambiente$oxy, utilizou-se o nome da coluna (oxy) e adicionou-se o argumento data = ambiente para indicar em qual data frame a fun√ß√£o ir√° buscar as vari√°veis.\n\n\n\n3.3 Gr√°fico de dispers√£o\nUm gr√°fico de dispers√£o mostra a associa√ß√£o entre duas vari√°veis quantitativas, por exemplo, concentra√ß√£o de nitrato (mg/l \\(\\times\\) 100) e dist√¢ncia da foz (km \\(\\times\\) 10). Neste caso a concentra√ß√£o de nitrato ser√° representada como dependente da dist√¢ncia da foz.\n\nplot(nit ~ dfs, data = ambiente)\n\n\n\n\n\n\n\n\nOs resultados expressam uma rela√ß√£o em que a concentra√ß√£o de nutrientes aumenta √† medida que distancia-se da foz.\nAdicionando formata√ß√£o gr√°fica: nomes dos eixos (argumentos xlab e ylab) e tipo de ponto (argumento pch).\n\nplot(nit ~ dfs, data = ambiente,\n     xlab = bquote(\"Vaz√£o m√©dia m√≠nima (m\" ^3/\"seg x 100)\"),\n     ylab = bquote(\"Concentra√ß√£o de Nitrato (mg\"/\"l x 100)\"),\n     pch = 19\n)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#compreendendo-o-ambiente-por-meio-de-suas-vari√°veis",
    "href": "content/visualizacao-dados/graficos-r.html#compreendendo-o-ambiente-por-meio-de-suas-vari√°veis",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "4 Compreendendo o ambiente por meio de suas vari√°veis",
    "text": "4 Compreendendo o ambiente por meio de suas vari√°veis\nUm dos objetivo da descri√ß√£o gr√°fica √© representar o sistema por meio das vari√°veis escolhidas para quantific√°-lo. Al√©m dos gr√°ficos apresentados anteriormente, h√° outras formas de incorporar essas vari√°veis em uma figura, utilizando cores, s√≠mbolos e textos no ambiente gr√°fico. Nesta se√ß√£o, ser√£o exploradas algumas possibilidades.\nOs pontos de amostragem foram obtidos ao longo do gradiente cabeceira-foz. As informa√ß√µes incluem as coordenadas geogr√°ficas desses pontos (no data frame $xy). A sequ√™ncia dos pontos segue uma ordem crescente de dist√¢ncia da foz. Inicialmente, ser√£o plotadas as coordenadas geogr√°ficas de todos os pontos utilizando um gr√°fico de linhas.\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\n\n\n\n\n\n\n\n\nCompare a figura com o desenho do rio Doubs.\n\n\n\n\n\n\nNota\n\n\n\nUtilizamos a defini√ß√£o de cores em HEXADECIMAL. Voc√™ pode fazer o mesmo, escolhendo a cor desejada aqui: hex color picker.\n\n\nRepresentando os pontos de amostragem.\n\npontos_extremos &lt;- doubs$xy[which(doubs$env$dfs == min(doubs$env$dfs) | \n                                      doubs$env$dfs == max(doubs$env$dfs)),]\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\ntext(x = pontos_extremos$x, \n       y = pontos_extremos$y,\n       labels = c(\"Cabeceira\", \"Foz\"))\n\n\n\n\n\n\n\n\nRepresentando as \\(4\\) se√ß√µes do rio.\n\nsecao_cor &lt;- as.numeric(ambiente$secao)\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\npoints(x = doubs$xy$x, y = doubs$xy$y, pch = 21, \n       bg = secao_cor, cex = 3)\nlegend(x = \"bottomright\", col = 1:4, \n       legend = levels(ambiente$secao), bty = \"n\", pch = 19)\n\n\n\n\n\n\n\n\nRepresentando a concentra√ß√£o de am√¥nia (amm).\n\nsecao_cor &lt;- as.numeric(ambiente$secao) + 1\n\nplot(x = doubs$xy$x, y = doubs$xy$y, type = \"l\",\n     xlab = \"Coordenada em x (km)\", \n     ylab = \"Coordenada em y (km)\",\n     col = \"#4287f5\", lwd = 3)\npoints(x = doubs$xy$x, y = doubs$xy$y, pch = 21, \n       bg = secao_cor, cex = 4)\nlegend(x = \"bottomright\", col = 1:4, \n       legend = levels(ambiente$secao), bty = \"n\", pch = 19)\ntext(x = doubs$xy$x, y = doubs$xy$y, labels = doubs$env$amm, \n     cex = 0.8, font = 2)\ntext(x = 55, y = 220, labels = \"Concentra√ß√£o de am√¥nia\")\ntext(x = 25, y = 120, label = \"Foz\")\ntext(x = 60, y = 20, label = \"Cabeceira\")\n\n\n\n\n\n\n\n\nA figura nos informa sobre a distribui√ß√£o espacial da concentra√ß√£o de am√¥nia entre as se√ß√µes. Verifica-se que a concentra√ß√£o de am√¥nia √© mais nas se√ß√µes \\(4\\) e \\(3\\).\n\n\n\n\n\n\nNota\n\n\n\nUtilizamos uma s√©rie de fun√ß√µes novas: text, points, legend. Para entender como elas funcionam, rode os comandos acima linha por linha e veja como cada fun√ß√£o adiciona uma informa√ß√£o adicional √† figura."
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#outros-argumentos-de-formata√ß√£o-gr√°fica",
    "href": "content/visualizacao-dados/graficos-r.html#outros-argumentos-de-formata√ß√£o-gr√°fica",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "5 Outros argumentos de formata√ß√£o gr√°fica",
    "text": "5 Outros argumentos de formata√ß√£o gr√°fica\nA capacidade de formata√ß√£o gr√°fica no R √© extensa e qualquer tentativa de resum√≠-las seria incompleta. Abaixo exemplificam alguns argumentos comuns de formata√ß√£o gr√°fica.\n\nplot(nit ~ dfs, data = ambiente)\nplot(nit ~ dfs, data = ambiente, pch = 2)\nplot(nit ~ dfs, data = ambiente, pch = 19)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\")\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\",\n     xlab = \"Nitrato\", ylab = \"Vaz√£o\")\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"b\", \n     xlab = \"Nitrato\", ylab = \"Vaz√£o\", font.lab = 3)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2, lwd = 3)\nplot(nit ~ dfs, data = ambiente, pch = 19, type = \"l\", \n     lty = 2, lwd = 3, col = 2)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#figuras-compostas",
    "href": "content/visualizacao-dados/graficos-r.html#figuras-compostas",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "6 Figuras compostas",
    "text": "6 Figuras compostas\nUma das formas mais simples para inserir m√∫ltiplas figuras no mesmo espa√ßo gr√°fico √© por meio da fun√ß√£o layout. Abaixo, ser√µ inseridos \\(6\\) gr√°ficos em uma espa√ßo de \\(3\\) colunas por \\(2\\) linhas.\n\nlayout(mat = matrix(1:6, nrow = 3, ncol = 2))\nplot(alt ~ dfs, data = ambiente)\nplot(amm ~ alt, data = ambiente)\nplot(nit ~ alt, data = ambiente)\nplot(pH ~ alt, data = ambiente)\nplot(bdo ~ alt, data = ambiente)\nplot(oxy ~ alt, data = ambiente)"
  },
  {
    "objectID": "content/visualizacao-dados/graficos-r.html#exportando-figuras-fun√ß√µes-png-tiff-jpeg-e-bmp",
    "href": "content/visualizacao-dados/graficos-r.html#exportando-figuras-fun√ß√µes-png-tiff-jpeg-e-bmp",
    "title": "(B√°sico da) Visualiza√ß√£o gr√°fica",
    "section": "7 Exportando figuras: fun√ß√µes png, tiff, jpeg e bmp",
    "text": "7 Exportando figuras: fun√ß√µes png, tiff, jpeg e bmp\n√â poss√≠vel exportar figuras em diversos formatos e resolu√ß√µes. A fun√ß√£o png √© exemplificada abaixo. As fun√ß√µes para exportar em outros formatos s√£o similares.\n\npng(filename = \"Exemplo_figura.png\",\n    width = 15, height = 15, units = \"cm\", \n    pointsize = 10, bg = \"white\", res = 800)\n\nplot(alt ~ dfs, data = ambiente, pch = 19, type = \"b\", \n     xlab = \"Vaz√£o\", ylab = \"Eleva√ß√£o\")\n\ndev.off()\n\nA figura foi salva do diret√≥rio atual de sua se√ß√£o de trabalho. Voc√™ pode conferir este diret√≥rio com o comando:\n\ngetwd()\n\nExperimente alterar os argumentos width, height, pointsize, units (com \"px\", \"in\", \"cm\" ou \"mm\") e res.\nAs capacidades gr√°ficas no R incluem ainda muitos outros argumentos. Alguns deles s√£o: cores (col), tipos da fonte (font), tamanhos de s√≠mbolos (cex), dos labels (cex.lab), dos r√≥tulos dos eixos (cex.axis), t√≠tulo (main), etc. Pode-se ainda inserir legendas (fun√ß√£o legend) e textos (fun√ß√£o text). Veja o help de cada uma destas fun√ß√µes e a lista de argumentos poss√≠veis para o ambiente gr√°fico do R em ?par. Veja tamb√©m uma demonstra√ß√£o com demo(graphics), demo(image), demo(persp) e demo(plotmath).\nExistem diversos outros pacotes gr√°ficos al√©m do graphics:\n\nggplot2\nggvis\nLattice\nhighcharter\nLeaflet\nRColorBrewer\nPlotly\nsunburstR\nRGL\ndygraphs"
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html",
    "href": "content/inferencia-estatistica/teorema-central-limite.html",
    "title": "Distribui√ß√£o das m√©dias amostrais",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nsource(\"scripts/tcl-simetry.r\")"
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html#teorema-central-do-limite",
    "href": "content/inferencia-estatistica/teorema-central-limite.html#teorema-central-do-limite",
    "title": "Distribui√ß√£o das m√©dias amostrais",
    "section": "1.1 Teorema Central do Limite",
    "text": "1.1 Teorema Central do Limite\nSeja uma popula√ß√£o estat√≠stica com m√©dia \\(\\mu\\) e desvio padr√£o \\(\\sigma\\). A distribui√ß√£o das m√©dias amostrais desta popula√ß√£o tender√° a apresentar uma distribui√ß√£o normal de probabilidades com m√©dia \\(\\mu\\) e desvio padr√£o \\(\\frac{\\sigma}{\\sqrt(n)}\\) √† medida que o tamanho amostral \\(n\\) aumenta, ainda que a distribui√ß√£o das observa√ß√µes originais n√£o possua uma distribui√ß√£o normal.\nSegundo o TCL, as m√©dias amostrais \\(\\overline{X}\\) de um experimento distribuem-se como:\n\\[\\overline{X} \\sim \\mathcal{N}(\\mu_{\\overline{X}},\\,\\sigma^{2}_{\\overline{X}})\\]\nem que \\(\\mu_{\\overline{X}} = \\mu\\) \\(\\sigma^{2}_{\\overline{X}} = \\frac{\\sigma^2}{n}\\)\nNote que a vari√¢ncia de \\(\\overline{X}\\) depende do tamanho amostral \\(n\\).\n\n1.1.1 Probabilidades na amostra original e na distribui√ß√£o de m√©dias\nSeja uma vari√°vel \\(X\\) qualquer com \\(\\mu = 50\\) e \\(\\sigma = 10\\). As figuras abaixo comparam as probabilidades acima de \\(x_1 = 55\\) para as observa√ß√µes originais e para as distribui√ß√µes de m√©dias amostrais de tamanho \\(n_1 = 2\\) e \\(n_2 = 10\\).\n\n\n\n\n\n\n\n\nFigura¬†3: Probabilidades na amostra original e na distribui√ß√£o de m√©dias.\n\n\n\n\n\nNote que existe uma probabilidade razo√°vel de que uma determinada observa√ß√£o em \\(X\\) esteja acima de \\(55\\), \\(P(X \\leq 55) = 0.309\\). No entando se tomarmos ao acaso uma amostra de tamanho \\(n_1 = 2\\), a probabilidade de que a m√©dia destas duas amostras esteja acima de \\(55\\) diminui para \\(P(\\overline{X} \\leq 55) = 0.24\\). Se tormarmos uma amostra ainda maior (\\(n_2 = 10\\)), a probabilidade se reduz ainda mais para \\(P(\\overline{X} \\leq 55) = 0.057\\).\nVemos portanto que a precis√£o de um experimento aumenta √† medida que aumentamos o tamanho amostral, pois para amostras grandes, a probabilidade de obtermos um \\(\\overline{X}\\) distante de \\(\\mu\\) torna-se cada vez menor.\n\n\n1.1.2 Distribui√ß√µes n√£o-normais\nO TCL √© v√°lido inclusive para distribui√ß√µes n√£o-normais. Isto torna a distribui√ß√£o normal uma das mais importantes em infer√™ncia estat√≠stica, pois ainda que o resultado de um experimento particular seja descrito por qualquer outro modelo de probabilidades, as m√©dias das amostras deste experimento seguir√£o uma distribui√ß√£o normal, √† medida que \\(n\\) aumenta. Isto justifica muitos dos processos de an√°lise e infer√™ncia estat√≠stica que ser√£o descritos nos cap√≠tulos posteriores.\nA Figura¬†4, simula a distribui√ß√£o de m√©dias amostrais para vari√°veis com diferentes distribui√ß√µes de probabiidades e tamanhos crescentes de \\(n\\). Podemos observar que independente do formato da distribui√ß√£o original, a distribui√ß√£o das m√©dias amostrais tende √† normalidade. O padr√£o normal aparece mais r√°pido se a distribui√ß√£o original √© sim√©trica. Ainda que para popula√ß√µes estat√≠sticas com distribui√ß√µes assim√©tricas, seja necess√°rio um tamanho amostral maior para que se alcance a normalidade, a figura mostra que a partir de \\(n = 30\\) todas as distribui√ß√µes parecem se aproximar do que seria esperado um modelo normal.\n\n\n\n\n\n\n\n\nFigura¬†4: Demostra√ß√£o emp√≠rica do Teorema Central do Limite, mostrando a tend√™ncia √† normalidade de \\(\\bar{X}\\) √† medina que \\(n\\) aumenta."
  },
  {
    "objectID": "content/inferencia-estatistica/teorema-central-limite.html#exerc√≠cios-resolvidos",
    "href": "content/inferencia-estatistica/teorema-central-limite.html#exerc√≠cios-resolvidos",
    "title": "Distribui√ß√£o das m√©dias amostrais",
    "section": "1.2 Exerc√≠cios resolvidos:",
    "text": "1.2 Exerc√≠cios resolvidos:\n\n1.2.1 Tamanho m√©dio de robalos no mercado de peixes\nEm 2014 no estu√°rio do rio Itanha√©m - SP foi pescado o ‚Äúmaior robalo j√° encontrado‚Äù (G1 Santos). O peixe tinha \\(133\\) cm e \\(27,8\\) kg . Em 2018 em Bertioga, tamb√©m no litoral de SP: ‚ÄúRobalo ‚Äògigante‚Äô quebra recordes e vira atra√ß√£o‚Äù (G1 Santos) pesando \\(33\\) kg. Finalmente, em ‚Äúuma das salas da Col√¥nia de Pesca Z2 de Atafona‚Äù RJ est√° uma imagem de um robalo de \\(28\\) kg capturado muitas d√©cadas atr√°s (Ambiente Cult)\n\n\n\n\n\n\n\n\n\n\n\n(a) Itanha√©m 2014\n\n\n\n\n\n\n\n\n\n\n\n(b) Bertioga 2018\n\n\n\n\n\n\n\n\n\n\n\n(c) Atafona, sem data\n\n\n\n\n\n\n\nFigura¬†5: Grandes robalos\n\n\n\nEstas capturas viram not√≠cias pois s√£o inusitadas. Dados de desembarque sugerem que a distribui√ß√£o de tamanho de robalos comumente capturados est√° muito abaixo destes limites (Figura¬†6) (Ximenes-Carvalho 2006) ( Acesse aqui o trabalho completo).\n\n\nC√≥digo\nTabelaI &lt;- data.frame(\n  compmedio = c(25.2, 34.4, 40.7, 46.3, 51.7, 56.5, 61.2, 65.8, 70.3, 73.4, 76.2),\n  N = c(130,130,112,100,82,64,47,30,18,12,6)\n)\n\ntabelaI_plt &lt;- ggplot(data = TabelaI, mapping = aes(x = compmedio, y = N)) +\n   geom_col(fill = 'dodgerblue4', color = 'black') +\n   labs(y = 'N√∫mero de indiv√≠duos analisados',\n        x = 'Comprimento m√©dio (cm)') +\n   theme_classic()\n\n\n\n\nC√≥digo\ntabelaI_plt\n\n\n\n\n\n\n\n\nFigura¬†6: Dados de desembarque no Mercado de S√£o Pedro (Niter√≥i, RJ). Extra√≠dos de XIMENES-CARVALHO, 2006.\n\n\n\n\n\nA distribui√ß√£o de tamanhos na Figura¬†6 √© altamente assim√©trica e claramente n√£o-normal. Um dos motivos para este forte grau de assimetria deve-se ao limite inferior de captura, pois a captura e comercializa√ß√£o de animais muito pequenos √© proibida.\nSuponha que o comprimento de robalos (\\(L\\)) dispon√≠veis para compra tenha m√©dia \\(\\mu = 44.1\\) e desvio padr√£o \\(\\sigma = 13.4\\). Voc√™ compra 10 robalos escolhidos ao acaso dos que est√£o dispon√≠veis. Qual a probabilidade de que:\n\nO tamanho m√©dio de uma compra esteja acima de \\(52,4\\) cm, isto √© \\(P(\\overline{L} &gt; 52,4)\\)?\nEm \\(95\\%\\) das vezes que fizer a compra, determine o intervalo sim√©trico que conter√° o tamanho m√©dio dos robalos selecionados, isto √© \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\nResponda novamente aos itens i. e ii. no caso de sua compra constar de \\(4\\) robalos.\n\nRESOLU√á√ÉO\nAinda que a distribui√ß√£o original claramente n√£o siga uma distribui√ß√£o normal, podemos utilizar o TCL para estimarmos as probabilidades de obter uma m√©dia amostral \\(\\overline{X}\\) a determinada dist√¢ncia de \\(\\mu\\). Para isto, no entanto devemos recordar que o desvio padr√£o das m√©dias amostrais ser√° dado por: \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\).\n\n\n\n\n\n\ni. \\(P(\\overline{L} &gt; 52,4)\\)\n\n\n\n\n\nCom base no TCL, uma amostra de \\(n = 10\\) ter√° m√©dia normalmente distribu√≠da com par√¢metros \\(\\mu\\) e \\(\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{10}}\\). Podemos assim, realizar a transforma√ß√£o \\(Z\\) como segue:\n\\(Z_{\\overline{L}} = \\frac{\\overline{L} - \\mu}{\\sigma_{\\mu}} = \\frac{\\overline{L} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\\(Z_{\\overline{L}} = \\frac{52,4 - 44.1}{\\frac{13.4}{\\sqrt{10}}} = 1.96\\)\nSe buscarmos na Tabela Z, veremos que a √°rea da distribui√ß√£o normal padronizada abaixo de \\(1.96\\) √© de \\(0,975\\). Consequentemente \\(P(\\overline{L} &gt; 52,4) = 1 - 0,975 = 0,025\\)\n\n\n\n\n\n\n\n\n\nii. \\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\n\n\n\nSe o intervalo √© sim√©trico e cont√©m \\(0,95\\) das observa√ß√µes, restam \\(0,025\\) em cada uma das caudas. Vimos no item anterior que \\(z = 1,96\\) que delimita \\(0,025\\) da cauda superior. Portanto os limites aqui ser√£o dados por: \\(a = -1.96\\) e \\(b = 1.96\\). Na distribui√ß√£o original estes limites resultar√£o em:\n\\(-1,96 = \\frac{a - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: a = 44.1 -1,96 \\frac{13.4}{\\sqrt{10}} = 35.8\\) cm\ne\n\\(+1,96 = \\frac{b - 44.1}{\\frac{13.4}{\\sqrt{10}}}:: b = 44.1 +1,96 \\frac{13.4}{\\sqrt{10}} = 52.4\\) cm\n\n\n\n\n\n\n\n\n\nReduzindo para \\(n = 4\\) robalos\n\n\n\n\n\nAqui voc√™ deve repetir exatamente os passos de i. e ii. substituindo \\(n = 10\\) por \\(n = 4\\).\n\n\n\n\n\n\n\n\n\nRESOLU√á√ÉO no R:\n\n\n\n\n\n\n\\(P(\\overline{L} &gt; 52,4)\\)\n\n\npnorm(52.4, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\n\n[1] 0.02507255\n\n\n\n\\(P(a \\le \\overline{L} \\le b) = 0,95\\)\n\n\na &lt;- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = TRUE)\na\n\n[1] 35.79475\n\nb &lt;- qnorm((1-0.95)/2, \n      mean = 44.1, \n      sd = 13.4/sqrt(10), \n      lower.tail = FALSE)\nb\n\n[1] 52.40525\n\n\n\nRepita os comandos acima para \\(n = 4\\)\n\n\n\n\n\n\n\n\n\n\nAten√ß√£o\n\n\n\nNeste exerc√≠cio aplicamos o que aprendemos sobre o TCL para estimar probabilidades de eventos, assumindo a distribui√ß√£o normal das m√©dias amostaris. √â importante resaltar, no entanto, que a distribui√ß√£o altamente assim√©trica do comprimento dos robalos (Figura¬†6) e um tamanho amostral reduzido (\\(n = 10\\) e \\(n = 4\\)) dificilmente justificariam o uso do TCL como vemos na Figura¬†4.\n\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "",
    "text": "Neste tutorial, exploraremos como analisar padr√µes de associa√ß√£o entre diferentes tipos de vari√°veis em Python, utilizando o dataset de pinguins de Palmer."
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#pacotes-necess√°rios",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#pacotes-necess√°rios",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "1 Pacotes necess√°rios",
    "text": "1 Pacotes necess√°rios\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom palmerpenguins import load_penguins\nimport seaborn as sns\nimport numpy as np"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#carregando-e-preparando-os-dados",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#carregando-e-preparando-os-dados",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "2 Carregando e preparando os dados",
    "text": "2 Carregando e preparando os dados\n\npenguins = load_penguins().dropna()\npenguins.shape\n\n(333, 8)\n\n\n\n# Visualizando as primeiras linhas\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-duas-vari√°veis-qualitativas-categ√≥ricas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-duas-vari√°veis-qualitativas-categ√≥ricas",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "3 Associa√ß√£o entre Duas Vari√°veis Qualitativas (Categ√≥ricas)",
    "text": "3 Associa√ß√£o entre Duas Vari√°veis Qualitativas (Categ√≥ricas)\nQuando queremos analisar a rela√ß√£o entre duas vari√°veis categ√≥ricas, utilizamos tabelas de conting√™ncia.\n\n3.1 Exemplo: Associa√ß√£o entre Esp√©cie e Ilha\n\n# Tabela de conting√™ncia (frequ√™ncias observadas)\ncontingency_table = pd.crosstab(penguins['species'], \n                                penguins['island'])\ncontingency_table\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\n\n\n\n3.2 Frequ√™ncias Relativas\n\n# Frequ√™ncias relativas por linha (marginais)\ntotal_row = contingency_table.sum(axis=1)\nrelative_row = contingency_table.div(total_row, axis=0)\nprint(\"Frequ√™ncias relativas por linha (esp√©cie):\")\nrelative_row\n\nFrequ√™ncias relativas por linha (esp√©cie):\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.30137\n0.376712\n0.321918\n\n\nChinstrap\n0.00000\n1.000000\n0.000000\n\n\nGentoo\n1.00000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n# Frequ√™ncias relativas por coluna (marginais)\ntotal_col = contingency_table.sum(axis=0)\nrelative_col = contingency_table.div(total_col, axis=1)\nprint(\"Frequ√™ncias relativas por coluna (ilha):\")\nrelative_col\n\nFrequ√™ncias relativas por coluna (ilha):\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.269939\n0.447154\n1.0\n\n\nChinstrap\n0.000000\n0.552846\n0.0\n\n\nGentoo\n0.730061\n0.000000\n0.0\n\n\n\n\n\n\n\n\n# Frequ√™ncias relativas conjuntas\nrelative_joint = contingency_table / contingency_table.sum().sum()\nprint(\"Frequ√™ncias relativas conjuntas:\")\nrelative_joint\n\nFrequ√™ncias relativas conjuntas:\n\n\n\n\n\n\n\n\nisland\nBiscoe\nDream\nTorgersen\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n0.132132\n0.165165\n0.141141\n\n\nChinstrap\n0.000000\n0.204204\n0.000000\n\n\nGentoo\n0.357357\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n3.3 Visualiza√ß√£o: Gr√°fico de Barras Agrupadas\n\ncontingency_table.plot(kind='bar', stacked=False, figsize=(8, 6))\nplt.title(\"Associa√ß√£o entre Esp√©cie e Ilha\")\nplt.xlabel(\"Esp√©cie\")\nplt.ylabel(\"Frequ√™ncia\")\nplt.legend(title=\"Ilha\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n# Gr√°fico alternativo com Seaborn\nplt.figure(figsize=(8, 6))\nsns.countplot(data=penguins, x='species', hue='island')\nplt.title(\"Distribui√ß√£o de Esp√©cies por Ilha\")\nplt.xlabel(\"Esp√©cie\")\nplt.ylabel(\"Frequ√™ncia\")\nplt.legend(title=\"Ilha\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando a associa√ß√£o:\n- Se as propor√ß√µes fossem similares em todas as categorias, n√£o haveria associa√ß√£o\n- Diferen√ßas significativas nas propor√ß√µes indicam poss√≠vel associa√ß√£o\n- No exemplo, vemos que diferentes esp√©cies t√™m distribui√ß√µes distintas entre as ilhas"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-duas-vari√°veis-quantitativas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-duas-vari√°veis-quantitativas",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "4 Associa√ß√£o entre Duas Vari√°veis Quantitativas",
    "text": "4 Associa√ß√£o entre Duas Vari√°veis Quantitativas\nPara vari√°veis quantitativas, utilizamos correla√ß√£o e covari√¢ncia.\n\n4.1 Exemplo: Comprimento do Bico vs Massa Corporal\n\n# Gr√°fico de dispers√£o\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    s=60\n)\nplt.title(\"Associa√ß√£o entre Comprimento do Bico e Massa Corporal\")\nplt.xlabel(\"Comprimento do Bico (mm)\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n4.2 Covari√¢ncia e Correla√ß√£o\n\n# Covari√¢ncia\ncovariance = penguins[['bill_length_mm', 'body_mass_g']].cov()\nprint(\"Matriz de Covari√¢ncia:\")\ncovariance\n\nMatriz de Covari√¢ncia:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n29.906333\n2595.623304\n\n\nbody_mass_g\n2595.623304\n648372.487699\n\n\n\n\n\n\n\n\n# Correla√ß√£o de Pearson\ncorrelation = penguins[['bill_length_mm', 'body_mass_g']].corr()\nprint(\"Matriz de Correla√ß√£o:\")\ncorrelation\n\nMatriz de Correla√ß√£o:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.000000\n0.589451\n\n\nbody_mass_g\n0.589451\n1.000000\n\n\n\n\n\n\n\n\n\n4.3 Entendendo a Correla√ß√£o como Covari√¢ncia Padronizada\n\n# Padronizando as vari√°veis (Z-score)\npenguins_padr = penguins[['bill_length_mm', 'body_mass_g']].copy()\npenguins_padr = (penguins_padr - penguins_padr.mean()) / penguins_padr.std()\n\nprint(\"M√©dia das vari√°veis padronizadas:\", penguins_padr.mean().values)\nprint(\"Desvio padr√£o das vari√°veis padronizadas:\", penguins_padr.std().values)\n\nM√©dia das vari√°veis padronizadas: [-9.38855266e-16 -8.53504788e-17]\nDesvio padr√£o das vari√°veis padronizadas: [1. 1.]\n\n\n\n# A covari√¢ncia de vari√°veis padronizadas = correla√ß√£o\nprint(\"Covari√¢ncia das vari√°veis padronizadas:\")\npenguins_padr.cov()\n\nCovari√¢ncia das vari√°veis padronizadas:\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.000000\n0.589451\n\n\nbody_mass_g\n0.589451\n1.000000"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-vari√°vel-quantitativa-e-qualitativa",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#associa√ß√£o-entre-vari√°vel-quantitativa-e-qualitativa",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "5 3. Associa√ß√£o entre Vari√°vel Quantitativa e Qualitativa",
    "text": "5 3. Associa√ß√£o entre Vari√°vel Quantitativa e Qualitativa\n\n5.1 Exemplo: Massa Corporal por Esp√©cie\n\n# Resumo descritivo por grupo\ngrouped_mass = penguins.groupby('species')['body_mass_g'].describe()\ngrouped_mass\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n146.0\n3706.164384\n458.620135\n2850.0\n3362.5\n3700.0\n4000.0\n4775.0\n\n\nChinstrap\n68.0\n3733.088235\n384.335081\n2700.0\n3487.5\n3700.0\n3950.0\n4800.0\n\n\nGentoo\n119.0\n5092.436975\n501.476154\n3950.0\n4700.0\n5050.0\n5500.0\n6300.0\n\n\n\n\n\n\n\n\n# Para outra vari√°vel\ngrouped_bill = penguins.groupby('species')['bill_length_mm'].describe()\ngrouped_bill\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n146.0\n38.823973\n2.662597\n32.1\n36.725\n38.85\n40.775\n46.0\n\n\nChinstrap\n68.0\n48.833824\n3.339256\n40.9\n46.350\n49.55\n51.075\n58.0\n\n\nGentoo\n119.0\n47.568067\n3.106116\n40.9\n45.350\n47.40\n49.600\n59.6\n\n\n\n\n\n\n\n\n\n5.2 Visualiza√ß√£o: Boxplot por Grupos\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='species', y='body_mass_g', data=penguins)\nplt.title(\"Distribui√ß√£o da Massa Corporal por Esp√©cie\")\nplt.xlabel(\"Esp√©cie\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n5.3 Gr√°fico de M√©dias com Barras de Erro\n\nplt.figure(figsize=(10, 6))\nsns.pointplot(\n    data=penguins,\n    x='species',\n    y='body_mass_g',\n    capsize=0.1,\n    color='black',\n    errorbar='sd'\n)\nplt.title(\"M√©dia e Desvio Padr√£o da Massa Corporal por Esp√©cie\")\nplt.xlabel(\"Esp√©cie\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando boxplots por grupos:\n- Medianas diferentes: Indica diferen√ßas entre os grupos\n- Sobreposi√ß√£o das caixas: Grupos com distribui√ß√µes similares\n- Outliers: Valores at√≠picos em cada grupo"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#an√°lises-multivariadas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#an√°lises-multivariadas",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "6 An√°lises Multivariadas",
    "text": "6 An√°lises Multivariadas\n\n6.1 Scatter Plot com M√∫ltiplas Dimens√µes\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    size='flipper_length_mm',\n    sizes=(50, 200)\n)\nplt.title(\"Massa Corporal vs Comprimento do Bico (tamanho = comprimento da nadadeira)\")\nplt.xlabel(\"Comprimento do Bico (mm)\")\nplt.ylabel(\"Massa Corporal (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.2 Regress√£o Linear por Grupos\n\nsns.lmplot(\n    data=penguins,\n    x='bill_length_mm',\n    y='body_mass_g',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"Regress√£o Linear: Massa Corporal vs Comprimento do Bico por Esp√©cie\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.3 Pairplot: Todas as Combina√ß√µes de Vari√°veis\n\n# Matriz de gr√°ficos de dispers√£o\nsns.pairplot(\n    data=penguins,\n    vars=['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],\n    hue='species',\n    diag_kind='kde',\n    height=2.5\n)\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n6.4 Matriz de Correla√ß√£o Completa\n\n# Calcular correla√ß√µes para todas as vari√°veis num√©ricas\nnumeric_vars = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\ncorrelation_matrix = penguins[numeric_vars].corr()\n\n# Heatmap da matriz de correla√ß√£o\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    correlation_matrix,\n    annot=True,\n    cmap='coolwarm',\n    center=0,\n    square=True,\n    fmt='.2f'\n)\nplt.title(\"Matriz de Correla√ß√£o das Vari√°veis Quantitativas\")\nplt.tight_layout()\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#exemplos-adicionais-de-visualiza√ß√£o",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#exemplos-adicionais-de-visualiza√ß√£o",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "7 Exemplos Adicionais de Visualiza√ß√£o",
    "text": "7 Exemplos Adicionais de Visualiza√ß√£o\n\n7.1 Comprimento da Nadadeira vs Massa Corporal\n\nsns.lmplot(\n    data=penguins,\n    x='flipper_length_mm',\n    y='body_mass_g',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"Massa Corporal vs Comprimento da Nadadeira por Esp√©cie\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n7.2 Altura vs Comprimento do Bico\n\nsns.lmplot(\n    data=penguins,\n    x='bill_depth_mm',\n    y='bill_length_mm',\n    hue='species',\n    height=6,\n    aspect=1.2,\n    markers=['o', 's', 'D'],\n    ci=None\n)\nplt.title(\"Comprimento vs Altura do Bico por Esp√©cie\")\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#resumo-dos-tipos-de-associa√ß√£o",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#resumo-dos-tipos-de-associa√ß√£o",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "8 Resumo dos Tipos de Associa√ß√£o",
    "text": "8 Resumo dos Tipos de Associa√ß√£o\n\n\n\n\n\n\n\n\nTipos de Vari√°veis\nMedidas\nVisualiza√ß√µes\n\n\n\n\nQualitativa vs Qualitativa\nTabelas de conting√™ncia, frequ√™ncias relativas\nBarras agrupadas, countplot\n\n\nQuantitativa vs Quantitativa\nCorrela√ß√£o, covari√¢ncia\nScatter plot, pairplot\n\n\nQuantitativa vs Qualitativa\nEstat√≠sticas por grupo (m√©dia, mediana)\nBoxplot, pointplot\n\n\nMultivariada\nCorrela√ß√µes m√∫ltiplas\nPairplot, heatmap, lmplot"
  },
  {
    "objectID": "content/manipulacao-dados-python/04-medidas-associacao-python.html#dicas-pr√°ticas",
    "href": "content/manipulacao-dados-python/04-medidas-associacao-python.html#dicas-pr√°ticas",
    "title": "Medidas de Associa√ß√£o e Relacionamentos entre Vari√°veis com Python",
    "section": "9 Dicas Pr√°ticas",
    "text": "9 Dicas Pr√°ticas\n\n9.1 Escolhendo a visualiza√ß√£o adequada\n\n# Para escolher o gr√°fico certo, considere:\nprint(\"Tipos de dados:\")\nprint(penguins.dtypes)\n\nTipos de dados:\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\n\n\n9.2 Identificando correla√ß√µes interessantes\n\n# Encontrar as maiores correla√ß√µes\ncorr_matrix = penguins[numeric_vars].corr()\n# Remover a diagonal (correla√ß√£o de uma vari√°vel consigo mesma)\ncorr_matrix_clean = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n# Empilhar e ordenar por valor absoluto\ncorrelations = corr_matrix_clean.stack().sort_values(key=abs, ascending=False)\nprint(\"Correla√ß√µes mais fortes:\")\ncorrelations.head()\n\nCorrela√ß√µes mais fortes:\n\n\nflipper_length_mm  body_mass_g          0.872979\nbill_length_mm     flipper_length_mm    0.653096\n                   body_mass_g          0.589451\nbill_depth_mm      flipper_length_mm   -0.577792\n                   body_mass_g         -0.472016\ndtype: float64"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "",
    "text": "Neste tutorial, exploraremos como realizar an√°lise estat√≠stica descritiva em Python, utilizando o dataset de [pinguins de Palmer](https://allisonhorst.github.io/palmerpenguins/index.html}{target=‚Äú_blank‚Äù} para exemplificar conceitos fundamentais de estat√≠stica."
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#pacotes-necess√°rios",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#pacotes-necess√°rios",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "1 Pacotes necess√°rios",
    "text": "1 Pacotes necess√°rios\n\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#carregando-e-preparando-os-dados",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#carregando-e-preparando-os-dados",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "2 Carregando e preparando os dados",
    "text": "2 Carregando e preparando os dados\n\npenguins = load_penguins().dropna()  # Remove valores ausentes\npenguins.shape  # Verificar dimens√µes\n\n(333, 8)"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#vari√°veis-qualitativas-categ√≥ricas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#vari√°veis-qualitativas-categ√≥ricas",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "3 Vari√°veis Qualitativas (Categ√≥ricas)",
    "text": "3 Vari√°veis Qualitativas (Categ√≥ricas)\n\n3.1 Identificando tipos de dados\n\npenguins.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\n\n\n3.2 Frequ√™ncia absoluta\n\npenguins['species'].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\n\n\n3.3 Frequ√™ncia relativa\n\npenguins['species'].value_counts(normalize=True)\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\n\n\n3.4 Visualiza√ß√£o: Gr√°fico de barras\n\npenguins['species'].value_counts().plot(kind='bar')\nplt.title(\"N√∫mero de Pinguins por Esp√©cie\")\nplt.xlabel(\"Esp√©cie\")\nplt.ylabel(\"Frequ√™ncia\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n# Para outra vari√°vel categ√≥rica\npenguins['island'].value_counts().plot(kind='bar')\nplt.title(\"Distribui√ß√£o de Pinguins por Ilha\")\nplt.xlabel(\"Ilha\")\nplt.ylabel(\"Frequ√™ncia\")\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#vari√°veis-quantitativas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#vari√°veis-quantitativas",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "4 Vari√°veis Quantitativas",
    "text": "4 Vari√°veis Quantitativas\n\n4.1 Resumo descritivo b√°sico\n\npenguins['body_mass_g'].describe()\n\ncount     333.000000\nmean     4207.057057\nstd       805.215802\nmin      2700.000000\n25%      3550.000000\n50%      4050.000000\n75%      4775.000000\nmax      6300.000000\nName: body_mass_g, dtype: float64\n\n\n\n# Para todas as vari√°veis num√©ricas\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n333.000000\n333.000000\n333.000000\n333.000000\n333.000000\n\n\nmean\n43.992793\n17.164865\n200.966967\n4207.057057\n2008.042042\n\n\nstd\n5.468668\n1.969235\n14.015765\n805.215802\n0.812944\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.500000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.500000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.600000\n18.700000\n213.000000\n4775.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\n\n4.2 Visualiza√ß√£o: Histograma\n\npenguins['body_mass_g'].plot(kind='hist', \n                            bins=5, \n                            edgecolor=\"white\")\nplt.title(\"Histograma da Massa Corporal\")\nplt.xlabel(\"Massa (g)\")\nplt.ylabel(\"Frequ√™ncia\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDica\n\n\n\nInterpretando histogramas:\n- Forma: sim√©trica, assim√©trica √† esquerda/direita\n- Tend√™ncia central: onde se concentram os dados\n- Dispers√£o: qu√£o espalhados est√£o os valores"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#quartis-e-medidas-de-posi√ß√£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#quartis-e-medidas-de-posi√ß√£o",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "5 Quartis e Medidas de Posi√ß√£o",
    "text": "5 Quartis e Medidas de Posi√ß√£o\n\n5.1 Quartis individuais\n\npenguins['body_mass_g'].quantile(0.25)  # Q1\npenguins['body_mass_g'].quantile(0.50)  # Q2 (mediana)\npenguins['body_mass_g'].quantile(0.75)  # Q3\n\nnp.float64(4775.0)\n\n\n\n\n5.2 M√∫ltiplos quantis\n\npenguins['body_mass_g'].quantile([0.25, 0.5, 0.75])\n\n0.25    3550.0\n0.50    4050.0\n0.75    4775.0\nName: body_mass_g, dtype: float64\n\n\n\n\n5.3 Visualiza√ß√£o: Boxplot\n\npenguins['body_mass_g'].plot(kind='box')\nplt.title(\"Boxplot da Massa Corporal\")\nplt.ylabel(\"Massa (g)\")\nplt.show()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretando boxplots:\n- Linha central: mediana (Q2)\n- Caixa: do Q1 ao Q3 (50% dos dados centrais)\n- Whiskers: extens√£o at√© ~1.5 √ó IQR\n- Pontos isolados: poss√≠veis outliers"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-tend√™ncia-central",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-tend√™ncia-central",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "6 Medidas de Tend√™ncia Central",
    "text": "6 Medidas de Tend√™ncia Central\n\npenguins['body_mass_g'].mean()    # M√©dia aritm√©tica\npenguins['body_mass_g'].median()  # Mediana\n\nnp.float64(4050.0)\n\n\n\n\n\n\n\n\nDica\n\n\n\nQuando usar cada medida:\n- M√©dia: dados sim√©tricos, sem outliers extremos\n- Mediana: dados assim√©tricos ou com outliers"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-varia√ß√£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#medidas-de-varia√ß√£o",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "7 Medidas de Varia√ß√£o",
    "text": "7 Medidas de Varia√ß√£o\n\npenguins['body_mass_g'].std()   # Desvio padr√£o\npenguins['body_mass_g'].var()   # Vari√¢ncia\n\nnp.float64(648372.4876985418)\n\n\n\n7.1 C√°lculo manual da vari√¢ncia\n\nx = penguins['body_mass_g']\n# F√≥rmula: Œ£(xi - xÃÑ)¬≤ / (n-1)\nvariancia_manual = np.sum((x - x.mean())**2) / (len(x) - 1)\nprint(f\"Vari√¢ncia manual: {variancia_manual}\")\nprint(f\"Vari√¢ncia pandas: {x.var()}\")\n\nVari√¢ncia manual: 648372.4876985418\nVari√¢ncia pandas: 648372.4876985418"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#escore-z-padroniza√ß√£o",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#escore-z-padroniza√ß√£o",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "8 Escore-Z (Padroniza√ß√£o)",
    "text": "8 Escore-Z (Padroniza√ß√£o)\nA padroniza√ß√£o transforma os dados para m√©dia = 0 e desvio padr√£o = 1:\n\\[Z = \\frac{(X - \\mu)}{\\sigma}\\]\n\nmedia = penguins['body_mass_g'].mean()\ndesvio_padrao = penguins['body_mass_g'].std()\n\npenguins['zscore_massa'] = (penguins['body_mass_g'] - media) / desvio_padrao\n\n\n8.1 Verificando a padroniza√ß√£o\n\npenguins[['body_mass_g', 'zscore_massa']].head()\n\n\n\n\n\n\n\n\nbody_mass_g\nzscore_massa\n\n\n\n\n0\n3750.0\n-0.567621\n\n\n1\n3800.0\n-0.505525\n\n\n2\n3250.0\n-1.188572\n\n\n4\n3450.0\n-0.940192\n\n\n5\n3650.0\n-0.691811\n\n\n\n\n\n\n\n\npenguins[['body_mass_g', 'zscore_massa']].describe()\n\n\n\n\n\n\n\n\nbody_mass_g\nzscore_massa\n\n\n\n\ncount\n333.000000\n3.330000e+02\n\n\nmean\n4207.057057\n-8.535048e-17\n\n\nstd\n805.215802\n1.000000e+00\n\n\nmin\n2700.000000\n-1.871619e+00\n\n\n25%\n3550.000000\n-8.160012e-01\n\n\n50%\n4050.000000\n-1.950496e-01\n\n\n75%\n4775.000000\n7.053301e-01\n\n\nmax\n6300.000000\n2.599232e+00\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpreta√ß√£o do Z-score:\n- Z = 0: valor igual √† m√©dia\n- Z = 1: um desvio padr√£o acima da m√©dia\n- Z = -1: um desvio padr√£o abaixo da m√©dia\n- |Z| &gt; 2: valor considerado incomum"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#compara√ß√£o-visual-original-vs-padronizado",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#compara√ß√£o-visual-original-vs-padronizado",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "9 Compara√ß√£o Visual: Original vs Padronizado",
    "text": "9 Compara√ß√£o Visual: Original vs Padronizado\n\nfig, axes = plt.subplots(2, 1, figsize=(8, 6))\n\n# Histograma da vari√°vel original\naxes[0].hist(penguins['body_mass_g'], bins=20, color='skyblue', edgecolor='black')\naxes[0].set_title(\"Massa Corporal (g) - Original\")\naxes[0].set_xlabel(\"Massa (g)\")\naxes[0].set_ylabel(\"Frequ√™ncia\")\n\n# Histograma da vari√°vel padronizada\naxes[1].hist(penguins['zscore_massa'], bins=20, color='lightgreen', edgecolor='black')\naxes[1].set_title(\"Massa Corporal - Z-Score\")\naxes[1].set_xlabel(\"Escore-Z\")\naxes[1].set_ylabel(\"Frequ√™ncia\")\n\nplt.tight_layout()\nplt.show()\nplt.close('all')"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#resumo-das-medidas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#resumo-das-medidas",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "10 Resumo das Medidas",
    "text": "10 Resumo das Medidas\n\n\n\nMedida\nFun√ß√£o Python\nInterpreta√ß√£o\n\n\n\n\nM√©dia\n.mean()\nValor central (sens√≠vel a outliers)\n\n\nMediana\n.median()\nValor central (robusta a outliers)\n\n\nDesvio Padr√£o\n.std()\nDispers√£o dos dados\n\n\nVari√¢ncia\n.var()\nDispers√£o ao quadrado\n\n\nQ1, Q3\n.quantile(0.25), .quantile(0.75)\nQuartis\n\n\nM√≠nimo/M√°ximo\n.min(), .max()\nValores extremos"
  },
  {
    "objectID": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#aplica√ß√µes-pr√°ticas",
    "href": "content/manipulacao-dados-python/03-estatistica-descrtitiva-python.html#aplica√ß√µes-pr√°ticas",
    "title": "Estat√≠stica Descritiva e Visualiza√ß√£o com Python",
    "section": "11 Aplica√ß√µes Pr√°ticas",
    "text": "11 Aplica√ß√µes Pr√°ticas\n\n11.1 Identificando outliers com Z-score\n\n# Valores com |Z| &gt; 2 s√£o considerados incomuns\noutliers = penguins[np.abs(penguins['zscore_massa']) &gt; 2]\nprint(f\"Encontrados {len(outliers)} poss√≠veis outliers\")\noutliers[['species', 'body_mass_g', 'zscore_massa']]\n\nEncontrados 9 poss√≠veis outliers\n\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\nzscore_massa\n\n\n\n\n165\nGentoo\n5850.0\n2.040376\n\n\n167\nGentoo\n5850.0\n2.040376\n\n\n169\nGentoo\n6300.0\n2.599232\n\n\n185\nGentoo\n6050.0\n2.288757\n\n\n229\nGentoo\n6000.0\n2.226661\n\n\n231\nGentoo\n5950.0\n2.164566\n\n\n263\nGentoo\n5950.0\n2.164566\n\n\n267\nGentoo\n5850.0\n2.040376\n\n\n269\nGentoo\n6000.0\n2.226661\n\n\n\n\n\n\n\n\n\n11.2 Compara√ß√£o r√°pida entre vari√°veis\n\n# Estat√≠sticas descritivas para m√∫ltiplas vari√°veis\ncolunas_numericas = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\npenguins[colunas_numericas].describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\ncount\n333.000000\n333.000000\n333.000000\n333.000000\n\n\nmean\n43.992793\n17.164865\n200.966967\n4207.057057\n\n\nstd\n5.468668\n1.969235\n14.015765\n805.215802\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n\n\n25%\n39.500000\n15.600000\n190.000000\n3550.000000\n\n\n50%\n44.500000\n17.300000\n197.000000\n4050.000000\n\n\n75%\n48.600000\n18.700000\n213.000000\n4775.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html",
    "title": "Introdu√ß√£o ao Python: Estrutura da Linguagem",
    "section": "",
    "text": "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, interpretada e de prop√≥sito geral. √â amplamente utilizada em ci√™ncia de dados, desenvolvimento web, automa√ß√£o e muitas outras √°reas. Para an√°lise de dados, utilizamos principalmente as bibliotecas NumPy para computa√ß√£o num√©rica e Pandas para manipula√ß√£o de dados tabulares."
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#pacotes-essenciais",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#pacotes-essenciais",
    "title": "Introdu√ß√£o ao Python: Estrutura da Linguagem",
    "section": "1 Pacotes essenciais",
    "text": "1 Pacotes essenciais\nAntes de come√ßarmos, vamos importar os pacotes fundamentais que utilizaremos:\n\nimport math\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#opera√ß√µes-aritm√©ticas",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#opera√ß√µes-aritm√©ticas",
    "title": "Introdu√ß√£o ao Python: Estrutura da Linguagem",
    "section": "2 Opera√ß√µes aritm√©ticas",
    "text": "2 Opera√ß√µes aritm√©ticas\nPython utiliza os operadores matem√°ticos padr√£o de forma intuitiva:\n\n2 + 4\n\n6\n\n\n\n2 * 4\n\n8\n\n\n\n2 - 4\n\n-2\n\n\n\n2**4  # Potencia√ß√£o\n\n16\n\n\n\n13 / 2   # Divis√£o comum (resultado decimal)\n\n6.5\n\n\n\n13 // 2  # Divis√£o inteira\n\n6\n\n\n\n13 % 2   # M√≥dulo (resto da divis√£o)\n\n1\n\n\nPython respeita a preced√™ncia dos operadores matem√°ticos:\n\n5 * (9 + 2)\n\n55\n\n\n\n5 * 9 + 2\n\n47\n\n\n\n3 + 4**2\n\n19\n\n\n\n2.1 Fun√ß√µes matem√°ticas\nPython oferece fun√ß√µes matem√°ticas tanto no m√≥dulo math quanto no NumPy:\n\nmath.log(100)      # Logaritmo natural\nmath.log10(100)    # Logaritmo base 10\nmath.sqrt(36)      # Raiz quadrada\nmath.pi            # Constante œÄ\n\n3.141592653589793\n\n\n\nmath.sin(0.5 * math.pi)       # Seno\nmath.sin(math.radians(90))    # Seno de 90 graus\n\n1.0\n\n\nCom NumPy, temos fun√ß√µes vetorizadas:\n\nnp.log(100)\nnp.sqrt(36)\n\nnp.float64(6.0)"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#atribui√ß√£o-de-valores",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#atribui√ß√£o-de-valores",
    "title": "Introdu√ß√£o ao Python: Estrutura da Linguagem",
    "section": "3 Atribui√ß√£o de valores",
    "text": "3 Atribui√ß√£o de valores\nEm Python, atribu√≠mos valores a vari√°veis usando o operador =:\n\nx = np.log(100)\nx\n\nnp.float64(4.605170185988092)\n\n\n\ny = x + 10\ny\n\nnp.float64(14.605170185988092)\n\n\nAo reatribuir um valor, o anterior √© substitu√≠do:\n\nx = 5\ny = x + 10\ny\n\n15\n\n\nPython diferencia mai√∫sculas de min√∫sculas:\n\na = math.sqrt(49)\nA = math.sqrt(81)\na, A\n\n(7.0, 9.0)"
  },
  {
    "objectID": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#estruturas-de-dados",
    "href": "content/manipulacao-dados-python/01-estrutura-linguagem-python.html#estruturas-de-dados",
    "title": "Introdu√ß√£o ao Python: Estrutura da Linguagem",
    "section": "4 Estruturas de dados",
    "text": "4 Estruturas de dados\n\n4.1 Listas\nListas s√£o cole√ß√µes ordenadas e mut√°veis em Python:\n\nx = [4, 3.0, 5, 9, 10]\nx\n\n[4, 3.0, 5, 9, 10]\n\n\n\ntype(x)        # Tipo do objeto\nlen(x)         # Comprimento da lista\n\n5\n\n\nAcessando elementos (√≠ndices come√ßam em 0):\n\nx[0]           # Primeiro elemento\nx[0:]          # Do primeiro elemento em diante\n\n[4, 3.0, 5, 9, 10]\n\n\nImportante: Multiplicar uma lista por um n√∫mero replica a lista:\n\nx * 2          # Replica a lista duas vezes\n\n[4, 3.0, 5, 9, 10, 4, 3.0, 5, 9, 10]\n\n\n\n\n4.2 Arrays NumPy\nArrays s√£o mais eficientes para opera√ß√µes num√©ricas:\n\ny = np.array(x)\ny\n\narray([ 4.,  3.,  5.,  9., 10.])\n\n\n\ntype(y)\nlen(y)\ny[0]           # Primeiro elemento\ny[0:2]         # Primeiros dois elementos\n\narray([4., 3.])\n\n\nOpera√ß√µes em arrays s√£o elemento por elemento:\n\ny * 2          # Multiplica cada elemento por 2\n\narray([ 8.,  6., 10., 18., 20.])\n\n\nCompara√ß√£o entre listas e arrays:\n\nx * 2                    # Lista: replica\ny * 2                    # Array: multiplica cada elemento\n[i * 2 for i in x]      # List comprehension: multiplica cada elemento\n\n[8, 6.0, 10, 18, 20]\n\n\n\n\n4.3 Sequ√™ncias\nPython oferece v√°rias formas de criar sequ√™ncias:\n\nlist(range(2, 11))       # Sequ√™ncia de 2 a 10\nnp.linspace(2, 10, 4)    # 4 pontos igualmente espa√ßados entre 2 e 10\nnp.repeat(4, 6)          # Repete o valor 4 seis vezes\n\narray([4, 4, 4, 4, 4, 4])\n\n\n\n[2, 5] * 3               # Lista: replica\nnp.tile([2, 5], 3)       # Array: repete o padr√£o\n\narray([2, 5, 2, 5, 2, 5])\n\n\n\n\n4.4 Strings (cadeias de caracteres)\nStrings s√£o sequ√™ncias de caracteres:\n\nespecies = [\"Deuterodon iguape\", \n           \"Characidium japuhybense\", \n           \"Trichomycterus zonatus\"]\nespecies\n\n['Deuterodon iguape', 'Characidium japuhybense', 'Trichomycterus zonatus']\n\n\n\nsorted(especies)         # Ordena alfabeticamente\n\n['Characidium japuhybense', 'Deuterodon iguape', 'Trichomycterus zonatus']\n\n\nImportante: Python √© tipado dinamicamente, mas opera√ß√µes devem ser compat√≠veis:\n\nespecies = [\n    \"Deuterodon iguape\",\n    \"Characidium japuhybense\", \n    \"Trichomycterus zonatus\",\n    4]\n\n# especies[3] + 3  # Isso causaria erro: n√£o pode somar string com n√∫mero\n\n\n\n4.5 Arrays 2D (matrizes)\nListas de listas podem representar matrizes:\n\nx = [\n    [21, 26, 5, 18],\n    [17, 28, 20, 15],\n    [13, 14, 27, 22]\n]\n\nx\nx[0]           # Primeira linha\nx[0][0]        # Elemento da primeira linha, primeira coluna\n\n21\n\n\nArrays NumPy oferecem indexa√ß√£o mais conveniente:\n\ny = np.array(x)\ny\ny[0]           # Primeira linha\ny[0][0]        # Elemento [0,0]\ny[0, 0]        # Nota√ß√£o matricial\ny[0,:]         # Primeira linha (todas as colunas)\ny[:,0]         # Primeira coluna (todas as linhas)\n\narray([21, 17, 13])\n\n\n\n\n4.6 Dicion√°rios\nDicion√°rios armazenam pares chave-valor:\n\nnosso_dic = {\n    'Ilha' : ['Ilhabela', 'Anchieta', 'Cardoso'],\n    'Areaskm2': [347.5, 8.3, 131]\n}\nnosso_dic\nnosso_dic.keys()       # Mostra as chaves\n\ndict_keys(['Ilha', 'Areaskm2'])\n\n\n\n\n4.7 DataFrames\nDataFrames s√£o estruturas tabulares do Pandas, similares a planilhas:\n\ndf = pd.DataFrame(nosso_dic)\ndf\ndf['Ilha']             # Acessa a coluna 'Ilha'\n\n0    Ilhabela\n1    Anchieta\n2     Cardoso\nName: Ilha, dtype: object"
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html",
    "href": "content/estatistica-descritiva/escorez.html",
    "title": "Medidas de posi√ß√£o: transforma√ß√£o Z",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/normal-empirica-gg.r')\nO √≠ndice (ou escore) \\(Z\\) indica a posi√ß√£o de uma observa√ß√£o particular (\\(X_i\\)) dentro de uma distribui√ß√£o, relacionando a posi√ß√£o de \\(X_i\\) com a m√©dia e o desvio padr√£o da distribui√ß√£o de \\(X\\). Suponha uma vari√°vel com m√©dia \\(\\overline{X}\\) e desvio padr√£o \\(s\\). O √≠ndice de \\(Z_i\\) para uma observa√ß√£o \\(i\\) particular √© calculado por:\n\\[Z_i = \\frac{X_i - \\overline{X}}{s}\\]\nSeja, por exemplo, a vari√°vel \\(X\\):\nC√≥digo\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\nnX &lt;- length(X)\nsX &lt;- sort(X)\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\nCom m√©dia e desvio padr√£o \\(\\overline{X} = 10.39\\) e \\(s = 1.82\\), respectivamente.\nO √≠ndice \\(Z_i\\) para a \\(3a\\) observa√ß√£o \\(X_{3} = 8.3\\) pode ser obtido por:\nC√≥digo\ni &lt;- 3\nXm &lt;- mean(X)\nXsd &lt;- sd(X)\nZi &lt;- (X[i] - Xm) / Xsd\n\\(Z_8.3 = \\frac{8.3 - 10.39}{1.82} = -1.15\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#interpretando-o-valor-de-z",
    "href": "content/estatistica-descritiva/escorez.html#interpretando-o-valor-de-z",
    "title": "Medidas de posi√ß√£o: transforma√ß√£o Z",
    "section": "1 Interpretando o valor de \\(Z\\)",
    "text": "1 Interpretando o valor de \\(Z\\)\nO c√°lculo do √≠ndice \\(Z\\) passa pela centraliza√ß√£o e padroniza√ß√£o da vari√°vel \\(X\\):\n\nCentraliza√ß√£o: a por√ß√£o \\(X_i - \\overline{X}\\) mede o desvio de cada observa√ß√£o, isto √©, a dist√¢ncia (positiva ou negativa) entre \\(X_i\\) e \\(\\overline{X}\\). O termo centraliza√ß√£o refere-se ao comportamento dos desvios estarem distribu√≠dos ao redor de zero, isto √©, a m√©dia dos desvios √© zero.\n\n\\[\\sum_{i=1}^{n}\\frac{(X_i - \\overline{X})}{n} = 0\\]\n\nPadroniza√ß√£o: ao dividirmos a quantia \\(X_i - \\overline{X}\\) pelo desvio padr√£o de \\(X\\), obtemos a nova vari√°vel denominada \\(Z\\). O termo padroniza√ß√£o refere-se ao fato de o desvio padr√£o de \\(Z\\) ser igual a \\(1\\).\n\nA transforma√ß√£o \\(Z\\) consiste, portanto, em gerar uma nova vari√°vel com m√©dia \\(\\overline{Z} = 0\\) e desvio padr√£o \\(s_{Z} = 1\\).\nDeste modo, o valor de \\(Z_i\\) associado a uma observa√ß√£o \\(X_i\\) particular nos indica quantos desvios padr√µes \\(X_i\\) est√° acima ou abaixo da m√©dia de seu grupo.\n\n\n\n\n\n\nRela√ß√£o \\(Z\\) e \\(X\\)\n\n\n\n\nSe \\(Z_i = 0\\), ent√£o \\(X_i = \\overline{X}\\);\nSe \\(Z_i &gt; 0\\), ent√£o \\(X_i &gt; \\overline{X}\\);\nSe \\(Z_i &lt; 0\\), ent√£o \\(X_i &lt; \\overline{X}\\);\n\n\n\nPara uma distribui√ß√£o com m√©dia igual a \\(10\\) e desvio padr√£o igual a \\(3\\), por exemplo, uma observa√ß√£o \\(X_i = 16\\) ter√° um valor de \\(Z = \\frac{16-10}{3} = 2\\), indicando que est√° dois desvios padr√µes acima da m√©dia de \\(X\\)."
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#c√°lculo-de-z-no-ambiente-r",
    "href": "content/estatistica-descritiva/escorez.html#c√°lculo-de-z-no-ambiente-r",
    "title": "Medidas de posi√ß√£o: transforma√ß√£o Z",
    "section": "2 C√°lculo de \\(Z\\) no ambiente R",
    "text": "2 C√°lculo de \\(Z\\) no ambiente R\nSeja:\n\n\nC√≥digo\nset.seed(1)\nX &lt;- round(rnorm(20, 10, 2), 1)\n\n\n\\(X\\) = 8.7, 10.4, 8.3, 13.2, 10.7, 8.4, 11, 11.5, 11.2, 9.4, 13, 10.8, 8.8, 5.6, 12.2, 9.9, 10, 11.9, 11.6, 11.2\n\\(Z\\) pode ser obtido pelos comandos:\n\nXm &lt;- mean(X)\nXsd &lt;- sd(X)\nZ &lt;- (sort(X) - Xm) / Xsd\n\nPodemos ver na Tabela¬†1 os valores de cada observa√ß√£o \\(X_i\\) e dos respectivos valores de \\(Z_i\\) em ordem crescente.\n\n\nC√≥digo\nPosicao_k &lt;- paste(1:length(X), \"a Posi√ß√£o\", sep = \"\")\ndf &lt;- tibble(`Posicao k` = Posicao_k, `X ordenado` = sX, Z = round(Z, 2)) |&gt;\n  add_row(\n    `Posicao k` = c(\"M√©dia\", \"Desvio padr√£o\"),\n    `X ordenado` = c(round(mean(sX), 2), round(sd(sX), 2)),\n    Z = c(round(mean(Z), 2), round(sd(Z), 2))\n  )\n\ndf |&gt;\n  gt()\n\n\n\n\nTabela¬†1: Associa√ß√£o entre uma distribui√ß√£o X e a transforma√ß√£o Z.\n\n\n\n\n\n\n\n\n\nPosicao k\nX ordenado\nZ\n\n\n\n\n1a Posi√ß√£o\n5.60\n-2.63\n\n\n2a Posi√ß√£o\n8.30\n-1.15\n\n\n3a Posi√ß√£o\n8.40\n-1.09\n\n\n4a Posi√ß√£o\n8.70\n-0.93\n\n\n5a Posi√ß√£o\n8.80\n-0.87\n\n\n6a Posi√ß√£o\n9.40\n-0.54\n\n\n7a Posi√ß√£o\n9.90\n-0.27\n\n\n8a Posi√ß√£o\n10.00\n-0.21\n\n\n9a Posi√ß√£o\n10.40\n0.01\n\n\n10a Posi√ß√£o\n10.70\n0.17\n\n\n11a Posi√ß√£o\n10.80\n0.23\n\n\n12a Posi√ß√£o\n11.00\n0.34\n\n\n13a Posi√ß√£o\n11.20\n0.45\n\n\n14a Posi√ß√£o\n11.20\n0.45\n\n\n15a Posi√ß√£o\n11.50\n0.61\n\n\n16a Posi√ß√£o\n11.60\n0.66\n\n\n17a Posi√ß√£o\n11.90\n0.83\n\n\n18a Posi√ß√£o\n12.20\n0.99\n\n\n19a Posi√ß√£o\n13.00\n1.43\n\n\n20a Posi√ß√£o\n13.20\n1.54\n\n\nM√©dia\n10.39\n0.00\n\n\nDesvio padr√£o\n1.82\n1.00\n\n\n\n\n\n\n\n\n\n\nPodemos comparar graficamente as distribui√ß√µes das vari√°veis \\(X\\) e \\(Z\\).\n\n\nC√≥digo\nhX &lt;- ggplot(df, aes(x = `X ordenado`)) +\n  geom_histogram(fill = 'darkblue', color = 'white', bins = 9) +\n  ylab('Frequ√™ncia') +\n  scale_x_continuous(n.breaks = 7) +\n  theme_classic(base_size = 20)\n\nhZ &lt;- ggplot(df, aes(x = Z)) +\n  geom_histogram(fill = 'darkblue', color = 'white', bins = 9) +\n  ylab('Frequ√™ncia') +\n  scale_x_continuous(n.breaks = 7) +\n  theme_classic(base_size = 20)\n\nhX / hZ\n\n\n\n\n\n\n\n\nFigura¬†1: Histogramas representando a distribui√ß√£o de X e Z.\n\n\n\n\n\nVeja na Tabela¬†1 que conforme o valor de \\(X_i\\) se distancia da m√©dia de \\(X = 10.39\\), mais distante de zero ser√° o valor de \\(Z_i\\). Neste exemplo, as observa√ß√µes mais extremas de \\(X\\) est√£o, respectivamente, a -2.63 desvios padr√µes abaixo e 1.54 desvios padr√µes acima da m√©dia. Como discutido acima, a nova vari√°vel \\(Z\\) tem m√©dia \\(\\overline{Z} = 0\\) (est√° centralizada) e desvio padr√£o \\(s_Z = 1\\) (est√° padronizada)."
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#obtendo-a-transforma√ß√£o-z-a-partir-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/escorez.html#obtendo-a-transforma√ß√£o-z-a-partir-de-uma-tabela-de-dados",
    "title": "Medidas de posi√ß√£o: transforma√ß√£o Z",
    "section": "3 Obtendo a transforma√ß√£o \\(Z\\) a partir de uma tabela de dados",
    "text": "3 Obtendo a transforma√ß√£o \\(Z\\) a partir de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUtilizando a fun√ß√£o mutate, vamos manter somente a vari√°vel CPUE e criar outra coluna denominada CPUE_z.\n\ndf_z &lt;- res |&gt; \n  select(CPUE) |&gt; \n  mutate(CPUE_z = (CPUE - mean(CPUE)) / sd(CPUE)) |&gt; \n  round(2)\n\ndf_z |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE\nCPUE_z\n\n\n\n\n9.22\n-0.47\n\n\n28.73\n2.17\n\n\n11.59\n-0.15\n\n\n30.76\n2.45\n\n\n5.95\n-0.92\n\n\n7.75\n-0.67\n\n\n7.51\n-0.70\n\n\n4.01\n-1.18\n\n\n20.83\n1.10\n\n\n2.43\n-1.39\n\n\n12.55\n-0.02\n\n\n11.73\n-0.13\n\n\n13.72\n0.14\n\n\n16.50\n0.52\n\n\n4.71\n-1.08\n\n\n7.95\n-0.64\n\n\n13.12\n0.06\n\n\n16.10\n0.46\n\n\n11.74\n-0.13\n\n\n17.95\n0.71\n\n\n13.86\n0.16\n\n\n13.04\n0.05\n\n\n7.35\n-0.73\n\n\n20.92\n1.12\n\n\n13.67\n0.13\n\n\n21.82\n1.24\n\n\n6.29\n-0.87\n\n\n9.40\n-0.45\n\n\n5.60\n-0.96\n\n\n2.05\n-1.45\n\n\n24.88\n1.65\n\n\n\n\n\n\n\nSe calcularmos a m√©dia e o desvio padr√£o das vari√°veis, veremos que CPUE mant√©m os valores originais, enquanto CPUE_z ter√° m√©dia igual a \\(0\\) e desvio padr√£o igual a \\(1\\).\n\ndf_z |&gt; \n  summarize(CPUE_media = mean(CPUE),\n            CPUE_dp = sd(CPUE),\n            CPUE_z_media = round(mean(CPUE_z), 2),\n            CPUE_z_dp = round(sd(CPUE_z), 2)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_media\nCPUE_dp\nCPUE_z_media\nCPUE_z_dp\n\n\n\n\n12.70097\n7.3701\n0\n1"
  },
  {
    "objectID": "content/estatistica-descritiva/escorez.html#valores-esperados-de-z-em-uma-distribui√ß√£o-normal-padronizada",
    "href": "content/estatistica-descritiva/escorez.html#valores-esperados-de-z-em-uma-distribui√ß√£o-normal-padronizada",
    "title": "Medidas de posi√ß√£o: transforma√ß√£o Z",
    "section": "4 Valores esperados de \\(Z\\) em uma distribui√ß√£o normal padronizada",
    "text": "4 Valores esperados de \\(Z\\) em uma distribui√ß√£o normal padronizada\nA interpreta√ß√£o de \\(Z\\) faz sentido quando desejamos posicionar uma determinada observa√ß√£o \\(X_i\\) como fun√ß√£o da m√©dia e desvio padr√£o de seu grupo. Adicionalmente, se uma vari√°vel \\(X\\) puder ser descrita adequadamente por uma distribui√ß√£o normal de probabilidades, existe uma regra emp√≠rica que permite determinar os percentuais das observa√ß√µes acima e abaixo de limites conhecidos.\n\n\nC√≥digo\n# Ver fun√ß√£o completa no arquivo 'scripts/normal-empirica-gg.r'\nnormal_empirica_gg()\n\n\n\n\n\n\n\n\nFigura¬†2: √Åreas de probabilidade em uma distribui√ß√£o normal.\n\n\n\n\n\nNa Figura¬†2, vemos que existe uma probabilidade de aproximadamente \\(68\\%\\) de que uma observa√ß√£o tomada ao acaso esteja entre os limites de \\(-1\\) e \\(1\\) desvios padr√µes da m√©dia. Existe ainda uma probabilidade de aproximadamente \\(95\\%\\) de que uma observa√ß√£o esteja entre \\(-2\\) e \\(2\\) desvios padr√µes da m√©dia. Por outro lado, √© muito improv√°vel encontrarmos ao acaso uma observa√ß√£o a mais de \\(3\\) desvios padr√µes distantes da m√©dia. Isto dever√° ocorrer em somente cerca de \\(0,26\\%\\) dos casos em que sortearmos uma amostra aleatoriamente.\n\n\n\n\n\n\nUso da distribui√ß√£o normal emp√≠rica\n\n\n\nSuponha que a distribui√ß√£o de altura de homens adultos siga uma distribui√ß√£o normal com m√©dia \\(\\mu = 175\\) cm e desvio padr√£o \\(\\sigma = 10\\) cm.\n\n\nC√≥digo\nmH &lt;- 175\nsdH &lt;- 10\nlim &lt;- 2\nlinf &lt;- round(mH - lim * sdH, 2)\nlsup &lt;- round(mH + lim * sdH, 2)\n\n\nNeste caso, se tomarmos os limites entre \\(-2\\) e \\(+2\\) desvios padr√µes teremos:\n\\(\\mu - 2 \\times \\sigma = 175 - 2 \\times 10 = 155\\) cm\ne\n\\(\\mu + 2 \\times \\sigma = 175 + 2 \\times 10 = 195\\) cm\nEstes resultados sugerem que nesta popula√ß√£o temos somente cerca de \\(5\\%\\) dos homens adultos com mais de \\(195\\) cm ou menos de \\(155\\) cm de altura."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html",
    "href": "content/estatistica-descritiva/tendcentral.html",
    "title": "Medidas de tend√™ncia central",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nsource('scripts/getmode.r')\nsource('scripts/assimetria-ggplot.r')\nTabelas de frequ√™ncia e histogramas permitem a visualiza√ß√£o dos padr√µes de distribui√ß√£o de uma vari√°vel quantitativa, evidenciando limites inferiores e superiores, faixas de valores mais ou menos frequentes etc. Neste cap√≠tulo, veremos medidas-resumo que possibilitam descrever a tend√™ncia central de um conjunto de dados. Algumas dessas medidas s√£o a m√©dia aritm√©tica, a mediana, a moda e o ponto m√©dio."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#m√©dia-aritm√©tica",
    "href": "content/estatistica-descritiva/tendcentral.html#m√©dia-aritm√©tica",
    "title": "Medidas de tend√™ncia central",
    "section": "1 M√©dia aritm√©tica",
    "text": "1 M√©dia aritm√©tica\nConsidere a vari√°vel \\(X\\) com \\(n\\) elementos \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(\\cdots, X_n\\). A m√©dia aritm√©tica (\\(\\overline{X}\\)) √© dada por:\n\\[\\overline{X}=\\frac{X_1+X_2+X_3+\\cdots+X_n}{n}=\\frac{\\sum_{i=1}^n{X_i}}{n}\\]\nExemplo\nSeja a vari√°vel \\(X\\) abaixo:\n\n\nC√≥digo\nn &lt;- 5\nset.seed(1)\nX &lt;- sample(x = 1:10, size = n, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2}\n\\(X\\) possui 5 observa√ß√µes e tem m√©dia:\n\\(\\overline{X}=\\frac{9 + 4 + 7 + 1 + 2}{5}\\)\n\\(\\overline{X}=\\frac{23}{5} = 4.6\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#mediana",
    "href": "content/estatistica-descritiva/tendcentral.html#mediana",
    "title": "Medidas de tend√™ncia central",
    "section": "2 Mediana",
    "text": "2 Mediana\n√â definida como o valor do meio de uma distribui√ß√£o, de modo que metade dos valores est√° abaixo e metade acima da mediana. Se organizarmos a vari√°vel \\(X\\) em ordem crescente teremos:\n\n\nC√≥digo\nX &lt;- sort(X)\nXmed &lt;- median(X)\n\n\n\\(X =\\) {1,2 , 4 , 7,9}\nsendo a mediana igual a \\(4\\).\nNeste exemplo, temos \\(n = 5\\) observa√ß√µes. Se tivermos um n√∫mero par de observa√ß√µes, teremos duas na posi√ß√£o central. Por exemplo, se:\n\n\nC√≥digo\nset.seed(1)\nX &lt;- sample(x = 1:10, size = 6, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2, 7}\nvemos que ap√≥s ordenarmos \\(X\\):\n\\(X =\\) {1, 2, 4, 7, 7, 9}\nteremos o \\(4\\) e o \\(7\\) como valores do meio.\nNeste caso, a mediana fica como sendo:\n\\(\\frac{4 + 7}{2} = 5.5\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#moda",
    "href": "content/estatistica-descritiva/tendcentral.html#moda",
    "title": "Medidas de tend√™ncia central",
    "section": "3 Moda",
    "text": "3 Moda\n√â definida como o valor mais frequente de uma distribui√ß√£o.\n\n\nC√≥digo\nset.seed(1)\nX &lt;- sample(x = 1:10, size = 6, rep = TRUE)\n\n\nPara \\(X =\\) {9, 4, 7, 1, 2, 7}, a moda √© 7, o valor que mais se repete na distribui√ß√£o.\n\n\n\n\n\n\nNota\n\n\n\nA moda nem sempre √© √∫nica. Se v√°rios valores repetem-se igualmente, teremos mais de uma moda na distribui√ß√£o."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#ponto-m√©dio",
    "href": "content/estatistica-descritiva/tendcentral.html#ponto-m√©dio",
    "title": "Medidas de tend√™ncia central",
    "section": "4 Ponto m√©dio",
    "text": "4 Ponto m√©dio\n√â calculado com base nos dois valores extremos da distribui√ß√£o (m√≠nimo e m√°ximo), sendo obtido por:\n\\[P_{medio}=\\frac{X_{minimo} + X_{maximo}}{2}\\]\nPara \\(X =\\) {9, 4, 7, 1, 2, 7}, o ponto m√©dio √©:\n\\(PM = \\frac{1 + 9}{2} = \\frac{10}{2} = 5\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#efeito-da-assimetria-sobre-os-descritores-de-tend√™ncia-central",
    "href": "content/estatistica-descritiva/tendcentral.html#efeito-da-assimetria-sobre-os-descritores-de-tend√™ncia-central",
    "title": "Medidas de tend√™ncia central",
    "section": "5 Efeito da assimetria sobre os descritores de tend√™ncia central",
    "text": "5 Efeito da assimetria sobre os descritores de tend√™ncia central\nCada um dos descritores de tend√™ncia central descritos acima √© mais ou menos sens√≠vel ao grau de assimetria de uma distribui√ß√£o. Em uma distribui√ß√£o perfeitamente sim√©trica, onde as observa√ß√µes est√£o igualmente dispersas acima e abaixo do ponto central, os valores da m√©dia, mediana, moda e ponto m√©dio coincidem. Por outro lado, pode ocorrer da distribui√ß√£o ser assim√©trica. Neste caso, a posi√ß√£o relativa dos descritores ir√° depender se a assimetria √© √† direita ou √† esquerda. Esta discrep√¢ncia ocorre devido √† sensibilidade destes descritores a valores extremos na distribui√ß√£o. O ponto m√©dio √© o mais sens√≠vel √† presen√ßa de pontos extremos, seguido da m√©dia, mediana e moda.\n\n\nC√≥digo\n# Ver fun√ß√£o completa no arquivo 'scripts/assimetria-ggplot.r'\nassimetria_ggplot()\n\n\n\n\n\n\n\n\nFigura¬†1: Efeito da assimetria de uma distribui√ß√£o sobre o ponto m√©dio, a m√©dia aritm√©tica, a mediana e a moda.\n\n\n\n\n\n\n\n\n\n\n\nMedidas de tend√™ncia central\n\n\n\nM√©dia aritm√©tica: utiliza todo o conjunto de dados. Relativamente sens√≠vel a valores extremos;\nMediana: o valor do meio. Metade dos pontos est√° acima e metade abaixo da mediana. A mediana √© uma medida resistente a valores extremos;\nModa: valor mais frequente. Se mais de um valor aparece com a mesma frequ√™ncia, os dados t√™m uma distribui√ß√£o multimodal;\nPonto m√©dio: considera somente o valor m√≠nimo e m√°ximo. O ponto m√©dio √© f√°cil de calcular, por√©m n√£o utiliza a maioria do conjunto de dados e √© muito sens√≠vel a valores extremos."
  },
  {
    "objectID": "content/estatistica-descritiva/tendcentral.html#obtendo-medidas-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/tendcentral.html#obtendo-medidas-de-uma-tabela-de-dados",
    "title": "Medidas de tend√™ncia central",
    "section": "6 Obtendo medidas de uma tabela de dados",
    "text": "6 Obtendo medidas de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nMedidas-resumo podem ser obtidas com a fun√ß√£o summarise.\nVamos encontrar a m√©dia aritm√©tica e a mediana da vari√°vel CPUE.\n\nres |&gt; \n  summarise(CPUE_medio = mean(CPUE),\n            CPUE_mediana = median(CPUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\n\n\n\n\n12.70097\n11.74\n\n\n\n\n\n\n\nOs valores s√£o parecidos, por√©m a m√©dia √© um pouco superior. Provavelmente a distribui√ß√£o deve ser ligeiramente assim√©trica √† direita. Podemos verificar isto por meio de um histograma.\n\ncl_cpue &lt;- seq(0, 35, by = 5)\n\nggplot(res, aes(x = CPUE)) +\n  geom_histogram(breaks = cl_cpue, \n                 fill = 'darkblue',\n                 color = 'white') +\n  theme_classic()\n\n\n\n\n\n\n\n\nAlguns valores de captura pr√≥ximos a \\(30\\) kg est√£o fazendo com que a m√©dia esteja um pouco acima da mediana.\nVamos verificar agora a m√©dia da vari√°vel Area dos reservat√≥rios:\n\nres |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\n\n\n\n\n64.7369\n12\n\n\n\n\n\n\n\nPara esta vari√°vel, a discrep√¢ncia √© muito maior.\n\n\nobs: tivemos que utilizar o argumento na.rm = TRUE para excluir do c√°lculo reservat√≥rios com dados faltantes para Area.\n\n\n\ncl_area &lt;- seq(0, 500, by = 50)\n\nggplot(res, aes(x = Area)) +\n  geom_histogram(breaks = cl_area, \n                 fill = 'darkblue',\n                 color = 'white') +\n  theme_classic()\n\n\n\n\n\n\n\n\nAo verificar o histograma, vemos que existe uma grande concentra√ß√£o de reservat√≥rios com √°reas at√© \\(50\\) \\(km^2\\), por√©m poucos reservat√≥rios muito grandes com mais de \\(200\\) \\(km^2\\). Estes grandes reservat√≥rios deslocam a m√©dia aritm√©tica √† direita.\nPodemos ver quais s√£o estes reservat√≥rios utilizando a fun√ß√£o filter.\n\nr_grandes &lt;- res |&gt; \n  filter(Area &gt;= 200) |&gt; \n  select(Reservatorio, Area)\n\nr_grandes |&gt; \n  gt()\n\n\n\n\n\n\n\nReservatorio\nArea\n\n\n\n\nSalto Santiago\n208.0\n\n\nCapivara\n419.3\n\n\nChavantes\n400.0\n\n\nRosana\n220.0\n\n\n\n\n\n\n\nEntre os 31 reservat√≥rios, temos 4 com √°reas acima de \\(200\\) \\(km^2\\) (Salto Santiago, Capivara, Chavantes, Rosana). A influ√™ncia destes reservat√≥rios √© maior para a m√©dia aritm√©tica, pois esta √© mais sens√≠vel a valores extremos do que a mediana. Se calcularmos o ponto m√©dio, veremos que esta influ√™ncia √© ainda maior.\n\nres |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE),\n            P_medio = sum(range(Area, na.rm = TRUE)) / 2) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\nP_medio\n\n\n\n\n64.7369\n12\n209.685\n\n\n\n\n\n\n\nSe calcularmos os descritores de tend√™ncia central sem estes reservat√≥rios, vemos que a diferen√ßa entre os descritores diminui, mas n√£o desaparece, o que ocorre devido √† elevada assimetria nesta vari√°vel.\n\nres |&gt; \n  filter(Area &lt; 200) |&gt; \n  summarise(CPUE_medio = mean(Area, na.rm = TRUE),\n            CPUE_mediana = median(Area, na.rm = TRUE),\n            P_medio = sum(range(Area, na.rm = TRUE)) / 2) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_medio\nCPUE_mediana\nP_medio\n\n\n\n\n25.2028\n7.2\n69.535"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html",
    "href": "content/estatistica-descritiva/variacao.html",
    "title": "Medidas de varia√ß√£o",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizados\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nAs medidas de varia√ß√£o indicam o grau de dispers√£o das observa√ß√µes. Distribui√ß√µes com observa√ß√µes muito pr√≥ximas √† m√©dia t√™m baixo grau de dispers√£o, enquanto aquelas com observa√ß√µes muito distantes da m√©dia t√™m alto grau de dispers√£o. Vamos apresentar quatro √≠ndices que medem o grau de dispers√£o: a vari√¢ncia, o desvio padr√£o, o coeficiente de varia√ß√£o e a amplitude de varia√ß√£o."
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#vari√¢ncia-amostral",
    "href": "content/estatistica-descritiva/variacao.html#vari√¢ncia-amostral",
    "title": "Medidas de varia√ß√£o",
    "section": "1 Vari√¢ncia amostral",
    "text": "1 Vari√¢ncia amostral\nA vari√¢ncia amostral, descrita pelo s√≠mbolo \\(s^2\\), mede qu√£o distantes as observa√ß√µes em uma vari√°vel est√£o de sua m√©dia aritm√©tica.\nPara um conjunto de observa√ß√µes, \\(s^2\\) √© dada por:\n\\[s^2=\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}\\]\nSeja a vari√°vel \\(X\\) abaixo:\n\n\nC√≥digo\nn &lt;- 5\nset.seed(1)\nX &lt;- sample(x = 1:10, size = n, rep = TRUE)\n\n\n\\(X =\\) {9, 4, 7, 1, 2}\n\\(X\\) tem 5 observa√ß√µes:\nPara calcularmos \\(s^2\\), devemos inicialmente obter a m√©dia de \\(X\\), que neste caso √©:\n\\(\\overline{X} = 4.6\\)\nE subtrair cada observa√ß√£o da m√©dia:\n\n\nC√≥digo\ndf &lt;- data.frame(X) |&gt; \n  mutate(dif = X - mean(X)) |&gt; \n  as.data.frame() # Garantir que √© um data frame simples\n\ndf |&gt; \n  knitr::kable(col.names = c('$X$', '$X - \\\\overline{X}$'))\n\n\n\n\n\n\\(X\\)\n\\(X - \\overline{X}\\)\n\n\n\n\n9\n4.4\n\n\n4\n-0.6\n\n\n7\n2.4\n\n\n1\n-3.6\n\n\n2\n-2.6\n\n\n\n\n\nEm seguida, elevamos cada diferen√ßa ao quadrado:\n\n\nC√≥digo\ndf &lt;- df |&gt; \n  mutate(dif = X - mean(X)) |&gt; \n  mutate(dif2 = dif^2)\n\ndf |&gt; \n  knitr::kable(col.names = c('$X$',\n                             '$X - \\\\overline{X}$',\n                             '${(X - \\\\overline{X})}^{2}$'))\n\n\n\n\n\n\\(X\\)\n\\(X - \\overline{X}\\)\n\\({(X - \\overline{X})}^{2}\\)\n\n\n\n\n9\n4.4\n19.36\n\n\n4\n-0.6\n0.36\n\n\n7\n2.4\n5.76\n\n\n1\n-3.6\n12.96\n\n\n2\n-2.6\n6.76\n\n\n\n\n\nSe somarmos essas quantias e dividirmos por \\(n-1\\), teremos a vari√¢ncia amostral como:\n\\(s^2 = \\frac{19.36 + 0.36 + 5.76 + 12.96 + 6.76}{5 - 1} = \\frac{45.2}{4} = 11.3\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#desvio-padr√£o-amostral",
    "href": "content/estatistica-descritiva/variacao.html#desvio-padr√£o-amostral",
    "title": "Medidas de varia√ß√£o",
    "section": "2 Desvio padr√£o amostral",
    "text": "2 Desvio padr√£o amostral\nO desvio padr√£o amostral (\\(s\\)) √© a raiz quadrada da vari√¢ncia amostral.\n\\[s=\\sqrt{\\frac{\\sum_{i=1}^n{(X_i - \\overline{X})^2}}{n-1}}\\]\nE em nosso exemplo:\n\\(s = \\sqrt{11.3} = 3.36\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#coeficiente-de-varia√ß√£o",
    "href": "content/estatistica-descritiva/variacao.html#coeficiente-de-varia√ß√£o",
    "title": "Medidas de varia√ß√£o",
    "section": "3 Coeficiente de varia√ß√£o",
    "text": "3 Coeficiente de varia√ß√£o\nO coeficiente de varia√ß√£o (cv) relaciona o desvio padr√£o √† m√©dia, sendo definido por:\n\\[cv = s/\\overline{X}\\] ou \\[cv_{\\%}  = s/\\overline{X}\\cdot 100\\]\nEm nosso exemplo:\n\\(cv = \\frac{3.36}{4.6} \\cdot 100 = 73.08\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#amplitude-de-varia√ß√£o",
    "href": "content/estatistica-descritiva/variacao.html#amplitude-de-varia√ß√£o",
    "title": "Medidas de varia√ß√£o",
    "section": "4 Amplitude de varia√ß√£o",
    "text": "4 Amplitude de varia√ß√£o\n√â a diferen√ßa entre os pontos m√°ximo e m√≠nimo de um grupo de observa√ß√µes.\nAmplitude de varia√ß√£o = \\(X_{maximo} - X_{minimo}\\)\nque em nosso exemplo √©:\nAmplitude de varia√ß√£o = \\(9 - 1 = 8\\)"
  },
  {
    "objectID": "content/estatistica-descritiva/variacao.html#obtendo-medidas-de-varia√ß√£o-de-uma-tabela-de-dados",
    "href": "content/estatistica-descritiva/variacao.html#obtendo-medidas-de-varia√ß√£o-de-uma-tabela-de-dados",
    "title": "Medidas de varia√ß√£o",
    "section": "5 Obtendo medidas de varia√ß√£o de uma tabela de dados",
    "text": "5 Obtendo medidas de varia√ß√£o de uma tabela de dados\nImporte a base de dados Reservatorios_Parana_parcial.csv.\n\nres &lt;- read_delim(\n  file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n  delim = \",\",\n  locale = locale(decimal_mark = \".\", encoding = \"latin1\")\n)\n\nUsaremos a fun√ß√£o summarise para obter descritores de varia√ß√£o para a vari√°vel CPUE.\n\nres |&gt; \n  summarise(CPUE_var = var(CPUE),\n            CPUE_dp = sd(CPUE),\n            CPUE_cv = sd(CPUE) / mean(CPUE) * 100,\n            CPUE_amplitude = max(CPUE) - min(CPUE)) |&gt; \n  gt()\n\n\n\n\n\n\n\nCPUE_var\nCPUE_dp\nCPUE_cv\nCPUE_amplitude\n\n\n\n\n54.31838\n7.3701\n58.02786\n28.71"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#conte√∫do-da-aula",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#conte√∫do-da-aula",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Conte√∫do da Aula",
    "text": "Conte√∫do da Aula\n\n\nIntrodu√ß√£o √† Regress√£o Linear Simples\nDefini√ß√£o dos Res√≠duos\nM√©todo dos M√≠nimos Quadrados\nRepresenta√ß√£o Vetorial dos Res√≠duos\nGeometria da Solu√ß√£o de M√≠nimos Quadrados\nSolu√ß√£o Matricial do M√©todo dos M√≠nimos Quadrados\nValores preditos\nSoma dos quadrados dos res√≠duos\nSoma dos quadrados dos totais\nCoeficiente de determina√ß√£o"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#introdu√ß√£o-√†-regress√£o-linear-simples",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#introdu√ß√£o-√†-regress√£o-linear-simples",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Introdu√ß√£o √† Regress√£o Linear Simples",
    "text": "Introdu√ß√£o √† Regress√£o Linear Simples\nA regress√£o linear simples √© um m√©todo para modelar a rela√ß√£o entre uma vari√°vel dependente \\(y\\) e uma vari√°vel independente \\(x\\). A equa√ß√£o da reta ajustada √© dada por:\n\\[ \\hat{y} = \\beta_0 + \\beta_1 x \\]\n\n\n\n\n\n\nObserva√ß√£o\n\\(x_i\\)\n\\(y_i\\)\n\n\n\n\n\\(1\\)\n\\(x_1\\)\n\\(y_1\\)\n\n\n\\(2\\)\n\\(x_2\\)\n\\(y_2\\)\n\n\n\\(3\\)\n\\(x_3\\)\n\\(y_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#defini√ß√£o-dos-res√≠duos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#defini√ß√£o-dos-res√≠duos",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Defini√ß√£o dos Res√≠duos",
    "text": "Defini√ß√£o dos Res√≠duos\nNa figura abaixo, os res√≠duos \\(e_i\\) representam as diferen√ßas entre os valores observados \\(y_i\\) e os valores ajustados \\(\\hat{y}_i\\) pela reta de regress√£o:\n\\[ e_i = y_i - (\\beta_0 + \\beta_1 x_i) \\]\nPortando na regress√£o linear, assume-se que o valor observado em \\(y_i\\) √© dado por:\n\\[ y_i = \\beta_0 + \\beta_1 x_i + e_i\\]\n\n\n\n\n\n\nDica\n\n\n\n\nAcesse o link Regres√£o linear Geogebra\n\n\n\n\n\nObserva√ß√£o\n\\(x_i\\)\n\\(y_i\\)\n\n\n\n\n\\(1\\)\n\\(x_1\\)\n\\(y_1\\)\n\n\n\\(2\\)\n\\(x_2\\)\n\\(y_2\\)\n\n\n\\(3\\)\n\\(x_3\\)\n\\(y_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#m√©todo-dos-m√≠nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#m√©todo-dos-m√≠nimos-quadrados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "M√©todo dos M√≠nimos Quadrados",
    "text": "M√©todo dos M√≠nimos Quadrados\nO M√©todo dos M√≠nimos Quadrados busca minimizar a soma dos quadrados dos res√≠duos:\n\\[ SQ_{res} = \\sum_{i=1}^{n} e_i^2 = e_1^2 + e_2^2 + \\cdots + e_n^2 \\]\nQue pode ser representada como:\n\\[\n\\begin{cases}\ne_1 = y_1 - (\\beta_0 + \\beta_1 x_1) \\\\\ne_2 = y_2 - (\\beta_0 + \\beta_1 x_2) \\\\\n\\vdots \\\\\ne_n = y_n - (\\beta_0 + \\beta_1 x_n) \\\\\n\\end{cases}\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#representa√ß√£o-vetorial-dos-res√≠duos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#representa√ß√£o-vetorial-dos-res√≠duos",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Representa√ß√£o Vetorial dos Res√≠duos",
    "text": "Representa√ß√£o Vetorial dos Res√≠duos\nPodemos portanto representar os res√≠duos como vetor em que o vetor \\(\\vec{e}\\) √© igual ao vetor \\(y\\) menos uma combina√ß√£o linear dos vetores \\(\\vec{f}_0\\) e \\(\\vec{f}_0\\) com constantes \\(\\beta_0\\) e \\(\\beta_1\\).\n\n\\[ \\vec{e} = \\vec{y} - (\\beta_0 \\vec{f}_0 + \\beta_1 \\vec{f}_1) \\]\n\n\n\\[\n\\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\ny_1 - (\\beta_0 + \\beta_1 x_1) \\\\\ny_2 - (\\beta_0 + \\beta_1 x_2) \\\\\n\\vdots \\\\\ny_n - (\\beta_0 + \\beta_1 x_n) \\\\\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{array} \\right]\n-\n\\left(\n\\beta_0\n\\left[ \\begin{array}{c}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{array} \\right]\n+\n\\beta_1\n\\left[ \\begin{array}{c}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{array} \\right]\n\\right)\n\\]\nOnde:\n\\[\\vec{e} =\n\\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right];\n\\vec{y} =\n\\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\n\\vec{f}_0 =\n\\left[ \\begin{array}{c}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{array} \\right];\n\\vec{f}_1 =\n\\left[ \\begin{array}{c}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n \\\\\n\\end{array} \\right]\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-solu√ß√£o-de-m√≠nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-solu√ß√£o-de-m√≠nimos-quadrados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Geometria da Solu√ß√£o de M√≠nimos Quadrados",
    "text": "Geometria da Solu√ß√£o de M√≠nimos Quadrados\nA Soma dos quadrados dos res√≠duos (\\(SQ_{res}\\)) pode ser obtida pela norma ao quadrado do vetor \\(\\vec{e}\\):\n\\[SQ_{res} = \\Vert\\vec{e}\\Vert^{2}=\\vec{e}\\cdot\\vec{e}=e_{1}^{2}+e_{2}^{2}+\\cdots+e_{n}^{2}\\]\n\n\n\n\n\n\n\n\nRepresenta√ß√£o da Solu√ß√£o do MMQ no GeoGebra\n\n\nO M√©todo dos M√≠nimos Quadrados determina \\(\\beta_0\\) e \\(\\beta_1\\) de modo a minimizar o comprimento (a norma) do vetor \\(\\vec{e}\\) que pode ser obtida impondo que o vetor \\(\\vec{e}\\) seja ortogonal aos vetores \\(\\vec{f_0}\\) e \\(\\vec{f_1}\\), ou seja:\n\\[ \\vec{f_0} \\cdot \\vec{e} = 0 \\] \\[ \\vec{f_1} \\cdot \\vec{e} = 0 \\]\nLink para solu√ß√£o vetorial do MMQ"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-solu√ß√£o-de-m√≠nimos-quadrados-1",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#geometria-da-solu√ß√£o-de-m√≠nimos-quadrados-1",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Geometria da Solu√ß√£o de M√≠nimos Quadrados",
    "text": "Geometria da Solu√ß√£o de M√≠nimos Quadrados\n\\[\n\\left\\{\\begin{array} {c}\n\\vec{f_0} \\cdot \\vec{e} = 0 \\Leftrightarrow \\vec{f_0}\\cdot(\\vec{y}-\\beta_0\\vec{f_0}-\\beta_1\\vec{f_1})=0\\\\\n\\vec{f_1} \\cdot \\vec{e} = 0 \\Leftrightarrow \\vec{f_1}\\cdot(\\vec{y}-\\beta_0\\vec{f_0}-\\beta_1\\vec{f_1})=0\n\\end{array} \\right.\n\\] que √© equivalente a: \\[\n\\left\\{\\begin{array} {c}\n\\beta_0\\vec{f_0}\\cdot\\vec{f_0}+\\beta_1\\vec{f_0}\\cdot\\vec{f_1}=\\vec{f_0}\\cdot\\vec{y}\\\\\n\\beta_0\\vec{f_1}\\cdot\\vec{f_0}+\\beta_1\\vec{f_1}\\cdot\\vec{f_1}=\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right.\n,\n\\] que ainda pode ser escrito na forma matricial: \\[\n\\left[ \\begin{array}{cc}\n\\vec{f_0}\\cdot\\vec{f_0} & \\vec{f_0}\\cdot\\vec{f_1}\\\\\n\\vec{f_1}\\cdot\\vec{f_0} & \\vec{f_1}\\cdot\\vec{f_1}\n\\end{array} \\right]\n\\left[ \\begin{array}{c}\n\\beta_0\\\\\n\\beta_1\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\n\\vec{f_0}\\cdot\\vec{y}\\\\\n\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right]\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#solu√ß√£o-matricial-do-m√©todo-dos-m√≠nimos-quadrados",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#solu√ß√£o-matricial-do-m√©todo-dos-m√≠nimos-quadrados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Solu√ß√£o Matricial do M√©todo dos M√≠nimos Quadrados",
    "text": "Solu√ß√£o Matricial do M√©todo dos M√≠nimos Quadrados\nA combina√ß√£o linear:\n\\[\n\\left[ \\begin{array}{cc}\n\\vec{f_0}\\cdot\\vec{f_0} & \\vec{f_0}\\cdot\\vec{f_1}\\\\\n\\vec{f_1}\\cdot\\vec{f_0} & \\vec{f_1}\\cdot\\vec{f_1}\n\\end{array} \\right]\n\\left[ \\begin{array}{c}\n\\beta_0\\\\\n\\beta_1\n\\end{array} \\right]\n=\n\\left[ \\begin{array}{c}\n\\vec{f_0}\\cdot\\vec{y}\\\\\n\\vec{f_1}\\cdot\\vec{y}\n\\end{array} \\right]\n\\]\npor ser expressa pelas matrizes:\n\\[X = \\left[ \\begin{array}{ccc}\n\\vec{f_0} & \\vdots & \\vec{f_1}\n\\end{array} \\right] =\n\\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right];\nY = \\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\nB = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]\nE finalmente:\n\\[B = (X^{T} X)^{-1}(X^{T}Y)\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#calculando-os-valores-preditos-haty",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#calculando-os-valores-preditos-haty",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Calculando os valores preditos (\\(\\hat{y}\\))",
    "text": "Calculando os valores preditos (\\(\\hat{y}\\))\nDefinimos \\(\\mathbf{F}\\) como a matriz coluna que cont√©m os valores preditos de \\(y\\) (denominados \\(\\hat{y}\\)), isto √©, aquela que cont√©m os pontos em \\(y\\) que se sobrep√µem √† reta da regress√£o linear. Podemos obter \\(\\mathbf{F}\\) por meio da opera√ß√£o matricial abaixo:\n\n\\[\\mathbf{F} = \\mathbf{X}\\mathbf{B}\\]\n\n\\[\\mathbf{F} = \\left[ \\begin{array}{c}\n\\hat{y}_1 \\\\\n\\hat{y}_2 \\\\\n\\vdots & \\vdots \\\\\n\\hat{y}_n \\\\\n\\end{array} \\right]; \\mathbf{X} = \\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right]; \\mathbf{B} = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#vetor-de-res√≠duos-e",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#vetor-de-res√≠duos-e",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Vetor de res√≠duos (\\(e\\))",
    "text": "Vetor de res√≠duos (\\(e\\))\nFinalmente, o vetor de res√≠duos √© obtido por:\n\n\\[e = \\mathbf{Y} - \\mathbf{F}\\]\n\nAgora temos todos os componentes da regress√£o linear estabelecida inicialmente:\n\\[ \\hat{y_i} = \\beta_0 + \\beta_1 x_i \\]\ne\n\\[ y_i = \\hat{y_i} + e_i \\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-dos-res√≠duos-sq_res",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-dos-res√≠duos-sq_res",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Soma dos quadrados dos res√≠duos (\\(SQ_{res}\\))",
    "text": "Soma dos quadrados dos res√≠duos (\\(SQ_{res}\\))\nA Soma dos quadrados dos res√≠duos foi definida pela express√£o abaixo:\n\\[SQ_{res} = \\Vert\\vec{e}\\Vert^{2}=\\vec{e}\\cdot\\vec{e}=e_{1}^{2}+e_{2}^{2}+\\cdots+e_{n}^{2}\\]\nConsiderando \\(\\vec{e}\\) como a matriz coluna \\(\\mathbf{e}\\):\n\\[\\mathbf{e} = \\left[ \\begin{array}{c}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n \\\\\n\\end{array} \\right]\n\\]\nPodemos fazer:\n\n\\[SQ_{res} = \\mathbf{e}^\\top \\mathbf{e}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-totais-sq_tot",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#soma-dos-quadrados-totais-sq_tot",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Soma dos quadrados totais (\\(SQ_{tot}\\))",
    "text": "Soma dos quadrados totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser definido como:\n\n\\[SQ_{tot} = \\sum_{i}^{n}{(y_i - \\overline{y})^{2}} = (y_1 - \\overline{y})^{2} + (y_2 - \\overline{y})^{2} + \\cdots + (y_n - \\overline{y})^{2}\\]\nem que \\(\\overline{y}\\) √© a m√©dia aritm√©tica de \\(y\\)\n\n\n\nPodemos definir a matrix coluna \\(\\mathbf{D}\\)\n\\[\\mathbf{D} = \\left[ \\begin{array}{c}\n(y_1 - \\overline{y})^{2} \\\\\n(y_2 - \\overline{y})^{2} \\\\\n\\vdots\\\\\n(y_n - \\overline{y})^{2} \\\\\n\\end{array} \\right]\n\\]\n\nE obter \\(SQ_{tot}\\) por:\n\\[SQ_{tot} = \\mathbf{D}^\\top \\mathbf{D}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determina√ß√£o-r2",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determina√ß√£o-r2",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Coeficiente de determina√ß√£o (\\(R^2\\))",
    "text": "Coeficiente de determina√ß√£o (\\(R^2\\))\nA qualidade do ajuste pode ser determinada pelo coeficiente de determina√ß√£o (\\(R^2\\)), um √≠ndice que varia entre 0 e 1.\n\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determina√ß√£o-r2-1",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#coeficiente-de-determina√ß√£o-r2-1",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "Coeficiente de determina√ß√£o (\\(R^2\\))",
    "text": "Coeficiente de determina√ß√£o (\\(R^2\\))"
  },
  {
    "objectID": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#m√©todo-dos-m√≠nimos-quadrados-resumo-dos-passos",
    "href": "content/regressao-linear/metodo-minimos-quadrados-apresentacao.html#m√©todo-dos-m√≠nimos-quadrados-resumo-dos-passos",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "M√©todo dos m√≠nimos quadrados: Resumo dos passos",
    "text": "M√©todo dos m√≠nimos quadrados: Resumo dos passos\n\n\n\n\n\n\n\n\n\nResolu√ß√£o do MMQ\n\n\n\nDefini√ß√£o das matrizes do sistema\n\n\\[X = \\left[ \\begin{array}{cc}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n \\\\\n\\end{array} \\right];\nY = \\left[ \\begin{array}{c}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n \\\\\n\\end{array} \\right];\nB = \\left[ \\begin{array}{c}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{array} \\right]\n\\]\n\nC√°lculo dos coeficientes\n\n\\[B = (X^{T} X)^{-1}(X^{T}Y)\\]\n\nValores preditos\n\n\\[\\mathbf{F} = \\mathbf{X}\\mathbf{B}\\]\n\nMatriz coluna de Res√≠duos\n\n\\[\\mathbf{e} = \\mathbf{Y} - \\mathbf{F}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nQualidade do ajuste\n\n\n\nSoma dos quadrados dos res√≠duos\n\n\\[SQ_{res} = \\mathbf{e}^\\top \\mathbf{e}\\]\n\nSoma dos quadrados totais\n\n\\[SQ_{tot} = \\mathbf{D}^\\top \\mathbf{D}\\]\n\nCoeficiente de determina√ß√£o\n\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]\n\n\n\n\n\n\n\n\n\nBICT Mar - Unifesp ¬∑ Ecologia Num√©rica"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "",
    "text": "Objetivos\n\n\n\nNeste tutorial, vamos implementar o M√©todo dos M√≠nimos Quadrados (MMQ) em Python para ajustar um modelo de regress√£o linear simples.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\) e \\(\\beta_1\\) da equa√ß√£o \\(\\hat{y} = \\beta_0 + \\beta_1 x\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#introdu√ß√£o",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#introdu√ß√£o",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "",
    "text": "Objetivos\n\n\n\nNeste tutorial, vamos implementar o M√©todo dos M√≠nimos Quadrados (MMQ) em Python para ajustar um modelo de regress√£o linear simples.\nObjetivo: Encontrar os coeficientes \\(\\beta_0\\) e \\(\\beta_1\\) da equa√ß√£o \\(\\hat{y} = \\beta_0 + \\beta_1 x\\) que melhor se ajustam aos nossos dados."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#importando-as-bibliotecas",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#importando-as-bibliotecas",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "2 üõ†Ô∏è Importando as Bibliotecas",
    "text": "2 üõ†Ô∏è Importando as Bibliotecas\nPrimeiro, vamos importar as bibliotecas que usaremos:\n\nimport matplotlib.pyplot as plt  # Para cria√ß√£o e manipula√ß√£o gr√°fica\nimport numpy as np           # Para opera√ß√µes matem√°ticas e matriciais\n\nüí° Dica: No Google Colab, essas bibliotecas j√° v√™m instaladas!"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#inserindo-os-dados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#inserindo-os-dados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "3 üìä Inserindo os Dados",
    "text": "3 üìä Inserindo os Dados\nVamos trabalhar um exemplo simples em que \\(x\\) e \\(y\\) s√£o inseridos como listas em Python:\n\n# Nossos dados de exemplo\nx = [0, 1, 2, 3, 4]  # Vari√°vel independente (preditora)\ny = [0, 1, 1, 4, 4]  # Vari√°vel dependente (resposta)\n\nCaso deseje visualizar se os objetos x e y foram criados corretamente podemos utilizar a fun√ß√£o print().\n\nprint(\"Valores de x:\", x)\nprint(\"Valores de y:\", y)\n\nValores de x: [0, 1, 2, 3, 4]\nValores de y: [0, 1, 1, 4, 4]"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-os-dados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-os-dados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "4 üìà Visualizando os Dados",
    "text": "4 üìà Visualizando os Dados\nAntes de ajustar o modelo, vamos visualizar nossos dados em um gr√°figo de dispers√£o utilizando a fun√ß√£o scatter() da biblioteca Matplotlib:\n\n# Criando o gr√°fico de dispers√£o\nplt.figure(figsize=(8, 6))\nplt.scatter(x, y, color = '#0072B2', s=120, label='Dados observados')\n\n# Configurando o layout gr√°fico\nplt.title('Gr√°fico de Dispers√£o dos Dados', fontsize=14, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nüìù Observa√ß√£o: O gr√°fico sugere uma rela√ß√£o linear entre as vari√°veis, o que justifica o uso da regress√£o linear simples, que iremos ajustra por meio do MMQ."
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#implementando-o-mmq---passo-a-passo",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#implementando-o-mmq---passo-a-passo",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "5 üßÆ Implementando o MMQ - Passo a Passo",
    "text": "5 üßÆ Implementando o MMQ - Passo a Passo\n\n5.1 Criando os Vetores Base\nLembre-se da teoria: inicialmente precisamos caracterizar os vetores \\(\\vec{f}_0\\), \\(\\vec{f}_1\\) e \\(\\vec{y}\\):\n\\[\\vec{f}_0 = \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\quad \\text{,} \\quad \\vec{f}_1 = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\quad \\text{e} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# N√∫mero de observa√ß√µes\nn = len(x)\n\n# Vetor f0: vetor de 1's (para o intercepto Œ≤‚ÇÄ)\nf0 = [1] * n  # Cria uma lista com n elementos iguais a 1\n\n# Vetor f1: nossos valores de x (para o coeficiente Œ≤‚ÇÅ)\nf1 = x.copy()  # Copia os valores de x para um novo objeto denominado f1\n\nVisualizando os vetores \\(\\vec{f}_0\\) e \\(\\vec{f}_1\\).\n\nprint(\"Vetor f0 (intercepto):\", f0)\nprint(\"Vetor f1 (coeficiente):\", f1)\n\nVetor f0 (intercepto): [1, 1, 1, 1, 1]\nVetor f1 (coeficiente): [0, 1, 2, 3, 4]\n\n\n\n\n5.2 Construindo as Matrizes X e Y\nAgora vamos montar as matrizes do sistema:\n\\[X = \\begin{bmatrix} \\vec{f}_0 & \\vec{f}_1 \\end{bmatrix} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\quad \\text{e} \\quad Y = \\begin{bmatrix} \\vec{y} \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\]\n\n# Matriz X: combinando f0 e f1 em colunas\nX = np.column_stack((f0, f1))\n\n# Matriz Y: transformando y em matriz com n linhas e 1 coluna \nY = np.array(y).reshape(n, 1)\n\nVisualizando as matrizes \\(X\\) e \\(Y\\).\n\nprint(\"Matriz X:\")\nprint(X)\nprint(\"\\nMatriz Y:\")\nprint(Y)\nprint(f\"\\nDimens√µes - X: {X.shape}, Y: {Y.shape}\")\n\nMatriz X:\n[[1 0]\n [1 1]\n [1 2]\n [1 3]\n [1 4]]\n\nMatriz Y:\n[[0]\n [1]\n [1]\n [4]\n [4]]\n\nDimens√µes - X: (5, 2), Y: (5, 1)\n\n\nNote agora que a matriz \\(X\\) tem 5 linhas e 2 colunas, enquanto a matriz \\(Y\\) tem 5 linhas e 1 colunas.\n\n\n5.3 Resolvendo o Sistema Normal\nAgora vamos calcular os coeficientes usando as opera√ß√µes matriciais: \\[B = (X^T X)^{-1} X^T Y\\]\n\n# Calculando X transposta vezes X\nXTX = np.dot(X.T, X)  # X.T √© a transposta de X\n# Calculando X transposta vezes Y\nXTY = np.dot(X.T, Y)\n# Calculando a matriz inversa (X^T X)^(-1)\nXTX_inv = np.linalg.inv(XTX)  # Inversa de X^T X\n# Coeficientes de regress√£o\nB = np.dot(XTX_inv, XTY)\n\nVisualizando os objetos\n\n# Calculando X transposta vezes X\nprint(\"X^T X:\")\nprint(XTX)\n\nprint(\"\\nX^T Y:\")\nprint(XTY)\n\nprint(\"\\nB:\")\nprint(B)\n\nX^T X:\n[[ 5 10]\n [10 30]]\n\nX^T Y:\n[[10]\n [31]]\n\nB:\n[[-0.2]\n [ 1.1]]\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nA fun√ß√£o ¬¥np.dot()¬¥ em Python pode ser substitu√≠da pelo s√≠mbolo @. Teste os c√≥digos abaixo e verifique que os resultados coincidem:\n\n\nprint(\"Usando np.dot()\")\nprint(np.dot(X.T, X))\n\nUsando np.dot()\n[[ 5 10]\n [10 30]]\n\n\n\nprint(\"Usando '@'\")\nprint(X.T @ X)\n\nUsando '@'\n[[ 5 10]\n [10 30]]\n\n\n\nOs elementos internos de uma matriz podem ser acessados destacando suas posi√ß√µes na linha e coluna. Considere a matrtiz B. O coeficiente \\(\\beta_0\\) pode ser acessado na linha 1 e coluna 1, enquanto \\(\\beta_1\\) pode ser acessado na linha 2 e coluna 1.\n\n\nprint(B[0,0]) # Beta 0\n\n-0.1999999999999993\n\n\n\nprint(B[1,0]) # Beta 1\n\n1.1\n\n\n\n\n\n\n5.4 Obtendo os Valores Ajustados de y\nTendo obtido os coeficientes de regress√£o, os valores ajustados de y (\\(\\hat{y}\\)) podem ser obtido pela multiplica√ß√£o matricial:\n\\[F = X B = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} \\begin{bmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{bmatrix}\\]\nObs.: denominamos \\(F\\) a matriz de valores ajustados de \\(y\\).\n\n# Valores ajustados (preditos)\nF = np.dot(X, B)\n\n\n# Valores ajustados (preditos)\nprint(F)\n\n[[-0.2]\n [ 0.9]\n [ 2. ]\n [ 3.1]\n [ 4.2]]\n\n\n\n\n5.5 Avaliando a Qualidade do Ajuste\n\n5.5.1 Calculando a Soma dos Quadrados dos Res√≠duos (\\(SQ_{res}\\))\n\\(SQ_{res}\\) pode ser obtida pela multiplica√ß√£o matricial:\n\\[SQ_{res} = \\boldsymbol{e}^T \\boldsymbol{e}\\]\nEm que \\(\\boldsymbol{e}\\) √© a matriz coluna dos res√≠duos obtida pela diferen√ßa entre os valores observados e ajustados de \\(y\\):\n\\[\\boldsymbol{e} = Y - F = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\]\n\n# Res√≠duos: diferen√ßa entre valores observados e ajustados\ne = Y - F\n\n# Soma dos Quadrados dos Res√≠duos\nSQres = np.dot(e.T, e)[0, 0]\n\n\n\n5.5.2 Calculando a Soma dos Quadrados Totais (\\(SQ_{tot}\\))\n\\(SQ_{tot}\\) pode ser obtida pela multiplica√ß√£o matricial:\n\\[SQ_{tot} = \\boldsymbol{D}^T \\boldsymbol{D}\\]\nEm que \\(\\boldsymbol{D}\\) √© a matriz coluna dos desvios da m√©dis obtida pela diferen√ßa entre os valores observados de \\(y\\) e a m√©dia de \\(\\overline{y}\\):\n\\[\\boldsymbol{D} = Y - \\overline{Y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} - \\begin{bmatrix} \\overline{y} \\\\ \\overline{y} \\\\ \\vdots \\\\ \\overline{y} \\end{bmatrix} = \\begin{bmatrix} d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_n \\end{bmatrix}\\]\n\n# Soma dos Quadrados Total\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = np.dot(D.T, D)[0, 0]\n\n\n\n5.5.3 Calculando o coeficiente de determina√ß√£o \\(R^2\\):\nO \\(R^2\\) √© dado pela express√£o:\n\\[R^2 = 1 - \\frac{SQ_{res}}{SQ_{tot}}\\]\n\n# Coeficiente de Determina√ß√£o R¬≤\nR2 = 1 - (SQres / SQtot)\n\n\nVisualizando os resultados:\n\nprint(\"üìä Medidas de Qualidade do Ajuste:\")\nprint(f\"Soma dos Quadrados dos Res√≠duos (SQres): {SQres:.4f}\")\nprint(f\"Soma dos Quadrados Total (SQtot): {SQtot:.4f}\")\nprint(f\"Coeficiente de Determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\n\nüìä Medidas de Qualidade do Ajuste:\nSoma dos Quadrados dos Res√≠duos (SQres): 1.9000\nSoma dos Quadrados Total (SQtot): 14.0000\nCoeficiente de Determina√ß√£o (R¬≤): 0.8643\nPorcentagem da varia√ß√£o explicada: 86.43%\n\n\nüìù Interpreta√ß√£o do \\(R^2\\):\n\nVaria de 0 a 1\nQuanto mais pr√≥ximo de 1, melhor o ajuste\nRepresenta a propor√ß√£o da varia√ß√£o em \\(y\\) explicada pelo modelo"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-o-resultado-final",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#visualizando-o-resultado-final",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "6 üìä Visualizando o Resultado Final",
    "text": "6 üìä Visualizando o Resultado Final\nVamos plotar os dados originais junto com a reta ajustada:\n\n# Criando o gr√°fico final\nplt.figure(figsize=(8, 6))\n\n# Pontos observados\nplt.scatter(x, y, \n            color = '#0072B2', s=120,\n            label=f'Dados observados (n={n})')\n\n# Valores ajustados\nplt.scatter(x, F[:,0],\n            color='#000000', marker='*', s=120, \n            label='Valores ajustados')\n\n# Reta ajustada\nplt.plot(x, F[:,0], color='#D55E00', \n         label=fr'Reta de regress√£o: $\\hat{{y}} = {B[0,0]:.3f} + {B[1,0]:.3f}x$')\n\n# Configura√ß√µes do gr√°fico\nplt.title(f'Regress√£o Linear Simples - MMQ\\nR¬≤ = {R2:.4f}', \n          fontsize=14, fontweight='bold')\nplt.xlabel('Vari√°vel X', fontsize=12)\nplt.ylabel('Vari√°vel Y', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-dos-resultados",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-dos-resultados",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "7 üéØ Resumo dos Resultados",
    "text": "7 üéØ Resumo dos Resultados\n\nprint(\"=\"*50)\nprint(\"         RESUMO DA REGRESS√ÉO LINEAR\")\nprint(\"=\"*50)\nprint(f\"Equa√ß√£o ajustada: y = {B[0,0]:.4f} + {B[1,0]:.4f}x\")\nprint(f\"Coeficiente de determina√ß√£o (R¬≤): {R2:.4f}\")\nprint(f\"Porcentagem da varia√ß√£o explicada: {R2*100:.2f}%\")\nprint(\"=\"*50)\n\n==================================================\n         RESUMO DA REGRESS√ÉO LINEAR\n==================================================\nEqua√ß√£o ajustada: y = -0.2000 + 1.1000x\nCoeficiente de determina√ß√£o (R¬≤): 0.8643\nPorcentagem da varia√ß√£o explicada: 86.43%\n=================================================="
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-do-c√≥digo",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#resumo-do-c√≥digo",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "8 üßæ Resumo do C√≥digo",
    "text": "8 üßæ Resumo do C√≥digo\n\nInser√ß√£o dos Dados\n\n\nx = [0, 1, 2, 3, 4]\ny = [0, 1, 1, 4, 4]\n\n\nDefini√ß√£o das matrizes do sistema\n\n\nn = len(x)\nf0 = [1] * n\nf1 = x.copy()\n\nX = np.column_stack((f0, f1))\nY = np.array(y).reshape(n, 1)\n\n\nC√°lculo dos coeficientes\n\n\nXTX = X.T @ X\nXTY = X.T @ Y\nXTX_inv = np.linalg.inv(XTX)\nB = XTX_inv @ XTY\n\n\nQualidade do ajuste\n\n\nF = X @ B\ne = Y - F\nSQres = (e.T @ e)[0, 0]\n\nY_medio = np.mean(Y)\nD = Y - Y_medio\nSQtot = (D.T @ D)[0, 0]\n\nR2 = 1 - (SQres / SQtot)"
  },
  {
    "objectID": "content/regressao-linear/mmq-regressao-linear-simples.html#exerc√≠cio-pr√°tico",
    "href": "content/regressao-linear/mmq-regressao-linear-simples.html#exerc√≠cio-pr√°tico",
    "title": "M√©todo dos M√≠nimos Quadrados na Regress√£o Linear Simples",
    "section": "9 üöÄ Exerc√≠cio Pr√°tico",
    "text": "9 üöÄ Exerc√≠cio Pr√°tico\nImplemente o MMQ com novos dados:\n\n# Experimente com estes dados:\nx_novo = [1, 2, 3, 4, 5, 6]\ny_novo = [2, 4, 5, 4, 5, 7]\n\n# Dica: voc√™ pode copiar e adaptar o c√≥digo acima!"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html",
    "href": "content/regressao-linear/regressao-linear-simples.html",
    "title": "Regress√£o linear simples",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nlibrary(knitr)\nUm modelo de regress√£o linear nos permite verificar se h√° uma rela√ß√£o funcional entre vari√°veis quantitativas. Nesta rela√ß√£o, uma vari√°vel √© denominada dependente (ou vari√°vel resposta - \\(Y\\)) e as demais independentes (ou vari√°veis preditoras - \\(X\\)). Portanto, ao ajustar um modelo de regress√£o linear, estamos assumindo que existe uma rela√ß√£o estat√≠stica de dependencia de \\(Y\\) como fun√ß√£o das vari√°veis preditoras em \\(X\\). No modelo de regress√£o linear simples temos somente uma vari√°vel preditora e sua rela√ß√£o funcional com \\(Y\\) √© dada por:\n\\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\]\nC√≥digo\nst &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook_wide.csv\") |&gt;\n    rename(FlowD = WS2_Flow_Defosrested, FlowR = WS3_Flow_reference, \n           RainD = WS2_precipitation, RainR = WS3_precipitation) |&gt;\n    mutate(FlowD = FlowD / 100, FlowR = FlowR / 100,\n           RainD = RainD / 10, RainR = RainR / 10) |&gt;\n    (\\(df) df[-31, ])()\nConsidere novamente os dados sobre pluviosidade anual e vaz√£o em uma bacia hidrogr√°fica americada, medidos entre os anos de 1958 e 1987 (dispon√≠vel em: tiee.esa.org). Vamos avaliar a rela√ß√£o entre a vaz√£o na bacia e os volumes de chuva.\nYear\nFlowD\nFlowR\nDiference\nRainD\nRainR\n\n\n\n\n1958\n645.15\n567.36\n7779\n1167.5\n1161.0\n\n\n1959\n1012.05\n918.23\n9382\n1482.6\n1479.1\n\n\n1960\n825.22\n752.06\n7316\n1321.3\n1325.3\n\n\n1961\n470.05\n436.25\n3380\n979.7\n978.9\n\n\n1962\n777.31\n699.29\n7802\n1232.2\n1230.6\n\n\n1963\n773.64\n662.58\n11106\n1138.6\n1151.7\n\n\n1964\n712.15\n630.45\n8170\n1175.4\n1175.2\n\n\n1965\n598.85\n546.69\n5216\n1115.2\n1120.6\n\n\n1966\n1189.34\n726.73\n46261\n1222.3\n1223.2\n\n\n1967\n1131.85\n780.76\n35109\n1315.1\n1296.8\n\n\n1968\n1056.54\n762.84\n29370\n1268.2\n1285.2\n\n\n1969\n1347.61\n998.68\n34893\n1368.5\n1403.5\n\n\n1970\n905.47\n697.53\n20794\n1184.1\n1201.5\n\n\n1971\n800.56\n676.19\n12437\n1164.2\n1173.4\n\n\n1972\n1005.90\n885.91\n11999\n1431.3\n1424.0\n\n\n1973\n1585.73\n1396.43\n18930\n1804.0\n1792.8\n\n\n1974\n998.20\n890.45\n10775\n1406.8\n1408.9\n\n\n1975\n1086.33\n939.52\n14681\n1422.4\n1448.6\n\n\n1976\n1142.59\n1022.06\n12053\n1511.4\n1516.0\n\n\n1977\n966.25\n843.75\n12250\n1382.7\n1388.2\n\n\n1978\n722.04\n613.79\n10825\n1087.9\n1085.7\n\n\n1979\n1136.17\n1036.93\n9924\n1417.0\n1432.7\n\n\n1980\n585.22\n548.28\n3694\n1087.9\n1101.1\n\n\n1981\n1129.09\n1093.91\n3518\n1631.5\n1664.9\n\n\n1982\n802.73\n756.12\n4661\n1088.2\n1114.4\n\n\n1983\n917.13\n889.35\n2778\n1436.6\n1451.8\n\n\n1984\n1000.54\n970.65\n2989\n1396.8\n1403.5\n\n\n1985\n634.76\n627.84\n692\n1128.4\n1137.2\n\n\n1986\n987.99\n960.94\n2705\n1364.0\n1372.3\n\n\n1987\n790.47\n797.09\n-662\n1222.1\n1234.6\n√â razo√°vel supor que em anos de mais chuva, seriam esperadas maiores vaz√µes e que anos mais secos resultassem menores volumes de vaz√£o. Para verificar esta suposi√ß√£o vamos fazer um gr√°fico de dispers√£o entre vaz√£o e chuva.\nO gr√°fico sugere que a suposi√ß√£o faz sentido. Volumes baixos de chuva est√£o associados a volumes baixos de vaz√£o e vice versa. O gr√°fico sugrere ainda que a rela√ß√£o funcional √© linear. Nestas condi√ß√µes, faz sentido tentar modelar a rela√ß√£o entre estas vari√°veis por meio de um modelo de regress√£o linear simples.\nAo ajustar um modelo de regress√£o, vemos que a linha em azul √© a que melhor descreve a rela√ß√£o linear entre as vari√°veis.\nEsta linha nos permite obter uma estimativa sobre a vaz√£o esperada (\\(Y\\)) para qualquer dado volume de chuva (\\(X\\)). Neste exemplo, a equa√ß√£o que melhor associa vaz√£o e chuva √©:\n\\[Y_i = -571.98 + 1.05 X_i\\]\nO valor de \\(\\beta_1 = 1.05\\) nos diz que para um aumento de 1 mm/area/ano de chuva, a vaz√£o aumentar√° 1.05 mm/area/ano. \\(\\beta_1\\) √© conhecido como coeficiente de inclina√ß√£o da reta e nos fornece magnitude da varia√ß√£o em \\(Y\\) para um aumento de 1 unidade em \\(X\\).\nEsta equa√ß√£o prev√™ por exemplo, que para um volume de chuva igual a 1400 mm/area/ano a vaz√£o na bacia ser√° de 898 mm/area/ano. Fa√ßa as contas para conferir.\n\\[898.02 = -571.98 + 1.05 \\times 1400\\]\nA reta descreve portanto os valores preditos de vaz√£o para cada n√≠vel de chuva."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#modelo-geral-de-regress√£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#modelo-geral-de-regress√£o",
    "title": "Regress√£o linear simples",
    "section": "1 Modelo geral de regress√£o",
    "text": "1 Modelo geral de regress√£o\nA estrutura de um modelo de regress√£o √© dada por:\n\\[Y_i = f(X_i, \\beta) + \\epsilon_i\\]\nonde \\(f(X_i, \\beta)\\) representa a parte determin√≠stica e \\(\\epsilon\\) a parte estoc√°stica. O sulfixo i nos diz que esta express√£o √© dada para cada par de observa√ß√£o \\((Y,X)\\).\n\n1.1 Por√ß√£o determin√≠stica\nA por√ß√£o determin√≠stica √© um modelo matem√°tico que descreve a rela√ß√£o funcional entre \\(X\\) e \\(Y\\). Os par√¢metros \\(\\beta\\)‚Äôs determinam a intensidade do efeito de \\(X\\) sobre \\(Y\\). Na regress√£o linear simples temos somente uma vari√°vel \\(X\\), e a rela√ß√£o funcional √© dada pela equa√ß√£o da reta. No modelo de regress√£o linear m√∫ltipla existe mais de uma vari√°vel \\(X\\). Finalmente, nos modelos de regress√£o n√£o-lineares a rela√ß√£o funcional pode ser representada por outros modelos matem√°ticos (ex. fun√ß√£o pot√™ncia \\(Y = \\beta_0X^{\\beta_1}\\)).\nNa regress√£o linear simples, o par√¢metro \\(\\beta_1\\) √© geralmente o de maior interesse. Este par√¢metro nos dir√° se a rela√ß√£o ser√° crescente (\\(\\beta_1 &gt; 0\\)), decrescente (\\(\\beta_1 &lt; 0\\)) ou nula (\\(\\beta_1 = 0\\)). \\(\\beta_0\\) √© o \\(\\textbf{intercepto}\\) e expressa o ponto em \\(Y\\) em que a reta cruza o eixo das ordenadas.\n\n\n\n\n\n\n\n\n\n\n\n1.2 Por√ß√£o estoc√°stica\nA por√ß√£o estoc√°stica, √© representada pelo res√≠duo ou erro. A cada observa√ß√£o \\(Y_i\\) est√° associado um valor de res√≠duo correspondente (\\(\\epsilon_i\\)), dado pela dist√¢ncia vertical entre \\(Y_i\\) e o valor predito \\(\\hat{Y_i}\\) sobre a reta de regress√£o.\n\n\n\n\n\n\n\n\n\nNo modelo de regress√£o linear que veremos aqui, os res√≠dos s√£o uma vari√°vel aleat√≥ria prevenientes de uma distribui√ß√£o normal de probabilidades com m√©dia \\(\\mu = 0\\) e vari√¢ncia \\(\\sigma^2\\) constante ao longo da reta de regress√£o, \\(N(0, \\sigma^2)\\).\n\n\n\n\n\n\nFigura¬†1: Res√≠duo normalmente distribu√≠do ao longo da reta de regress√£o."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#ajuste-dos-dados-ao-modelo-de-regress√£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#ajuste-dos-dados-ao-modelo-de-regress√£o",
    "title": "Regress√£o linear simples",
    "section": "2 Ajuste dos dados ao modelo de regress√£o",
    "text": "2 Ajuste dos dados ao modelo de regress√£o\nO ajuste de dados observados a um modelo de regress√£o requer a obten√ß√£o de estimativas para \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma^2\\), denotadas respectivamente por \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\). Note que o s√≠mbolo \\(\\hat{}\\) significa que estamos falando de estimativas obtidas a partir de dados amostrais e n√£o dos par√¢metros populacionais.\nAo obter estas estimativas, podemos encontrar valores ajustados de \\(Y\\) para um dados valor de \\(X\\). Os valores ajustados de \\(Y\\) s√£o denotados por \\(\\hat{Y}\\).\n\\[\\hat{Y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}X_i\\]\n\n2.1 M√©todo dos m√≠nimos quadrados\nO M√©todo dos M√≠nimos Quadrados (\\(MMQ\\)) √© uma das formas dispon√≠veis para calcularmos \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\). O \\(MMQ\\) envolve encontrar a combina√ß√£o de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimiza a Soma dos Quadrados dos Res√≠duos (\\(SQ_{Res√≠duo}\\)), ou seja, que minimizam a quantia:\n\\[SQ_{Res√≠duo} = \\sum{(Y_i-\\hat{Y_ i})^2} = \\sum{(Y_i-(\\hat{\\beta_0} + \\hat{\\beta_1}X_i))^2}\\]\n\n\n\n\n\n\n\n\n\nNas figuras acima, a linha da esquerda (\\(SQ_{Res√≠duo} = \\sum{\\epsilon_i^2} = 37\\)) est√° claramente melhor ajustada √† nuvem de pontos, o que se expressa em um menor somat√≥rio dos quadrados dos res√≠duos (\\(SQ_{Res√≠duo} = \\sum{\\epsilon_i^2} = 37\\)) quando comparado com o ajuste da figura √† direita (\\(SQ_{Res√≠duo} = \\sum{\\epsilon_i^2} = 145\\)).\n\n\n2.2 Vari√¢ncias, covari√¢ncias e coeficientes da regress√£o\nPara estimarmos os coeficientes da regress√£o \\(\\beta_0\\) e \\(\\beta_1\\) devemos retomar o conceito de vari√¢ncia amostral e introduzir o conceito de covari√¢ncia amostral.\nA vari√¢ncia amostral de \\(Y\\) por exemplo, pode ser obtida subtraindo cada observa√ß√£o em \\(Y\\) de sua m√©dia (\\(\\overline{Y}\\)) e elevando esta subtra√ß√£o ao quadrado \\((Y_i - \\overline{Y})^2\\). Ao somar para todos os valores de \\(Y_i\\) teremos o somat√≥rio dos quadrados de \\(Y\\) (\\(SQ_Y\\)).\n\\[SQ_Y = \\sum_{i-1}^{n} (Y_i - \\overline{Y})^2 = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (Y_i - \\overline{Y})\\]\nDividindo \\(SQ_Y\\) por \\(n-1\\) teremos a vari√¢ncia amostral de \\(Y\\) (\\(s^2_Y\\)).\n\\[s^2_Y = \\frac{\\sum_{i-1}^{n} (Y_i - \\overline{Y})^2}{n-1}\\]\nAdotando o mesmo procedimento para \\(X\\), podemos calcular o somat√≥rio dos quadrados de \\(X\\) (\\(SQ_X\\)).\n\\[SQ_X = \\sum_{i-1}^{n} (X_i - \\overline{X})^2 = \\sum_{i-1}^{n}(X_i - \\overline{X}) (X_i - \\overline{X})\\]\ne a vari√¢ncia amostral de \\(X\\) (\\(s^2_X\\)).\n\\[s^2_X = \\frac{\\sum_{i-1}^{n} (X_i - \\overline{X})^2}{n-1}\\]\nCombinando as duas ideias, teremos o produto cruzado de \\(Y\\) e \\(X\\) (\\(SQ_{YX}\\))\n\\[SQ_{YX} = \\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})\\]\ne a covari√¢ncia amostral entre \\(Y\\) e \\(X\\) (\\(s_{YX}\\)).\n\\[s_{YX} = \\frac{\\sum_{i-1}^{n}(Y_i - \\overline{Y}) (X_i - \\overline{X})}{n-1}\\]\nO estimador \\(\\hat{\\beta_1}\\) nada mais √© que a covari√¢ncia entre \\(Y\\) e \\(X\\) padronizada pela vari√¢ncia de \\(X\\).\n\\[\\hat{\\beta_1} = \\frac{s_{YX}}{s^2_X} = \\frac{\\frac{SQ_{XY}}{n-1}}{\\frac{SQ_X}{n-1}} = \\frac{SQ_{XY}}{SQ_X} = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sum{(X_i - \\overline{X})^2}}\\]\n\\[\\hat{\\beta_1} = \\frac{\\sum{(Y_i - \\overline{Y})(X_i - \\overline{X})}}{\\sum{(X_i - \\overline{X})^2}}\\]\nAp√≥s encontrar \\(\\hat{\\beta_1}\\), podemos calcular \\(\\hat{\\beta_0}\\) sabendo que a melhor reta de regress√£o passar√° necessariamente pelo ponto m√©dio de \\(X\\) e de \\(Y\\). Deste modo temos:\n\\[\\hat{\\beta_0} = \\overline{Y} - \\hat{\\beta_1}\\overline{X}\\]\nCalculados \\(\\hat{\\beta_1}\\) e \\(\\hat{\\beta_0}\\), podemos encontrar os valores ajustados de \\(Y\\) para cada valor de \\(X\\) que ser√£o utilizados para construir a reta de regress√£o. \\(\\hat{Y_i}\\) ser√° dado por:\n\\[\\hat{Y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}X_i\\]\nPor fim, a vari√¢ncia residual \\(s^2\\) √© dada por:\n\\[s^2 = QM_{Res√≠duo} = \\frac{SQ_{Res√≠duo}}{n-2} = \\frac{\\sum{(Y_i-\\hat{Y_ i})^2}}{n-2}\\]\n\n\n2.3 Exemplo de ajuste ao modelo de regress√£o\n\nrk = read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/RIKZ.csv')\nrks = rk |&gt; \n  (\\(df) df[seq(3,43,by = 5),])()\n\nConsidere a tabela abaixo com os dados de riqueza da macro-fauna praial (n√∫mero de esp√©cies) e de um √≠ndice de exposi√ß√£o √†s ondas (NAP). Os dados foram obtidos em 2002 na costa da Holanda em nove praias (Zuur et al. 2009). Valores negativos de NAP se referem a locais mais expostos e valores positivos a locais menos expostos √† a√ß√£o das ondas.\n\nrks |&gt; \n  select(Richness, NAP) |&gt; \n  gt()\n\n\n\n\n\n\n\nRichness\nNAP\n\n\n\n\n13\n-1.336\n\n\n8\n0.635\n\n\n4\n-0.201\n\n\n3\n0.460\n\n\n6\n0.729\n\n\n1\n2.222\n\n\n1\n1.375\n\n\n7\n-1.005\n\n\n3\n-0.002\n\n\n\n\n\n\n\nO gr√°fico de dispers√£o sugere uma rela√ß√£o negativa e possivelmente linear, em que a riqueza de esp√©cies diminui com o aumento no grau de exposi√ß√£o. Vamos ajustar um modelo de regress√£o a estes pontos calculando \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}^2\\).\n\n\n\n\n\n\n\n\n\nOs passos intermedi√°rios envolvem o c√°lculo do somat√≥rios dos quadrados de X:\n\\[SQ_X = \\sum{(X_i - \\overline{X})^2}\\]\nde Y:\n\\[SQ_Y = \\sum{(Y_i - \\overline{Y})^2}\\]\ne do somat√≥rio dos produtos cruzados de X e Y:\n\\[SQ_{XY} = \\sum{(X_i - \\overline{X}) (Y_i - \\overline{Y})}\\]\nEstes passos s√£o descritos na tabela a seguir.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichness\nNAP\n\\((X_i - \\overline{X})\\)\n\\((Y_i - \\overline{Y})\\)\n\\((X_i - \\overline{X})^2\\)\n\\((Y_i - \\overline{Y})^2\\)\n\\((X_i - \\overline{X})(Y_i - \\overline{Y})\\)\n\n\n\n\n13\n-1.34\n-1.66\n7.89\n2.74\n62.23\n-13.06\n\n\n8\n0.64\n0.32\n2.89\n0.10\n8.35\n0.91\n\n\n4\n-0.20\n-0.52\n-1.11\n0.27\n1.23\n0.58\n\n\n3\n0.46\n0.14\n-2.11\n0.02\n4.46\n-0.30\n\n\n6\n0.73\n0.41\n0.89\n0.17\n0.79\n0.36\n\n\n1\n2.22\n1.90\n-4.11\n3.62\n16.90\n-7.82\n\n\n1\n1.38\n1.06\n-4.11\n1.11\n16.90\n-4.34\n\n\n7\n-1.00\n-1.32\n1.89\n1.75\n3.57\n-2.50\n\n\n3\n0.00\n-0.32\n-2.11\n0.10\n4.46\n0.68\n\n\n\n\n\nAp√≥s os c√°lculos, os valores estimados s√£o:\n\\[\\hat{\\beta_1} = \\frac{\\sum{(X_i - \\overline{X})(Y_i - \\overline{Y})}}{\\sum{(X_i - \\overline{X})^2}} = \\frac{-25.49}{9.88} = -2.58\\]\n\\[\\hat{\\beta_0} = \\overline{Y} - \\hat{\\beta_1}\\overline{X} = 5.11 -2.58 \\times 0.32 = 5.94\\]\n\\[\\hat{\\sigma}^2 = QM_{Res√≠duo} = \\frac{SQ_{Res√≠duo}}{n-2} = \\frac{\\sum{(Y_i-\\hat{Y_ i})^2}}{n-2} = \\frac{53.11}{7} = 7.59\\]\nDe modo que a melhor reta de regress√£o √© dada por:\n\\[Richness = 5.94 -2.58 \\times NAP\\]"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#testes-de-hip√≥teses-na-regress√£o-linear-simples",
    "href": "content/regressao-linear/regressao-linear-simples.html#testes-de-hip√≥teses-na-regress√£o-linear-simples",
    "title": "Regress√£o linear simples",
    "section": "3 Testes de hip√≥teses na regress√£o linear simples",
    "text": "3 Testes de hip√≥teses na regress√£o linear simples\nAt√© o momento, apresentamos uma discuss√£o sobre o m√©todo para calcular os estimadores \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) e \\(\\hat{\\sigma}\\). Entretanto, como nossas observa√ß√µes prov√™m de amostras, estas estimativas est√£o sujeitas √† varia√ß√£o inerente √†s observa√ß√µes de que dispomos e certamente n√£o ser√£o iguais ao valor da popula√ß√£o estat√≠stica. Devemos portanto, entender quais evid√™ncias estes estimadores nos fornecem para a exist√™ncia de um efeito de \\(X\\) sobre \\(Y\\), ou seja, para rejeitarmos a hip√≥tese nula em favor de \\(H_A\\).\n\n3.1 Teste sobre \\(\\beta_1\\)\nNa regress√£o linear simples, o efeito de \\(X\\) sobre \\(Y\\) depende do valor de \\(\\beta_1\\)\n\\(Y_i = \\beta + \\beta_1X_i + \\epsilon_i\\)\nA n√£o exist√™ncia de um efeito implica em \\(\\beta_1 = 0\\) e consequentemente:\n\\(Y_i = \\beta_0 + 0 \\times X_i + \\epsilon_i\\) \\(\\rightarrow\\) \\(Y = \\beta_0 + \\epsilon_i\\)\nPortanto, as hip√≥teses nula e alternativa seriam:\n\\(H_0: \\beta_1 = 0\\)\n\\(H_A: \\beta_1 \\ne 0\\)\nSegundo \\(H_0\\), a inclina√ß√£o da reta \\(populacional\\) n√£o √© diferente de zero e o valor estimado \\(\\hat{\\beta_1}\\) ocorreu puramente ao acaso, como efeito da varia√ß√£o amostral. Para testar esta hip√≥tese, utilizamos a distribui√ß√£o de t de modo que:\n\\[t = \\frac{\\hat{\\beta_1} - \\beta_1}{s_{\\hat{\\beta_1}}}\\]\nComo segundo \\(H_0\\), \\(\\beta_1  = 0\\) a express√£o fica:\n\\[t = \\frac{\\hat{\\beta_1} - 0}{s_{\\hat{\\beta_1}}} = \\frac{\\hat{\\beta_1}}{s_{\\hat{\\beta_1}}}\\]\n\\(s_{\\hat{\\beta_1}}\\) √© o erro padr√£o de \\(\\beta_1\\) calculado por:\n\\[s_{\\hat{\\beta_1}} = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum{(X_i-\\overline{X})^2}}}\\]\nNo exemplo sobre a fauna praial estamos interessados em testar a hip√≥tese de que a riqueza de esp√©cies esteja associada ao grau de exposi√ß√£o √†s ondas. Em regress√£o linear, esta hip√≥tese pode ser expressa por:\n\\[t = \\frac{\\hat{\\beta_1}}{s_{\\hat{\\beta_1}}} = \\frac{-2.58}{0.88} = -2.944\\]\nQue na distribui√ß√£o de t fica:\n\n\n\n\n\n\n\n\n\nSe nosso n√≠vel de significancia \\(\\alpha = 0.05\\), ent√£o a probabilidade \\(p = 0.011 + 0.011 = 0.022\\) indica que devemos rejeitar \\(H_0\\) e aceitar que existe uma rela√ß√£o entre Riqueza de esp√©cies e NAP.\n\n\n3.2 An√°lise de vari√¢ncia da regress√£o\nComo j√° dizemos, a estrutura de um modelo de regress√£o √© dada por um componente sistem√°tico expresso como fun√ß√£o de \\(X\\) (\\(\\beta_0 + \\beta_1X_i\\)) e um componente aleat√≥rio expresso pelos res√≠duos do modelo (\\(\\epsilon_i\\)). A varia√ß√£o total em \\(Y\\) no modelo de regress√£o portanto, pode ser atribu√≠da a ambos os efeitos de \\(X\\) e do res√≠duo. Estas quantias de varia√ß√£o podem mensuradas pelos somat√≥rio dos quadrados abaixo.\nSoma dos quadrados totais:\n\\(SQ_Y = \\sum{(Y_i - \\overline{Y})^2}\\)\nSoma dos quadrados da regress√£o:\n\\(SQ_{Regress√£o}= \\sum{(\\hat{Y_i} - \\overline{Y})^2}\\)\nE soma dos quadrados do res√≠duo:\n\\(SQ_{Res√≠duo}= \\sum{(Y_i - \\hat{Y_i})^2}\\)\nPode-se mostrar ainda que vale a express√£o:\n\\[SQ_Y = SQ_{Regress√£o} + SQ_{Res√≠duo}\\] A decomposi√ß√£o destas quantias √© conhecida parti√ß√£o das somas dos quadrados e nos permitem comparar a influ√™ncia de \\(X\\) com a influ√™ncia do puro acaso sobre a variabilidade em \\(Y\\). Se todos os pontos estiverem perfeitamente sobre a reta, ent√£o toda a varia√ß√£o em \\(Y\\) seria atribu√≠da √† influ√™ncia de \\(X\\). Por outro lado, √† medida que aumenta a dist√¢ncia m√©dia dos pontos acima e abaixo da curva, aumenta a parcela atribu√≠da ao acaso.\n\n\n\n\n\n\n\n\n\nEstes componentes de varia√ß√£o podem ser organizados em uma Tabela de An√°lise de Vari√¢ncia (ANOVA). \\(n\\) se refere ao n√∫mero de amostras.\n\n\n\n\n\n\n\n\n\n\n\nFonte de varia√ß√£o\nSQ\ngl\nQM\nF\np\n\n\n\n\nRegress√£o\n\\(SQ_{Regress√£o}\\)\n\\(gl_{Regress√£o}\\)\n\\(QM_{Regress√£o} = \\frac{SQ_{Regress√£o}}{gl_{Regress√£o}}\\)\n\\(\\frac{QM_{Regress√£o}}{QM_{Res√≠duo}}\\)\nProbabilidade associada √† cauda da distribui√ß√£o F\n\n\nRes√≠duo\n\\(SQ_{Res√≠duo}\\)\n\\(gl_{Res√≠duo}\\)\n\\(QM_{Res√≠duo} = \\frac{SQ_{Res√≠duo}}{gl_{Res√≠duo}}\\)\n\n\n\n\nTotal\n\\(SQ_{Y}\\)\n\\(gl_{Y}\\)\n\\(QM_{Y} = \\frac{SQ_{Y}}{gl_{Y}}\\)\n\n\n\n\n\nAs coluna \\(gl\\) se refer aos graus de liberdade nos modelo de regress√£o, a semelhan√ßa do que discutimos para o teste t de Student. A coluna QM (Quadrado m√©dio) apresenta os estimadores de vari√¢ncia da regress√£o (\\(QM_{Regress√£o}\\)), do res√≠duo (\\(QM_{Res√≠duo}\\)) e total (\\(QM_{Y}\\)).\n\n3.2.1 A distribui√ß√£o F\nO valor de \\(F\\) na tabela se refere a distribui√ß√£o de probabilidade F. Esta distribui√ß√£o de probabilidades √© esperada para a raz√£o entre duas vari√¢ncias amostrais. No caso da regress√£o linear, estas s√£o a vari√¢ncia da regress√£o (\\(QM_{Regress√£o}\\) no numerador) e a vari√¢ncia residual (\\(QM_{Res√≠duo}\\) no denominador). Diferente da distribui√ßao t, a distribui√ß√£o F tem um formato assim√©trico, sendo que o grau de assimetria depende dos graus de liberdade do numerador e do denominador. O valor de \\(p\\) na tabela se refere √† √°rea sob a distribui√ß√£o F, acima do valor de \\(F\\) calculado. Na ANOVA da regress√£o, um valor de \\(p &lt; \\alpha\\) nos leva a rejeitar a hip√≥tese nula e assumir que a vari√°vel \\(X\\) exerce algum efeito sobre \\(Y\\).\n\nO s√≠mbolo \\(F\\) foi dado em homenagem a Ronald Aylmer Fisher o estat√≠stico e geneticista Brit√¢nico do in√≠cio do s√©c. XX, que entre in√∫meras outras contribui√ß√µes, desenvolveu a An√°lise de Vari√¢ncia. Fisher √© descrito como ‚Äúa genius who almost single-handedly created the foundations for modern statistical science‚Äù (Halt 1998) e como ‚Äúthe single most important figure in 20th century statistics‚Äù (Efron 1998). Ver Ronald Aylmer Fisher.\n\n\n\n\n\n\n\n\n\n\nOs resultados da ANOVA para os dados da fauna praial nos d√° os seguintes valores. Confira os c√°lculos.\n\n\n\n\n\nFonte de varia√ß√£o\nSQ\ngl\nQM\nF\np\n\n\n\n\nRegress√£o\n65.68\n1\n65.68\n8.64\n0.022\n\n\nRes√≠duo\n53.21\n7\n7.60\nNA\nNA\n\n\nTotal\n118.89\n8\n14.86\nNA\nNA\n\n\n\n\n\nO valor de \\(p = 0.022\\) abaixo do n√≠vel de signific√¢ncia \\(\\alpha = 0.05\\), nos leva a rejeitar a hip√≥tese nula em favor da alternativa, concluindo que o √≠ndice de exposi√ß√£o √†s ondas interfere sobre a riqueza da macro-fauna. O valor de \\(p\\) foi identico ao obtido no teste de hip√≥teses de \\(\\beta_1\\). No modelo de regress√£o linear simples isto √© necessariamente verdadeiro, pois toda a varia√ß√£o associada √† regress√£o √© devida ao efeito do coeficiente \\(\\beta_1\\). Por outro lado, nos modelos de regress√£o m√∫ltipla, em que temos:\n\\[Y_i = \\beta_0 + \\beta_1X_{i1} + \\beta_1X_{i2} + \\cdots + \\beta_mX_{im} + \\epsilon_i\\]\nesta rela√ß√£o n√£o √© mais observada, pois existem m√∫ltiplos coeficientes agindo sobre a varia√ß√£o em \\(Y\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#coeficiente-de-determina√ß√£o-r2",
    "href": "content/regressao-linear/regressao-linear-simples.html#coeficiente-de-determina√ß√£o-r2",
    "title": "Regress√£o linear simples",
    "section": "4 Coeficiente de determina√ß√£o \\(R^2\\)",
    "text": "4 Coeficiente de determina√ß√£o \\(R^2\\)\nUma vez que toda a varia√ß√£o observada em Y pode ser alocada aos efeitos da reta de regress√£o e e do res√≠duo podemos fazer a seguinte quest√£o:\n\nQual parcela da varia√ß√£o na Riqueza √© explicada exclusivamente pelo modelo de regress√£o?\n\nEsta pergunta pode ser respondida calculando o que denominamos de coeficiente de determin√ß√£o ou simplesmente \\(R^2\\):\n\\[R^2 = \\frac{SQ_{Regress√£o}}{SQ_Y} = 1 - \\frac{SQ_{Res√≠duo}}{SQ_Y}\\]\nO valor de \\(SQ_{Regress√£o}\\) mede a varia√ß√£o explicada exclusivamente pela regress√£o, \\(SQ_{Res√≠duo}\\) a varia√ß√£o residual e \\(SQ_Y\\) mede a varia√ß√£o total em \\(Y\\). Ao dividir \\(SQ_{Res√≠duo}\\) por \\(SQ_Y\\), o \\(r^2\\) nos informa sobre qual a fra√ß√£o da varia√ß√£o total √© explicada somente pela reta de regress√£o.\nNpo exemplo da fauna praial:\n\\[R^2 = 1 - \\frac{53.11}{118.89} = 0.5533\\]\nO que significa que aproximadamente 55.33% da varia√ß√£o na riqueza √© explicada pela varia√ß√£o no grau de exposi√ß√£o √†s ondas (NAP). N√£o sabemos a que se deve o restante da varia√ß√£o e, no contexto do modelo de regress√£o, assumimos ser uma varia√ß√£o aleat√≥ria inerente a cada observa√ß√£o (\\(\\epsilon_i\\)). Esta varia√ß√£o aleat√≥ria, como dito, segue uma distribui√ß√£o normal com ponto central sobre a reta e vari√¢ncia data por \\(\\sigma^2\\). Este pressuposto √© fundamental para a discuss√£o do pr√≥ximo ponto a respeito do intervalo de confian√ßa de \\(Y\\)"
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#intervalo-de-confian√ßa-de-y",
    "href": "content/regressao-linear/regressao-linear-simples.html#intervalo-de-confian√ßa-de-y",
    "title": "Regress√£o linear simples",
    "section": "5 Intervalo de confian√ßa de \\(Y\\)",
    "text": "5 Intervalo de confian√ßa de \\(Y\\)\nComo nem todos os pontos caem perfeitamente sobre a reta, seria interessante que pud√©ssemos obter um intervalo de confian√ßa de \\(Y\\) para um dado valor de \\(X\\). A amplitude deste intervalo ir√° depender da vari√¢ncia dos valores ajustados (\\(s^2_{Y|X}\\)) de \\(Y\\), calculada por:\n\\[s^2_{Y|X} = s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})\\]\ndo modo que:\n\\[s_{Y|X} = \\sqrt{s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})}\\]\nNote pela express√£o acima que o \\(s_{Y|X}\\) diminui quanto:\n\na vari√¢ncia residual \\(s^2\\) diminui;\no tamanho amostral \\(n\\) aumenta.\no dado valor de \\(X_i\\) est√° pr√≥ximo √† m√©dia, pois neste caso \\((X_i-\\overline{X})\\) diminui.\n\nEncontrado \\(s_{Y|X}\\), o intervalo de confian√ßa de \\(Y\\) √© dado por:\n\\[IC_{Y} = \\hat{Y}\\pm t_{(\\alpha, n-2)} \\times s_{Y|X}\\]\nPara os dados da macrofauna, vamos exemplificar o c√°lculo de \\(IC_{95\\%}\\) para a \\(4^a\\) observa√ß√£o da tabela, em que Richness = 3 e NAP = 0.46.\nLembre-se que j√° estimamos anteriormente a vari√¢ncia residual destes dados (\\(s^2 = 7.59\\)). Como temos 9 observa√ß√µes, o valor de \\(t_{(\\alpha, n-2)} = 2.36\\), portanto:\n\\(s_{Y|X} = \\sqrt{s^2(\\frac{1}{n} + \\frac{(X_i-\\overline{X})^2}{SQ_X})} = 0.93\\)\nO valor estimado de riqueza neste ponto √© 4.75, portanto:\n\\(IC_{Y} = \\hat{Y} \\pm t_{(\\alpha, n-2)} \\times s_{Y|X} = 4.75 \\pm 2.36 \\times 0.93\\)\n\\(IC_{Y} = 4.75 \\pm 2.19\\)\n\\(IC_{Y_{limite superior}} = 6.94\\)\n\\(IC_{Y_{limite inferior}} = 2.56\\)\nPodemos calcular intervalos destes para todos os pontos observados como expresso na tabela abaixo.\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichness\nNAP\n\\(\\hat{Y}\\)\n\\(s_{Y \\mid X}\\)\n\\(IC_{inferior}\\)\n\\(IC_{superior}\\)\n\n\n\n\n13\n-1.34\n9.40\n1.72\n5.34\n13.46\n\n\n8\n0.64\n4.29\n0.96\n2.02\n6.56\n\n\n4\n-0.20\n6.46\n1.03\n4.04\n8.88\n\n\n3\n0.46\n4.75\n0.93\n2.56\n6.94\n\n\n6\n0.73\n4.06\n0.99\n1.73\n6.39\n\n\n1\n2.22\n0.21\n1.90\n-4.29\n4.71\n\n\n1\n1.38\n2.38\n1.30\n-0.70\n5.46\n\n\n7\n-1.00\n8.52\n1.48\n5.02\n12.02\n\n\n3\n0.00\n5.94\n0.96\n3.67\n8.21\n\n\n\n\n\nE represent√°-los graficamente, juntamente com os valores ajustados de Y.\n\n\n\n\n\n\n\n\n\nNote que na figura acima, est√£o representados os valores observados de riqueza de esp√©cies (em preto), os valores ajustados (azul) e os intervalos a 95% (vermelho). Os valores ajustados s√£o aqueles utilizados para construir a reta de regress√£o. O intervalo n√£o costuma ser representados por pontos individuais, mas por uma banda que delimita a √°rea que restringe o intervalo de confian√ßa ao n√≠vel \\(1 - \\alpha\\) como na figura abaixo.\n\n\n\n\n\n\n\n\n\nA banda mais estreita pr√≥xima ao ponto m√©dio de \\(X\\), reflete o ponto comentado anteriormente, de que quanto mais pr√≥ximo ao centro da distibui√ß√£o de pontos, mais confian√ßa temos sobre os limites m√°ximos e m√≠nimos que um valor de \\(Y\\) pode assumir. Do mesmo modo, esta confian√ßa diminui √† medida que nos aproximamos dos extremos dos valores observados em \\(X\\)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#pressupostos-da-regress√£o-linear-simples",
    "href": "content/regressao-linear/regressao-linear-simples.html#pressupostos-da-regress√£o-linear-simples",
    "title": "Regress√£o linear simples",
    "section": "6 Pressupostos da regress√£o linear simples",
    "text": "6 Pressupostos da regress√£o linear simples\nAo realizar uma regress√£o linear simples, devemos assumir como verdadeiros alguns pressupostos.\n\nO modelo linear descreve adequadamente a rela√ß√£o funcional entre \\(X\\) e \\(Y\\);\nCada par de observa√ß√£o \\((X,Y)\\) √© independente dos demais;\nA vari√°vel \\(X\\) √© medida sem erros;\nOs res√≠duos t√™m distribui√ß√£o normal, e;\nA vari√¢ncia residual \\(\\sigma^2\\) √© constante ao longo dos valores de \\(X\\).\n\n\n6.1 Rela√ß√£o funcional linear\nCaso a rela√ß√£o funcional entre \\(X\\) e \\(Y\\) assuma uma forma diferente de \\(Y_i = \\beta_0 + \\beta_1X_i\\), o modelo de regress√£o n√£o √© mais v√°lido, pois a estimativa de erro ir√° conter, al√©m do componente aleat√≥rio residual, um componente sistem√°tico. Este componente ter√° efeito sobre influ√™ncia sobre a predi√ß√£o do modelo, sobretudo nos extremos das observa√ß√µes. Por modelo linear, entendemos aqueles em que os coeficientes \\(\\beta\\) aparecem de forma aditiva. Modelos em que os componentes aparecem de outro modo na equa√ß√£o como pot√™ncia ou no denominador de uma equa√ß√£o s√£o exemplos de modelos n√£o-lineares. Abaixo est√£o dois exemplos de rela√ß√µes n√£o-lineares comumente observadas em fen√¥menos ambientais:\nEqua√ß√£o pot√™ncia: \\(Y_i = \\beta_0 X_i^{\\beta_1}\\)\nModelo de Michaelis-Menten: \\(Y_i = \\frac{\\beta_0 X_i}{\\beta_1 + X_i}\\)\n\n\n6.2 Independ√™ncia\nA falta de independ√™ncia pode ocorrer como resultado do delineamento amostral inapropriado para a quest√£o em teste. A falta de independ√™ncia torna cr√≠tico o uso de uma distribui√ß√£o de probabilidade para o c√°lculo do intervalo de confian√ßa (distribui√ß√£o \\(t\\)) e para o teste de hip√≥teses (distribui√ß√µes \\(t\\) e \\(F\\) ). Casos cl√°ssicos de falta de independ√™ncia s√£o aqueles em que as observa√ß√µes s√£o denominadas como pseudor√©plicas (Hurlbert 1984). Ap√≥s a publica√ß√£o cl√°ssica de Hurlbert, muito tem sido dito sobre pseudoreplica√ß√£o. Em experimentos de campo, a falta de independ√™ncia ocorre geralmente como resultados da proximidade espacial entre as r√©plicas ou sobre s√©ries temporais.\n\n\n6.3 Vari√°vel \\(X\\) √© medida sem erros\nVeja que a parcela residual do modelo de regress√£o se refere √† dist√¢ncia vertical de \\(Y_i\\), para um dados valor de \\(X\\). Isto implica que os n√≠veis de \\(X\\) s√£o previamente definidos. Quando existe variabilidade aleat√≥ria tanto em \\(Y\\) quanto em \\(X\\), o modelo correto para a estimativa dos par√¢metros da regress√£o √© conhecido como Modelo II de regress√£o. Este pressuposto √© frequ√™ntemente ignorado em delineamentos de regress√£o, sobretudo em estudos observacionais, o que n√£o parece ser particularmente problem√°tico.\n\n\n6.4 Distribui√ß√£o normal dos res√≠duos\nAssim como no pressuposto de independ√™ncia, assumir que os res√≠duos t√™m uma distribui√ß√£o normal permite o uso da distribui√ß√£o \\(F\\) pra o teste de hip√≥tese e da distribui√ß√£io \\(t\\) para o c√°lculo do intervalo de confian√ßa. Uma distribui√ß√£o de erros diferente da distribui√ß√£o normal ter√° influ√™ncia sobre o c√°lculo da amplitude do intervalo de confian√ßa.\n\n\n6.5 Vari√¢ncia residual constante\nCaso, a vari√¢ncia \\(\\sigma\\) n√£o seja constante ao longo da reta de regress√£o, o c√°lculo do intervalo de confian√ßa e o resultado do teste de hip√≥teses s√£o afetados. Uma vez diagnosticada uma vari√¢ncia n√£o-constante existem modelos de regress√£o que podem ser apicados para incorporar este efeito em suas estimativas (Zuur et al. 2009)."
  },
  {
    "objectID": "content/regressao-linear/regressao-linear-simples.html#diagn√≥sticos-da-regress√£o",
    "href": "content/regressao-linear/regressao-linear-simples.html#diagn√≥sticos-da-regress√£o",
    "title": "Regress√£o linear simples",
    "section": "7 Diagn√≥sticos da regress√£o",
    "text": "7 Diagn√≥sticos da regress√£o\nO diagn√≥stivo da regress√£o √© composto por observa√ß√µes e testes que ajudam a decidirmos se a regress√£o linear foi um bom modelo para ajustar a um conjunto de dados particular. Um bom modelo neste contexto significa um modelo que atendeu aos pressuostos descritos acima. Esta verifica√ß√£o passa pela observa√ß√£o de padr√µes nos res√≠duos da regress√£o, ou seja, pela observa√ß√£o da parcela estoc√°stica do modelo.\n\n7.1 Gr√°fico de res√≠duos\nO primeiro diagn√≥stico da regress√£o √© conhecido como gr√°fico de res√≠duos, que consiste em um gr√°fico de dispers√£o entre os res√≠duos e o valor ajustado \\(\\hat{Y}\\). Abaixo est√£o os gr√°ficos de res√≠duos que surge quando ajustamos uma reta a dados que apresentam uma rela√ß√£o linear, uma fun√ß√£o pot√™ncia, uma fun√ß√£o assint√≥tica e uma rela√ß√£o linear por√©m comm vari√¢ncia heterog√™nea.\n\n\n\n\n\n\n\n\n\nNas primeiras duas figuras, em que a rela√ß√£o √© linear, vemos um padr√£o crescente de \\(Y\\) como fun√ß√£o de \\(X\\) (figura da esquerda), em que os pontos est√£o aleat√≥riamente acima e abaixo da reta de regress√£o. Este padr√£o se reflete em um gr√°fico de res√≠duos (figura da direita) em que os pontos ficam aleat√≥riamente acima e abaixo de zero expressando res√≠duos positivos e negativos respectivamente. Em uma situa√ß√£o em que os pontos estivessem perfeitamente sobre a reta, os res√≠duos seriam todos iguais a zero e o gr√°fico de res√≠duos mostraria todos os pontos alinhados horizontalmente em zero.\nQuando a rela√ß√£o √© pot√™ncia e tentamos ajustar uma reta sobre, vemos que inicialmente os res√≠duos sao positivos, o seja, est√£o acima da reta. Os res√≠duos se tornam negativos no centro da nuvem de pontos e novamente positivos ao final do gr√°fico. Este padr√£o √© mais evidente no gr√°fico de res√≠duos, que mostra um componente sistem√°tico dos res√≠duos como fu√ß√£o do valor ajustado. Ao usar uma regress√£o linear neste caso, ir√≠amos subestimar consistentemente os valores de Y nos extremos da figura e superestiml√°-los no trecho central. Portanto, uma reta de regress√£o, quando ajustada a um conjunto de dados que expressa um padr√£o n√£o-linear, n√£o √© capaz de isolar adequadamente as parcelas aleat√≥rias e sistem√°ticas da rela√ß√£o entre \\(Y\\) e \\(X\\). Isto pode ser corrigido aplicando-se uma regress√£o n√£o-linear aos dados.\nQuando a rela√ß√£o √© assint√≥tica, o resultado do ajuste foi inverso ao anterior. De fato, resultados an√°logos ser√£o observados senpre que tentarmos ajustra uma regress√£o linear a dados que expressam padr√µes n√£o-lineares.\nNo √∫ltimo exemplo (vari√¢ncia heterog√™nea) os pontos tendem a se afastar consistentemente da reta de regress√£o conforme aumentam os valores de \\(X\\). Isto denota que o pressuposto de vari√¢ncia \\(\\sigma^2\\) constante n√£o √© v√°lido nesta rela√ß√£o. Isto pode ser corrigido aplicando-se um modelo de regress√£o linear com vari√¢ncia heterog√™nea.\n\n\n7.2 Histograma dos res√≠duos\nOutro diagn√≥stico da regress√£o consiste em fazer um histograma dos gr√°ficos de res√≠duos. Um histograma, aproximadamente sim√©trico ao redor de zero o que sugere que o pressuposto de normalidade dos res√≠duos √© v√°lido neste caso. Existem testes formais de normalidade cmo o teste de Kolmogorov Smirnov ou o teste de Shapiro-Wilk."
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html",
    "href": "content/multivariada-numerica/cossine-similarity.html",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "",
    "text": "Considere a situa√ß√£o em que temos 8 esp√©cies de peixes nas descritas por 6 tra√ßos funcionais (Tabela¬†1). Tra√ßos funcionais s√£o caracter√≠sticas morfol√≥gicas, fisiol√≥gicas ou comportamentais mensur√°veis que influenciam diretamente o desempenho ecol√≥gico das esp√©cies, determinando como elas interagem com o ambiente e utilizam recursos (como habitats, alimento e abrigo). Espera-se, por exemplo, que esp√©cies similares em seus tra√ßos funcionais ocupem um espa√ßo de nicho e respondam de forma similar a press√µes ambientais. Nosso objetivo ser√° quantificar o grau de similaridade entre os pares de esp√©cies por meio do √≠ndice de similaridade por cossenos.\n\n\n\nTabela¬†1: Tra√ßos funcionais entre 8 esp√©cies de peixes de riachos. CI: √çndice de compress√£o; RD: Altura relativa; IVF: √çndice de achatamento ventral; RAC: √Årea relativa da nadadeira caudal; REP: Posi√ß√£o relativa do olho; MO: orienta√ß√£o da boca. Bstr: Bryconamericus stramineus; Bsp: Bryconamericus sp.; Cfasc: Characidium fasciatum; Czeb: Characidium zebra; Cih: Cetopsorhamdia iheringi; Imin: Imparfinis minutus; Hsp: Hisonotus sp.; Hypsp: Hypostomus sp.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTra√ßo\nBstr\nBsp\nCfasc\nCzeb\nCih\nImin\nHsp\nHypsp\n\n\n\n\nCI\n1.67\n1.71\n1.41\n1.47\n0.97\n0.69\n0.73\n0.66\n\n\nRD\n0.21\n0.26\n0.21\n0.22\n0.17\n0.12\n0.16\n0.19\n\n\nIVF\n0.57\n0.53\n0.51\n0.49\n0.59\n0.55\n0.39\n0.35\n\n\nRAC\n0.14\n0.13\n0.14\n0.11\n0.22\n0.26\n0.19\n0.3\n\n\nREP\n0.7\n0.68\n0.79\n0.8\n0.91\n0.76\n0.71\n0.85\n\n\nMO\n1.26\n1.74\n3.03\n1.98\n2.06\n2.24\n3.14\n3.14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBryconamericus stramineus\n\n\n\n\n\n\n\nBryconamericus sp\n\n\n\n\n\n\n\n\n\nCharacidium fasciatum\n\n\n\n\n\n\n\nCharacidium zebra\n\n\n\n\n\n\n\n\n\nCetopsorhamdia iheringi\n\n\n\n\n\n\n\nImparfinis minutus\n\n\n\n\n\n\n\n\n\nHisonotus sp\n\n\n\n\n\n\n\nHypostomus sp\n\n\n\n\n\n\nFigura¬†1: Esp√©cies da Tabela¬†1.\n\n\n\nCada esp√©cie est√° representada em uma coluna, e as linhas correspondem √†s medidas morfol√≥gicas que podem ser associadas aos tra√ßos funcionais das esp√©cies. Em nota√ß√£o matricial, podemos representar a Tabela¬†1 como:\n\\[\\mathbf{T} =\n\\begin{bmatrix}\n1.67 & 1.71 & \\dots & 0.66\\\\\n0.21 & 0.26 & \\dots & 0.19\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n1.26 & 1.74 & \\dots & 3.14\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#matriz-de-tra√ßos-morfol√≥gicos",
    "href": "content/multivariada-numerica/cossine-similarity.html#matriz-de-tra√ßos-morfol√≥gicos",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "",
    "text": "Considere a situa√ß√£o em que temos 8 esp√©cies de peixes nas descritas por 6 tra√ßos funcionais (Tabela¬†1). Tra√ßos funcionais s√£o caracter√≠sticas morfol√≥gicas, fisiol√≥gicas ou comportamentais mensur√°veis que influenciam diretamente o desempenho ecol√≥gico das esp√©cies, determinando como elas interagem com o ambiente e utilizam recursos (como habitats, alimento e abrigo). Espera-se, por exemplo, que esp√©cies similares em seus tra√ßos funcionais ocupem um espa√ßo de nicho e respondam de forma similar a press√µes ambientais. Nosso objetivo ser√° quantificar o grau de similaridade entre os pares de esp√©cies por meio do √≠ndice de similaridade por cossenos.\n\n\n\nTabela¬†1: Tra√ßos funcionais entre 8 esp√©cies de peixes de riachos. CI: √çndice de compress√£o; RD: Altura relativa; IVF: √çndice de achatamento ventral; RAC: √Årea relativa da nadadeira caudal; REP: Posi√ß√£o relativa do olho; MO: orienta√ß√£o da boca. Bstr: Bryconamericus stramineus; Bsp: Bryconamericus sp.; Cfasc: Characidium fasciatum; Czeb: Characidium zebra; Cih: Cetopsorhamdia iheringi; Imin: Imparfinis minutus; Hsp: Hisonotus sp.; Hypsp: Hypostomus sp.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTra√ßo\nBstr\nBsp\nCfasc\nCzeb\nCih\nImin\nHsp\nHypsp\n\n\n\n\nCI\n1.67\n1.71\n1.41\n1.47\n0.97\n0.69\n0.73\n0.66\n\n\nRD\n0.21\n0.26\n0.21\n0.22\n0.17\n0.12\n0.16\n0.19\n\n\nIVF\n0.57\n0.53\n0.51\n0.49\n0.59\n0.55\n0.39\n0.35\n\n\nRAC\n0.14\n0.13\n0.14\n0.11\n0.22\n0.26\n0.19\n0.3\n\n\nREP\n0.7\n0.68\n0.79\n0.8\n0.91\n0.76\n0.71\n0.85\n\n\nMO\n1.26\n1.74\n3.03\n1.98\n2.06\n2.24\n3.14\n3.14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBryconamericus stramineus\n\n\n\n\n\n\n\nBryconamericus sp\n\n\n\n\n\n\n\n\n\nCharacidium fasciatum\n\n\n\n\n\n\n\nCharacidium zebra\n\n\n\n\n\n\n\n\n\nCetopsorhamdia iheringi\n\n\n\n\n\n\n\nImparfinis minutus\n\n\n\n\n\n\n\n\n\nHisonotus sp\n\n\n\n\n\n\n\nHypostomus sp\n\n\n\n\n\n\nFigura¬†1: Esp√©cies da Tabela¬†1.\n\n\n\nCada esp√©cie est√° representada em uma coluna, e as linhas correspondem √†s medidas morfol√≥gicas que podem ser associadas aos tra√ßos funcionais das esp√©cies. Em nota√ß√£o matricial, podemos representar a Tabela¬†1 como:\n\\[\\mathbf{T} =\n\\begin{bmatrix}\n1.67 & 1.71 & \\dots & 0.66\\\\\n0.21 & 0.26 & \\dots & 0.19\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n1.26 & 1.74 & \\dots & 3.14\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#calculando-similaridade-por-cossenos",
    "href": "content/multivariada-numerica/cossine-similarity.html#calculando-similaridade-por-cossenos",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "2 Calculando Similaridade por cossenos",
    "text": "2 Calculando Similaridade por cossenos\nCada esp√©cie na Tabela¬†1 pode ser vista como um vetor \\(\\vec{v}\\) ou \\(\\vec{u}\\) com 6 entradas, uma para cada tra√ßo funcional. Assim, o cosseno do √¢ngulo \\(\\theta\\) entre os vetores pode ser calculado por:\n\\[\\cos(\\theta) = \\frac{\\vec{v} \\cdot \\vec{u}}{\\|\\vec{v}\\| \\|\\vec{u}\\|}\n\\tag{1}\\]\nOnde:\n\n\\(\\vec{v} \\cdot \\vec{u}\\) √© o produto escalar entre os vetores \\(\\vec{v}\\) e \\(\\vec{u}\\).\n\\(\\|\\vec{v}\\|\\) e \\(\\|\\vec{u}\\|\\) s√£o as normas (comprimentos) dos vetores.\n\\(\\theta\\) √© o √¢ngulo entre os vetores no espa√ßo multidimensional de 6 dimens√µes.\n\nO valor do \\(\\cos(\\theta)\\) funciona como um √≠ndice de similaridade cuja interpreta√ß√£o ecol√≥gica √© direta:\n\n\\(\\cos(\\theta) \\approx 1\\) (√¢ngulo pr√≥ximo a 0¬∞), indica esp√©cies com alta similaridade funcional, compartilhando estrat√©gias ecol√≥gicas semelhantes;\n\\(\\cos(\\theta) \\approx 0\\) (√¢ngulo pr√≥ximo a 90¬∞) revela esp√©cies ecologicamente distintas, com tra√ßos funcionais divergentes."
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#exemplo-pr√°tico-similaridade-entre-bstr-e-bsp",
    "href": "content/multivariada-numerica/cossine-similarity.html#exemplo-pr√°tico-similaridade-entre-bstr-e-bsp",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "3 Exemplo Pr√°tico: Similaridade entre Bstr e Bsp",
    "text": "3 Exemplo Pr√°tico: Similaridade entre Bstr e Bsp\n\nVetores das esp√©cies:\n\n\\[\n\\vec{v}_{\\text{Bstr}} = \\begin{bmatrix}\n1.67 \\\\ 0.21 \\\\ 0.57 \\\\ 0.14 \\\\ 0.7 \\\\ 1.26\n\\end{bmatrix}, \\quad\n\\vec{u}_{\\text{Bsp}} = \\begin{bmatrix}\n1.71 \\\\ 0.26 \\\\ 0.53 \\\\ 0.13 \\\\ 0.68 \\\\ 1.74\n\\end{bmatrix}\n\\]\n\nProduto Escalar:\n\n\\[\\vec{v} \\cdot \\vec{u} = (1.67 \\times 1.71) + (0.21 \\times 0.26) + \\dots + (1.26 \\times 1.74) = 5.899\\]\n\nNormas dos Vetores: \\[\\|\\vec{v}\\| = \\sqrt{1.67^2 + 0.21^2 + \\dots + 1.26^2} \\approx 2.2924\\] \\[\\|\\vec{u}\\| = \\sqrt{1.71^2 + 0.26^2 + \\dots + 1.74^2} \\approx 2.6037\\]\nCosseno do √Çngulo: \\[\\cos(\\theta) = \\frac{5.899}{2.2924 \\times 2.6037} \\approx 0.988\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#similaridade-por-cossenos-a-partir-de-opera√ß√µes-matriciais",
    "href": "content/multivariada-numerica/cossine-similarity.html#similaridade-por-cossenos-a-partir-de-opera√ß√µes-matriciais",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "4 Similaridade por Cossenos a partir de opera√ß√µes matriciais",
    "text": "4 Similaridade por Cossenos a partir de opera√ß√µes matriciais\nOs passos do item dois podem ser generalizados para todos os pares de esp√©cies utilizando uma s√©rie de opera√ß√µes matriciais.\n\nObten√ß√£o da Matriz de Produtos Escalares (\\(\\mathbf{E}\\)): \\[\\mathbf{E} = \\mathbf{T}^\\top \\mathbf{T}\\]\n\n\\[\\mathbf{T^\\top} =\n\\begin{bmatrix}\n1.67 & 0.21 & \\dots & 1.26\\\\\n1.71 & 0.26 & \\dots & 1.74\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n0.66 & 0.19 & \\dots & 3.14\n\\end{bmatrix}, \\quad\n\\mathbf{E} =\n\\begin{bmatrix}\ne_{11} & e_{12} & \\dots & e_{18}\\\\\ne_{21} & e_{22} & \\dots & e_{28}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\ne_{81} & e_{82} & \\dots & e_{88}\n\\end{bmatrix}\n\\]\n\n\n\nObten√ß√£o da Matriz \\(\\mathbf{D}\\):\n\nAs normas dos vetores de esp√©cies da matriz \\(\\mathbf{T}\\) podem ser obtidas a partir dos elementos da diagonal da matriz \\(\\mathbf{E}\\), em que:\n\\[\\text{norma}_i = \\sqrt{e_{ii}}\\]\nSabendo disso, obtenha a Matriz \\(\\mathbf{D}\\):\n\\[\\mathbf{D} =\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{e_{11}}} & 0 & \\dots & 0\\\\\n0 & \\frac{1}{\\sqrt{e_{22}}} & \\dots & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n0 & 0 & \\dots & \\frac{1}{\\sqrt{e_{88}}}\n\\end{bmatrix}\n\\]\n\n\nMatriz Final de similaridade por cossenos (\\(\\mathbf{C}\\)):\n\n\\[\\mathbf{C} = \\mathbf{D} \\mathbf{E} \\mathbf{D}\n\\tag{2}\\]"
  },
  {
    "objectID": "content/multivariada-numerica/cossine-similarity.html#roteiro-matriz-de-similaridade-no-google-planilhas",
    "href": "content/multivariada-numerica/cossine-similarity.html#roteiro-matriz-de-similaridade-no-google-planilhas",
    "title": "Ecologia Funcional: aplica√ß√£o da √°lgebra matricial",
    "section": "5 Roteiro: Matriz de Similaridade no Google Planilhas",
    "text": "5 Roteiro: Matriz de Similaridade no Google Planilhas\n\nAcesse sheets.google.com.\nInsira os dados da tabela \\(\\mathbf{T}\\) (Tabela¬†1). Se necess√°rio modifique o decimal de ponto (.) para v√≠rgula (,).\nCalcule \\(\\mathbf{T}^\\top\\).\n\nDica - utilize a f√≥rmula:\n=TRANSPOR()\n\nCalcule a matriz \\(\\mathbf{E}\\).\n\nDica - utilize a f√≥rmula:\n=MATRIZ.MULT()\n\nCalcule as normas das colunas da matriz \\(\\mathbf{E}\\) e monte a matriz diagonal \\(\\mathbf{D}\\).\n\nDica: A matriz diagonal \\(\\mathbf{D}\\) ter√° as mesmas dimens√µes de \\(\\mathbf{E}\\), mas ser√° preenchida com zeros exceto na diagonal principal. Nela, os valores ser√£o \\(\\frac{1}{\\sqrt{e_{ii}}}\\), onde \\(e_{ii}\\) s√£o os elementos da diagonal principal de \\(\\mathbf{E}\\).\n\nCalcule a matriz \\(\\mathbf{C}\\) conforme a Equa√ß√£o¬†2.\n\nDica - utilize a f√≥rmula:\n=MATRIZ.MULT()\n\nVerifica√ß√£o: calcule o cosseno de \\(\\theta\\) entre algumas esp√©cies utilizando a Equa√ß√£o¬†1 e verifique se os resultados coincidem com os observados na matriz de similaridade \\(\\mathbf{C}\\).\nVerifica√ß√£o: Considerando as imagens apresentadas na Figura¬†1, avalie criticamente se a matriz de similaridade representa de maneira fidedigna a semelhan√ßa morfom√©trica entre as esp√©cies."
  },
  {
    "objectID": "content/multivariada-numerica/clustering.html",
    "href": "content/multivariada-numerica/clustering.html",
    "title": "Agrupamento (Clustering)",
    "section": "",
    "text": "1 Agrupamento (Clustering)\n(Conte√∫do em constru√ß√£o)"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "",
    "text": "Bibliotecas utilizadas nesta se√ß√£o\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nA partir da Figura¬†1, percebemos que a maioria dos alunos tem alturas intermedi√°rias, enquanto poucos s√£o muito altos ou muito baixos, o que est√° de acordo com nossa intui√ß√£o sobre a distribui√ß√£o das alturas em adultos. Vamos construir passo-a-passo uma fun√ß√£o matem√°tica que seja capaz de capturar este comportamento."
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#um-modelo-para-a-distribui√ß√£o-de-alturas",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#um-modelo-para-a-distribui√ß√£o-de-alturas",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "1 Um modelo para a distribui√ß√£o de alturas",
    "text": "1 Um modelo para a distribui√ß√£o de alturas\nCome√ßaremos com a fun√ß√£o de crescimento exponencial:\n\\[f(x) = e^x\\]\ne de decaimento exponencial:\n\\[f(x) = e^{-x}\\]\nCombinando as duas, temos:\n\\[f(x) = e^{-\\mid x \\mid}\\]\nPara ter uma transi√ß√£o mais suave, fazemos uma pequena modifica√ß√£o na fun√ß√£o:\n\\[f(x) = e^{-x^2}\\]\nO c√≥digo a seguir cria vetores a partir destas fun√ß√µes que podemos visualizar graficamente:\nx = np.linspace(-4, 4, 1000)\n\n# Crescimento exponencial\nfx = np.exp(x)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^x$')\nplt.show()\n\n# Decaimento exponencial\nfx = np.exp(-x)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-x}$')\nplt.show()\n\n# Combina√ß√£o dos dois\nfx = np.exp(-np.abs(x))\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-|x|}$')\nplt.show()\n\n# Transi√ß√£o suave\nfx = np.exp(-x**2)\nplt.plot(x, fx)\nplt.title(r'$f(x) = e^{-x^2}$')\nplt.show()\n\n\n\n\n\n\nCrescimento exponencial\n\n\n\n\n\n\n\nDecaimento exponencial\n\n\n\n\n\n\n\n\n\nCombinando o crescimento e decaimento\n\n\n\n\n\n\n\nFazendo uma transi√ß√£o suave"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-par√¢metro-de-dispers√£o-sigma",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-par√¢metro-de-dispers√£o-sigma",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "2 Inserindo o par√¢metro de dispers√£o \\(\\sigma\\)",
    "text": "2 Inserindo o par√¢metro de dispers√£o \\(\\sigma\\)\nEm \\(f(x) = e^{-x^2}\\), n√£o h√° nada de especial com a escolha da base de Euler (\\(e = 2.718282...\\)). Poder√≠amos ter escolhido qualquer outro n√∫mero, por exemplo, \\(30^{-x^2}\\), o que nos daria uma fun√ß√£o com formato similar:\n\n# Compara√ß√£o entre e^{-x^2} e 30^{-x^2}\nfx1 = np.exp(-x**2)\nfx2 = 30**(-x**2)\n\nplt.plot(x, fx1, label=r'$f(x) = e^{-x^2}$')\nplt.plot(x, fx2, label=r'$f(x) = 30^{-x^2}$')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNote, entretanto, que a fun√ß√£o \\(f(x) = e^{-x^2}\\) tem um decaimento mais suave se comparado √† \\(f(x) = 30^{-x^2}\\), um comportamento que pode ser controlado inserindo uma constante \\(c = \\frac{1}{2\\sigma^2}\\):\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}\\]\nFazendo desta forma, o par√¢metro \\(\\sigma\\) passa a controlar a largura ou dispers√£o da curva: valores maiores de \\(\\sigma\\) tornam o decaimento mais lento e a curva mais ‚Äúespalhada‚Äù, enquanto valores menores de \\(\\sigma\\) a tornam mais estreita e concentrada ao redor de zero.\n\n\n\n\n\n\nCuriosidade\n\n\n\nA escolha da constante \\(c = \\frac{1}{2\\sigma^2}\\) tem o efeito pr√°tico de fazer com que a concavidade da curva mude exatamente nos pontos \\(x = +\\sigma\\) e \\(x = -\\sigma\\). Na fun√ß√£o da distribui√ß√£o normal, \\(\\sigma\\) ser√° chamado de desvio padr√£o.\n\n\n\n# Variando o valor de sigma\nsigmas = [0.5, 1, 2]\n\nfor sigma in sigmas:\n    fx = np.exp(-(1/(2*(sigma**2)))*x**2)\n    plt.plot(x, fx, label=fr'$\\sigma = {sigma}$')\n\nplt.legend()\nplt.title(r'$f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}$')\nplt.show()"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-par√¢metro-de-posi√ß√£o-mu",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#inserindo-o-par√¢metro-de-posi√ß√£o-mu",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "3 Inserindo o par√¢metro de posi√ß√£o \\(\\mu\\)",
    "text": "3 Inserindo o par√¢metro de posi√ß√£o \\(\\mu\\)\nPor enquanto temos a fun√ß√£o:\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}x^2}\\]\nque nos permite agora alterar a abertura da curva, mas est√° centralizada em zero. Se quisermos que elaesta fun√ß√£o possa representar fen√¥menos que n√£o estejam centrados em zero, precisamos ser capazes de deslocar a fun√ß√£o para a direita ou para a esquerda. Fazemos isso inserindo um novo par√¢metro que ser√° denominado de a m√©dia \\(\\mu\\) da dsitribui√ß√£o:\n\\[f(x) = e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\]\n\n# Variando o valor de mi (m√©dia)\nmis = [-2, 0, 2]\nsigma = 1\n\nfor mi in mis:\n    fx = np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    plt.plot(x, fx, label=fr'$\\mu = {mi}$')\n\nplt.legend()\nplt.title(r'$f(x) = e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}$')\nplt.show()"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#usando-a-fun√ß√£o-como-uma-distribui√ß√£o-de-probabilidades",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#usando-a-fun√ß√£o-como-uma-distribui√ß√£o-de-probabilidades",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "4 Usando a fun√ß√£o como uma Distribui√ß√£o de Probabilidades",
    "text": "4 Usando a fun√ß√£o como uma Distribui√ß√£o de Probabilidades\nSe queremos utilizar a fun√ß√£o acima para prever a frequ√™ncia relativa de alturas, precisamos que a √°rea abaixo da curva seja igual a 1, o que a transforma em uma Fun√ß√£o de Densidade de Probabilidade (PDF).\nVemos entretanto que a √°rea da fun√ß√£o √© igual a \\(\\sigma \\sqrt{2\\pi}\\).\nO que pode ser conferido obtendo a integral da fun√ß√£o: \\(\\int_{-\\infty}^{+\\infty} f(x) d(x)\\)\n\nfrom scipy.integrate import quad\n\n# Definindo a fun√ß√£o f\ndef f(x, mi, sigma):\n    if sigma &lt;= 0:\n        sigma = 1\n    fx = np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    return (fx)\n\n# Area sob a curva\nmi = 0\nsigma = 1\n\narea, erro = quad(f, -np.inf, np.inf, args = (mi, sigma))\n\nprint(f\"√Årea sob a curva = {area:.5f}\")\n\n# 2 x raiz(2 x pi)\nprint(sigma * np.sqrt(2*np.pi))\n\n√Årea sob a curva = 2.50663\n2.5066282746310002\n\n\nPara corrigir a √°rea sob a curva, inserimos \\(\\sigma \\sqrt{2\\pi}\\) no denominador da fun√ß√£o, ficando com:\n\\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\]\nA fun√ß√£o acima √© conhecida como Distribui√ß√£o Normal ou Curva de Gauss. Nesta fun√ß√£o \\(\\mu\\) √© a m√©dia, que representa o ponto central da curva, e \\(\\sigma\\) √© o desvio padr√£o que controla a abertura da curva.\nPodemos verificar agora que a √°rea desta fun√ß√£o √© sempre igua a 1.\n\nfrom scipy.integrate import quad\n\n# Definindo a fun√ß√£o f\ndef fnormal(x, mi, sigma):\n    if sigma &lt;= 0:\n        sigma = 1\n    fx = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-(1/(2*(sigma**2)))*(x-mi)**2)\n    return (fx)\n\n# Area sob a curva\nmi = 0\nsigma = 30\narea, erro = quad(fnormal, -np.inf, np.inf, args = (mi, sigma))\n\nprint(f\"√Årea sob a curva = {area:.5f}\")\n\n√Årea sob a curva = 1.00000"
  },
  {
    "objectID": "content/distribuicao-normal/distribuicao-normal-modelo.html#biblioteca-scipy",
    "href": "content/distribuicao-normal/distribuicao-normal-modelo.html#biblioteca-scipy",
    "title": "O modelo da distribui√ß√£o normal",
    "section": "5 Biblioteca SciPy",
    "text": "5 Biblioteca SciPy\nExiste uma fun√ß√£o pronta em python que nos d√° a fun√ß√£o da distribui√ß√£o normal dispon√≠vel em scipy.stats. Como j√° importamos esta bibloteca no in√≠cio do c√≥digo, podemos acess√°-la para comparar com nossa fun√ß√£o fnormal:\n\nimport scipy.stats as st\n\nx = np.linspace(2, 18, 1000)\ny1 = fnormal(x, mi = 10, sigma = 2)\ny2 = st.norm.pdf(x = x, loc = 10, scale = 2)\n\nE colocar as figuras lado-a-lado:\n\nfig, axes = plt.subplots(1, 2)\n\naxes[0].plot(x, y1)\naxes[0].set_title('fun√ß√£o `fnormal`')\naxes[1].plot(x, y2)\naxes[1].set_title('fun√ß√£o scipy.stats.norm.pdf()')\n\nplt.tight_layout()"
  },
  {
    "objectID": "content/glms/intro.html",
    "href": "content/glms/intro.html",
    "title": "Modelos Lineares Generalizados (GLMs)",
    "section": "",
    "text": "1 Introdu√ß√£o aos GLMs\n(Conte√∫do em constru√ß√£o)"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html",
    "href": "content/manipulacao-dados-R/transform.html",
    "title": "Transforma√ß√£o de Dados",
    "section": "",
    "text": "Ap√≥s importar uma base de dados para o R, os pacotes dplyr e tidyr s√£o essenciais para transforma√ß√£o de data frames. As fun√ß√µes desses pacotes ajudam na an√°lise, modelagem e comunica√ß√£o de dados. Neste se√ß√£o s√£o apresentadas as principais fun√ß√µes para transformar observa√ß√µes (linhas) e vari√°veis em um data frame a partir de uma ou mais tabelas. A Cheatsheets do dplyr apresenta outros recursos n√£o discutidos nesta se√ß√£o."
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#ordenando-as-linhas-fun√ß√µes-arrange-e-desc",
    "href": "content/manipulacao-dados-R/transform.html#ordenando-as-linhas-fun√ß√µes-arrange-e-desc",
    "title": "Transforma√ß√£o de Dados",
    "section": "1 Ordenando as linhas: fun√ß√µes arrange() e desc()",
    "text": "1 Ordenando as linhas: fun√ß√µes arrange() e desc()\nAs fun√ß√µes arrange() e desc() permitem ordenar a base de dados com base nos valores de uma ou mais colunas. Usar√°-se o conjunto de dados iris como exemplo.\nCarregue os pacote dplyr, tidyr e readr.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\nPara carregar e visualizar as primeiras linhas da base de dados iris:\n\ndata(\"iris\")\nhead(iris, 10)\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n2           4.9         3.0          1.4         0.2  setosa\n3           4.7         3.2          1.3         0.2  setosa\n4           4.6         3.1          1.5         0.2  setosa\n5           5.0         3.6          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n7           4.6         3.4          1.4         0.3  setosa\n8           5.0         3.4          1.5         0.2  setosa\n9           4.4         2.9          1.4         0.2  setosa\n10          4.9         3.1          1.5         0.1  setosa\n\n\nPara ordenar a tabela pela coluna Sepal.Length em ordem crescente:\n\niris |&gt; \n  arrange(Sepal.Length)\n\nPara ordenar em ordem decrescente:\n\niris |&gt; \n  arrange(desc(Sepal.Length))\n\n√â poss√≠vel tamb√©m combinar duas colunas, ordenando a tabela pela coluna Species (em ordem alfab√©tica decrescente) e Sepal.Length (em ordem crescente):\n\niris |&gt; \n  arrange(desc(Species), Sepal.Length)\n\nPara criar um novo objeto com a tabela ordenada\n\niris_ordenado &lt;- iris |&gt; \n  arrange(Sepal.Length)\n\niris_ordenado"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#filtrando-linhas-fun√ß√£o-filter",
    "href": "content/manipulacao-dados-R/transform.html#filtrando-linhas-fun√ß√£o-filter",
    "title": "Transforma√ß√£o de Dados",
    "section": "2 Filtrando linhas: fun√ß√£o filter()",
    "text": "2 Filtrando linhas: fun√ß√£o filter()\nA fun√ß√£o filter() extrai linhas que satisfazem uma condi√ß√£o l√≥gica. Para filtrar as linhas referentes √† esp√©cie virginica:\n\niris |&gt; \n  filter(Species == \"virginica\")\n\nPara filtrar esp√©cies diferentes de virginica.\n\niris |&gt; \n  filter(Species != \"virginica\")\n\nPara filtrar linhas onde o comprimento das p√©talas seja menor que \\(1.3\\):\n\niris |&gt; \n  filter(Petal.Length &lt; 1.3)\n\nPara filtrar onde o comprimento das p√©talas seja menor que \\(1.3\\) e o comprimento das s√©palas seja maior ou igual a \\(5\\):\n\niris |&gt; \n  filter(Petal.Length &lt; 1.3 & Sepal.Length &gt;= 5)"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#selecionando-colunas-fun√ß√£o-select",
    "href": "content/manipulacao-dados-R/transform.html#selecionando-colunas-fun√ß√£o-select",
    "title": "Transforma√ß√£o de Dados",
    "section": "3 Selecionando colunas: fun√ß√£o select()",
    "text": "3 Selecionando colunas: fun√ß√£o select()\nA fun√ß√£o select() permite extrair ou reorganizar um subconjunto de colunas de um data frame.\nPara extrair uma coluna:\n\niris |&gt; \n  select(Petal.Length)\n\nPara extrair m√∫ltiplas colunas:\n\niris |&gt; \n  select(Petal.Length, Species)\n\nPara extrair um intervalo de colunas:\n\niris |&gt; \n  select(Petal.Length:Species)\n\nPara excluir uma coluna:\n\niris |&gt; \n  select(-Petal.Length)\n\nPara excluir colunas espec√≠ficas:\n\niris |&gt; \n  select(!c(Petal.Length, Species))\n\nPara selecionar colunas que come√ßam com ‚ÄúSepal‚Äù:\n\niris |&gt; \n  select(starts_with(\"Sepal\"))\n\nPara combinar filter() e select() a fim de extrair um subconjunto do data frame:\n\niris |&gt; \n  select(starts_with(\"Sepal\")) |&gt; \n  filter(Sepal.Length &lt;= 4.5)\n\n\n3.1 Selecionando/Excluindo vari√°veis num√©ricas e categ√≥ricas\nImporte o conjuntoi de dados Reservatorios_Parana_parcial.csv:\n\nres = read_delim(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/Reservatorios_Parana_parcial.csv\",\n                  delim = ',',\n                  locale = locale(decimal_mark = '.',\n                                  encoding = 'latin1'))\n\n\n3.1.1 Sele√ß√£o de vari√°veis categ√≥ricas\n\nres |&gt;\n  select(Reservatorio, Bacia, Trofia)\n\n# A tibble: 31 √ó 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu Oligotr√É¬≥fico\n 2 Curucaca     Iguacu Oligotr√É¬≥fico\n 3 Foz do Areia Iguacu Oligotr√É¬≥fico\n 4 Irai         Iguacu Eutr√É¬≥fico   \n 5 JMF          Iguacu Mesotr√É¬≥fico \n 6 Jordao       Iguacu Oligotr√É¬≥fico\n 7 Passauna     Iguacu Oligotr√É¬≥fico\n 8 Piraquara    Iguacu Oligotr√É¬≥fico\n 9 Salto Caxias Iguacu Oligotr√É¬≥fico\n10 Salto do Vau Iguacu Oligotr√É¬≥fico\n# ‚Ñπ 21 more rows\n\nres |&gt;\n  select(where(is.character))\n\n# A tibble: 31 √ó 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu Oligotr√É¬≥fico\n 2 Curucaca     Iguacu Oligotr√É¬≥fico\n 3 Foz do Areia Iguacu Oligotr√É¬≥fico\n 4 Irai         Iguacu Eutr√É¬≥fico   \n 5 JMF          Iguacu Mesotr√É¬≥fico \n 6 Jordao       Iguacu Oligotr√É¬≥fico\n 7 Passauna     Iguacu Oligotr√É¬≥fico\n 8 Piraquara    Iguacu Oligotr√É¬≥fico\n 9 Salto Caxias Iguacu Oligotr√É¬≥fico\n10 Salto do Vau Iguacu Oligotr√É¬≥fico\n# ‚Ñπ 21 more rows\n\n\n\n\n3.1.2 Sele√ß√£o de vari√°veis num√©ricas\n\nres |&gt;\n  select(Fechamento, Area, pH, Condutividade, Alcalinidade, P.total, Riqueza, CPUE)\n\n# A tibble: 31 √ó 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# ‚Ñπ 21 more rows\n\nres |&gt;\n  select(Fechamento, Area, pH:CPUE)\n\n# A tibble: 31 √ó 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# ‚Ñπ 21 more rows\n\nres |&gt;\n  select(where(is.numeric))\n\n# A tibble: 31 √ó 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# ‚Ñπ 21 more rows\n\n\n\n\n\n3.2 Exclus√£o de vari√°veis\n\nres |&gt;\n  select(-Fechamento, -Area)\n\n# A tibble: 31 √ó 9\n   Reservatorio Bacia  Trofia      pH Condutividade Alcalinidade P.total Riqueza\n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Cavernoso    Iguacu Oligotr‚Ä¶   7.4          33.1        140.      7.8      18\n 2 Curucaca     Iguacu Oligotr‚Ä¶   7            32.4        126.      4.7      16\n 3 Foz do Areia Iguacu Oligotr‚Ä¶   7.3          35.5         97      14.3      19\n 4 Irai         Iguacu Eutr√É¬≥f‚Ä¶   6.9          50.2          3.3    53.4      12\n 5 JMF          Iguacu Mesotr√É‚Ä¶   7.3          40.2          3.7    41.2      18\n 6 Jordao       Iguacu Oligotr‚Ä¶   7.1          23.7        153.      3.3      17\n 7 Passauna     Iguacu Oligotr‚Ä¶   8.8         126.         526      15.2      11\n 8 Piraquara    Iguacu Oligotr‚Ä¶   7.1          22.8         50.7     4.5       8\n 9 Salto Caxias Iguacu Oligotr‚Ä¶   7.3          39.6        106      12.1      21\n10 Salto do Vau Iguacu Oligotr‚Ä¶   6.5          23.2        279      11         8\n# ‚Ñπ 21 more rows\n# ‚Ñπ 1 more variable: CPUE &lt;dbl&gt;\n\nres |&gt;\n  select(!where(is.numeric))\n\n# A tibble: 31 √ó 3\n   Reservatorio Bacia  Trofia       \n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;        \n 1 Cavernoso    Iguacu Oligotr√É¬≥fico\n 2 Curucaca     Iguacu Oligotr√É¬≥fico\n 3 Foz do Areia Iguacu Oligotr√É¬≥fico\n 4 Irai         Iguacu Eutr√É¬≥fico   \n 5 JMF          Iguacu Mesotr√É¬≥fico \n 6 Jordao       Iguacu Oligotr√É¬≥fico\n 7 Passauna     Iguacu Oligotr√É¬≥fico\n 8 Piraquara    Iguacu Oligotr√É¬≥fico\n 9 Salto Caxias Iguacu Oligotr√É¬≥fico\n10 Salto do Vau Iguacu Oligotr√É¬≥fico\n# ‚Ñπ 21 more rows\n\nres |&gt;\n  select(!where(is.character))\n\n# A tibble: 31 √ó 8\n   Fechamento   Area    pH Condutividade Alcalinidade P.total Riqueza  CPUE\n        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1       1965   2.9    7.4          33.1        140.      7.8      18  9.22\n 2       1982   2      7            32.4        126.      4.7      16 28.7 \n 3       1980 139      7.3          35.5         97      14.3      19 11.6 \n 4       2000  15      6.9          50.2          3.3    53.4      12 30.8 \n 5       1970   0.45   7.3          40.2          3.7    41.2      18  5.95\n 6       1996   3.4    7.1          23.7        153.      3.3      17  7.75\n 7       1978  14      8.8         126.         526      15.2      11  7.51\n 8       1979   3.3    7.1          22.8         50.7     4.5       8  4.01\n 9       1998 124      7.3          39.6        106      12.1      21 20.8 \n10       1959   2.9    6.5          23.2        279      11         8  2.43\n# ‚Ñπ 21 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#outros-exemplos-de-sele√ß√£oexclus√£o-de-vari√°veis",
    "href": "content/manipulacao-dados-R/transform.html#outros-exemplos-de-sele√ß√£oexclus√£o-de-vari√°veis",
    "title": "Transforma√ß√£o de Dados",
    "section": "4 Outros exemplos de sele√ß√£o/exclus√£o de vari√°veis",
    "text": "4 Outros exemplos de sele√ß√£o/exclus√£o de vari√°veis\n\n4.1 all_off(), any_of(), one_of()\n\n# 1. all_of(): Seleciona todas as colunas mencionadas\nres |&gt;\n  select(all_of(c('Reservatorio', 'Bacia')))\n\n# A tibble: 31 √ó 2\n   Reservatorio Bacia \n   &lt;chr&gt;        &lt;chr&gt; \n 1 Cavernoso    Iguacu\n 2 Curucaca     Iguacu\n 3 Foz do Areia Iguacu\n 4 Irai         Iguacu\n 5 JMF          Iguacu\n 6 Jordao       Iguacu\n 7 Passauna     Iguacu\n 8 Piraquara    Iguacu\n 9 Salto Caxias Iguacu\n10 Salto do Vau Iguacu\n# ‚Ñπ 21 more rows\n\n# 2. any_of(): Seleciona qualquer coluna que exista na lista (ignora colunas inexistentes)\nres |&gt;\n  select(any_of(c('Reservatorio', 'Bacia', 'Turbidez'))) # funciona, any_of() ignora que `Turbidez` n√£o existe\n\n# A tibble: 31 √ó 2\n   Reservatorio Bacia \n   &lt;chr&gt;        &lt;chr&gt; \n 1 Cavernoso    Iguacu\n 2 Curucaca     Iguacu\n 3 Foz do Areia Iguacu\n 4 Irai         Iguacu\n 5 JMF          Iguacu\n 6 Jordao       Iguacu\n 7 Passauna     Iguacu\n 8 Piraquara    Iguacu\n 9 Salto Caxias Iguacu\n10 Salto do Vau Iguacu\n# ‚Ñπ 21 more rows\n\nres |&gt;\n  select(one_of(c('Reservatorio', 'Trofia', 'Turbidez'))) # funciona, one_of() avisa que `Turbidez` n√£o existe\n\n# A tibble: 31 √ó 2\n   Reservatorio Trofia       \n   &lt;chr&gt;        &lt;chr&gt;        \n 1 Cavernoso    Oligotr√É¬≥fico\n 2 Curucaca     Oligotr√É¬≥fico\n 3 Foz do Areia Oligotr√É¬≥fico\n 4 Irai         Eutr√É¬≥fico   \n 5 JMF          Mesotr√É¬≥fico \n 6 Jordao       Oligotr√É¬≥fico\n 7 Passauna     Oligotr√É¬≥fico\n 8 Piraquara    Oligotr√É¬≥fico\n 9 Salto Caxias Oligotr√É¬≥fico\n10 Salto do Vau Oligotr√É¬≥fico\n# ‚Ñπ 21 more rows\n\n# res |&gt;\n#   select(Reservatorio, Bacia, Turbidez) # N√£o funciona, pois `Turbidez` n√£o existe\n\n\n\n4.2 contains(), ends_with(), everything(), last_col()\n\n# 3. contains(): Seleciona colunas cujos nomes cont√™m uma string espec√≠fica\nres |&gt;\n  select(contains('to'))\n\n# A tibble: 31 √ó 3\n   Reservatorio Fechamento P.total\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 Cavernoso          1965     7.8\n 2 Curucaca           1982     4.7\n 3 Foz do Areia       1980    14.3\n 4 Irai               2000    53.4\n 5 JMF                1970    41.2\n 6 Jordao             1996     3.3\n 7 Passauna           1978    15.2\n 8 Piraquara          1979     4.5\n 9 Salto Caxias       1998    12.1\n10 Salto do Vau       1959    11  \n# ‚Ñπ 21 more rows\n\n# 4. ends_with(): Seleciona colunas que terminam com uma string espec√≠fica\nres |&gt;\n  select(ends_with('dade'))\n\n# A tibble: 31 √ó 2\n   Condutividade Alcalinidade\n           &lt;dbl&gt;        &lt;dbl&gt;\n 1          33.1        140. \n 2          32.4        126. \n 3          35.5         97  \n 4          50.2          3.3\n 5          40.2          3.7\n 6          23.7        153. \n 7         126.         526  \n 8          22.8         50.7\n 9          39.6        106  \n10          23.2        279  \n# ‚Ñπ 21 more rows\n\n# 5. everything(): Seleciona todas as colunas (pode ser usado para reorganizar)\nres |&gt;\n  select(Fechamento, pH, everything())\n\n# A tibble: 31 √ó 11\n   Fechamento    pH Reservatorio Bacia    Area Trofia Condutividade Alcalinidade\n        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n 1       1965   7.4 Cavernoso    Iguacu   2.9  Oligo‚Ä¶          33.1        140. \n 2       1982   7   Curucaca     Iguacu   2    Oligo‚Ä¶          32.4        126. \n 3       1980   7.3 Foz do Areia Iguacu 139    Oligo‚Ä¶          35.5         97  \n 4       2000   6.9 Irai         Iguacu  15    Eutr√É‚Ä¶          50.2          3.3\n 5       1970   7.3 JMF          Iguacu   0.45 Mesot‚Ä¶          40.2          3.7\n 6       1996   7.1 Jordao       Iguacu   3.4  Oligo‚Ä¶          23.7        153. \n 7       1978   8.8 Passauna     Iguacu  14    Oligo‚Ä¶         126.         526  \n 8       1979   7.1 Piraquara    Iguacu   3.3  Oligo‚Ä¶          22.8         50.7\n 9       1998   7.3 Salto Caxias Iguacu 124    Oligo‚Ä¶          39.6        106  \n10       1959   6.5 Salto do Vau Iguacu   2.9  Oligo‚Ä¶          23.2        279  \n# ‚Ñπ 21 more rows\n# ‚Ñπ 3 more variables: P.total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, CPUE &lt;dbl&gt;\n\n# 6. last_col(): Seleciona a √∫ltima coluna\nres |&gt;\n  select(last_col())\n\n# A tibble: 31 √ó 1\n    CPUE\n   &lt;dbl&gt;\n 1  9.22\n 2 28.7 \n 3 11.6 \n 4 30.8 \n 5  5.95\n 6  7.75\n 7  7.51\n 8  4.01\n 9 20.8 \n10  2.43\n# ‚Ñπ 21 more rows\n\n\n\n\n4.3 Expressoes regulares\n\n# 7. matches(): Seleciona colunas que correspondem a uma express√£o regular\nres |&gt;\n  select(matches('^[FA]')) # Colunas que come√ßam com 'F ou A'\n\n# A tibble: 31 √ó 3\n   Fechamento   Area Alcalinidade\n        &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;\n 1       1965   2.9         140. \n 2       1982   2           126. \n 3       1980 139            97  \n 4       2000  15             3.3\n 5       1970   0.45          3.7\n 6       1996   3.4         153. \n 7       1978  14           526  \n 8       1979   3.3          50.7\n 9       1998 124           106  \n10       1959   2.9         279  \n# ‚Ñπ 21 more rows\n\n# 8. Seleciona colunas cujos nomes:\n# 1. Come√ßam com a letra \"A\" ou \"C\"\n# 2. Podem conter qualquer sequ√™ncia de caracteres ap√≥s a primeira letra\n# 3. Terminam com as letras \"a\" ou \"e\"\nres |&gt;\n  select(matches('^[AC].*[ae]$'))\n\n# A tibble: 31 √ó 4\n     Area Condutividade Alcalinidade  CPUE\n    &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1   2.9           33.1        140.   9.22\n 2   2             32.4        126.  28.7 \n 3 139             35.5         97   11.6 \n 4  15             50.2          3.3 30.8 \n 5   0.45          40.2          3.7  5.95\n 6   3.4           23.7        153.   7.75\n 7  14            126.         526    7.51\n 8   3.3           22.8         50.7  4.01\n 9 124             39.6        106   20.8 \n10   2.9           23.2        279    2.43\n# ‚Ñπ 21 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#renomeando-colunas",
    "href": "content/manipulacao-dados-R/transform.html#renomeando-colunas",
    "title": "Transforma√ß√£o de Dados",
    "section": "5 Renomeando colunas",
    "text": "5 Renomeando colunas\n\nres |&gt;\n  rename(Fosforo_total = P.total,\n         Captura_kg = CPUE)\n\n# A tibble: 31 √ó 11\n   Reservatorio Bacia  Fechamento   Area Trofia    pH Condutividade Alcalinidade\n   &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n 1 Cavernoso    Iguacu       1965   2.9  Oligo‚Ä¶   7.4          33.1        140. \n 2 Curucaca     Iguacu       1982   2    Oligo‚Ä¶   7            32.4        126. \n 3 Foz do Areia Iguacu       1980 139    Oligo‚Ä¶   7.3          35.5         97  \n 4 Irai         Iguacu       2000  15    Eutr√É‚Ä¶   6.9          50.2          3.3\n 5 JMF          Iguacu       1970   0.45 Mesot‚Ä¶   7.3          40.2          3.7\n 6 Jordao       Iguacu       1996   3.4  Oligo‚Ä¶   7.1          23.7        153. \n 7 Passauna     Iguacu       1978  14    Oligo‚Ä¶   8.8         126.         526  \n 8 Piraquara    Iguacu       1979   3.3  Oligo‚Ä¶   7.1          22.8         50.7\n 9 Salto Caxias Iguacu       1998 124    Oligo‚Ä¶   7.3          39.6        106  \n10 Salto do Vau Iguacu       1959   2.9  Oligo‚Ä¶   6.5          23.2        279  \n# ‚Ñπ 21 more rows\n# ‚Ñπ 3 more variables: Fosforo_total &lt;dbl&gt;, Riqueza &lt;dbl&gt;, Captura_kg &lt;dbl&gt;"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#agrupando-tabelas-fun√ß√µes-do-grupo-join",
    "href": "content/manipulacao-dados-R/transform.html#agrupando-tabelas-fun√ß√µes-do-grupo-join",
    "title": "Transforma√ß√£o de Dados",
    "section": "6 Agrupando tabelas: fun√ß√µes do grupo join",
    "text": "6 Agrupando tabelas: fun√ß√µes do grupo join\nAs fun√ß√µes left_join(), right_join(), inner_join(), anti_join() e full_join() do pacote dplyr em R s√£o utilizadas para combinar dois data frames baseados em uma coluna ou colunas comuns. Esses tipos de joins s√£o amplamente utilizados em opera√ß√µes de banco de dados e manipula√ß√£o de dados.\nConsidere os arquivos regiao.csv e habitat.csv do reposit√≥rio datasets.\n\nregiao &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/regiao.csv\")\nhabitat &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/habitat.csv\")\nregiao\n\n# A tibble: 10 √ó 4\n   Riacho Bacia      Munic√≠pio      √Årea\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;\n 1 R1     Boicucanga S√£o Sebasti√£o  30.3\n 2 R4     Boicucanga S√£o Sebasti√£o  30.3\n 3 R8     Boicucanga S√£o Sebasti√£o  30.3\n 4 R2     Cubat√£o    Cubat√£o       189  \n 5 R5     Cubat√£o    Cubat√£o       189  \n 6 R10    Cubat√£o    Cubat√£o       189  \n 7 R13    Cubat√£o    Cubat√£o       189  \n 8 R6     Quilombo   Santos         86  \n 9 R9     Quilombo   Santos         86  \n10 R7     Quilombo   Santos         86  \n\nhabitat\n\n# A tibble: 8 √ó 4\n  Riacho Altitude Largura Profundidade\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1           74     7.8         20.2\n2 R4           14    10.9         17.7\n3 R8          245     8.3         19.5\n4 R11         241     2.2         20.3\n5 R2           29     1.6         11.8\n6 R6           86    15.2         35.3\n7 R9           77     4.1         18.9\n8 R7           63    14.2         42.1\n\n\nTabela regiao: Cont√©m informa√ß√µes sobre a bacia hidrogr√°fica, √°rea da bacia e munic√≠pio de alguns riachos da regi√£o litor√¢nea de S√£o Paulo.\nTabela habitat: Cont√©m informa√ß√µes sobre a largura e profundidade desses riachos. Algumas entradas s√£o comuns √†s duas tabelas, enquanto outras s√£o exclusivas de uma delas. A coluna Riacho serve como chave para combinar as informa√ß√µes.\n\nFun√ß√£o left_join()\nRetorna todas as linhas da tabela √† esquerda (regiao) e adiciona colunas da tabela √† direita (habitat). Linhas sem correspond√™ncia na tabela da direita ter√£o valores de NA.\n\nregiao |&gt; left_join(y = habitat)\n\n# A tibble: 10 √ó 7\n   Riacho Bacia      Munic√≠pio      √Årea Altitude Largura Profundidade\n   &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 R1     Boicucanga S√£o Sebasti√£o  30.3       74     7.8         20.2\n 2 R4     Boicucanga S√£o Sebasti√£o  30.3       14    10.9         17.7\n 3 R8     Boicucanga S√£o Sebasti√£o  30.3      245     8.3         19.5\n 4 R2     Cubat√£o    Cubat√£o       189         29     1.6         11.8\n 5 R5     Cubat√£o    Cubat√£o       189         NA    NA           NA  \n 6 R10    Cubat√£o    Cubat√£o       189         NA    NA           NA  \n 7 R13    Cubat√£o    Cubat√£o       189         NA    NA           NA  \n 8 R6     Quilombo   Santos         86         86    15.2         35.3\n 9 R9     Quilombo   Santos         86         77     4.1         18.9\n10 R7     Quilombo   Santos         86         63    14.2         42.1\n\n\n\n\nFun√ß√£o right_join()\nRetorna todas as linhas da tabela √† direita (habitat) e adiciona colunas da tabela √† esquerda (regiao). Linhas sem correspond√™ncia na tabela da esquerda ter√£o valores de NA.\n\nregiao |&gt; right_join(y = habitat, keep=TRUE)\n\n# A tibble: 8 √ó 8\n  Riacho.x Bacia      Munic√≠pio      √Årea Riacho.y Altitude Largura Profundidade\n  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1       Boicucanga S√£o Sebasti√£o  30.3 R1             74     7.8         20.2\n2 R4       Boicucanga S√£o Sebasti√£o  30.3 R4             14    10.9         17.7\n3 R8       Boicucanga S√£o Sebasti√£o  30.3 R8            245     8.3         19.5\n4 R2       Cubat√£o    Cubat√£o       189   R2             29     1.6         11.8\n5 R6       Quilombo   Santos         86   R6             86    15.2         35.3\n6 R9       Quilombo   Santos         86   R9             77     4.1         18.9\n7 R7       Quilombo   Santos         86   R7             63    14.2         42.1\n8 &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;           NA   R11           241     2.2         20.3\n\n\n\n\nFun√ß√£o inner_join()\nRetorna apenas as linhas que t√™m correspond√™ncia em ambas as tabelas.\n\nregiao |&gt; inner_join(y = habitat)\n\n# A tibble: 7 √ó 7\n  Riacho Bacia      Munic√≠pio      √Årea Altitude Largura Profundidade\n  &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R1     Boicucanga S√£o Sebasti√£o  30.3       74     7.8         20.2\n2 R4     Boicucanga S√£o Sebasti√£o  30.3       14    10.9         17.7\n3 R8     Boicucanga S√£o Sebasti√£o  30.3      245     8.3         19.5\n4 R2     Cubat√£o    Cubat√£o       189         29     1.6         11.8\n5 R6     Quilombo   Santos         86         86    15.2         35.3\n6 R9     Quilombo   Santos         86         77     4.1         18.9\n7 R7     Quilombo   Santos         86         63    14.2         42.1\n\n\n\n\nFun√ß√£o anti_join()\nRetorna as linhas da tabela √† esquerda que n√£o t√™m correspond√™ncia na tabela √† direita. Tamb√©m retorna todas as colunas da tabela √† esquerda.\n\nregiao |&gt; anti_join(y = habitat)\n\n# A tibble: 3 √ó 4\n  Riacho Bacia   Munic√≠pio  √Årea\n  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 R5     Cubat√£o Cubat√£o     189\n2 R10    Cubat√£o Cubat√£o     189\n3 R13    Cubat√£o Cubat√£o     189\n\n\n\nhabitat |&gt; anti_join(y = regiao)\n\n# A tibble: 1 √ó 4\n  Riacho Altitude Largura Profundidade\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 R11         241     2.2         20.3\n\n\n\n\nFun√ß√£o full_join()\nRetorna todas as linhas e colunas de ambas as tabelas. Nas c√©lulas onde n√£o houver correspond√™ncia, retorna NA.\n\nregiao |&gt; full_join(y = habitat, keep = TRUE)\n\n# A tibble: 11 √ó 8\n   Riacho.x Bacia      Munic√≠pio     √Årea Riacho.y Altitude Largura Profundidade\n   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 R1       Boicucanga S√£o Sebasti‚Ä¶  30.3 R1             74     7.8         20.2\n 2 R4       Boicucanga S√£o Sebasti‚Ä¶  30.3 R4             14    10.9         17.7\n 3 R8       Boicucanga S√£o Sebasti‚Ä¶  30.3 R8            245     8.3         19.5\n 4 R2       Cubat√£o    Cubat√£o      189   R2             29     1.6         11.8\n 5 R5       Cubat√£o    Cubat√£o      189   &lt;NA&gt;           NA    NA           NA  \n 6 R10      Cubat√£o    Cubat√£o      189   &lt;NA&gt;           NA    NA           NA  \n 7 R13      Cubat√£o    Cubat√£o      189   &lt;NA&gt;           NA    NA           NA  \n 8 R6       Quilombo   Santos        86   R6             86    15.2         35.3\n 9 R9       Quilombo   Santos        86   R9             77     4.1         18.9\n10 R7       Quilombo   Santos        86   R7             63    14.2         42.1\n11 &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;          NA   R11           241     2.2         20.3"
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#criando-e-modificando-colunas-com-mutate",
    "href": "content/manipulacao-dados-R/transform.html#criando-e-modificando-colunas-com-mutate",
    "title": "Transforma√ß√£o de Dados",
    "section": "7 Criando e modificando colunas com mutate()",
    "text": "7 Criando e modificando colunas com mutate()\nA fun√ß√£o mutate() permite criar e modificar colunas em um data frame. Usando a base de dados Doubs river:\n\nlibrary(ade4)\ndata(doubs)\ndbenv &lt;- doubs$env\nhead(dbenv)\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n1   3 934 6.176  84 79  45   1  20   0 122  27\n2  22 932 3.434 100 80  40   2  20  10 103  19\n3 102 914 3.638 180 83  52   5  22   5 105  35\n4 185 854 3.497 253 80  72  10  21   0 110  13\n5 215 849 3.178 264 81  84  38  52  20  80  62\n6 324 846 3.497 286 79  60  20  15   0 102  53\n\n\n\nAjustando a escala de pH\nA coluna pH est√° multiplicada por \\(10\\). Vamos ajustar isso:\n\ndbenv &lt;- dbenv  |&gt; \n  mutate(pH = pH / 10)\n\nhead(dbenv)\n\n  dfs alt   slo flo  pH har pho nit amm oxy bdo\n1   3 934 6.176  84 7.9  45   1  20   0 122  27\n2  22 932 3.434 100 8.0  40   2  20  10 103  19\n3 102 914 3.638 180 8.3  52   5  22   5 105  35\n4 185 854 3.497 253 8.0  72  10  21   0 110  13\n5 215 849 3.178 264 8.1  84  38  52  20  80  62\n6 324 846 3.497 286 7.9  60  20  15   0 102  53\n\n\n\n\nCriando vari√°vel categ√≥rica\nCriar uma vari√°vel categ√≥rica pH_cat com n√≠veis Elevado (maior ou igual a \\(8\\)) e Neutro (menor que \\(8\\)):\n\ndbenv &lt;- dbenv |&gt; \n  mutate(pH = pH / 10) |&gt; \n  mutate(pH_cat = if_else(pH &lt; 8, true = \"Neutro\", false = \"Elevado\"),\n         , .after = pH)\n\nhead(dbenv)\n\n  dfs alt   slo flo   pH pH_cat har pho nit amm oxy bdo\n1   3 934 6.176  84 0.79 Neutro  45   1  20   0 122  27\n2  22 932 3.434 100 0.80 Neutro  40   2  20  10 103  19\n3 102 914 3.638 180 0.83 Neutro  52   5  22   5 105  35\n4 185 854 3.497 253 0.80 Neutro  72  10  21   0 110  13\n5 215 849 3.178 264 0.81 Neutro  84  38  52  20  80  62\n6 324 846 3.497 286 0.79 Neutro  60  20  15   0 102  53\n\n\n\n\nUnindo colunas com unite()\nA fun√ß√£o unite() do tidyr combina duas colunas em uma nova coluna. Usando a tabela iris:\n\niris2 &lt;- iris |&gt; \n  mutate(Genus = \"Iris\", .before = Species)  |&gt;  \n  unite(scientic_name, Genus, Species, sep = \" \")\n\nhead(iris2)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width scientic_name\n1          5.1         3.5          1.4         0.2   Iris setosa\n2          4.9         3.0          1.4         0.2   Iris setosa\n3          4.7         3.2          1.3         0.2   Iris setosa\n4          4.6         3.1          1.5         0.2   Iris setosa\n5          5.0         3.6          1.4         0.2   Iris setosa\n6          5.4         3.9          1.7         0.4   Iris setosa\n\n\n\n\n\n\n\n\nObserva√ß√£o\n\n\n\nA fun√ß√£o unite() excluiu as colunas que foram unificadas da tabela. Mara mant√™-las na tabela utilize o argumento remove = FALSE."
  },
  {
    "objectID": "content/manipulacao-dados-R/transform.html#reformatando-data-frames-fun√ß√µes-pivot_wider-e-pivot_longer",
    "href": "content/manipulacao-dados-R/transform.html#reformatando-data-frames-fun√ß√µes-pivot_wider-e-pivot_longer",
    "title": "Transforma√ß√£o de Dados",
    "section": "8 Reformatando data frames: fun√ß√µes pivot_wider() e pivot_longer()",
    "text": "8 Reformatando data frames: fun√ß√µes pivot_wider() e pivot_longer()\nA tabela HubbardBrook.csv (datasets) cont√©m dados anuais de vaz√£o e precipita√ß√£o em dois bacias hidrogr√°ficas (Hornbeck et al. 1993). A primeira (Deforested) teve toda a vegeta√ß√£o removida como parte de um experimento de longa dura√ß√£o enquanto a outra se manteve intacta (Referenca). Os daods de origem e o experimento detalhado s√£o apresentados am Os dados foram retirados de tiee.esa.org\n\nhbrook &lt;- read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/HubbardBrook.csv\")\nhbrook\n\n# A tibble: 62 √ó 4\n    Year Treatment   Flow Precipitation\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n 1  1958 Deforested  645.         1168.\n 2  1959 Deforested 1012.         1483.\n 3  1960 Deforested  825.         1321.\n 4  1961 Deforested  470.          980.\n 5  1962 Deforested  777.         1232.\n 6  1963 Deforested  774.         1139.\n 7  1964 Deforested  712.         1175.\n 8  1965 Deforested  599.         1115.\n 9  1966 Deforested 1189.         1222.\n10  1967 Deforested 1132.         1315.\n# ‚Ñπ 52 more rows\n\n\n\nReorganizando data frames de formato longo para formato largo\nA fun√ß√£o pivot_wider() √© utilizada para transformar dados do formato longo para o formato largo. A seguir, ser√° feito isso apenas para a vari√°vel Flow, excluindo Precipitation, separando os dados nas colunas Deforested e Reference.\n\nhbrook_largo &lt;- hbrook |&gt;\n  select(-Precipitation) |&gt;\n  pivot_wider(names_from = Treatment, values_from = Flow)\nhbrook_largo\n\n# A tibble: 31 √ó 3\n    Year Deforested Reference\n   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1  1958       645.      567.\n 2  1959      1012.      918.\n 3  1960       825.      752.\n 4  1961       470.      436.\n 5  1962       777.      699.\n 6  1963       774.      663.\n 7  1964       712.      630.\n 8  1965       599.      547.\n 9  1966      1189.      727.\n10  1967      1132.      781.\n# ‚Ñπ 21 more rows\n\n\n\n\nReorganizando data frames de formato largo para formato longo\nA fun√ß√£o pivot_longer() √© utilizada para transformar dados do formato largo para o formato longo, fazendo o caminho inverso de pivot_wider().\n\nhbrook_longo &lt;- hbrook_largo |&gt;\n  pivot_longer(!Year, names_to = \"Desmatamento\", values_to = \"Flow\")\nhbrook_longo\n\n# A tibble: 62 √ó 3\n    Year Desmatamento  Flow\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1  1958 Deforested    645.\n 2  1958 Reference     567.\n 3  1959 Deforested   1012.\n 4  1959 Reference     918.\n 5  1960 Deforested    825.\n 6  1960 Reference     752.\n 7  1961 Deforested    470.\n 8  1961 Reference     436.\n 9  1962 Deforested    777.\n10  1962 Reference     699.\n# ‚Ñπ 52 more rows"
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html",
    "href": "content/manipulacao-dados-R/tidyverse.html",
    "title": "Os pacotes em tidyverse",
    "section": "",
    "text": "O Tidyverse √© uma cole√ß√£o de pacotes em R projetados para ci√™ncia de dados que inclui ferramentas para importar, arrumar, transformar, visualizar e modelar dados, todas integradas de forma coesa para tornar a an√°lise de dados mais eficiente e intuitiva. O Tidyverse facilita a pr√°tica de uma ci√™ncia de dados mais limpa, clara e reproduz√≠vel. Entre os pacotes mais populares do Tidyverse est√£o ggplot2 para visualiza√ß√£o de dados, dplyr para manipula√ß√£o de dados e tidyr para arruma√ß√£o de dados.\nAl√©m destes existem ainda outros que se integram bem √† filosofia do tidyverse como o lubridade (manipula√ß√£o de datas), o readxl (leitura de arquivos .xls e .xlsx), al√©m de muitos outros. Veremos algumas fun√ß√µes e pr√°ticas √∫teis utilizando estes pacotes. Para uma vis√£o geral de cada pacote, verifique as Cheatsheets que oferecem um resumo sobre as fun√ß√µes principais."
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html#instalando-os-pacotes",
    "href": "content/manipulacao-dados-R/tidyverse.html#instalando-os-pacotes",
    "title": "Os pacotes em tidyverse",
    "section": "1 Instalando os pacotes",
    "text": "1 Instalando os pacotes\nCada um dos pacotes incorporados no tidyverse pode ser instalado individualmente. Por exemplo:\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\n\nEntretando, ao instalar o tidyverse, todos s√£o instalados de uma √∫nica vez:\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "content/manipulacao-dados-R/tidyverse.html#carregando-os-pacotes",
    "href": "content/manipulacao-dados-R/tidyverse.html#carregando-os-pacotes",
    "title": "Os pacotes em tidyverse",
    "section": "2 Carregando os pacotes",
    "text": "2 Carregando os pacotes\nAo iniciar uma se√ß√£o, voc√™ deve sempre carregar os pacotes que ir√° utilizar. No caso do tidyverse, voc√™ pode carregar cada pacote individualmente:\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nOu todos de uma √∫nica vez:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "content/introducao-r/data-frames.html",
    "href": "content/introducao-r/data-frames.html",
    "title": "(B√°sico da) Manipula√ß√£o de data frames",
    "section": "",
    "text": "Embora seja possivel criar um data frame entrando com os dados diretamente via linha de comando, √© mais eficiente import√°-los a partir de arquivos texto (.csv, .txt)."
  },
  {
    "objectID": "content/introducao-r/data-frames.html#importando-arquivos-.csv",
    "href": "content/introducao-r/data-frames.html#importando-arquivos-.csv",
    "title": "(B√°sico da) Manipula√ß√£o de data frames",
    "section": "1 Importando arquivos .csv",
    "text": "1 Importando arquivos .csv\nUm arquivo do tipo .csv pode ser lido com a fun√ß√£o read.csv. Fa√ßa o download do conjunto de dados dbenv.csv dispon√≠vel no reposit√≥rio datasets e salve-o em sua pasta de trabalho (ex. \"C:/seu_caminho/Introducao_R\"). Ao abrir o arquivo em algum editor de texto ver√° que ele √© composto por \\(30\\) linhas por \\(11\\) colunas.\nAp√≥s fazer o download, voc√™ pode importar o conjunto de dados utilizando o comando:\n\ndbenv &lt;- read.csv(file = \"C:/seu_caminho/Introducao_R/dbenv.csv\", \n                 header = TRUE, dec = '.', sep = ',')\n\nA fun√ß√£o read.csv possui diferentes argumentos. A argumento header define se a primeira linha consiste do cabe√ßalho (TRUE) ou n√£o (FALSE). O argumento dec define se o separador decimal consiste de v√≠rgula ou ponto e o argumento sep informa sobre qual √© o caracter separador de colunas utilizado no arquivo. No arquivo em quest√£o as colunas s√£o separadas por v√≠rgulas. Outros tipos de separadores comuns s√£o ponto-e-v√≠rgula ou tabula√ß√µes.\nConfira os nomes das \\(11\\) vari√°veis (cabe√ßalho), a dimens√£o da tabela (n√∫mero de linhas e colunas) e sua estrutura (um data.frame formado por \\(11\\) vetores num√©ricos).\n\ndbenv\n\n    dfs alt   slo  flo pH har pho nit amm oxy bdo\n1     3 934 6.176   84 79  45   1  20   0 122  27\n2    22 932 3.434  100 80  40   2  20  10 103  19\n3   102 914 3.638  180 83  52   5  22   5 105  35\n4   185 854 3.497  253 80  72  10  21   0 110  13\n5   215 849 3.178  264 81  84  38  52  20  80  62\n6   324 846 3.497  286 79  60  20  15   0 102  53\n7   268 841 4.205  400 81  88   7  15   0 111  22\n8   491 792 3.258  130 81  94  20  41  12  70  81\n9   705 752 2.565  480 80  90  30  82  12  72  52\n10  990 617 4.605 1000 77  82   6  75   1 100  43\n11 1234 483 3.738 1990 81  96  30 160   0 115  27\n12 1324 477 2.833 2000 79  86   4  50   0 122  30\n13 1436 450 3.091 2110 81  98   6  52   0 124  24\n14 1522 434 2.565 2120 83  98  27 123   0 123  38\n15 1645 415 1.792 2300 86  86  40 100   0 117  21\n16 1859 375 3.045 1610 80  88  20 200   5 103  27\n17 1985 348 1.792 2430 80  92  20 250  20 102  46\n18 2110 332 2.197 2500 80  90  50 220  20 103  28\n19 2246 310 1.792 2590 81  84  60 220  15 106  33\n20 2477 286 2.197 2680 80  86  30 300  30 103  28\n21 2812 262 2.398 2720 79  85  20 220  10  90  41\n22 2940 254 2.708 2790 81  88  20 162   7  91  48\n23 3043 246 2.565 2880 81  97 260 350 115  63 164\n24 3147 241 1.386 2976 80  99 140 250  60  52 123\n25 3278 231 1.792 3870 79 100 422 620 180  41 167\n26 3579 214 1.792 3910 79  94 143 300  30  62  89\n27 3732 206 2.565 3960 81  90  58 300  26  72  63\n28 3947 195 1.386 4320 83 100  74 400  30  81  45\n29 4220 183 1.946 6770 78 110  45 162  10  90  42\n30 4530 172 1.099 6900 82 109  65 160  10  82  44\n\ncolnames(dbenv)\n\n [1] \"dfs\" \"alt\" \"slo\" \"flo\" \"pH\"  \"har\" \"pho\" \"nit\" \"amm\" \"oxy\" \"bdo\"\n\ndim(dbenv)\n\n[1] 30 11\n\n\n\n\n\n\n\n\nAcessando .csv em uma url\n\n\n\nComo este arquivo est√° em um reposit√≥rio na nuvem, poderia ser lido acessando diretamente sua url, sem a necessidade de fazer o download:\n\ndbenv &lt;- read.csv(file = \"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/dbenv.csv\", \n                 header = TRUE, dec = '.', \n                 sep = ',')\n\n\n\n\n\n\n\n\n\nIniciando uma se√ß√£o de trabalho\n\n\n\nUma se√ß√£o no R, se refere ao ambiente em que ficam armazenados os objetos (vetores, matrizes, data frames, etc.) criados durante o processo de manipula√ß√£o e an√°lise de dados. Ao fechar uma se√ß√£o do R (ex. ao sair do RStudio), esta pode ser salva guardando os objetos criados. O arquivo de uma se√ß√£o √© salvo com extens√£o .RData.\nAo abrir um novo script (com extens√£o .r) em um editor de texto √© importante definir o diret√≥rio de trabalho, que ser√° o local onde ficar√£o dados e onde ser√£o salvos os resultados do trabalho (ex. figuras, tabelas, etc.). No RStudio, um novo script pode ser aberto via menu Arquivo --&gt; Novo script. Ao iniciar o R-Studio abre-se uma nova se√ß√£o. O diret√≥rio desta se√ß√£o pode ser verificado pelo comando:\n\ngetwd()\n\nPara criar uma pasta (ex. Introducao_R) e direcionar a se√ß√£o de trabalho para esta pasta utiliza-se a fun√ß√£o setwd():\n\nsetwd(\"C:/seu_caminho/Introducao_R\")\n\nA fun√ß√£o getwd() pode ser utilizada para verificar se a altera√ß√£o de diret√≥rio foi realizada\n\ngetwd()\n\n\n\nC:/seu_caminho/Introducao_R\n\n\nA partir deste momento o R ir√° ler e salvar aquivos sempre a partir desse diret√≥rio."
  },
  {
    "objectID": "content/introducao-r/data-frames.html#manipula√ß√£o-de-data-frames",
    "href": "content/introducao-r/data-frames.html#manipula√ß√£o-de-data-frames",
    "title": "(B√°sico da) Manipula√ß√£o de data frames",
    "section": "2 Manipula√ß√£o de data frames",
    "text": "2 Manipula√ß√£o de data frames\n\n2.1 Sele√ß√£o de linhas e colunas em data frames\nNo data frame os nomes das colunas e linhas podem ser acessados por:\n\ncolnames(dbenv)\n\n [1] \"dfs\" \"alt\" \"slo\" \"flo\" \"pH\"  \"har\" \"pho\" \"nit\" \"amm\" \"oxy\" \"bdo\"\n\n\n\nrownames(dbenv)\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\" \"26\" \"27\" \"28\" \"29\" \"30\"\n\n\nOs n√∫meros ‚Äúentre aspas‚Äù significam que est√£o sendo lidos como caracteres.\nColunas espec√≠ficas podem ser acessadas por meio de seus nomes:\n\ncolunas &lt;- c(\"dfs\", \"flo\", \"oxy\")\ndbenv[,colunas]\n\n    dfs  flo oxy\n1     3   84 122\n2    22  100 103\n3   102  180 105\n4   185  253 110\n5   215  264  80\n6   324  286 102\n7   268  400 111\n8   491  130  70\n9   705  480  72\n10  990 1000 100\n11 1234 1990 115\n12 1324 2000 122\n13 1436 2110 124\n14 1522 2120 123\n15 1645 2300 117\n16 1859 1610 103\n17 1985 2430 102\n18 2110 2500 103\n19 2246 2590 106\n20 2477 2680 103\n21 2812 2720  90\n22 2940 2790  91\n23 3043 2880  63\n24 3147 2976  52\n25 3278 3870  41\n26 3579 3910  62\n27 3732 3960  72\n28 3947 4320  81\n29 4220 6770  90\n30 4530 6900  82\n\n\nOu por suas posi√ß√µes:\n\ncolunas_num &lt;- c(1, 3, 4)\ndbenv[,colunas_num]\n\n    dfs   slo  flo\n1     3 6.176   84\n2    22 3.434  100\n3   102 3.638  180\n4   185 3.497  253\n5   215 3.178  264\n6   324 3.497  286\n7   268 4.205  400\n8   491 3.258  130\n9   705 2.565  480\n10  990 4.605 1000\n11 1234 3.738 1990\n12 1324 2.833 2000\n13 1436 3.091 2110\n14 1522 2.565 2120\n15 1645 1.792 2300\n16 1859 3.045 1610\n17 1985 1.792 2430\n18 2110 2.197 2500\n19 2246 1.792 2590\n20 2477 2.197 2680\n21 2812 2.398 2720\n22 2940 2.708 2790\n23 3043 2.565 2880\n24 3147 1.386 2976\n25 3278 1.792 3870\n26 3579 1.792 3910\n27 3732 2.565 3960\n28 3947 1.386 4320\n29 4220 1.946 6770\n30 4530 1.099 6900\n\n\nO mesmo √© v√°lido para as linhas.\n\nlinhas &lt;- c(\"3\", \"7\", \"9\")\ndbenv[linhas,]\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n3 102 914 3.638 180 83  52   5  22   5 105  35\n7 268 841 4.205 400 81  88   7  15   0 111  22\n9 705 752 2.565 480 80  90  30  82  12  72  52\n\n\n\nlinhas_num &lt;- c(3, 7, 9)\ndbenv[linhas_num,]\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo\n3 102 914 3.638 180 83  52   5  22   5 105  35\n7 268 841 4.205 400 81  88   7  15   0 111  22\n9 705 752 2.565 480 80  90  30  82  12  72  52\n\n\nSub-conjunto do data frame podem ser selecionados combinando esses procedimentos.\n\ndbenv[linhas,colunas]\n\n  dfs flo oxy\n3 102 180 105\n7 268 400 111\n9 705 480  72\n\n\n\n\n2.2 Adicionando novas colunas\nEste conjunto de dados mostra medidas f√≠sicas e qu√≠micas obtidas em um riacho amostrado desde a cabeceira at√© a foz. O ponto mais alto (934 m de altitude) est√° a 3 km da cabeceira enquanto o ponto mais baixo est√° a 172 m de altitude e a 4530 km da cabeceira. Vamos criar uma nova vari√°vel categorizando os trechos do rio em Alto, Medio e Baixo assumindo a seguinte rela√ß√£o:\n\n\\(0\\) a \\(300\\) m: Baixo;\n\\(300\\) a \\(600\\) m: M√©dio;\nAcima de \\(600\\) m: Alto.\n\n\nelv_cat &lt;- cut(dbenv$alt, breaks = c(0, 300, 600, 1000), \n              labels = c(\"Baixo\", \"Medio\", \"Alto\"))\n\nA inser√ß√£o do novo objeto elv_cat no data frame pode ser feito simplesmente por:\n\ndbenv$trecho &lt;- elv_cat\n\nA nova coluna denominada trecho foi inserida no data frame, como pode ser visto:\n\nhead(dbenv)\n\n  dfs alt   slo flo pH har pho nit amm oxy bdo trecho\n1   3 934 6.176  84 79  45   1  20   0 122  27   Alto\n2  22 932 3.434 100 80  40   2  20  10 103  19   Alto\n3 102 914 3.638 180 83  52   5  22   5 105  35   Alto\n4 185 854 3.497 253 80  72  10  21   0 110  13   Alto\n5 215 849 3.178 264 81  84  38  52  20  80  62   Alto\n6 324 846 3.497 286 79  60  20  15   0 102  53   Alto\n\n\nO mesmo pode ser realizado com a fun√ß√£o transform(). Vamos utiliz√°-la para criar uma nova vari√°vel categ√≥rica a partir do oxig√™nio dissolvido, considerando 3 n√≠veis de satua√ß√£o: Pobre (\\(0\\) a \\(5\\)), M√©dio (\\(5\\) a \\(8\\)) e Saturado (acima de \\(8\\)).\n\ndbenv &lt;- transform(dbenv,  \n saturacao = cut(dbenv$oxy, breaks = c(0, 40, 109, 124), \n           labels = c(\"Pobre\", \"Medio\", \"Saturado\")))\n\nVeja agora o data frame\n\ndbenv\n\n    dfs alt   slo  flo pH har pho nit amm oxy bdo trecho saturacao\n1     3 934 6.176   84 79  45   1  20   0 122  27   Alto  Saturado\n2    22 932 3.434  100 80  40   2  20  10 103  19   Alto     Medio\n3   102 914 3.638  180 83  52   5  22   5 105  35   Alto     Medio\n4   185 854 3.497  253 80  72  10  21   0 110  13   Alto  Saturado\n5   215 849 3.178  264 81  84  38  52  20  80  62   Alto     Medio\n6   324 846 3.497  286 79  60  20  15   0 102  53   Alto     Medio\n7   268 841 4.205  400 81  88   7  15   0 111  22   Alto  Saturado\n8   491 792 3.258  130 81  94  20  41  12  70  81   Alto     Medio\n9   705 752 2.565  480 80  90  30  82  12  72  52   Alto     Medio\n10  990 617 4.605 1000 77  82   6  75   1 100  43   Alto     Medio\n11 1234 483 3.738 1990 81  96  30 160   0 115  27  Medio  Saturado\n12 1324 477 2.833 2000 79  86   4  50   0 122  30  Medio  Saturado\n13 1436 450 3.091 2110 81  98   6  52   0 124  24  Medio  Saturado\n14 1522 434 2.565 2120 83  98  27 123   0 123  38  Medio  Saturado\n15 1645 415 1.792 2300 86  86  40 100   0 117  21  Medio  Saturado\n16 1859 375 3.045 1610 80  88  20 200   5 103  27  Medio     Medio\n17 1985 348 1.792 2430 80  92  20 250  20 102  46  Medio     Medio\n18 2110 332 2.197 2500 80  90  50 220  20 103  28  Medio     Medio\n19 2246 310 1.792 2590 81  84  60 220  15 106  33  Medio     Medio\n20 2477 286 2.197 2680 80  86  30 300  30 103  28  Baixo     Medio\n21 2812 262 2.398 2720 79  85  20 220  10  90  41  Baixo     Medio\n22 2940 254 2.708 2790 81  88  20 162   7  91  48  Baixo     Medio\n23 3043 246 2.565 2880 81  97 260 350 115  63 164  Baixo     Medio\n24 3147 241 1.386 2976 80  99 140 250  60  52 123  Baixo     Medio\n25 3278 231 1.792 3870 79 100 422 620 180  41 167  Baixo     Medio\n26 3579 214 1.792 3910 79  94 143 300  30  62  89  Baixo     Medio\n27 3732 206 2.565 3960 81  90  58 300  26  72  63  Baixo     Medio\n28 3947 195 1.386 4320 83 100  74 400  30  81  45  Baixo     Medio\n29 4220 183 1.946 6770 78 110  45 162  10  90  42  Baixo     Medio\n30 4530 172 1.099 6900 82 109  65 160  10  82  44  Baixo     Medio\n\n\n\n\n2.3 Fam√≠lia apply e aggregate\nEm muitas situa√ß√µes temos interesse aplicar uma determinada fun√ß√£o a cada linha ou a cada coluna de um data frame ou ainda para grupos distintos de linhas.\nObserve por exemplo que se extra√≠mos a m√©dia aritm√©tica da coluna pH (\\(\\times 10\\)).\n\nmean(dbenv$pH)  # m√©dia aritm√©tica\n\n[1] 80.5\n\n\nO resultado √© calculado para toda a coluna.\n\n\nFun√ß√£o tapply\nPodemos estar interessados no entanto, em extrair as m√©dias separadamente para os trechos alto, m√©dio e baixo do rio. A fun√ß√£o tapply() √© √∫til nestas situa√ß√µes.\n\ntapply(dbenv$pH, dbenv$trecho, mean)\n\n   Baixo    Medio     Alto \n80.27273 81.22222 80.10000 \n\n\nA fun√ß√£o acima, pode ser lida do modo:\n\nSelecione a coluna pH;\nAgrupe os elementos em fun√ß√£o dos n√≠veis em trecho (Baixo, Medio, Alto);\nCalcule a m√©dia aritm√©tica para cada sub-grupo.\n\nNote que o resultado foi um vetor em que cada elemento corresponde √† m√©dia de um sub-grupo. Fun√ß√µes que retornam mais de um valor resultam em um objeto no formato de lista. A fun√ß√£o range() por exemplo, retorna dois valores (m√≠nimo e m√°ximo). Ao utiliz√°-la junto √† fun√ß√£o tapply() termos como resultado uma lista composta por um vetor para cada subgrupo.\n\ntapply(dbenv$pH, dbenv$trecho, range)\n\n$Baixo\n[1] 78 83\n\n$Medio\n[1] 79 86\n\n$Alto\n[1] 77 83\n\n\n\n\nFun√ß√£o apply\nPodemos aplicar uma determinada fun√ß√£o a todas as linhas ou colunas de um data frame (ou matriz).\n\napply(dbenv[,1:5], MARGIN = 2, mean)\n\n        dfs         alt         slo         flo          pH \n1879.033333  481.500000    2.757733 2220.100000   80.500000 \n\n\nO argumento MARGIN = 2 diz que desejamos aplicar a fun√ß√£o √°s colunas da matriz. Com MARGIN = 1 aplicamos a fun√ß√£o √†s linhas da matriz.\n\n\nFun√ß√£o lapply\nSe o objeto √© do formato lista, o comando lapply() aplica uma fun√ß√£o a cada elemento da lista. Considere a lista:\n\nnossalista &lt;- list(Ilha = c(\"Ilhabela\", \"Anchieta\", \"Cardoso\"), \n                  Areaskm2 = c(347.5, 8.3, 131), \n                  Bioma = rep(\"Mata Atlantica\",3),\n                  Lat = c(23, 25, 23),\n                  Long = c(45, 47, 45))\n\nVeja os resultados dos comandos abaixo:\n\nlapply(nossalista, sort)\n\n$Ilha\n[1] \"Anchieta\" \"Cardoso\"  \"Ilhabela\"\n\n$Areaskm2\n[1]   8.3 131.0 347.5\n\n$Bioma\n[1] \"Mata Atlantica\" \"Mata Atlantica\" \"Mata Atlantica\"\n\n$Lat\n[1] 23 23 25\n\n$Long\n[1] 45 45 47\n\n\n\n\n\n\n\n\nNota\n\n\n\nExistem outras fun√ß√µes neste grupo, Veja o help() destas fun√ß√µes pois s√£o extremamente √∫teis na manipula√ß√£o de data frames e listas.\n\n?tapply\n?apply\n?lapply\n?mapply\n?replicate\n\n\n\n\n\nFun√ß√£o aggregate\nA fun√ß√£o tapply() aplica uma fun√ß√£o a subgrupos de uma √∫nica coluna. A fun√ß√£o aggregate() faz o mesmo, por√©m para m√∫ltiplas colunas agrupadas de acordo com uma ou mais categorias. O comando abaixo calcula os valores m√©dios das vari√°veis para os trechos alto, m√©dio e baixo combinados com n√≠veis de \\(pH\\).\n\nmedia.trecho &lt;- aggregate(dbenv[, 1:11], \n                         by = list(TRECHO = dbenv$trecho,\n                                   ALCALINO = dbenv$pH &gt;= 80),\n                         FUN = mean)\nmedia.trecho\n\n  TRECHO ALCALINO      dfs      alt      slo       flo       pH      har\n1  Baixo    FALSE 3472.250 222.5000 1.982000 4317.5000 78.75000 97.25000\n2  Medio    FALSE 1324.000 477.0000 2.833000 2000.0000 79.00000 86.00000\n3   Alto    FALSE  439.000 799.0000 4.759333  456.6667 78.33333 62.33333\n4  Baixo     TRUE 3402.286 228.5714 1.986571 3786.5714 81.14286 95.57143\n5  Medio     TRUE 1754.625 393.3750 2.501500 2206.2500 81.50000 91.50000\n6   Alto     TRUE  284.000 847.7143 3.396429  258.1429 80.85714 74.28571\n        pho       nit        amm       oxy      bdo\n1 157.50000 325.50000 57.5000000  70.75000 84.75000\n2   4.00000  50.00000  0.0000000 122.00000 30.00000\n3   9.00000  36.66667  0.3333333 108.00000 41.00000\n4  92.42857 274.57143 39.7142857  77.71429 73.57143\n5  31.62500 165.62500  7.5000000 111.62500 30.50000\n6  16.00000  36.14286  8.4285714  93.00000 40.57143"
  },
  {
    "objectID": "content/introducao-r/data-frames.html#exportando-um-data-frame",
    "href": "content/introducao-r/data-frames.html#exportando-um-data-frame",
    "title": "(B√°sico da) Manipula√ß√£o de data frames",
    "section": "3 Exportando um data frame",
    "text": "3 Exportando um data frame\nFinalmente, podemos exportar o data frame media.trecho obtido acima para um arquivo Mediaportecho.csv.\n\nwrite.table(media.trecho, file = \"C:/seu_caminho/Introducao_R/Mediaportecho.csv\", \n            sep = \",\", dec = '.', row.names = FALSE, \n            col.names = TRUE)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "",
    "text": "A modelagem bayesiana constitui um processo sistem√°tico e iterativo para integrar dados e conhecimento pr√©vio, visando a compreens√£o aprofundada de um fen√¥meno. O fluxo de trabalho bayesiano √© um ciclo cont√≠nuo que envolve:\nDescobertas ou problemas identificados em etapas posteriores (como diagn√≥stico ou valida√ß√£o) frequentemente levam √† revis√£o e ao refinamento de decis√µes tomadas em etapas anteriores (como a especifica√ß√£o do modelo ou a escolha das priors). Para uma dsicuss√£o detalhada do fluxo de trabalho Bayesiano, veja o texto Bayesian workflow.\nPara demonstrar este fluxo de trabalho de forma pr√°tica, utilizaremos a biblioteca Bambi (BAyesian Model-Building Interface), uma interface de alto n√≠vel constru√≠da sobre o PyMC que simplifica a implementa√ß√£o de modelos bayesianos comuns em Python. A biblioteca Bambi utiliza uma sintaxe baseada em f√≥rmulas, semelhante √†quela encontrada em pacotes R como lme4 ou brms, permitindo que nos concentremos mais nas etapas anal√≠ticas do fluxo de trabalho do que nos detalhes computacionais subjacentes.\nNosso objetivo ser√° percorrer estas etapas utilizando o conjunto de dados altura_adultos_subset.csv, que descreve a rela√ß√£o entre altura de indiv√≠duos e n√∫mero do cal√ßado. Ao fazer isso, esperamos que voc√™ reflita criticamente sobre como a avalia√ß√£o sistem√°tica e o refinamento cont√≠nuo do modelo, facilitados por ferramentas como Bambi/PyMC, s√£o essenciais para extrair conhecimento cient√≠fico robusto sobre os processos subjacentes aos dados observados.\nNosso objetivo ser√° percorrer cada uma das etapas do fluxo de trabalho bayesiano utilizando o conjunto de dados altura_adultos_subset.csv, que descreve a rela√ß√£o entre a altura de indiv√≠duos e o n√∫mero do cal√ßado."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#prepara√ß√£o-do-ambiente",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#prepara√ß√£o-do-ambiente",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "1 Prepara√ß√£o do ambiente",
    "text": "1 Prepara√ß√£o do ambiente\n\n# Importa√ß√£o das principais bibliotecas necess√°rias para an√°lise de dados, visualiza√ß√£o, modelagem bayesiana e diagn√≥stico.\nimport arviz as az\nimport bambi as bmb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport random"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#importa√ß√£o-e-visualiza√ß√£o-dos-dados",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#importa√ß√£o-e-visualiza√ß√£o-dos-dados",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "2 Importa√ß√£o e visualiza√ß√£o dos dados",
    "text": "2 Importa√ß√£o e visualiza√ß√£o dos dados\nVamos visualizar a rela√ß√£o entre o n√∫mero do cal√ßado e a altura. Esta etapa √© importante para termos uma ideia preliminar do padr√£o nos dados a fim de julgarmos qual modelo adequado para descrever esta rela√ß√£o.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/altura_adultos_subset.csv')\n\n\nsns.regplot(data=df, x='calcado', y='altura', ci=None, scatter=True, fit_reg=False)\n\n\n\n\n\n\n\n\nOs dados observados, sugere que um modelo linear √© razo√°vel se buscamos prever a altura de uma passoal adultra como fun√ß√£o do n√∫mero do cal√ßado o que justifica a implementa√ß√£o de um modelo de regress√£o linear simples."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#especifica√ß√£o-e-ajuste-do-modelo",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#especifica√ß√£o-e-ajuste-do-modelo",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "3 Especifica√ß√£o e ajuste do modelo",
    "text": "3 Especifica√ß√£o e ajuste do modelo\nEspecificamos um modelo de regress√£o linear bayesiano em que a altura √© modelada como uma fun√ß√£o do n√∫mero do cal√ßado. A biblioteca Bambi adota uma sintaxe onde expressamos a rela√ß√£o entre as vari√°veis na forma y ~ x. Essa nota√ß√£o indica que a vari√°vel resposta (y) √© explicada linearmente pela vari√°vel preditora (x), o que corresponde, ao modelo:\n\\[\ny = \\beta_0 + \\beta_1 x.\n\\]\nNesse caso, o Bambi interpreta a f√≥rmula altura ~ calcado como uma especifica√ß√£o de que a altura dos indiv√≠duos depende linearmente do n√∫mero do cal√ßado, com coeficientes a serem estimados a partir dos dados.\n\nmod = bmb.Model(\"altura ~ calcado\", df)\nmod\n\n       Formula: altura ~ calcado\n        Family: gaussian\n          Link: mu = identity\n  Observations: 5\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 172.0, sigma: 300.3331)\n            calcado ~ Normal(mu: 0.0, sigma: 7.3612)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 11.8659)\n\n\n\n\n\n\n\n\nEstrutura do modelo em Bambi\n\n\n\nAo inspecionair o objeto mod, podemos verificar um resumo da estrutura do modelo especificado:\n\nFormula: altura ~ calcado: Descreve a f√≥rmula estat√≠stica especificada no modelo.\nFamily: gaussian: Indica a fam√≠lia da distribui√ß√£o de probabilidade que Bambi assumiu para a vari√°vel resposta.\nLink: mu = identity: Especifica a fun√ß√£o de liga√ß√£o que conecta o modelo linear ao par√¢metro da fam√≠lia da distribui√ß√£o.\nObservations: 5: Mostra o n√∫mero de linhas (observa√ß√µes) no DataFrame que foram usadas para construir o modelo.\nPriors: Distribui√ß√µes a priori. Se n√£o especificadas pelo usu√°rio, o Bambi atribui priors padr√£o razo√°veis parea o conjuto de dados e o modelo utilizado.\n\ntarget = mu: Indica que o modelo linear est√° focando em estimar a m√©dia (mu) da distribui√ß√£o Gaussiana.\n\nCommon-level effects: Lista os par√¢metros associados aos termos fixos no modelo linear.\nIntercept ~ Normal(‚Ä¶): Define a prior para o intercepto (\\(\\beta_0\\))\ncalcado ~ Normal(‚Ä¶): Define a prior para o coeficiente de regress√£o associado √† vari√°vel calcado (\\(\\beta_1\\)).\n\nAuxiliary parameters: Par√¢metros n√£o diretamente modelados pelo predictor linear.\n\nsigma ~ HalfStudentT(‚Ä¶): Define a prior para o par√¢metro de desvio padr√£o (\\(\\sigma\\))."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#amostragem-mcmc",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#amostragem-mcmc",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "4 Amostragem MCMC",
    "text": "4 Amostragem MCMC\nRealizamos a amostragem MCMC (Markov Chain Monte Carlo) para obter amostras da distribui√ß√£o a posteriori dos par√¢metros, combinando as informa√ß√µes fornecidas pelos dados com as distribui√ß√µes a priori.\n\nmod_fit = mod.fit()\nmod_fit\n\n\n\n\n\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:    (chain: 4, draw: 1000)\nCoordinates:\n  * chain      (chain) int64 32B 0 1 2 3\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\nData variables:\n    sigma      (chain, draw) float64 32kB 12.82 5.324 4.266 ... 7.573 19.83 4.2\n    Intercept  (chain, draw) float64 32kB -6.19 79.7 72.66 ... 3.963 11.6 104.6\n    calcado    (chain, draw) float64 32kB 4.255 2.204 2.379 ... 3.947 1.687\nAttributes:\n    created_at:                  2026-02-19T12:17:54.860559+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    sampling_time:               1.056750774383545\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (3)sigma(chain, draw)float6412.82 5.324 4.266 ... 19.83 4.2array([[12.81741535,  5.32434608,  4.26571042, ...,  7.19993658,\n        18.07536279, 15.50659824],\n       [ 7.26439627,  9.49991108,  9.55902361, ..., 11.4661689 ,\n        10.74318121,  6.98709945],\n       [15.47477747, 13.03995877, 14.70813622, ...,  6.28721435,\n         8.42474631,  9.2594542 ],\n       [ 5.93351046,  4.58998872, 12.66511175, ...,  7.57266598,\n        19.82840813,  4.19956176]], shape=(4, 1000))Intercept(chain, draw)float64-6.19 79.7 72.66 ... 11.6 104.6array([[ -6.19002754,  79.69758448,  72.65792859, ...,  66.34573898,\n         11.42168586,   0.21231097],\n       [113.37660505,  83.33559985,  77.07392243, ...,  -8.89825319,\n         56.66426362,  31.95409566],\n       [ 27.282223  , -43.20413615,  60.13479023, ...,  92.20121133,\n         34.81016428,  51.79221444],\n       [ 49.1165146 ,  78.32703166,  12.44660229, ...,   3.96294101,\n         11.60458819, 104.57452517]], shape=(4, 1000))calcado(chain, draw)float644.255 2.204 2.379 ... 3.947 1.687array([[4.25496197, 2.20358419, 2.37866834, ..., 2.62769952, 3.99674521,\n        4.46528147],\n       [1.45262439, 2.28667928, 2.40997987, ..., 4.46953765, 2.64979557,\n        3.37974788],\n       [3.8324902 , 4.88799605, 2.61513966, ..., 1.8536024 , 3.36991379,\n        2.91825591],\n       [2.9832878 , 2.35062828, 3.94609027, ..., 4.12731208, 3.94672787,\n        1.6866787 ]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2026-02-19T12:17:54.860559+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1sampling_time :1.056750774383545tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 528kB\nDimensions:                (chain: 4, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 32B 0 1 2 3\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/18)\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 30.27 30.68 ... 30.95\n    acceptance_rate        (chain, draw) float64 32kB 1.0 0.6788 ... 0.9679\n    perf_counter_start     (chain, draw) float64 32kB 7.678e+04 ... 7.678e+04\n    index_in_trajectory    (chain, draw) int64 32kB 2 2 -1 -2 -2 2 ... 0 2 2 2 3\n    lp                     (chain, draw) float64 32kB -29.4 -27.12 ... -28.84\n    ...                     ...\n    tree_depth             (chain, draw) int64 32kB 2 2 2 2 2 2 ... 2 1 2 2 2 3\n    n_steps                (chain, draw) float64 32kB 3.0 3.0 3.0 ... 3.0 7.0\n    perf_counter_diff      (chain, draw) float64 32kB 0.0001957 ... 0.0003335\n    process_time_diff      (chain, draw) float64 32kB 0.0001957 ... 0.0003336\n    energy_error           (chain, draw) float64 32kB -0.08676 ... -1.165\n    max_energy_error       (chain, draw) float64 32kB -0.1561 1.997 ... -1.435\nAttributes:\n    created_at:                  2026-02-19T12:17:54.873214+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    sampling_time:               1.056750774383545\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,))Data variables: (18)reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))energy(chain, draw)float6430.27 30.68 28.56 ... 30.91 30.95array([[30.27393878, 30.67543373, 28.56101895, ..., 29.28834498,\n        30.75944379, 34.44819584],\n       [29.90123906, 28.70629638, 27.64538882, ..., 29.79278723,\n        30.39238441, 30.32281733],\n       [30.82192164, 35.95668999, 34.72839293, ..., 30.13014212,\n        29.11322617, 27.53532614],\n       [30.38110092, 26.96631799, 29.53502712, ..., 28.56744654,\n        30.91345457, 30.95141848]], shape=(4, 1000))acceptance_rate(chain, draw)float641.0 0.6788 0.5379 ... 0.8919 0.9679array([[1.        , 0.67878498, 0.5379292 , ..., 0.71582217, 0.73838575,\n        0.78614672],\n       [0.26708511, 0.80102127, 1.        , ..., 0.99856967, 0.97472883,\n        0.78149229],\n       [1.        , 0.34647542, 0.97975062, ..., 0.18083964, 0.96185254,\n        0.96531319],\n       [0.00989953, 0.96340269, 0.22685756, ..., 0.93412117, 0.89194835,\n        0.96785717]], shape=(4, 1000))perf_counter_start(chain, draw)float647.678e+04 7.678e+04 ... 7.678e+04array([[76782.59272149, 76782.59298821, 76782.59326042, ...,\n        76782.94385301, 76782.94410061, 76782.94434225],\n       [76782.60839864, 76782.60866101, 76782.60908722, ...,\n        76782.92483403, 76782.92510155, 76782.92561194],\n       [76782.62023255, 76782.62050318, 76782.62093457, ...,\n        76782.97129487, 76782.97153542, 76782.97177893],\n       [76782.61768904, 76782.61793218, 76782.61897322, ...,\n        76782.99912862, 76782.99937174, 76782.99961328]], shape=(4, 1000))index_in_trajectory(chain, draw)int642 2 -1 -2 -2 2 3 ... 1 0 0 2 2 2 3array([[ 2,  2, -1, ...,  0,  2, -1],\n       [ 0,  1, -1, ...,  2,  3, -1],\n       [ 1,  3, -2, ...,  0, -2, -1],\n       [ 0,  2, -2, ...,  2,  2,  3]], shape=(4, 1000))lp(chain, draw)float64-29.4 -27.12 ... -30.66 -28.84array([[-29.40385555, -27.1203794 , -27.7456118 , ..., -26.42615354,\n        -30.21853676, -30.71018626],\n       [-27.45173278, -27.60796675, -27.34997936, ..., -28.90480287,\n        -28.80930955, -27.21956464],\n       [-30.6292007 , -33.76882204, -29.21037938, ..., -28.10749287,\n        -27.07349483, -27.13772958],\n       [-26.51487079, -26.86958249, -28.67399841, ..., -28.12686346,\n        -30.65672201, -28.84172835]], shape=(4, 1000))step_size_bar(chain, draw)float640.6221 0.6221 ... 0.5931 0.5931array([[0.622073  , 0.622073  , 0.622073  , ..., 0.622073  , 0.622073  ,\n        0.622073  ],\n       [0.67658689, 0.67658689, 0.67658689, ..., 0.67658689, 0.67658689,\n        0.67658689],\n       [0.73021543, 0.73021543, 0.73021543, ..., 0.73021543, 0.73021543,\n        0.73021543],\n       [0.59309938, 0.59309938, 0.59309938, ..., 0.59309938, 0.59309938,\n        0.59309938]], shape=(4, 1000))diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]], shape=(4, 1000))divergences(chain, draw)int640 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], shape=(4, 1000))step_size(chain, draw)float640.6071 0.6071 ... 0.4018 0.4018array([[0.60705735, 0.60705735, 0.60705735, ..., 0.60705735, 0.60705735,\n        0.60705735],\n       [0.59858393, 0.59858393, 0.59858393, ..., 0.59858393, 0.59858393,\n        0.59858393],\n       [0.8307564 , 0.8307564 , 0.8307564 , ..., 0.8307564 , 0.8307564 ,\n        0.8307564 ],\n       [0.40181627, 0.40181627, 0.40181627, ..., 0.40181627, 0.40181627,\n        0.40181627]], shape=(4, 1000))smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(4, 1000))largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], shape=(4, 1000))tree_depth(chain, draw)int642 2 2 2 2 2 3 2 ... 3 2 2 1 2 2 2 3array([[2, 2, 2, ..., 2, 2, 3],\n       [2, 3, 1, ..., 2, 3, 3],\n       [2, 3, 3, ..., 2, 2, 3],\n       [1, 2, 3, ..., 2, 2, 3]], shape=(4, 1000))n_steps(chain, draw)float643.0 3.0 3.0 3.0 ... 3.0 3.0 3.0 7.0array([[3., 3., 3., ..., 3., 3., 7.],\n       [3., 7., 1., ..., 3., 7., 7.],\n       [3., 7., 7., ..., 3., 3., 7.],\n       [1., 3., 7., ..., 3., 3., 7.]], shape=(4, 1000))perf_counter_diff(chain, draw)float640.0001957 0.000198 ... 0.0003335array([[0.00019572, 0.00019799, 0.00018841, ..., 0.00017997, 0.00017787,\n        0.00032984],\n       [0.00019109, 0.00035057, 0.00012336, ..., 0.0001983 , 0.00043593,\n        0.00033786],\n       [0.00019956, 0.00035933, 0.0003723 , ..., 0.00017631, 0.00017898,\n        0.00034069],\n       [0.00010224, 0.00019691, 0.00035692, ..., 0.00017861, 0.00017772,\n        0.0003335 ]], shape=(4, 1000))process_time_diff(chain, draw)float640.0001957 0.0001981 ... 0.0003336array([[0.00019567, 0.00019813, 0.00018853, ..., 0.00018003, 0.00017798,\n        0.00032994],\n       [0.00019112, 0.00035065, 0.00012334, ..., 0.00019844, 0.00043603,\n        0.00033802],\n       [0.00019968, 0.00035942, 0.0003725 , ..., 0.00017642, 0.0001791 ,\n        0.00034083],\n       [0.0001021 , 0.00019684, 0.00035714, ..., 0.00017866, 0.00017778,\n        0.00033364]], shape=(4, 1000))energy_error(chain, draw)float64-0.08676 -0.5571 ... 0.1704 -1.165array([[-0.08676354, -0.55707971,  0.46624801, ...,  0.        ,\n         0.325291  , -0.21060465],\n       [ 0.        ,  0.10864021, -0.01464868, ..., -0.04108794,\n        -0.03409156, -0.21987311],\n       [-0.00613259,  0.04629629, -0.42920601, ...,  0.        ,\n        -0.04840926,  0.03876647],\n       [ 0.        ,  0.11630007,  0.70080163, ...,  0.1755585 ,\n         0.17036824, -1.16462335]], shape=(4, 1000))max_energy_error(chain, draw)float64-0.1561 1.997 ... 0.1704 -1.435array([[-0.15613274,  1.99704598,  0.99571865, ...,  0.73611675,\n         0.325291  ,  0.85477271],\n       [ 4.67880379,  0.96693172, -0.01464868, ..., -0.04108794,\n        -0.16684677,  0.46602193],\n       [-0.00924969,  2.85872406, -0.55769345, ...,  6.74226374,\n         0.12153775, -0.13772793],\n       [ 4.61526805, -0.12556977,  6.95041544, ...,  0.1755585 ,\n         0.17036824, -1.43494468]], shape=(4, 1000))Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2026-02-19T12:17:54.873214+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1sampling_time :1.056750774383545tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.15.0\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 80B\nDimensions:  (__obs__: 5)\nCoordinates:\n  * __obs__  (__obs__) int64 40B 0 1 2 3 4\nData variables:\n    altura   (__obs__) float64 40B 178.0 163.0 175.0 155.0 189.0\nAttributes:\n    created_at:                  2026-02-19T12:17:54.877341+00:00\n    arviz_version:               0.23.4\n    inference_library:           pymc\n    inference_library_version:   5.25.1\n    modeling_interface:          bambi\n    modeling_interface_version:  0.15.0xarray.DatasetDimensions:__obs__: 5Coordinates: (1)__obs__(__obs__)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (1)altura(__obs__)float64178.0 163.0 175.0 155.0 189.0array([178., 163., 175., 155., 189.])Indexes: (1)__obs__PandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='__obs__'))Attributes: (6)created_at :2026-02-19T12:17:54.877341+00:00arviz_version :0.23.4inference_library :pymcinference_library_version :5.25.1modeling_interface :bambimodeling_interface_version :0.15.0"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verifica√ß√£o-das-priors",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verifica√ß√£o-das-priors",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "5 Verifica√ß√£o das priors",
    "text": "5 Verifica√ß√£o das priors\nNeste exemplo as priors foram atribu√≠das automaticamente. Veremos como especific√°-las manualmente mais adiante. Por enquanto, iremos nos concentrar em visualizar as distribui√ß√µes a priori para entender as expectativas iniciais do modelo sobre os par√¢metros antes de processar os dados.\n\nmod.plot_priors(var_names=['Intercept', 'calcado', 'sigma'], figsize=(9, 4))\n\narray([&lt;Axes: title={'center': 'Intercept'}&gt;,\n       &lt;Axes: title={'center': 'calcado'}&gt;,\n       &lt;Axes: title={'center': 'sigma'}&gt;], dtype=object)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#diagn√≥sticos-de-converg√™ncia",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#diagn√≥sticos-de-converg√™ncia",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "6 Diagn√≥sticos de converg√™ncia",
    "text": "6 Diagn√≥sticos de converg√™ncia\nAp√≥s realizar a amostragem MCMC, √© fundamental verificar se o processo de amostragem funcionou corretamente. Para isso, utilizamos diagn√≥sticos de converg√™ncia, que nos ajudam a avaliar se as cadeias geradas est√£o representando adequadamente a distribui√ß√£o a posteriori dos par√¢metros.\nUma das ferramentas mais comuns para essa avalia√ß√£o s√£o os trace plots ‚Äî gr√°ficos que mostram os valores amostrados para cada par√¢metro ao longo das itera√ß√µes. Idealmente, essas cadeias devem parecer bem misturadas e sem padr√µes vis√≠veis, o que indica que a amostragem atingiu o chamado estado estacion√°rio, sugerindo que as estimativas s√£o confi√°veis.\nTend√™ncias, oscila√ß√µes sistem√°ticas ou falta de sobreposi√ß√£o entre diferentes cadeias pode ser um sinal de que o algoritmo n√£o convergiu adequadamente, exigindo ajustes no modelo ou no processo de amostragem.\n\n# Gr√°ficos de diagn√≥stico\nfig, axes = plt.subplots(3, 2, figsize=(8, 8))\n\n# Trace plots\naz.plot_trace(mod_fit, var_names=['Intercept', 'calcado', 'sigma'], axes=axes)\nplt.suptitle('Trace Plots - Converg√™ncia das Cadeias MCMC', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#resumo-do-ajuste",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#resumo-do-ajuste",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "7 Resumo do ajuste",
    "text": "7 Resumo do ajuste\n\naz.summary(mod_fit)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nsigma\n8.946\n4.194\n3.423\n16.528\n0.134\n0.156\n1013.0\n1041.0\n1.0\n\n\nIntercept\n66.679\n44.019\n-24.246\n146.581\n0.959\n1.430\n2226.0\n1800.0\n1.0\n\n\ncalcado\n2.596\n1.069\n0.504\n4.635\n0.023\n0.034\n2291.0\n1781.0\n1.0\n\n\n\n\n\n\n\nAp√≥s a amostragem MCMC e a verifica√ß√£o da converg√™ncia, exploramos um resumo estat√≠stico das distribui√ß√µes a posteriori dos par√¢metros do modelo. Na tabela acima, cada linha corresponde a um par√¢metro (sigma, Intercept, calcado). As colunas fornecem estimativas pontuais (MEAN), intervalos de incerteza (SD, HDI) e m√©tricas para verificar a qualidade e a confiabilidade das amostras MCMC (MCSE, ESS, R_HAT).\n\n\n\n\n\n\nTabela resumo em um modelo bayesiano\n\n\n\n\nMEAN: A m√©dia das amostras a posteriori para o par√¢metro.\nSD: O desvio padr√£o das amostras a posteriori.\nHDI_3% e HDI_97%: Os limites inferior (3%) e superior (97%) do Intervalo de Credibilidade de Maior Densidade (HDI).\nMCSE_MEAN (Monte Carlo Standard Error of the Mean): O Erro Padr√£o de Monte Carlo da M√©dia estima a variabilidade da estimativa da m√©dia a posteriori devido ao n√∫mero finito e √† correla√ß√£o entre as amostras MCMC.\nMCSE_SD (Monte Carlo Standard Error of the Standard Deviation): O Erro Padr√£o de Monte Carlo do Desvio Padr√£o. Similar ao MCSE_MEAN, mas estima a precis√£o com que o desvio padr√£o a posteriori foi estimado a partir das amostras.\nESS_BULK (Effective Sample Size - Bulk): O Tamanho Efetivo da Amostra. Devido √† autocorrela√ß√£o nas cadeias MCMC, o n√∫mero de amostras efetivamente independentes √© geralmente menor que o n√∫mero total de amostras coletadas.\nESS_TAIL (Effective Sample Size - Tail): O Tamanho Efetivo da Amostra para as caracter√≠sticas das caudas da distribui√ß√£o (como quantis extremos).\nR_HAT (Gelman-Rubin statistic): O R-hat √© um diagn√≥stico de converg√™ncia que compara a variabilidade dentro de cada cadeia MCMC com a variabilidade entre as diferentes cadeias. Se todas as cadeias convergiram para a mesma distribui√ß√£o estacion√°ria (a posteriori alvo), o valor de R_HAT deve ser muito pr√≥ximo de 1 (idealmente &lt;= 1.01 ou &lt;= 1.05 no m√°ximo). Valores significativamente maiores que 1 indicam que as cadeias n√£o convergiram bem."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verifica√ß√£o-das-posteriores-e-compara√ß√£o-com-as-priors",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#verifica√ß√£o-das-posteriores-e-compara√ß√£o-com-as-priors",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "8 Verifica√ß√£o das posteriores e compara√ß√£o com as priors",
    "text": "8 Verifica√ß√£o das posteriores e compara√ß√£o com as priors\nA compara√ß√£o gr√°fica entre as distribui√ß√µes a priori e a posteriori dos par√¢metros nos ajuda a avaliar o quanto os dados foram informativos, mostrando quais par√¢metros foram mais ou menos atualizados em rela√ß√£o √†s nossas cren√ßas iniciais. Uma pequena mudan√ßa da prior para a posteriori indica que os dados trouxeram pouca informa√ß√£o nova sobre aquele par√¢metro, enquanto uma grande diferen√ßa sugere que os dados foram bastante informativos. No gr√°fico abaixo, visualizamos essa compara√ß√£o para os par√¢metros do modelo (Intercept, calcado e sigma), onde a linha superior exibe as distribui√ß√µes a priori (atribu√≠das automaticamente) e a linha inferior apresenta as distribui√ß√µes a posteriori resultantes da an√°lise bayesiana.\n\nparam_order = ['Intercept', 'calcado', 'sigma']\n\nfig, axes = plt.subplots(nrows=2, ncols=len(param_order), figsize=(9, 6))\n\nmod.plot_priors(var_names=param_order, ax=axes[0, :])\naz.plot_posterior(mod_fit, var_names=param_order, ax=axes[1, :])\n\naxes[0, 0].set_ylabel('Densidade das Prioris')\naxes[1, 0].set_ylabel('Densidade das Posteriores')\n\nText(0, 0.5, 'Densidade das Posteriores')\n\n\n\n\n\n\n\n\n\n\naz.plot_trace(mod_fit, figsize=(9,10))\n\narray([[&lt;Axes: title={'center': 'sigma'}&gt;,\n        &lt;Axes: title={'center': 'sigma'}&gt;],\n       [&lt;Axes: title={'center': 'Intercept'}&gt;,\n        &lt;Axes: title={'center': 'Intercept'}&gt;],\n       [&lt;Axes: title={'center': 'calcado'}&gt;,\n        &lt;Axes: title={'center': 'calcado'}&gt;]], dtype=object)"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#predi√ß√£o-bayesiana",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#predi√ß√£o-bayesiana",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "9 Predi√ß√£o Bayesiana",
    "text": "9 Predi√ß√£o Bayesiana\nO processo de predi√ß√£o nos permite estimar valores da vari√°vel resposta para novas observa√ß√µes n√£o inclu√≠das no conjunto de dados original. Na abordagem bayesiana, a predi√ß√£o vai al√©m de fornecer uma estimativa pontual (isto √©, da m√©dia), incorporando explicitamente a incerteza associada tanto aos par√¢metros do modelo quanto √† variabilidade intr√≠nseca do processo gerador dos dados.\nA predi√ß√£o bayesiana utiliza toda a distribui√ß√£o a posteriori dos par√¢metros para gerar a distribui√ß√£o preditiva a posteriori. Esta distribui√ß√£o captura duas fontes principais de incerteza:\n\nIncerteza epist√™mica: Relacionada ao nosso conhecimento limitado sobre os verdadeiros valores dos par√¢metros do modelo (representada pela distribui√ß√£o a posteriori dos par√¢metros).\nIncerteza aleat√≥ria: Relacionada √† variabilidade natural do processo (representada pelo componente estoc√°stico do modelo, como o termo de erro \\(\\sigma\\)).\n\nA combina√ß√£o dessas duas fontes de incerteza resulta em intervalos de predi√ß√£o mais amplos que os intervalos de credibilidade da reta m√©dia, refletindo de forma mais realista nossa incerteza sobre observa√ß√µes futuras.\n\n9.1 Predi√ß√£o sobre a reta m√©dia (Incerteza epist√™mica)\nA predi√ß√£o da reta m√©dia quantifica nossa incerteza sobre o valor esperado da vari√°vel resposta, considerando apenas a incerteza nos par√¢metros do modelo. As amostras da posteriori geradas pelo m√©todo MCMC nos fornecem v√°rias combina√ß√µes de par√¢metros poss√≠veis ajustadas ao conjunto de dados. Podemos entender estas como retas poss√≠veis para o conjunto observado - algumas combina√ß√µes dos par√¢metros fornecem retas mais prov√°veis, outras menos.\n\n9.1.1 Visualiza√ß√£o das retas poss√≠veis\nPara visualizar essa incerteza epist√™mica, vamos primeiro obter amostras da distribui√ß√£o posterior e construir algumas retas poss√≠veis:\n\n# Definir pontos extremos para constru√ß√£o das retas\nx_vals = [32, 48]\nnovo_x = pd.DataFrame({\"calcado\": x_vals})\nposterior_par = mod.predict(mod_fit, kind=\"response_params\", data=novo_x, inplace=False)\nmu_vals = posterior_par.posterior['mu'].values\nmu_flat = mu_vals.reshape(-1, mu_vals.shape[-1])\n\n\n# Calcular a reta m√©dia\ny_mean = (posterior_par.posterior['Intercept'].mean().values + \n          posterior_par.posterior['calcado'].mean().values * x_vals)\n\n\n# Plotar uma amostra de retas poss√≠veis\nn = 100\nindices = np.random.choice(mu_flat.shape[0], size=n, replace=False)\n\nplt.figure(figsize=(9, 6))\nfor i in indices:\n    plt.plot(x_vals, mu_flat[i, :], '#e37d76', alpha=0.1)\n\nplt.plot(x_vals, y_mean, '#162be0', linewidth=2, label='Reta m√©dia')\n\n# Adicionar os pontos observados e reta m√©dia\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', label='Observa√ß√µes', s = 100)\n\n\nplt.xlabel(\"Cal√ßado\")\nplt.ylabel(\"Altura prevista\")\nplt.title(f\"Amostra de {n} retas da posteriori\")\nplt.legend()\nplt.grid(True)\nplt.ylim(120, 210)\nplt.xlim(32, 48)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n9.1.2 Intervalo de Credibilidade (IC) para \\(\\mu\\)\nAo inv√©s de representar todas as retas poss√≠veis, podemos criar um envelope contendo as combina√ß√µes que determinam os intervalos de credibilidade para a reta m√©dia, representando nossa incerteza sobre o valor esperado da resposta:\n\n# Criar sequ√™ncia cont√≠nua para visualiza√ß√£o\nx_seq = np.linspace(32, 48, 100)\n\n# Extrair amostras dos par√¢metros\nintercept = posterior_par.posterior['Intercept'].values.flatten()\nslope = posterior_par.posterior['calcado'].values.flatten()\n\n# Calcular retas para toda a sequ√™ncia\ny_seq = intercept[:, None] + slope[:, None] * x_seq[None, :]\n\n# Calcular intervalo de credibilidade de 95%\ny_ci = np.percentile(y_seq, [2.5, 97.5], axis=0)\n\n# Reta m√©dia para toda a sequ√™ncia\nintercept_mean = posterior_par.posterior['Intercept'].mean().values\nslope_mean = posterior_par.posterior['calcado'].mean().values\ny_mean_seq = intercept_mean + slope_mean * x_seq\n\n\n# Plotar resultados\nplt.figure(figsize=(9, 6))\n\n# Intervalo de credibilidade (envelope)\nplt.fill_between(x_seq, y_ci[0], y_ci[1], color='#e37d76', alpha=0.2, \n                 label='IC 95% da reta m√©dia')\n\n# Pontos observados\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', label='Observa√ß√µes', s = 100)\n\nplt.plot(x_seq, y_mean_seq, '#162be0', linewidth=2, label='Reta m√©dia')\n\nplt.xlabel(\"Cal√ßado\")\nplt.ylabel(\"Resposta m√©dia predita ($\\mu$)\")\nplt.title(\"Reta m√©dia e intervalo de credibilidade (95%)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nO Intervalo de Credibilidade representa nossa incerteza sobre o valor m√©dio esperado da altura para indiv√≠duos com um determinado n√∫mero de cal√ßado, refletindo exclusivamente a incerteza epist√™mica associada aos par√¢metros do modelo. Note que a maioria das retas passa pr√≥xima ao centro da distribui√ß√£o de \\(x\\) e \\(y\\), pois, nas proximidades da m√©dia de \\(x\\), h√° maior confian√ßa na estimativa da trajet√≥ria da reta. √Ä medida que nos afastamos desse centro, a incerteza aumenta, resultando em maior variabilidade nas regi√µes mais afastadas de \\(x\\).\n\n\n\n9.2 Predi√ß√£o sobre novos pontos (Incerteza epist√™mica + aleat√≥ria)\nA predi√ß√£o de novas observa√ß√µes vai al√©m da estimativa da m√©dia, incorporando tamb√©m a variabilidade intr√≠nseca do processo. Enquanto o intervalo de credibilidade nos representa nossa incerteza quanto √† reta m√©dia, o Intervalo de Predi√ß√£o (IP) nos informa sobre a incerteza associada ao valor que uma nova observa√ß√£o espec√≠fica pode assumir.\n\n9.2.1 Implementa√ß√£o da predi√ß√£o para novas observa√ß√µes\n\n# Definir valores para predi√ß√£o\ncalcado_pred = np.array([35, 40, 45])\ndados_pred = pd.DataFrame({\"calcado\": calcado_pred})\n\n# Predi√ß√£o da resposta m√©dia (Œº - apenas incerteza epist√™mica)\npred_mu = mod.predict(mod_fit, kind=\"response_params\", data=dados_pred, inplace=False)\n\n# Predi√ß√£o de novas observa√ß√µes (Œº + œÉ - ambas as incertezas)\npred_obs = mod.predict(mod_fit, kind=\"response\", data=dados_pred, inplace=False)\n\nprint(\"Valores preditos para n√∫mero do cal√ßado:\", calcado_pred)\nprint(\"\\nResumo das predi√ß√µes:\")\nprint(f\"Cal√ßado 35: Œº = {pred_mu.posterior['mu'].values[:,:,0].mean():.1f} cm\")\nprint(f\"Cal√ßado 40: Œº = {pred_mu.posterior['mu'].values[:,:,1].mean():.1f} cm\") \nprint(f\"Cal√ßado 45: Œº = {pred_mu.posterior['mu'].values[:,:,2].mean():.1f} cm\")\n\nValores preditos para n√∫mero do cal√ßado: [35 40 45]\n\nResumo das predi√ß√µes:\nCal√ßado 35: Œº = 157.6 cm\nCal√ßado 40: Œº = 170.5 cm\nCal√ßado 45: Œº = 183.5 cm\n\n\n\n# Visualiza√ß√£o das predi√ß√µes pontuais\n# Extrair amostras aleat√≥rias de novas observa√ß√µes para cada valor de cal√ßado\nn_samples = 80\ncalcado_pred = [35, 40, 45]\ncores = ['#ff6b6b', '#4ecdc4', '#d1c845']\n\nplt.figure(figsize=(8, 5))\n\n# Reta m√©dia\nplt.plot(x_seq, y_mean_seq, '#162be0', linewidth=2, label='Reta m√©dia (Œº)')\n\n# Plotar dados originais\nsns.scatterplot(data=df, x='calcado', y='altura', color='green', s=100, \n                label='Dados observados', zorder=5)\n\n# Plotar uma amostra das predi√ß√µes para novos pontos\nfor i, (calcado_val, cor) in enumerate(zip(calcado_pred, cores)):\n    x_sample = [calcado_val] * n_samples\n    y_sample = random.sample(list(pred_mu.posterior['mu'].values[:,:,i].flatten()), n_samples)\n    plt.scatter(x_sample, y_sample, color=cor, alpha=0.4, s=50, label=f'Predi√ß√µes cal√ßado n. {calcado_val}')\n\nplt.xlabel(\"N√∫mero do cal√ßado\")\nplt.ylabel(\"Altura (cm)\")\nplt.title(f\"Reta m√©dia e amostra de {n_samples} predi√ß√µes para cada valor de cal√ßado\")\nplt.legend(loc='lower right')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHistograma das novas predi√ß√µes\n\nplt.figure(figsize=(8, 5))\n\nfor i, (calcado_val, cor) in enumerate(zip(calcado_pred, cores)):\n    y_sample = random.sample(\n        list(pred_mu.posterior['mu'].values[:, :, i].flatten()), n_samples\n    )\n    sns.kdeplot(y_sample, color=cor, fill=True, alpha=0.3, linewidth=2,\n                label=f'Cal√ßado n. {calcado_val}')\n\nplt.xlabel(\"Altura prevista\")\nplt.ylabel(\"Densidade\")\nplt.title(\"Distribui√ß√µes de altura\\ndas novas predi√ß√µes por n√∫mero de cal√ßado\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nObserve que as m√©dias das predi√ß√µes para novas observa√ß√µes coincidem com a reta m√©dia estimada (\\(\\mu\\)), mas a variabilidade em torno dessas m√©dias √© maior. Isso ocorre porque essas predi√ß√µes incorporam tanto a incerteza epist√™mica, proveniente da estima√ß√£o dos par√¢metros do modelo, e a incerteza aleat√≥ria, associada √† variabilidade intr√≠nseca do processo (\\(\\sigma\\)).\n\n\n\n\n\n\nInterpreta√ß√£o dos tipos de predi√ß√£o bayesiana\n\n\n\nA abordagem bayesiana fornece uma caracteriza√ß√£o completa e hier√°rquica da incerteza preditiva: primeiro quantificando nossa incerteza sobre a rela√ß√£o m√©dia entre as vari√°veis, e depois expandindo essa an√°lise para incluir a variabilidade natural do fen√¥meno. Essa distin√ß√£o √© fundamental para decis√µes informadas, pois diferentes tipos de decis√£o podem requerer diferentes tipos de intervalo preditivo.\nIntervalo de Credibilidade (IC) para Œº: Representa nossa incerteza sobre o valor m√©dio esperado da altura para indiv√≠duos com um determinado n√∫mero de cal√ßado. Este intervalo reflete apenas a incerteza epist√™mica sobre os par√¢metros do modelo. √â mais estreito porque representa nossa incerteza sobre a linha m√©dia da rela√ß√£o.\nIntervalo de Predi√ß√£o (IP) para novas observa√ß√µes: Representa nossa incerteza sobre a altura de um novo indiv√≠duo espec√≠fico com um determinado n√∫mero de cal√ßado. Este intervalo √© sempre mais amplo pois incorpora tanto a incerteza epist√™mica (sobre os par√¢metros) quanto a incerteza aleat√≥ria (variabilidade natural representada por \\(\\sigma\\)).\nA raz√£o entre as larguras dos intervalos indica o quanto a variabilidade intr√≠nseca do processo contribui para a incerteza total. Valores maiores sugerem que a variabilidade natural dos dados (\\(\\sigma\\)) √© a principal fonte de incerteza nas predi√ß√µes, enquanto valores pr√≥ximos de 1 indicariam que a incerteza sobre os par√¢metros √© dominante. Essa raz√£o tamb√©m permite avaliar aspectos do delineamento experimental, pois a incerteza epist√™mica diminui √† medida que obtemos mais dados, aumentando nossa confian√ßa na posi√ß√£o da reta m√©dia. Por outro lado, a incerteza aleat√≥ria √© inerente ao processo gerador dos dados e n√£o √© afetada pelo tamanho da amostra, representando um limite irreduc√≠vel da precis√£o nas predi√ß√µes."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#estrutura-de-c√≥digo-bambi-vs-pymc",
    "href": "content/modelos-regressao-bayes/regressao-linear-bayesiana-bambi.html#estrutura-de-c√≥digo-bambi-vs-pymc",
    "title": "Fluxo de Trabalho na Modelagem Bayesiana",
    "section": "10 Estrutura de c√≥digo: Bambi vs PyMC",
    "text": "10 Estrutura de c√≥digo: Bambi vs PyMC\nNeste bloco, utilizamos a biblioteca Bambi como alternativa ao PyMC. Segue portanto uma compara√ß√£o entre as duas abordagens para a implementa√ß√£o de uma regress√£o linear bayesiana.\n\n\n\n\n\n\nQuando usar cada abordagem\n\n\n\nBambi: estrutura de c√≥digo\n\n# Bambi\nmodelo = bmb.Model(\"altura ~ calcado\", df, priors=priors)\nresultados = modelo.fit()\n\nQuando usar:\n\nDeseja implementar modelos estat√≠sticos padr√£o (regress√£o linear, GLMs, modelos hier√°rquicos)\nNecessita de rapidez de desenvolvimento e ajustes\n\nPyMC: estrutura de c√≥digo\n\n# PyMC - requer defini√ß√£o manual de todas as componentes\nwith pm.Model() as modelo:\n    # Priors\n    beta_0 = pm.Normal(\"beta_0\", mu=60, sigma=5)\n    beta_1 = pm.Normal(\"beta_1\", mu=2.8, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n    \n    # Verossimilhan√ßa\n    mu = beta_0 + beta_1 * X\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, observed=Y)\n    trace = pm.sample()\n\nQuando usar:\n\nNecessitar controle total sobre a especifica√ß√£o do modelo\nNecessita implementar modelos customizados ou muito complexos\nNecessita de funcionalidades espec√≠ficas n√£o dispon√≠veis no Bambi"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-prioris-e-posterioris",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-prioris-e-posterioris",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "O que aprendemos at√© aqui: prioris e posterioris",
    "text": "O que aprendemos at√© aqui: prioris e posterioris"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-distribui√ß√£o-normal-de-probabilidade",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-distribui√ß√£o-normal-de-probabilidade",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "O que aprendemos at√© aqui: distribui√ß√£o Normal de Probabilidade",
    "text": "O que aprendemos at√© aqui: distribui√ß√£o Normal de Probabilidade\n\\[\nf(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2} \\left(\\frac{y - \\mu}{\\sigma} \\right)^2} \\longrightarrow \\quad y \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-o-modelo-de-regress√£o-linear",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-o-modelo-de-regress√£o-linear",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "O que aprendemos at√© aqui: o modelo de Regress√£o linear",
    "text": "O que aprendemos at√© aqui: o modelo de Regress√£o linear\n\n\n\nVari√°vel aleat√≥ria resposta\n\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\n\\[\n\\mu = \\beta_0 + \\beta_1 x\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-programa√ß√£o-probabil√≠stica",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-programa√ß√£o-probabil√≠stica",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "O que aprendemos at√© aqui: Programa√ß√£o Probabil√≠stica",
    "text": "O que aprendemos at√© aqui: Programa√ß√£o Probabil√≠stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # Defini√ß√£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=60, sigma=5)\n    calcado = pm.Normal(\"calcado\", mu=2.8, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n    \n    # Defini√ß√£o do modelo\n    mu = beta_0 + beta_1 * X\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, \n                        observed=Y)\n    \n    # Amostra a distribui√ß√£o posterior\n    resultados = pm.sample()\n\n\nBambi\n\n# Defini√ß√£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=60, sigma=5),\n    \"calcado\": bmb.Prior(\"Normal\", mu=2.8, sigma=0.1),\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\n\n# Defini√ß√£o do modelo\nmodelo = bmb.Model(\"altura ~ calcado\", df, \n                    priors=custom_priors)\n\n# Amostra a distribui√ß√£o posterior\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-ajuste-da-posteriori",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#o-que-aprendemos-at√©-aqui-ajuste-da-posteriori",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "O que aprendemos at√© aqui: ajuste da posteriori",
    "text": "O que aprendemos at√© aqui: ajuste da posteriori"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#daqui-para-frente-uma-variedade-de-modelos-e-estruturas",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#daqui-para-frente-uma-variedade-de-modelos-e-estruturas",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Daqui para frente: uma variedade de modelos e estruturas",
    "text": "Daqui para frente: uma variedade de modelos e estruturas\n\nExten√ß√£o da Regress√£o Linear para:\n\nM√∫ltiplos preditores.\nDiferentes tipos de vari√°veis resposta (GLMs).\nDados com estrutura de agrupamento (Modelos Hier√°rquicos)."
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-linear-m√∫ltipla",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-linear-m√∫ltipla",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Regress√£o linear m√∫ltipla",
    "text": "Regress√£o linear m√∫ltipla\n\n\n\nVari√°vel aleat√≥ria resposta\n\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\n\\[\n\\mu = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_j \\sim \\mathcal{N}(\\mu_{\\beta_j}, \\sigma_{\\beta_j}) \\quad \\text{para } j = 1, \\dots, k\n\\]\n\\[\n\\sigma \\sim \\text{Lognormal}(\\mu_{\\log \\sigma}, \\sigma_{\\log \\sigma})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Programa√ß√£o Probabil√≠stica",
    "text": "Programa√ß√£o Probabil√≠stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # Defini√ß√£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=60, sigma=5)\n    beta_1 = pm.Normal(\"beta_1\", mu=2.8, sigma=0.1)\n    beta_2 = pm.Normal(\"beta_2\", mu=1.5, sigma=0.1)\n    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n\n    # Defini√ß√£o do modelo\n    mu = Intercept + beta_1 * X1 + beta_2 * X2\n    altura = pm.Normal(\"altura\", mu=mu, sigma=sigma, \n                       observed=Y)\n\n    # Amostra a distribui√ß√£o posterior\n    resultados = pm.sample()\n\n\nBambi\n\n# Defini√ß√£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=60, sigma=5),\n    \"X1\": bmb.Prior(\"Normal\", mu=2.8, sigma=0.1),\n    \"X2\": bmb.Prior(\"Normal\", mu=1.5, sigma=0.1),\n    \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)\n}\n\n# Defini√ß√£o do modelo\nmodelo = bmb.Model(\"altura ~ X1 + X2\", df, \n                   priors=custom_priors)\n\n# Amostra a distribui√ß√£o posterior\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-de-poisson-dados-de-contagem",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-de-poisson-dados-de-contagem",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Regress√£o de Poisson: dados de contagem",
    "text": "Regress√£o de Poisson: dados de contagem\n\n\n\\[\ny \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu = \\beta_0 + \\beta_1 x\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-de-poisson-dados-de-contagem-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-de-poisson-dados-de-contagem-1",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Regress√£o de Poisson: dados de contagem",
    "text": "Regress√£o de Poisson: dados de contagem\n\n\n\\[\nf(y) = \\frac{e^{-\\lambda} \\lambda^y}{y!} \\longrightarrow \\quad y \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu\n\\]\n\n\nVari√°vel aleat√≥ria resposta\n\n\\[\ny \\sim \\text{Poisson}(\\lambda)\n\\]\n\\[\n\\log(\\lambda) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\nPrioris\n\n\\[\n\\beta_0 \\sim \\mathcal{N}(\\mu_{\\beta_0}, \\sigma_{\\beta_0})\n\\]\n\\[\n\\beta_1 \\sim \\mathcal{N}(\\mu_{\\beta_1}, \\sigma_{\\beta_1})\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica-1",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Programa√ß√£o Probabil√≠stica",
    "text": "Programa√ß√£o Probabil√≠stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # Defini√ß√£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=0, sigma=5)\n    beta = pm.Normal(\"beta\", mu=0, sigma=2)\n    \n    # Fun√ß√£o de liga√ß√£o log: log(Œª) = Œº = Intercept + beta * X\n    mu = Intercept + beta * X\n    lambda_ = pm.math.exp(mu)\n    \n    # Modelo de verossimilhan√ßa\n    contagem = pm.Poisson(\"contagem\", mu=lambda_, \n                          observed=Y)\n    \n    # Amostragem\n    resultados = pm.sample()\n\n\nBambi\n\n# Defini√ß√£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n    \"x\": bmb.Prior(\"Normal\", mu=0, sigma=2),\n}\n\n# Modelo com fun√ß√£o de liga√ß√£o log (default da fam√≠lia Poisson)\nmodelo = bmb.Model(\"contagem ~ x\", df, \n                   family=\"poisson\", priors=custom_priors)\n\n# Amostragem\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-log√≠stica-dados-dicot√¥micos",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-log√≠stica-dados-dicot√¥micos",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Regress√£o Log√≠stica: dados dicot√¥micos",
    "text": "Regress√£o Log√≠stica: dados dicot√¥micos\n\n\n\\[\ny \\sim \\text{Bernoulli}(p)\n\\]\n\\[\n\\log\\left(\\frac{p}{1-p}\\right) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\\[\np = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}}\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-log√≠stica-dados-dicot√¥micos-1",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#regress√£o-log√≠stica-dados-dicot√¥micos-1",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Regress√£o Log√≠stica: dados dicot√¥micos",
    "text": "Regress√£o Log√≠stica: dados dicot√¥micos\n\n\n\nDistribui√ß√£o da vari√°vel resposta\n\n\\[\nf(y) = p^y (1 - p)^{1 - y}\n\\]\n\\[\ny \\sim \\text{Bernoulli}(p)\n\\]\n\nFun√ß√£o de liga√ß√£o\n\n\\[\n\\text{logit}(p) = \\mu = \\beta_0 + \\beta_1 x\n\\]\n\\[\n\\text{logit}(p) = \\log\\left(\\frac{p}{1 - p}\\right)\n\\]\n\\[\n\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 x\n\\]\n\n\\[\n\\frac{p}{1 - p} = e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = (1 - p) \\cdot e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = e^{\\beta_0 + \\beta_1 x} - p \\cdot e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np \\left(1 + e^{\\beta_0 + \\beta_1 x}\\right) = e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\np = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica-2",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#programa√ß√£o-probabil√≠stica-2",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Programa√ß√£o Probabil√≠stica",
    "text": "Programa√ß√£o Probabil√≠stica\n\n\n\nPyMC\n\nwith pm.Model() as modelo:\n    # Defini√ß√£o das prioris\n    Intercept = pm.Normal(\"Intercept\", mu=0, sigma=5)\n    beta = pm.Normal(\"beta\", mu=0, sigma=2)\n    \n    # Preditor linear e fun√ß√£o de liga√ß√£o logit\n    mu = Intercept + beta * X\n    p = pm.math.sigmoid(mu)\n    \n    # Verossimilhan√ßa\n    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=Y)\n    \n    # Amostragem\n    resultados = pm.sample()\n\n\nBambi\n\n# Defini√ß√£o das prioris\ncustom_priors = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n    \"x\": bmb.Prior(\"Normal\", mu=0, sigma=2),\n}\n\n# Modelo log√≠stico (liga√ß√£o logit √© padr√£o para bernoulli)\nmodelo = bmb.Model(\"y ~ x\", df, \n                   family=\"bernoulli\", priors=custom_priors)\n\n# Amostragem\nresultados = modelo.fit()"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#modelo-hier√°rquico-normal-com-intercepto-e-inclina√ß√£o-variaveis",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#modelo-hier√°rquico-normal-com-intercepto-e-inclina√ß√£o-variaveis",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Modelo Hier√°rquico Normal com Intercepto e Inclina√ß√£o VariaÃÅveis",
    "text": "Modelo Hier√°rquico Normal com Intercepto e Inclina√ß√£o VariaÃÅveis\n\n\n\\[\ny_{ij} \\sim \\mathcal{N}(\\mu_{ij}, \\sigma^2)\n\\]\n\\[\n\\mu_{ij} = \\beta_{0j} + \\beta_{1j} x_{ij}\n\\]\n\\[\n\\beta_{0j} \\sim \\mathcal{N}(\\gamma_0, \\tau_0^2) \\\\\n\\beta_{1j} \\sim \\mathcal{N}(\\gamma_1, \\tau_1^2)\n\\]"
  },
  {
    "objectID": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#varia√ß√£o-entre-grupos-coeficientes-do-modelo-hier√°rquico",
    "href": "content/modelos-regressao-bayes/regressao-glm-hierarquico-apresentacao.html#varia√ß√£o-entre-grupos-coeficientes-do-modelo-hier√°rquico",
    "title": "Explorando Modelos de Regress√£o Bayesiana",
    "section": "Varia√ß√£o entre grupos: coeficientes do modelo hier√°rquico",
    "text": "Varia√ß√£o entre grupos: coeficientes do modelo hier√°rquico\n\n\nCoeficientes espec√≠ficos por grupo:\n\\[\n\\beta_{0j} \\sim \\mathcal{N}(\\gamma_0, \\tau_0^2) \\\\\n\\beta_{1j} \\sim \\mathcal{N}(\\gamma_1, \\tau_1^2)\n\\]\nVisualizando a dispers√£o dos par√¢metros em rela√ß√£o √†s m√©dias populacionais \\(\\gamma_0, \\gamma_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstituto do Mar - Unifesp ¬∑ M√©todos em Estat√≠stica e An√°lise de Dados"
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html",
    "href": "content/amostragem/tipos-amostragem.html",
    "title": "Amostrando uma popula√ß√£o estat√≠stica",
    "section": "",
    "text": "Pacotes, fun√ß√µes e base de dados utilizadas no cap√≠tulo\n\n\n\n\n\nPacotes:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\nlibrary(knitr)\nO objetivo da amostragem √© descrever caracter√≠sticas da popula√ß√£o estat√≠stica por meio de caracter√≠sticas da amostra. Por exemplo, em um estudo sobre o tamanho do pescado em uma √°rea de pesca, a popula√ß√£o estat√≠stica s√£o os comprimentos de todos os peixes que podem ser pescados na regi√£o. A popula√ß√£o estat√≠stica pode ser descrita por par√¢metros que representam medidas de centro como o comprimento m√©dio (\\(\\mu\\)), ou por medidas de varia√ß√£o como o desvio padr√£o (\\(\\sigma\\)), que representam o grau de dispers√£o das unidades amostrais ao redor da m√©dia. Se amostramos n elementos desta popula√ß√£o, a m√©dia amostral (\\(\\overline{X}\\)) e o desvio padr√£o amostral (\\(s\\)) dos di√¢metros ser√£o os estimadores destas caracter√≠sticas.\nDependendo da quest√£o envolvida e do conhecimento pr√©vio sobre a popula√ß√£o, diferentes m√©todos de amostragem s√£o apropriados. A teoria da amostragem √© a √°rea da ci√™ncia que estuda estes m√©todos. Neste cap√≠tulo vamos discutir tr√™s tipos de amostragem: aleat√≥ria simples, estratificada e sistem√°tica."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-aleat√≥ria-simples",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-aleat√≥ria-simples",
    "title": "Amostrando uma popula√ß√£o estat√≠stica",
    "section": "1 Amostragem aleat√≥ria simples",
    "text": "1 Amostragem aleat√≥ria simples\n√â aquela em que cada elemento da popula√ß√£o tem a mesma probabilidade de ser selecionado para compor a amostra. Se a popula√ß√£o consiste de \\(1000\\) elementos, cada um ter√° uma probabilidade de \\(\\frac{1}{1000}\\) de ser escolhido. Isto isenta o pesquisador de tomar qualquer decis√£o com base em julgamentos pr√©-concebidos, sobre quais elementos devem ou n√£o compor a amostra.\n\n\nC√≥digo\nset.seed(1)\npop = c(3, 10, 14, 19, 27, 28, 29, 41, 42, 43)\nN = length(pop)\nAm1 = sort(pop)[1:5]\nset.seed(2)\nAm2 = sample(pop, size = 5, replace = F)\n\n\nSuponha uma popula√ß√£o hipot√©tica de somente \\(10\\) elementos:\nPopula√ß√£o: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nEm uma amostra aleat√≥ria simples de cinco elementos, qualquer combina√ß√£o destes \\(10\\) elementos √© igualmente prov√°vel. Se por puro acaso sortearmos uma amostra aleat√≥ria contendo os cinco menores valores da popula√ß√£o:\nAmostra 1: 3, 10, 14, 19, 27\nA amostra seria t√£o aleat√≥ria e v√°lida do ponto de vista estat√≠stico quanto qualquer outra como:\nAmostra 2: 27, 28, 42, 3, 43\nIsto significa que uma amostra aleat√≥ria pode n√£o ser necessariamente representativa da popula√ß√£o. Amostras pequenas por exemplo, t√™m uma chance maior de selecionar apenas valores extremos, ou seja, os maiores ou menores elementos da popula√ß√£o. A m√©dia amostral (\\(\\overline{X}\\)) calculada para estas amostras estar√° distante da m√©dia populacional (\\(\\mu\\)). No entanto, a import√¢ncia central da amostragem aleat√≥ria em estat√≠stica est√° no fato de que a aleatoriedade produz, em m√©dia, amostras representativas da popula√ß√£o. Deste modo, √© esperado que na maioria das vezes, uma amostra aleat√≥ria gere m√©dias amostrais pr√≥ximas √† m√©dia populacional. Por este motivo, √© fundamental prezar pela aleatoriedade no processo amostral, pois de outro modo n√£o poderemos garantir que a infer√™ncia seja v√°lida com base nas leis de probabilidade.\nO modo mais direto de se obter uma amostra aleat√≥ria √© por meio de sorteio. Ap√≥s atribuir n√∫meros de 1 a \\(N\\) a cada unidade amostral, estas unidades s√£o sorteadas at√© que seja atingido o tamanho \\(n\\) desejado. Na pr√°tica, nem sempre √© simples, ou mesmo poss√≠vel obter uma amostra aleat√≥ria nestes moldes. N√£o seria poss√≠vel enumerar todos os peixes de uma regi√£o para, ap√≥s um sorteio, tomar as medidas somente dequeles selecionados. Entretanto, se empregarmos m√©todos de captura em que indiv√≠duos de todos os tamanhos sejam igualmente sujeitos a serem capturados poder√≠amos no aproximar do que seria uma amostra verdsadeiramente aleat√≥ria. Outras dificuldades pr√°ticas surgiriam neste estudo como por exemplo: garantir acesso irrestrito √† toda a √°rea de ocorr√™ncia da esp√©cie, tempo dispon√≠vel para percorrer a toda regi√£o. Quest√µes como estas n√£o desmerecem o requisito b√°sico de se obter uma amostra aleat√≥ria, mas devem nos auxiliar a decidir como conciliar a pr√°tica experimental com a necessidade de garantirmos uma amostra aleat√≥ria."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-aleat√≥ria-estratificada",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-aleat√≥ria-estratificada",
    "title": "Amostrando uma popula√ß√£o estat√≠stica",
    "section": "2 Amostragem aleat√≥ria estratificada",
    "text": "2 Amostragem aleat√≥ria estratificada\nSe tivermos algum conhecimento pr√©vio de como a popula√ß√£o est√° estruturada, a amostra aleat√≥ria simples, embora n√£o esteja incorreta, pode n√£o ser a estrat√©gia mais eficiente do ponto de vista estat√≠stico. Se for possivel identificar estratos ou subgrupos dentro da popula√ß√£o, podemos conduzir uma amostragem aleat√≥ria estatificada.\nVoltemos ao exemplo do comprimento do pescado. Suponha que existam duas √°reas de ocorr√™ncia da esp√©cie. Uma delas sujeita a intensa atividade pesqueira e outra sendo uma √°rea protegida. Poder√≠amos supor que na √°rea protegida estejam os maiores indiv√≠duos, justamente porque nesta √°rea n√£o h√° atividade de pesca (que em geral busca indiv√≠duos maiores). Dizemos que os comprimentos em cada uma das duas regi√µes comp√µem estratos da popula√ß√£o estat√≠stica.\nNesta situa√ß√£o, uma amostra puramente aleat√≥ria sem considerar a exist√™ncia dos dois estratos pode fazer com que, puramente ao acaso, um deles se torne mais representados na amostra. Se por exemplo da maioria dos pontos selecionados estiverem na regi√£o intensamente pescada, o comprimento m√©dio da amostra (\\(\\overline{X}\\)) tender√° a ficar consistentemente abaixo de \\(\\mu\\). A chance disto ocorrer se torna maior principalmente se o tamanho amostral for pequeno.\nEntretanto, se a sele√ß√£o dos indiv√≠duos foi feita por meio de sorteio, o simples fato de observarmos este padr√£o n√£o seria por si s√≥ justificativa para refarzermos a amostra. O ponto relevante aqui √© que em uma amostra aleat√≥ria simples, estes extremos indesej√°veis (um estrato mais representado que outro) s√£o mais prov√°veis de acontecer.\nSe temos conhecimento da exist√™ncia dos dois estratos portanto, a amostragem aleat√≥ria estratificada seria a mais indicada. Neste tipo de amostragem, o esfor√ßo amostral √© subdividido entre os estratos. O tamanho amostral em cada estrato ser√° o mesmo, ou proporcional ao seu tamanho. Uma vez definirmos os tamanhos amostrais que ser√° aplicado aos estratos, as unidades s√£o selecionadas por meio de uma amostragem aleat√≥ria simples em cada um.\nA amostragem aleat√≥ria estratificada garante que todos os estratos estejam presentes na amostra conforme sua representatividade na popula√ß√£o. Ao fazer isto, as estimativas da amostra tender√£o a se concentrar mais pr√≥ximas ao par√¢metro da popula√ß√£o. Deste modo, quando os estratos s√£o identificados corretamente, a principal vantagem da amostra aleat√≥ria estratificada sobre a amostra aleat√≥ria simples est√° em aumentar a precis√£o das estimativas. Mais a frente iremos discutir os conceitos de precis√£o e acur√°cia e relacion√°-los com as estrat√©gias amostrais discutidas aqui."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#amostragem-sistem√°tica",
    "href": "content/amostragem/tipos-amostragem.html#amostragem-sistem√°tica",
    "title": "Amostrando uma popula√ß√£o estat√≠stica",
    "section": "3 Amostragem sistem√°tica",
    "text": "3 Amostragem sistem√°tica\nEm uma amostragem sistem√°tica o pesquisador escolhe um elemento inicial e toma medidas a cada \\(k\\) ocorr√™ncias, seguindo a ordem de observa√ß√£o. No caso do comprimento de pescado, para facilitar a tomada de dados, o pesquisador pode medir o primeiro peixe coletado e, em seguida, medir os peixes em intervalos regulares, por exemplo a cada \\(10\\) observados.\nA escolha da amostragem sistem√°tica ao inv√©s de uma amostragem aleat√≥ria simples, deve-se √† sua praticidade. Se a caracter√≠stica de interesse das unidades amostrais estiver disposta de forma aleat√≥ria ao longo da sequ√™ncia escolhida, a amostragem aleat√≥ria e sistem√°tica ir√£o gerar resultados similares. Na maioria dos casos, √© isto que o pesquisador assume (ainda que implicitamente) quando opta por uma amostragem sistem√°tica."
  },
  {
    "objectID": "content/amostragem/tipos-amostragem.html#erro-amostral-acur√°cia-e-precis√£o",
    "href": "content/amostragem/tipos-amostragem.html#erro-amostral-acur√°cia-e-precis√£o",
    "title": "Amostrando uma popula√ß√£o estat√≠stica",
    "section": "4 Erro amostral, acur√°cia e precis√£o",
    "text": "4 Erro amostral, acur√°cia e precis√£o\nComo as estimativas s√£o obtidas de um subconjunto da popula√ß√£o (a amostra), √© regra que o resultado obtido de uma amostra aleat√≥ria particular, n√£o ser√° igual ao verdadeiro valor da popula√ß√£o (o par√¢metro), embora exista uma grande probabilidade estar pr√≥ximo.\n\nErro amostral: √© a diferen√ßa entre uma estimativa em particular e o par√¢metro na popula√ß√£o e portanto, √© inerente √† variabilidade do processo de amostragem. Suponha que, puramente ao acaso, a amostra inclua os menores elementos da popula√ß√£o. A m√©dia amostral (\\(\\overline{X}\\)) estar√° muito abaixo da m√©dia populacional (\\(\\mu\\)) e o erro amostral ser√° grande. Se calcularmos a m√©dia (\\(\\overline{X}\\)) de uma amostra particular, o erro amostral ser√° dado por:\n\n\\[E = \\overline{X} - \\mu\\]\nA estat√≠stica estuda o comportamento probabil√≠stico dos erros amostrais. Existe tamb√©m o erro n√£o amostral que decorre de equ√≠vocos de amostragem, inexperi√™ncia do amostrador, falha de equipamentos, enganos no c√¥mputo dos resultados, etc. A estat√≠stica n√£o lida com este tipo de erro.\n\nAcur√°cia: se refere √† proximidade entre o par√¢metro e o estimador. Um estimador acurado √©, em m√©dia, igual ao par√¢metro populacional. Diferente do erro amostral, a acur√°cia n√£o se refere a uma estimativa em particular, mas ao valor esperado do estimador, caso a amostragem fosse repetida um grande n√∫mero de vezes. Um estimador n√£o-acurado (viciado) resulta em valores consistentemente diferentes do par√¢metro, podendo estar acima (vi√©s positivo) ou abaixo (vi√©s negativo) do valor populacional. A m√©dia aritm√©tica amostral (\\(\\overline{X}\\)) √© um estimador n√£o-viciado da m√©dia populacional (\\(\\mu\\)) pois:\n\n\\[\\mu_{\\overline{X}} = \\mu\\]\n\nPrecis√£o: tem rela√ß√£o com a variabilidade do estimador. Estimadores que geram estimativas similares entre si s√£o mais precisos. Por√©m, se as estimativas estiverem distantes de sua m√©dia, o estimador √© dito pouco preciso. Exemplo: Para uma popula√ß√£o normalmente distribu√≠da, tanto a m√©dia aritm√©tica quanto a mediana s√£o estimadores acurados. Entretanto, a vari√¢ncia da mediana √© maior que da m√©dia aritm√©tica. Dizemos portanto, que a m√©dia aritm√©tica √© um estimador mais preciso que a mediana. A precis√£o de um estimador √© medida pelo erro padr√£o da m√©dia.\n\n\\[\\sigma_{\\overline{X}} =\\frac{\\sigma}{\\sqrt{n}}\\]\nA figura abaixo √© comnmente utilizada para representar os conceitos de preci√ß√£o e acur√°cia. O centro do alvo √© o valor do par√¢metro populacional e os pontos em preto s√£o as estimativas. Estimadores acurados geram, em m√©dia, estimativas ao redor do par√¢metro populacional (vi√©s \\(= 0\\)). Estimadores n√£o-acurados geram, em m√©dia, valores deslocados do par√¢metro populacional (vi√©s \\(\\ne 0\\)). Estimadores precisos resultam sempre em estimativas pr√≥ximas entre si, enquanto estimadores n√£o precisos resultam em estimativas distantes umas das outras.\n\n\n\n\n\n\nFigura¬†1: Representa√ß√£o dos conceitos de precis√£o e acur√°cia.\n\n\n\n\n4.1 Erro amostral\nVoltemos √† nossa popula√ß√£o fict√≠cia com \\(N = 10\\) elementos:\nPopula√ß√£o: 3, 10, 14, 19, 27, 28, 29, 41, 42, 43\nPara esta popula√ß√£o em particular n√≥s conhecemos a m√©dia populacional (\\(\\mu\\) = 25.6), de modo que ser√° poss√≠vel compar√°-la com as estimativas amostrais.\n\n\nC√≥digo\nset.seed(4)\nn = 5\nAm1 = sample(pop, size = n, replace = F)\nsomaAm1 = paste(Am1, collapse = \"+\")\nmp = round(mean(pop),1)\nmAm1 = round(mean(Am1),1)\nE1 = mAm1 - mp\n\n\nVamos tomar uma amostra aleat√≥ria de tamanho \\(n = 5\\):\nAmostra 1: \\(41, 14, 42, 29, 19\\)\nPara esta amostra, a m√©dia vale: \\(\\overline{X} =\\frac{41+14+42+29+19}{5} = 29\\).\nOs valores \\(\\mu = 25.6\\) e \\(\\overline{X} = 29\\) n√£o s√£o id√™nticos, pois a amostra cont√©m somente alguns elementos da popula√ß√£o. A diferen√ßa entre \\(\\mu\\) e \\(\\overline{X}\\) √© o chamamos de erro amostral.\nNeste caso, o erro amostral √©:\nErro amostral 1: \\(E_1 = 29  -  25.6  =  3.4\\)\nSe tomarmos outra amostra aleat√≥ria, teremos outro conjunto de unidades amostrais, e consequentemente, um \\(\\overline{X}\\) e um erro amostral diferentes. Por exemplo:\n\n\nC√≥digo\nset.seed(3)\nn = 5\nAm2 = sample(pop, size = n, replace = F)\nmAm2 = round(mean(Am2),1)\nE2 = mAm2 - mp\n\n\nAmostra 2: \\(27, 29, 19, 10, 14\\)\nM√©dia amostral 2: \\(\\overline{X_2} = 19.8\\)\nErro amostral 2: \\(E_2 = 19.8  -  25.6  =  -5.8\\)\n\n\n4.2 Acur√°cia\n\n\nC√≥digo\nN = length(pop)\nn = 5\nCT = choose(N,n)\n\n\nAt√© agora, analisamos duas amostras diferentes da popula√ß√£o. Por√©m, quantas amostras distintas seriam poss√≠veis? Para uma amostragem sem reposi√ß√£o, a teoria combinat√≥ria nos diz que s√£o poss√≠veis:\n\\[{{10}\\choose{5}} = \\frac{10!}{(10-5)! \\times 5!} = 252\\]\nformas diferentes de combinarmos \\(N = 10\\) elementos em amostras de tamanho \\(n = 5\\).\n\n\nC√≥digo\nset.seed(8)\nR = 8\nA15 = replicate(n = R, sample(pop, size = n, replace = F))\ncolnames(A15) = paste(\"A\", 1:ncol(A15), sep = \"\")\nMedias = round(apply(A15, 2, mean),2)\n\n\nInicialmente vamos avaliar a quest√£o com um n√∫mero menor. Sejam por exemplo, 8 amostras tomadas aleatoriamente, gerando os resultados a seguir:\n\n\nC√≥digo\nA15 |&gt; \n  as.data.frame() |&gt; \n  add_column('Obs' = rep('', times = nrow(A15)), .before = 'A1') |&gt; \n  rbind(Obs = c('M√©dias', Medias)) |&gt; \n  gt() |&gt; \n  tab_style(\n    style = list(cell_fill(color = \"lightblue\")),\n    locations = cells_body(\n      rows = Obs == \"M√©dias\"\n    )\n  ) |&gt; \n  cols_width(\n    everything() ~ px(150)\n  )\n\n\n\n\nTabela¬†1: Oito amostras de tamanho n = 5 da popula√ß√£o estat√≠stica.\n\n\n\n\n\n\n\n\n\nObs\nA1\nA2\nA3\nA4\nA5\nA6\nA7\nA8\n\n\n\n\n\n19\n29\n10\n19\n42\n29\n28\n43\n\n\n\n29\n43\n14\n41\n29\n10\n42\n28\n\n\n\n10\n28\n42\n43\n41\n27\n10\n42\n\n\n\n42\n3\n28\n28\n14\n42\n43\n27\n\n\n\n43\n27\n29\n3\n28\n43\n27\n19\n\n\nM√©dias\n28.6\n26\n24.6\n26.8\n30.8\n30.2\n30\n31.8\n\n\n\n\n\n\n\n\n\n\nCada coluna desta matriz corresponde a uma poss√≠vel amostra aleat√≥ria e suas respectivas m√©dias.\nAlgumas amostras tiveram m√©dias muito distantes de \\(\\mu\\), como: \\(\\overline{X_{A8}} = 31.8\\) ou \\(\\overline{X_{A3}} = 24.6\\). Esta varia√ß√£o √© natural do processo amostral. Os m√©todos de amostragem e de infer√™ncia estat√≠stica tratam justamente de como interpretar e como lidar com esta varia√ß√£o. Para entender melhor este processo, vamos obter todas as 252 combina√ß√µes poss√≠veis de amostras com \\(n = 5\\) e, em seguida, extrair suas respectivas m√©dias.\nOs resultados das 252 m√©dias poss√≠veis podem ser vistos a seguir ordenados da menor para a maior m√©dia poss√≠vel:\n\n\nC√≥digo\nAllcomb = combn(x = pop, m = 5)\nM_Allcomb = apply(Allcomb,2,mean)\nM_Allcomb_round = round(M_Allcomb,1)\nknitr::kable(matrix(M_Allcomb_round,nc = 14, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.6\n14.8\n15.0\n17.4\n17.6\n17.8\n16.4\n16.6\n19.0\n19.2\n19.4\n16.8\n19.2\n19.4\n\n\n19.6\n19.4\n19.6\n19.8\n22.0\n22.2\n22.4\n17.4\n17.6\n20.0\n20.2\n20.4\n17.8\n20.2\n\n\n20.4\n20.6\n20.4\n20.6\n20.8\n23.0\n23.2\n23.4\n19.4\n21.8\n22.0\n22.2\n22.0\n22.2\n\n\n22.4\n24.6\n24.8\n25.0\n22.2\n22.4\n22.6\n24.8\n25.0\n25.2\n25.0\n25.2\n25.4\n27.8\n\n\n18.2\n18.4\n20.8\n21.0\n21.2\n18.6\n21.0\n21.2\n21.4\n21.2\n21.4\n21.6\n23.8\n24.0\n\n\n24.2\n20.2\n22.6\n22.8\n23.0\n22.8\n23.0\n23.2\n25.4\n25.6\n25.8\n23.0\n23.2\n23.4\n\n\n25.6\n25.8\n26.0\n25.8\n26.0\n26.2\n28.6\n21.2\n23.6\n23.8\n24.0\n23.8\n24.0\n24.2\n\n\n26.4\n26.6\n26.8\n24.0\n24.2\n24.4\n26.6\n26.8\n27.0\n26.8\n27.0\n27.2\n29.6\n25.6\n\n\n25.8\n26.0\n28.2\n28.4\n28.6\n28.4\n28.6\n28.8\n31.2\n28.6\n28.8\n29.0\n31.4\n31.6\n\n\n19.6\n19.8\n22.2\n22.4\n22.6\n20.0\n22.4\n22.6\n22.8\n22.6\n22.8\n23.0\n25.2\n25.4\n\n\n25.6\n21.6\n24.0\n24.2\n24.4\n24.2\n24.4\n24.6\n26.8\n27.0\n27.2\n24.4\n24.6\n24.8\n\n\n27.0\n27.2\n27.4\n27.2\n27.4\n27.6\n30.0\n22.6\n25.0\n25.2\n25.4\n25.2\n25.4\n25.6\n\n\n27.8\n28.0\n28.2\n25.4\n25.6\n25.8\n28.0\n28.2\n28.4\n28.2\n28.4\n28.6\n31.0\n27.0\n\n\n27.2\n27.4\n29.6\n29.8\n30.0\n29.8\n30.0\n30.2\n32.6\n30.0\n30.2\n30.4\n32.8\n33.0\n\n\n23.4\n25.8\n26.0\n26.2\n26.0\n26.2\n26.4\n28.6\n28.8\n29.0\n26.2\n26.4\n26.6\n28.8\n\n\n29.0\n29.2\n29.0\n29.2\n29.4\n31.8\n27.8\n28.0\n28.2\n30.4\n30.6\n30.8\n30.6\n30.8\n\n\n31.0\n33.4\n30.8\n31.0\n31.2\n33.6\n33.8\n28.8\n29.0\n29.2\n31.4\n31.6\n31.8\n31.6\n\n\n31.8\n32.0\n34.4\n31.8\n32.0\n32.2\n34.6\n34.8\n33.4\n33.6\n33.8\n36.2\n36.4\n36.6\n\n\n\n\n\nA menor e maior m√©dias poss√≠veis s√£o 14.6 e 36.6 respectivamente. Estes valores s√£o os mais distantes do par√¢metro populacional (\\(\\mu = 25.6\\)) e ocorrem puramente ao acaso quanto s√£o amostrados os 5 menores (3, 10, 14, 19, 27) ou os 5 maiores (43, 42, 41, 29, 28) elementos da popula√ß√£o estat√≠stica. Estes casos extremos s√£o raros. Em nosso exemplo, valores superiores a 33.8 ou inferiores a 17.4 s√£o muito improv√°veis.\nPodemos avaliar graficamente a distribui√ß√£o das m√©dias amostrais atrav√©s de um histograma. A grande maioria das m√©dias amostrais concentra-se na por√ß√£o intermedi√°ria do gr√°fico entre estes limites. Por exemplo, somente 3.2% das observa√ß√µes est√£o acima de 33.8. Da mesma forma, somente 3.2% das observa√ß√µes est√£o abaixo de 17.4\n\n\nC√≥digo\nM_Allcomb_df = data.frame(M = as.numeric(M_Allcomb))\n\ngp5 &lt;- ggplot(M_Allcomb_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"M√©dias\",\n       y = \"Frequ√™ncia\") +\n  theme_classic()\n\ngp5\n\n\n\n\n\n\n\n\nFigura¬†2: Histograma das 252 m√©dias amostrais obtidas a partis de amostras de tamanho n = 5.\n\n\n\n\n\nSe calcularmos a m√©dia das m√©dias (\\(\\mu_{\\overline{X}}\\)), ou seja, somarmos todos estes valores e dividirmos por 252, o resultado ser√° 25.6, que √© exatamente o valor da m√©dia populacional \\(\\mu\\). Isto t√™m uma implica√ß√£o central em infer√™ncia estat√≠stica. Significa que a m√©dia amostral \\(\\overline{X}\\) √© um estimador acurado (= n√£o-viciado), pois tende a estimar corretamente o valor da m√©dia populacional \\(\\mu\\). Ou seja, o histograma acima est√° centrado ao redor de \\(\\mu\\), o que significa que em m√©dia uma amostra particular tem maior probabilidade de expressar um \\(\\overline{X}\\) pr√≥ximo ao valor populacional.\n\n\n4.3 Precis√£o: o erro padr√£o da m√©dia (\\(\\sigma_{\\overline{X}}\\))\n\n\nC√≥digo\nn2 = 7\nAllcomb7 = combn(x = pop, m = n2)\nM_Allcomb7 = apply(Allcomb7,2,mean)\nM_Allcomb7_round = round(M_Allcomb7,1)\nCT2 = choose(N,n2)\n\n\nSuponha agora que tomemos ao acaso amostras com \\(n = 7\\) desta mesma popula√ß√£o. Existem ao todo:\n\\[{{10}\\choose{7}} = \\frac{10!}{(10-7)! \\times 7!} = 120\\]\namostras diferentes de tamanho \\(n = 7\\) que podem ser retiradas de uma popula√ß√£o de tamanho \\(n = 10\\). Se tomarmos estas 120 amostras e calcularmos suas respectivas m√©dias amostrais, teremos os resultados abaixo:\n\n\nC√≥digo\nknitr::kable(matrix(M_Allcomb7_round,nc = 12, byrow = T))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n18.6\n20.3\n20.4\n20.6\n20.4\n20.6\n20.7\n22.3\n22.4\n22.6\n20.6\n20.7\n\n\n20.9\n22.4\n22.6\n22.7\n22.6\n22.7\n22.9\n24.6\n21.7\n21.9\n22.0\n23.6\n\n\n23.7\n23.9\n23.7\n23.9\n24.0\n25.7\n23.9\n24.0\n24.1\n25.9\n26.0\n22.4\n\n\n22.6\n22.7\n24.3\n24.4\n24.6\n24.4\n24.6\n24.7\n26.4\n24.6\n24.7\n24.9\n\n\n26.6\n26.7\n25.7\n25.9\n26.0\n27.7\n27.9\n28.0\n23.0\n23.1\n23.3\n24.9\n\n\n25.0\n25.1\n25.0\n25.1\n25.3\n27.0\n25.1\n25.3\n25.4\n27.1\n27.3\n26.3\n\n\n26.4\n26.6\n28.3\n28.4\n28.6\n27.0\n27.1\n27.3\n29.0\n29.1\n29.3\n30.4\n\n\n24.0\n24.1\n24.3\n25.9\n26.0\n26.1\n26.0\n26.1\n26.3\n28.0\n26.1\n26.3\n\n\n26.4\n28.1\n28.3\n27.3\n27.4\n27.6\n29.3\n29.4\n29.6\n28.0\n28.1\n28.3\n\n\n30.0\n30.1\n30.3\n31.4\n28.6\n28.7\n28.9\n30.6\n30.7\n30.9\n32.0\n32.7\n\n\n\n\n\n\n\nC√≥digo\nM_Allcomb7_df = data.frame(M = as.numeric(M_Allcomb7))\n\ngp7 &lt;- ggplot(M_Allcomb7_df, aes(x = M)) +\n  geom_histogram(fill = 'brown3', color = 'black', bins = 10) +\n  scale_x_continuous(breaks = seq(0, 50, by = 5)) +\n  coord_cartesian(xlim = c(10, 40)) +\n  labs(x = \"M√©dia\",\n       y = \"Frequ√™ncia\") +\n  theme_classic()\n\ngp7\n\n\n\n\n\n\n\n\nFigura¬†3: Histograma das 120 m√©dias amostrais obtidas a partis de amostras de tamanho n = 7\n\n\n\n\n\n\n\nC√≥digo\nmu_pop = mean(pop)\nN = length(pop)\nvar_pop = mean((pop - mu_pop)^2)\nsigma_pop = sqrt(var_pop)\n\nep5 = sigma_pop/sqrt(n)\nep7 = sigma_pop/sqrt(n2)\n\n\nSe compararmos os histogramas com \\(n = 5\\) e \\(n = 7\\) (Figura¬†2 e Figura¬†3), veremos que os dois resultam em estimadores acurados, pois \\(\\mu_{\\overline{X}} = \\mu\\). No entando, o intervalo de varia√ß√£o √© menor para amostras de tamanho \\(n = 7\\). Para esta figura, os valores est√£o mais concentrados ao redor da m√©dia. Portanto, √† medida que aumenta o tamanho amostral, diminui a dispers√£o das m√©dias amostrais ao redor de \\(\\mu\\). Assim, para amostras grandes torna-se mais improv√°vel obter uma m√©dia amostral distante da m√©dia populacional. Dizemos ent√£o que conforme aumenta o tamanho amostral, conseguimos estimativas mais precisas.\nA precis√£o de um estimador pode ser medida pelo Erro padr√£o da m√©dia (\\(\\sigma_{\\overline{X}}\\)) que pode ser calculado por:\n\\[\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\]\nO erro padr√£o da m√©dia √© o desvio padr√£o de todas as m√©dias amostrais que poderiam ser obtidas de uma amostra com tamanho \\(n\\). Para nosso exemplo com \\(n = 5\\), \\(\\sigma_{\\overline{X}}\\) = 5.93, enquanto para \\(n = 7\\), \\(\\sigma_{\\overline{X}}\\) = 5.01. Dizemos que o √∫ltimo exemplo fornece estimativas mais precisas.\n\n\n\n\n\n\nErro padr√£o amostral\n\n\n\nNa pr√°tica cient√≠fica n√£o conhecemos o desvio padr√£o populacional \\(\\sigma\\) e, consequentemente, n√£o temos obter o erro padr√£o populacional \\(\\sigma_{\\overline{X}}\\). No entanto, dado que temos uma amostra particular, podemos estim√°-lo a partir do desvio padr√£o amostral \\(\\sigma_{\\overline{X}}\\) pela express√£o:\n\\[s_{\\overline{X}} = \\frac{s}{\\sqrt{n}}\\]\nem que \\(s_{\\overline{X}}\\) √© denominado de erro padr√£o amostral\n\n\n\n\n\n\n\n\n\nV√≠deo-aulas"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html",
    "title": "Construindo um modelo bayesiano",
    "section": "",
    "text": "Considere um globo representando o planeta Terra, pequeno o suficiente para caber em suas m√£os. Seu objetivo √© estimar a fra√ß√£o da superf√≠cie coberta por √°gua. Para isso, voc√™ adota a seguinte estrat√©gia: joga o globo para cima girando e, ao peg√°-lo, registra se o ponto tocado pelo seu dedo indicador direito √© √°gua (üåä) ou terra (üèúÔ∏è). Voc√™ repete esse procedimento algumas vezes, obtendo uma sequ√™ncia de \\(n\\) observa√ß√µes.\nVoc√™ faz quatro lan√ßamentos do globo e conta quantos deles resultam em √°gua. Um poss√≠vel resultado seria \\(üåäüåäüèúÔ∏èüåä\\), totalizando 3 observa√ß√µes de √°gua e 1 de terra. Outro resultado poss√≠vel √© \\(üèúÔ∏èüèúÔ∏èüåäüåä\\), com 2 observa√ß√µes de √°gua e 2 de terra. Para \\(n = 4\\) observa√ß√µes, existem 16 resultados poss√≠veis (Tabela¬†1).\nObserve que apenas um dos resultados cont√©m 4 observa√ß√µes de terra e somente um cont√©m 4 observa√ß√µes de √°gua. Os demais s√£o varia√ß√µes entre esses extremos.\nPodemos reorganizar a tabela para evidenciar todas as combina√ß√µes que levam ao mesmo n√∫mero \\(y_i\\) de pontos em √°gua:\nDefina \\(p\\) como a probabilidade de observar √°gua e \\(1 - p\\) como a probabilidade de observar terra ap√≥s cada lan√ßamento do globo.\nA √∫ltima linha da Tabela¬†2 (üåäüåäüåäüåä) tem probabilidade: \\[P(4) = p \\times p \\times p \\times p.\\]\nEnquanto a primeira linha (üèúÔ∏èüèúÔ∏èüèúÔ∏èüèúÔ∏è) ocorre com probabilidade: \\[P(0) = (1 - p) \\times (1 - p) \\times (1 - p) \\times (1 - p).\\]\nAs linhas correspondentes a \\(P(1)\\), \\(P(2)\\) e \\(P(3)\\) s√£o combina√ß√µes de \\(p\\) e \\((1 - p)\\), multiplicadas pelo n√∫mero de formas pelas quais 1, 2 ou 3 registros de √°gua podem ocorrer em 4 lan√ßamentos."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#o-modelo-binomial",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#o-modelo-binomial",
    "title": "Construindo um modelo bayesiano",
    "section": "1 O modelo Binomial",
    "text": "1 O modelo Binomial\nA partir das express√µes para \\(P(y)\\) apresentadas na Tabela¬†3, obt√©m-se uma f√≥rmula geral que pode ser escrita como:\n\\[P(y \\mid n, p) = \\binom{n}{y} \\, p^y (1 - p)^{n - y}.\n\\tag{1}\\]\nOnde:\n\n\\(y \\in \\{0, 1, 2, \\dots, n\\}\\) √© o n√∫mero de observa√ß√µes de üåä;\n\\(n\\) √© o n√∫mero total de observa√ß√µes;\n\\(p\\) √© a fra√ß√£o de üåä que cobre o globo;\n\\(\\binom{n}{y}\\) √© o coeficiente binomial, calculado por \\(\\frac{n!}{y!(n - y)!}\\), indicando de quantas maneiras a combina√ß√£o \\(p^y (1 - p)^{n - y}\\) pode ocorrer.\n\nA Equa√ß√£o¬†1 fornece a probabilidade de cada resultado poss√≠vel (n√∫mero de observa√ß√µes üåä) em \\(n\\) tentativas, permitindo calcular a probabilidade de todos os poss√≠veis resultados do experimento."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#verossimilhan√ßa-a-plausibilidade-de-uma-hip√≥tese",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#verossimilhan√ßa-a-plausibilidade-de-uma-hip√≥tese",
    "title": "Construindo um modelo bayesiano",
    "section": "2 Verossimilhan√ßa: a plausibilidade de uma hip√≥tese",
    "text": "2 Verossimilhan√ßa: a plausibilidade de uma hip√≥tese\nA partir do modelo binomial, podemos definir a fun√ß√£o de verossimilhan√ßa para um resultado observado. Imagine que, em \\(n = 4\\) lan√ßamentos, foram observados \\(y = 2\\) pontos sobre a √°gua. N√£o sabemos a verdadeira propor√ß√£o \\(p\\) de √°gua que cobre a Terra; portanto, fazemos conjecturas e avaliamos cada uma com base nas observa√ß√µes.\nPor exemplo, se supormos que a propor√ß√£o verdadeira seja 40% \\((p = 0.4)\\), a distribui√ß√£o binomial determina que a probabilidade de observar \\(y = 2\\) sucessos em \\(n = 4\\) lan√ßamentos seja:\n\\[P(y = 2 \\mid n = 4, p = 0.4) = \\binom{4}{2} \\, 0.4^2 (1 - 0.4)^{4 - 2} = 0.35\\]\nEssa hip√≥tese √© apenas uma das poss√≠veis. Para ilustrar outras conjecturas, considere:\n\nSe \\(p = 0.3\\):\n\\(P(2 \\mid 4, 0.3) = \\binom{4}{2} \\, 0.3^2 (1 - 0.3)^{4 - 2} = 0.26\\)\nSe \\(p = 0.8\\):\n\\(P(2 \\mid 4, 0.8) = \\binom{4}{2} \\, 0.8^2 (1 - 0.8)^{4 - 2} = 0.15\\)\n\nEm cada caso, os dados observados \\((y)\\) e o n√∫mero total de observa√ß√µes \\((n)\\) est√£o fixos, enquanto o par√¢metro \\(p\\) varia conforme a hip√≥tese considerada. Embora a forma matem√°tica seja id√™ntica √† da fun√ß√£o de probabilidade binomial, seu uso √© diferente. Na fun√ß√£o de probabilidade, lemos a probabilidade de \\(y\\) dado \\(n\\) e \\(p\\), enquanto nos exemplos acima, avaliamos a plausibilidade de diferentes hip√≥teses sobre \\(p\\) dados valores fixos de \\(y\\) e \\(n\\).\nPara evitar confus√µes, vamos definir a fun√ß√£o de verossimilhan√ßa como:\n\\[\n\\mathcal{L}(p \\mid n, y) = \\binom{n}{y} \\, p^y (1 - p)^{n - y}.\n\\tag{2}\\]\nAssim, as verossimilhan√ßas para as tr√™s conjecturas espec√≠ficas sobre a propor√ß√£o de √°gua na superf√≠cie do globo ser√£o:\n\n\\(\\mathcal{L}(p = 0.4 \\mid n = 4, y = 2) = 0.35\\),\n\\(\\mathcal{L}(p = 0.3 \\mid n = 4, y = 2) = 0.26\\),\n\\(\\mathcal{L}(p = 0.8 \\mid n = 4, y = 2) = 0.15\\).\n\nDessa forma, entre as tr√™s hip√≥teses levantadas, aquela em que \\(p = 0.4\\) recebe maior suporte das evid√™ncias, por estar associada √† maior verossimilhan√ßa.\nPodemos quantificar esse suporte por meio da raz√£o de verossimilhan√ßas:\n\\[RV = \\frac{\\mathcal{L}(p = 0.4 \\mid 4, 2)}{\\mathcal{L}(p = 0.3 \\mid 4, 2)} = \\frac{0.35}{0.26} = 1.35,\\]\no que indica que, com base nos dados observados, a hip√≥tese de \\(p = 0.4\\) √© aproximadamente \\(1.35\\) vezes mais veross√≠mil do que a hip√≥tese de \\(p = 0.3\\).\n\n\n\n\n\n\nResumo: A Fun√ß√£o de Verossimilhan√ßa Binomial\n\n\n\n\nA express√£o √© matematicamente id√™ntica √† fun√ß√£o de probabilidade binomial, por√©m interpretada como uma fun√ß√£o de \\(p\\) quando os dados \\(Y\\) e \\(n\\) s√£o fixos.\nA verossimilhan√ßa indica a plausibilidade de diferentes valores de \\(p\\) √† luz dos dados observados.\nNa distribui√ß√£o binomial, lemos: probabilidade de \\(Y\\) dado \\(n\\) e \\(p\\).\nNa fun√ß√£o de verossimilhan√ßa, interpretamos: verossimilhan√ßa de \\(p\\) dado \\(n\\) e \\(Y\\).\nA raz√£o de verossimilhan√ßas pode ser utilizada para quantificar o suporte relativo entre diferentes hip√≥teses.\n\n\n\n\n2.1 O perfil de verossimilhan√ßa\nAcima, foram testadas tr√™s conjecturas espec√≠ficas para a propor√ß√£o de √°gua na superf√≠cie da Terra (\\(p = 0.3\\), \\(p = 0.4\\), \\(p = 0.8\\)). Para uma avalia√ß√£o mais completa, podemos analisar o perfil de verossimilhan√ßa para uma s√©rie de valores de \\(p\\) entre 0 e 1:\n\n\n\n\n\n\n\n\n\nO perfil de verossimilhan√ßa indica que, √† luz dos nossos dados \\(y = 2\\), a conjectura mais plaus√≠vel √© que a propor√ß√£o de √°gua que cobre a Terra esteja pr√≥xima de 0.5 (neste caso, a verossimilhan√ßa m√°xima √© exatamente para \\(p = 0.5\\))."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#infer√™ncia-bayesiana-distribui√ß√µes-a-priori-e-a-posteriori",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#infer√™ncia-bayesiana-distribui√ß√µes-a-priori-e-a-posteriori",
    "title": "Construindo um modelo bayesiano",
    "section": "3 Infer√™ncia Bayesiana: distribui√ß√µes a priori e a posteriori",
    "text": "3 Infer√™ncia Bayesiana: distribui√ß√µes a priori e a posteriori\nA infer√™ncia bayesiana utiliza o Teorema de Bayes para derivar a distribui√ß√£o a posteriori dos par√¢metros de interesse, \\(p(\\theta \\mid Y)\\), a partir da verossimilhan√ßa \\(p(Y \\mid \\theta)\\) e da distribui√ß√£o a priori \\(p(\\theta)\\):\n\\[p(\\theta \\mid Y) = \\frac{p(Y \\mid \\theta) \\times p(\\theta)}{p(Y)} \\tag{3}\\]\nEm que:\n\n\\(p(\\theta \\mid Y)\\): distribui√ß√£o a posteriori de \\(\\theta\\) dado os dados observados \\(Y\\);\n\\(p(Y \\mid \\theta)\\): verossimilhan√ßa dos dados \\(Y\\) dada \\(\\theta\\);\n\\(p(\\theta)\\): distribui√ß√£o a priori de \\(\\theta\\);\n\\(p(Y)\\): probabilidade marginal dos dados, obtida por\n\n\\[\\int p(Y \\mid \\theta) \\times p(\\theta) \\, d\\theta\\]\nNo contexto bayesiano, √© comum substituir \\(p(Y \\mid \\theta)\\) pela fun√ß√£o de verossimilhan√ßa \\(\\mathcal{L}(\\theta \\mid Y)\\), pois ambas s√£o matematicamente equivalentes. Assim, a f√≥rmula da distribui√ß√£o a posteriori pode ser reescrita como:\n\\[p(\\theta \\mid Y) = \\frac{\\mathcal{L}(\\theta \\mid Y) \\times p(\\theta)}{p(Y)} \\tag{4}\\]"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#priori-informativa-e-n√£o-informativa",
    "href": "content/intro-bayes/intro-bayes-modelo-bayesiano.html#priori-informativa-e-n√£o-informativa",
    "title": "Construindo um modelo bayesiano",
    "section": "4 Priori informativa e n√£o informativa",
    "text": "4 Priori informativa e n√£o informativa\nDenominamos priori n√£o informativa aquela que n√£o acrescenta informa√ß√µes relevantes √† distribui√ß√£o a posteriori al√©m daquelas j√° contidas nos dados observados. Nesses casos, a distribui√ß√£o a posteriori √© proporcional apenas √† verossimilhan√ßa:\n\\[p(\\theta \\mid Y) \\propto \\mathcal{L}(\\theta \\mid Y) \\tag{5}\\]\nPor outro lado, ao adotarmos uma priori informativa, atribu√≠mos diferentes densidades de probabilidade √†s regi√µes espec√≠ficas do espa√ßo de par√¢metros, refletindo o conhecimento pr√©vio sobre o fen√¥meno estudado. A distribui√ß√£o a posteriori, nesse caso, ser√° proporcional ao produto entre a verossimilhan√ßa e a priori, integrando evid√™ncias anteriores com a informa√ß√£o contida nos dados:\n\\[p(\\theta \\mid Y) \\propto \\mathcal{L}(\\theta \\mid Y) \\times p(\\theta) \\tag{6}\\]\nNo modelo binomial aplicado √† propor√ß√£o de √°gua na superf√≠cie oce√¢nica, o par√¢metro \\(\\theta\\) representa a propor√ß√£o de √°gua \\(p\\), e sua distribui√ß√£o posterior √© condicional ao n√∫mero de observa√ß√µes \\(n\\) e aos dados observados \\(y\\).\nA distribui√ß√£o a priori para \\(p\\) pode ser n√£o informativa, como no caso da distribui√ß√£o uniforme, que n√£o favorece nenhum valor espec√≠fico de \\(p\\). Alternativamente, pode-se adotar uma priori informativa, como a distribui√ß√£o Beta, que permite ajustar a forma da densidade de probabilidade por meio dos par√¢metros \\(\\alpha\\) e \\(\\beta\\), incorporando conhecimento pr√©vio sobre o fen√¥meno de interesse.\nPara ilustrar o efeito de prioris informativas e n√£o-informativas sobre a distribui√ß√£o a posteriori, siga a atividade abaixo:\n\n\n\n\n\n\nAtividades interativas: estimando a propor√ß√£o da superf√≠cie oce√¢nica!\n\n\n\n\nAmostre pontos no globo e fa√ßa sua pr√≥pria infer√™ncia bayesiana\nNo app abaixo, gere pontos aleat√≥rios na superf√≠cie da Terra e verifique quantos caem em √°gua ou em terra.\nüëâ Estimando a Propor√ß√£o da Superf√≠cie Oce√¢nica\n\nEscolha quantos pontos deseja amostrar (1 a 1000).\n\nClique em ‚ÄúGerar Pontos Aleat√≥rios‚Äù e observe quantos ficam sobre a √°gua versus sobre a terra.\n\nRegistre esses valores como \\(k\\) sucessos em \\(N\\) pontos (N observa√ß√µes).\n\nUtilize seus dados na infer√™ncia Bayesiana\nEm seguida, abra o app abaixo para visualizar como as observa√ß√µes (sucessos e fracassos) combinadas a diferentes escolhas de par√¢metros a priori (\\(\\alpha\\), \\(\\beta\\)) geram a distribui√ß√£o a posteriori:\nüëâ Infer√™ncia Bayesiana\nDicas de uso\n\nInsira o mesmo n√∫mero de observa√ß√µes (N) e sucessos (k) obtidos no primeiro app.\n\nAjuste interativamente a distribui√ß√£o a priori Beta, modificando os par√¢metros \\(\\alpha\\) e \\(\\beta\\).\nObserve como a curva azul (‚Äúposteriori‚Äù) se altera de acordo com a a priori e com os dados observados, e compare com o perfil de verossimilhan√ßa (curva verde).\nNote que ao escolher \\(\\alpha = 1\\) e \\(\\beta = 1\\) a distribui√ß√£o assume um formato uniforme, tornando-se n√£o-informativa."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html",
    "title": "Infer√™ncia Bayesiana Binomial",
    "section": "",
    "text": "A estrat√©gia de infer√™ncia via grid consiste em discretizar o par√¢metro \\(p\\) em pequenos intervalos, avaliando a distribui√ß√£o a priori e a verossimilhan√ßa em cada ponto da grade. Em seguida, multiplica-se esses valores e normaliza-se o resultado para obter a distribui√ß√£o a posteriori."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#aproxima√ß√£o-bayesiana-via-grid",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#aproxima√ß√£o-bayesiana-via-grid",
    "title": "Infer√™ncia Bayesiana Binomial",
    "section": "1 Aproxima√ß√£o Bayesiana via Grid",
    "text": "1 Aproxima√ß√£o Bayesiana via Grid\n\nDefinir os dados\n\n\\(N\\): n√∫mero total de observa√ß√µes (ensaios Bernoulli).\n\n\\(k\\): n√∫mero de sucessos observados.\n\nCriar a malha (grid) de valores para \\(p\\)\n\nDivida o intervalo \\([0, 1]\\) em muitos pontos (ex. 1000 pontos).\n\nCada ponto ser√° uma hip√≥tese para o valor de \\(p\\).\n\nAvaliar a priori\n\nEscolha uma forma para a distribui√ß√£o a priori de \\(p\\).\n\nExemplos: uma Beta(\\(\\alpha, \\beta\\)) ou mesmo uma priori uniforme.\n\nCalcule a densidade da priori em cada ponto do grid.\n\nCalcular a verossimilhan√ßa\n\nPara cada valor de \\(p\\) no grid, calcule \\(P(Y = k \\mid p, N)\\) usando a distribui√ß√£o Binomial:\n\\[\\mathcal{L}(p) = \\binom{N}{k}\\, p^k (1-p)^{N-k}.\\]\nUse por exempo o m√©todo binom.pmf(k, N, p) do m√≥dulo SciPy ou escreva a f√≥rmula manualmente.\n\nCombinar priori e verossimilhan√ßa\n\nA posteriori n√£o normalizada em cada ponto do grid √©:\n\\[\\text{posterior}_{\\text{unnorm}}(p) = \\text{prior}(p) \\times \\mathcal{L}(p).\\]\n\nNormalizar a posteriori\n\nSome os valores de \\(\\text{posterior}_{\\text{unnorm}}(p)\\) sobre todos os pontos \\(p\\).\n\nDivida cada valor pela soma total (use integra√ß√£o, como scipy.integrate.simpson para maior precis√£o).\n\nO resultado √© a distribui√ß√£o a posteriori discreta (aproximada).\n\nCalcular probabilidades de intervalo\n\nPara calcular \\(P(x_1 \\leq p \\leq x_2)\\), some (ou integre) os valores da posteriori nos pontos entre \\(x_1\\) e \\(x_2\\).\n\nVisualizar os resultados\n\nFa√ßa gr√°ficos do perfil da priori, da verossimilhan√ßa e da posteriori ao longo do grid de \\(p\\).\n\nDestaque intervalos de interesse (\\(x_1, x_2\\)) e use os valores de probabilidade para estimar o valor de \\(p\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#exemplo-em-python",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#exemplo-em-python",
    "title": "Infer√™ncia Bayesiana Binomial",
    "section": "2 Exemplo em Python",
    "text": "2 Exemplo em Python\nA seguir, um exemplo completo usando numpy e matplotlib para ilustrar cada etapa. Ajuste os valores de \\(N\\), \\(k\\), \\(\\alpha\\) e \\(\\beta\\) conforme necess√°rio.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, beta\nfrom scipy.integrate import simpson\n\n# Par√¢metros do experimento\nN = 10   # n√∫mero total de ensaios\nk = 6    # n√∫mero de sucessos observados\n\n# Par√¢metros da priori Beta\nalpha_param = 1\nbeta_param = 1\n\n# Grid de p (1000 pontos entre 0 e 1)\np_grid = np.linspace(0, 1, 1000)\n\n# 1) Prior: densidade Beta em cada ponto do grid\nprior = beta.pdf(p_grid, a=alpha_param, b=beta_param)\n\n# 2) Verossimilhan√ßa: Binomial(k | N, p)\nlikelihood = binom.pmf(k, N, p_grid)\n\n# 3) Posterior n√£o normalizada\nposterior_unnorm = prior * likelihood\n\n# 4) Normaliza para obter a posteriori propriamente dita\narea = simpson(y=posterior_unnorm, x=p_grid)  # integra usando Simpson\nposterior = posterior_unnorm / area\n\n# 5) (Opcional) Calcular probabilidade de um intervalo [x1, x2]\nx1, x2 = 0.4, 0.7\nmask_interval = (p_grid &gt;= x1) & (p_grid &lt;= x2)\nprob_interval = simpson(y=posterior[mask_interval], x=p_grid[mask_interval])\n\n# Visualizar\nfig, axs = plt.subplots(3, 1, figsize=(6, 8))\n\n# Plot da Prior\naxs[0].plot(p_grid, prior, color='red')\naxs[0].set_title(\"Priori Beta\")\naxs[0].set_ylabel(\"Densidade\")\n\n# Plot da Verossimilhan√ßa\naxs[1].plot(p_grid, likelihood, color='green')\naxs[1].set_title(f\"Verossimilhan√ßa Binomial (k={k}, N={N})\")\naxs[1].set_ylabel(\"PMF\")\n\n# Plot da Posterior\naxs[2].plot(p_grid, posterior, color='blue')\naxs[2].set_title(f\"Posteriori - Prob({x1:.2f} ‚â§ p ‚â§ {x2:.2f}) = {prob_interval:.3f}\")\naxs[2].set_xlabel(\"p\")\naxs[2].set_ylabel(\"Densidade\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-binomial-grid.html#interpreta√ß√£o",
    "href": "content/intro-bayes/intro-bayes-binomial-grid.html#interpreta√ß√£o",
    "title": "Infer√™ncia Bayesiana Binomial",
    "section": "3 Interpreta√ß√£o",
    "text": "3 Interpreta√ß√£o\n\nObserve como a forma da posteriori (curva azul) √© proporcional ao produto da priori (vermelho) pela verossimilhan√ßa (verde).\nSe a priori for \\(Beta(1,1)\\) (uniforme), a posteriori fica essencialmente guiada pelos dados.\nAlterar \\(\\alpha\\) e \\(\\beta\\) faz a priori pesar mais (ou menos) no resultado final, dependendo de qu√£o informativa ela √© e do tamanho amostral \\(N\\)."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html",
    "title": "Modelo Normal Bayesiano",
    "section": "",
    "text": "Exploraremos a infer√™ncia bayesiana, com foco na modelagem de dados cont√≠nuos por meio da distribui√ß√£o normal. Nosso objetivo ser√° desenvolver a intui√ß√£o sobre como escolher distribui√ß√µes a priori e como o PyMC nos auxilia a visualizar as consequ√™ncias dessas escolhas sobre a distribui√ß√£o preditiva a priori da vari√°vel de interesse. Para isso, utilizaremos um exemplo baseado na distribui√ß√£o de altura em adultos.\n# Configura√ß√£o inicial e importa√ß√£o de bibliotecas\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Configura√ß√µes para plots\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (9, 6)"
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#explorando-a-distribui√ß√£o-normal",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#explorando-a-distribui√ß√£o-normal",
    "title": "Modelo Normal Bayesiano",
    "section": "1 Explorando a Distribui√ß√£o Normal",
    "text": "1 Explorando a Distribui√ß√£o Normal\nA Distribui√ß√£o Normal, frequentemente chamada de curva de sino ou curva Gaussiana, √© central em estat√≠stica. Ela √© caracterizada por dois par√¢metros: a m√©dia (\\(\\mu\\)) e o desvio padr√£o (\\(\\sigma\\)). A m√©dia determina o centro da distribui√ß√£o, enquanto o desvio padr√£o determina sua dispers√£o ou largura. Muitos fen√¥menos naturais podem ser adequadamente descritos por essa distribui√ß√£o.\nA ideia intuitiva: Pense na altura de adultos. H√° um valor central (a m√©dia) em torno do qual a maioria das alturas se agrupa. H√° tamb√©m uma varia√ß√£o: algumas pessoas s√£o mais altas, outras mais baixas. O desvio padr√£o nos diz o qu√£o espalhadas essas alturas tendem a ser em rela√ß√£o √† m√©dia.\n\n1.1 Curva de densidade de probabilidade\nGerando a Distribui√ß√£o de Densidade Normal para diferentes valores de \\(\\mu\\) e \\(\\sigma\\).\n\n# Par√¢metros da distribui√ß√£o\nmu_1 = 20\nsigma_1 = 3\n\nmu_2 = 20\nsigma_2 = 6\n\nmu_3 = 30\nsigma_3 = 5\n\n# Limites gr√°ficos\nx_min = np.min(np.array([mu_1, mu_2, mu_3]) - 4*np.array([sigma_1, sigma_2, sigma_3]))\nx_max = np.max(np.array([mu_1, mu_2, mu_3]) + 4*np.array([sigma_1, sigma_2, sigma_3]))\nx = np.linspace(x_min, x_max, 1000) # Faixa de alturas para plotar\n\npdf_1 = stats.norm.pdf(x, loc=mu_1, scale=sigma_1)\npdf_2 = stats.norm.pdf(x, loc=mu_2, scale=sigma_2)\npdf_3 = stats.norm.pdf(x, loc=mu_3, scale=sigma_3)\n\nVisualizando as distribui√ß√µes de densidade de probabilidade\n\nplt.plot(x, pdf_1, label=f'$\\mu={mu_1}, \\sigma={sigma_1}$', color='b', lw=2)\nplt.plot(x, pdf_2, label=f'$\\mu={mu_2}, \\sigma={sigma_2}$', color='r', lw=2)\nplt.plot(x, pdf_3, label=f'$\\mu={mu_3}, \\sigma={sigma_3}$', color='g', lw=2)\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade de Probabilidade', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='-', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFigura¬†1: Desidades da distribui√ß√£o normal para diferentes valores de Œº e œÉ.\n\n\n\n\n\n\n\n1.2 Amostrando valores de distribui√ß√£o normal\nNa Figura¬†1 vemos as curvas te√≥ricas de densidade da distribui√ßao normal. Podemos tamb√©m gerar amostras valores ao acaso destas distribui√ß√µes para verificar como estas amostras se parecem. Isso simula o processo de sortear alturas de uma popula√ß√£o que segue essa distribui√ß√£o.\n\nmu = 20\nsigma = 4\nnum_amostras = 60\n\nVerificando o histograma dos valores sorteados.\n\namostras_y = stats.norm.rvs(loc=mu, scale=sigma, size=num_amostras)\nx_dens = np.linspace(mu-4*sigma, mu+4*sigma, 500)\n\nplt.hist(amostras_y, bins=30, density=True, alpha=0.8, color='lightblue', label='Amostras Geradas')\nsns.kdeplot(amostras_y, color='blue', linewidth=2, label='Densidade Emp√≠rica')\nplt.plot(x_dens, stats.norm.pdf(x_dens, loc=mu, scale=sigma), color='red', linewidth=2.5, label='Densidade Te√≥rica')\nplt.xlabel('X', fontsize=12)\nplt.ylabel('Densidade / Frequ√™ncia Normalizada', fontsize=12)\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\nFigura¬†2: Histograma de amostras geradas a partir de uma distribui√ß√£o normal com m√©dia \\(\\mu\\) e desvio padr√£o \\(\\sigma\\), acompanhado da densidade emp√≠rica estimada por kernel e da densidade te√≥rica correspondente.\n\n\n\n\n\n\n\n\n\n\n\nAtividade em laborat√≥rio\n\n\n\n\nRode este o trecho de c√≥digo acima algumas vezes e observe como se d√° a varia√ß√£o amostral.\nAumente e diminua o tamanho da amostras e verifique a varia√ß√£o entre as curvas enp√≠ricas e a curva te√≥rica."
  },
  {
    "objectID": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#intui√ß√£o-bayesiana",
    "href": "content/intro-bayes/intro-bayes-modelo-normal-bayesiano-priori.html#intui√ß√£o-bayesiana",
    "title": "Modelo Normal Bayesiano",
    "section": "2 Intui√ß√£o Bayesiana",
    "text": "2 Intui√ß√£o Bayesiana\nEm infer√™ncia Bayesiana, come√ßamos com cren√ßas sobre os par√¢metros (a priori) e as atualizamos com dados (a posteriori). Para a altura humana (\\(y\\)), podemos assumir que a distribui√ß√£o normal √© um bom modelo preditivo.\nDeste modo, escrevemos que:\n\\[y \\sim \\mathcal{N}(\\mu, \\sigma)\n\\tag{1}\\]\nEm seguida, precisamos sugerir uma dristribui√ß√£o a priori para a m√©dia \\(\\mu\\) e o desvio padr√£o \\(\\sigma\\) que traduzam de forma adequada o que esperamos sobre a distribui√ß√£o de altura em adultos. Sabemos por exemplo que a m√©dia da altura de adultos n√£o √© 50 cm nem 300 cm. Qual sua intui√ß√£o sobre o desvio padr√£o?\n\n\n\n\n\n\nAtividade em laborat√≥rio\n\n\n\n\nAssumindo que a distribui√ß√£o de alturas em adultos segue uma dsitribui√ß√£o normal proponha valores razo√°veis para a m√©dia (\\(\\mu\\)) e o desvio padr√£o (\\(\\sigma\\)).\nPara ajudar a decidir sobre o que seriam valores valores razo√°veis, plote as curvas de densidade de probabilidade resultante de sua escolha e fa√ßa algumas simula√ß√µes para verificar quais valores estremos sua escolha √© capaz de gerar, utilizando os c√≥digos da Se√ß√£o¬†1.2.\n\n\n\n\n2.1 Checagem Priori Preditiva\nAssumindo que a altura de adultos segue uma distribui√ß√£o (Equa√ß√£o¬†1), vamos assumir que o par√¢metro \\(\\mu\\) segue tamb√©m uma distribui√ß√£o normal e que \\(\\sigma\\) segue uma distribui√ß√£o log-normal\nComo utilizamos estes pressupostos para escolher distribui√ß√£o razoi√°veis para \\(\\mu\\) e \\(\\sigma\\)?\nPriori para \\(\\mu\\)\n\nmean_prior_mu =  # INSIRA SUA ESCOLHA PARA A M√âDIA DA PRIORI DE mu\nsd_prior_mu =  # INSIRA SUA ESCOLHA PARA O DESVIO PADR√ÉO DA PRIORI DE mu\n\n# Gere sequancia de x e calcule a PDF\nxmean_prior = np.linspace(mean_prior_mu - 4*sd_prior_mu, mean_prior_mu + 4*sd_prior_mu, 1000)\npdf_mean_prior = stats.norm.pdf(x = xmean_prior, loc = mean_prior_mu, scale = sd_prior_mu)\n\n# Plote os resultados\nplt.plot(xmean_prior, pdf_mean_prior)\nplt.title(f'Priori para $\\mu$')\nplt.show()\n\nPriori para \\(\\sigma\\)\n\nlmean_prior_sigma =  # INSIRA SUA ESCOLHA PARA A M√âDIA DA PRIORI DE sigma\nlsd_prior_sigma =  # INSIRA SUA ESCOLHA PARA O DESVIO PADR√ÉO DA PRIORI DE sigma\n\nxsd_prior = np.linspace(0.01, 20, 1000)\npdf_sd_prior = stats.lognorm.pdf(xsd_prior, s=lsd_prior_sigma, scale=lmean_prior_sigma)\n\nplt.close()\nplt.plot(xsd_prior, pdf_sd_prior)\nplt.title(f'Priori para $\\sigma$')\nplt.show()\n\nExtraindo distribui√ß√£o a priori preditiva de \\(y\\) no PyMC\n\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a m√©dia\n    mu = pm.Normal(\"mu\", mu = mean_prior_mu, sigma = sd_prior_mu)\n\n    # Priori lognormal para o desvio padr√£o\n    sigma = pm.Lognormal(\"sigma\", mu = np.log(lmean_prior_sigma), sigma = lsd_prior_sigma)\n\n    # Distribui√ß√£o preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu = mu, sigma = sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n\nAgora, vamos visualizar a distribui√ß√£o dessas amostras preditivas a priori:\n\n\n\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nplt.figure(figsize=(10, 6))\nplt.hist(y_pred_prior, color='skyblue', edgecolor='black')\nplt.xlabel('Alturas priori simulada (cm)', fontsize=12)\nplt.ylabel('Densidade', fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.show()\n\n\nFigura¬†3\n\n\n\n\n\n\n\n\n\nDiscuss√£o\n\n\n\nOlhe para o histograma. As alturas simuladas parecem razo√°veis para alturas de adultos? A distribui√ß√£o faz sentido dada a sua intui√ß√£o? Se sim, suas priores iniciais eram sensatas. Se n√£o, √© importante considerar um ajuste de suas priores (ex: tornar a priori de \\(\\sigma\\) mais restrita se a dispers√£o for muito grande, ou ajustar a localiza√ß√£o/escala da priori de \\(\\mu\\)).\n\n\nChecagem priori preditiva com PyMC\nPodemos chegar n√£o somente a distribui√ß√£o preditiva de \\(y\\), mas tamb√©m dos par√¢metros \\(\\mu\\) e \\(\\sigma\\) usando o PyMC. Al√©m disso, poder√≠amos testar outras distribui√ß√µes a priori para algum dos par√¢metros, por exemplo sigma. Teste cada uma destas e verifique os efeitos sobre as distribui√ß√µes preditivas.\n\n# Definindo o modelo APENAS com as priores compartilhadas\nwith pm.Model() as prior_predictive_model:\n    \n    # Priori para a m√©dia\n    mu = pm.Normal(\"mu\", mu=175, sigma=10)\n\n    # Escolha uma das prioris para sigma:\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(0.08), sigma=0.5)\n    # sigma = pm.InverseGamma(\"sigma\", alpha=8, beta=0.9)\n    # sigma = pm.HalfNormal(\"sigma\", sigma=0.1)\n    # sigma = pm.HalfCauchy(\"sigma\", beta=0.1)\n    # sigma = pm.Exponential(\"sigma\", lam=20)\n    # sigma = pm.TruncatedNormal(\"sigma\", mu=0.08, sigma=0.02, lower=0)\n    # sigma = pm.Uniform(\"sigma\", lower=0, upper=1)\n\n    # Distribui√ß√£o preditiva de y\n    y_pred = pm.Normal(\"y_pred\", mu=mu, sigma=sigma)\n\n    # Amostras da priori preditiva\n    prior_predictive_samples = pm.sample_prior_predictive(samples=1000)\n\n\n\n\nmu_pred_prior = prior_predictive_samples.prior[\"mu\"].values.flatten()\nsigma_pred_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\ny_pred_prior = prior_predictive_samples.prior[\"y_pred\"].values.flatten()\n\nfig, axes = plt.subplots(1, 3, figsize=(9, 3))\n\naxes[0].hist(mu_pred_prior, bins=30, color='skyblue', edgecolor='black')\naxes[0].set_xlabel(\"Œº\")\naxes[0].set_ylabel(\"Frequ√™ncia\")\n\naxes[1].hist(sigma_pred_prior, bins=30, color='lightgreen', edgecolor='black')\naxes[1].set_xlabel(\"œÉ\")\naxes[1].set_ylabel(\"Frequ√™ncia\")\n\naxes[2].hist(y_pred_prior, bins=30, color='salmon', edgecolor='black')\naxes[2].set_xlabel(\"alturas (y)\")\naxes[2].set_ylabel(\"Frequ√™ncia\")\n\nplt.tight_layout()\nplt.show()\n\n\nFigura¬†4"
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html",
    "href": "content/medidas-associacao/biquantquali.html",
    "title": "Associa√ß√£o entre vari√°veis quantitativas e qualitativas",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas no cap√≠tulo\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(gridExtra)\nsource('scripts/anova-sim.r')\nNeste cap√≠tulo vamos descrever a associa√ß√£o entre uma vari√°vel \\(Y\\) cont√≠nua e uma vari√°vel \\(X\\) categ√≥rica denominadas respectivamente de vari√°vel dependente (ou resposta) e vari√°vel independente (ou preditora)\nAssumimos explicitamente que \\(Y\\) √© fun√ß√£o (depende) de \\(X\\) e n√£o o contr√°rio. O nome vari√°vel preditora vem do fato que, se \\(Y\\) e \\(X\\) est√£o associadas, ao conhecemos \\(X\\) somos capazer de predizer a resposta m√©dia em \\(Y\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#visualizando-a-distribui√ß√£o-de-y-em-diferentes-grupos",
    "href": "content/medidas-associacao/biquantquali.html#visualizando-a-distribui√ß√£o-de-y-em-diferentes-grupos",
    "title": "Associa√ß√£o entre vari√°veis quantitativas e qualitativas",
    "section": "1 Visualizando a distribui√ß√£o de \\(Y\\) em diferentes grupos",
    "text": "1 Visualizando a distribui√ß√£o de \\(Y\\) em diferentes grupos\nImporte a base de dados medley.csv (dispon√≠vel tamb√©m em Chapter 10 - Single factor classification (ANOVA)) que avalia o impacto da presen√ßa de metais pesados na diversidade de esp√©cies de diatom√°cias em riachos (Medley e Clements (1998); Queen, Quinn, e Keough (2002); Logan (2011)).\n\nmedley = read_csv(\"https://raw.githubusercontent.com/FCopf/datasets/refs/heads/main/medley.csv\") |&gt; \n  mutate(STREAM = factor(STREAM),\n         ZINC = factor(ZINC, ordered = TRUE,\n                       levels = c(\"BACK\", \"LOW\", \"MED\", \"HIGH\")))\nvar_medley = colnames(medley)\nstream_levels = levels(medley$STREAM)\nn_stream = nlevels(medley$STREAM)\nzinc_levels = levels(medley$ZINC)\nn_zinc = nlevels(medley$ZINC)\n\n\nmedley |&gt; gt()\n\n\n\n\n\n\n\nSTREAM\nZINC\nDIVERSITY\n\n\n\n\nEagle\nBACK\n2.27\n\n\nEagle\nHIGH\n1.25\n\n\nEagle\nHIGH\n1.15\n\n\nEagle\nMED\n1.62\n\n\nBlue\nBACK\n1.70\n\n\nBlue\nHIGH\n0.63\n\n\nBlue\nBACK\n2.05\n\n\nBlue\nBACK\n1.98\n\n\nBlue\nHIGH\n1.04\n\n\nBlue\nMED\n2.19\n\n\nBlue\nMED\n2.10\n\n\nSnake\nBACK\n2.20\n\n\nSnake\nMED\n2.06\n\n\nSnake\nHIGH\n1.90\n\n\nSnake\nHIGH\n1.88\n\n\nSnake\nHIGH\n0.85\n\n\nArkan\nLOW\n1.40\n\n\nArkan\nLOW\n2.18\n\n\nArkan\nLOW\n1.83\n\n\nArkan\nLOW\n1.88\n\n\nArkan\nMED\n2.02\n\n\nArkan\nMED\n1.94\n\n\nArkan\nLOW\n2.10\n\n\nChalk\nLOW\n2.38\n\n\nChalk\nHIGH\n1.43\n\n\nChalk\nHIGH\n1.37\n\n\nChalk\nMED\n1.75\n\n\nChalk\nLOW\n2.83\n\n\nSplat\nBACK\n1.53\n\n\nSplat\nBACK\n0.76\n\n\nSplat\nMED\n0.80\n\n\nSplat\nLOW\n1.66\n\n\nSplat\nMED\n0.98\n\n\nSplat\nBACK\n1.89\n\n\n\n\n\n\n\nA coluna STREAM √© uma vari√°vel categ√≥rica contendo o nome dos \\(6\\) riachos amostrados (Arkan, Blue, Chalk, Eagle, Snake, Splat). A coluna ZINC √© uma vari√°vel categ√≥rica ordinal com \\(4\\) n√≠veis de concentra√ß√£o de zinco na √°gua (BACK &lt; LOW &lt; MED &lt; HIGH). O primeiro n√≠vel (BACK) √© o n√≠vel de refer√™ncia (BACKGROUND). Finalmente, a coluna DIVERSITY √© uma vari√°vel cont√≠nua que cont√©m a diversidade de diatom√°cieas (medida pelo √≠ndice de diversidade de Shannon medida de cada uma das 34 amostras.\nVamos nos concentrar nas vari√°veis DIVERSITY e ZINC. DIVERSITY ser√° a vari√°vel resposta. Em delineamento experimental, dizemos que ZINC √© um tratamento, isto √©, uma condi√ß√£o experimental sob a qual nossa vari√°vel dependente \\(Y\\) foi mensurada.\nPara verificarmos a distribui√ß√£o de diversidade para cada concentra√ß√£o de zinco poder√≠amos fazer um gr√°fico de dispers√£o. A diferen√ßa agora √© que \\(X\\) trata-se de uma vari√°vel categ√≥rica ordinal com \\(4\\) n√≠veis.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_point() +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\n1.1 Boxplots para os n√≠veis do tratamento\nN√£o h√° problema em apresentarmos um gr√°fico de dispers√£o. No entanto, em situa√ß√µes deste tipo estamos comumente interessados em representar medidas-resumo que nos permitam comparar os diferentes n√≠veis do tratamento. A forma mais comum de representar esta situa√ß√£o √© por meio de um boxplot para cada n√≠vel do tratamento.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot() +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nNa figura acima est√£o representadas a mediana, os quartis (\\(1^o\\) e \\(3^o\\)) e os pontos m√°ximo e m√≠nimo para cada n√≠vel do tratamento. Alguns pontos extremos podem aparecer isoladamente para indicar que est√£o muito distantes dos demais. Podemos controlar esta representa√ß√£o com o argumento coef na fun√ß√£o geom_boxplot.\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nVemos que o boxplot referente ao n√≠vel HIGH est√° em uma posi√ß√£o inferior aos demais, sugerindo que a diversidade de diatom√°ceas tende a ser mais baixa para n√≠veis elevados de zinco.\nExitem outras varia√ß√µes que podem nos ajudar a entender melhor os padr√µes. Podemos sobrepor os pontos individuais sobre os boxplots:\n\nggplot(medley) +\n  aes(x = ZINC, y = DIVERSITY) +\n  geom_boxplot(coef = 3) +\n  geom_point(size = 3) +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\n\n\n1.2 O gr√°fico de erros\nNas figuras acima representamos os quartis das distribui√ß√µes. Podemos estar interessados em apresentar somente os pontos m√©dios (m√©dia aritim√©tica) juntamente com barras de erro que representem alguma medida de dispers√£o (ex. desvio padr√£o). Para isto √© necess√°rio inicialmente criar um data.frame com estas medidas.\n\nmedley_barras = medley |&gt; \n  group_by(ZINC) |&gt; \n  summarise(Media = mean(DIVERSITY),\n            Desvio = sd(DIVERSITY))\nmedley_barras |&gt; \n  gt()\n\n\n\n\n\n\n\nZINC\nMedia\nDesvio\n\n\n\n\nBACK\n1.797500\n0.4852613\n\n\nLOW\n2.032500\n0.4449960\n\n\nMED\n1.717778\n0.5030104\n\n\nHIGH\n1.277778\n0.4268717\n\n\n\n\n\n\n\nE em seguida plotar a figura.\n\nggplot(medley_barras, aes(x = ZINC)) +\n  geom_point(aes(y = Media), size = 3) +\n  geom_errorbar(aes(ymin = Media - Desvio,\n                    ymax = Media + Desvio), width = 0.4) +\n  labs(y = 'DIVERSITY') +\n  theme_classic(base_size = 15)\n\n\n\n\n\n\n\n\nAqui vemos somente os pontos m√©dios e as barras de erro, que est√£o √† dist√¢ncia de \\(1\\) desvio padr√£o acima e abaixo da m√©dia (\\(\\overline{Y} \\pm 1s\\)). Embora tenhamos expressado as dist√¢ncias utilizado o desvio padr√£o como medida de varia√ß√£o, poder√≠amos ter utilizado outras medidas como o erro padr√£o ou o intervalo de confian√ßa O importante √© sempre deixar claro qual medida de varia√ß√£o est√° semdo representada no gr√°fico de erros (Veja: Krzywinski & Altman, 2013 - Error bars - Points of Significance)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#parti√ß√£o-das-soma-dos-quadrados",
    "href": "content/medidas-associacao/biquantquali.html#parti√ß√£o-das-soma-dos-quadrados",
    "title": "Associa√ß√£o entre vari√°veis quantitativas e qualitativas",
    "section": "2 Parti√ß√£o das Soma dos Quadrados",
    "text": "2 Parti√ß√£o das Soma dos Quadrados\nAo representarmos a distribui√ß√£o de uma vari√°vel \\(Y\\) cont√≠nua em fun√ß√£o de uma vari√°vel \\(X\\) categ√≥rica, geralmente estamos interessados em determinar se os diferentes n√≠veis de \\(X\\) (diferentes grupos) t√™m m√©dias similares ou se ao menos um dos n√≠veis t√™m m√©dia diferente dos demais. Queremos uma medida que nos permita diferenciar situa√ß√µes como as apresentadas abaixo.\n\n\n\n\n\n\n\n\n\nNa figura \\(A\\) todos os grupos s√£o provenientes da mesma distribui√ß√£o e t√™m m√©dias aproximadamente iguais (\\(\\overline{Y}_A \\approx  \\overline{Y}_B \\approx \\overline{Y}_C \\approx \\overline{Y}_D\\)). Na figura \\(B\\) o segundo grupo tem m√©dia mais elevada que os demais, e na da figura \\(C\\), todas as m√©dias parecem ser diferentes entre si (\\(\\overline{Y}_A \\ne  \\overline{Y}_B \\ne \\overline{Y}_C \\ne \\overline{Y}_D\\)).\nPara mensurar o grau de associa√ß√£o entre \\(Y\\) e \\(X\\) e entender como podemos diferenciar as situa√ß√µes acima, vamos introduzir o processo de Parti√ß√£o da Soma dos Quadrados.\nSuponha a situ√ß√£o abaixo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota√ß√µes\n\n\n\n\nTemos \\(k = 3\\) grupos (A, B ou C) e para cada grupo \\(n =  5\\) observa√ß√µes. Denotamos por \\(n_{ij}\\) o n√∫mero de observa√ß√µes dentro de cada grupo, em que \\(i\\) √© a i-√©sima observa√ß√£o (\\(i = 1\\) a \\(5\\)) do j-√©simo grupo (\\(j = 1\\) a \\(3\\) - grupos A ao C). Neste exemplo, o n√∫mero de observa√ß√µes em cada grupo √© o mesmo (\\(n_1 = n_2 = n_3 = n\\)), de modo que o total de observa√ß√µes √© dado por:\n\n\\(N = k \\times n = n_1 + n_2 + n_3 = 15\\)\n\nA m√©dia de cada grupo ser√° denotada por \\(\\overline{Y}_j\\), que neste exemplo s√£o: \\(Y_1 = 20.64\\) (grupo A), \\(Y_2 = 28.68\\) (grupo B) e \\(Y_3 = 12.18\\) (grupo C).\nVamos denotar por \\(\\overline{\\overline{Y}}\\) a Grande M√©dia, isto √©, a m√©dia geral de todas as observa√ß√µes independente do grupo de origem.\n\n\\[\\overline{\\overline{Y}} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}\\frac{Y_{ij}}{N} = \\frac{\\overline{Y_1} + \\overline{Y_2} + \\overline{Y_3}}{3} = 20.5\\]\n\n\nPodemos agora observar estes elementos no gr√°fico de dispers√£o.\n\n\n\n\n\n\n\n\n\nEm seguida, precisamos calcular \\(3\\) quantias, a Soma dos Quadrados Totais (\\(SQ_{Total}\\)), a Soma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\) e a Soma dos Quadrados dos Res√≠duos \\(SQ_{Res}\\).\n\nSoma dos Quadrados Totais \\(SQ_{Total}\\): mede as diferen√ßas entre \\(Y_{ij}\\) e \\(\\overline{\\overline{Y}}\\). Temos nesta express√£o o somat√≥rio dos desvios ao quadrado de todas as observa√ß√µes com rela√ß√£o √† grand, fig.align=‚Äòcenter‚Äô, fig.width=8, fig.height=4e m√©dia independente do grupo de origem de cada observa√ß√£o.\n\n\\[SQ_{Total} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Tratamentos \\(SQ_{Trat}\\): mede as diferen√ßas entre as m√©dias dos tratamentos \\(\\overline{Y}_j\\) e \\(\\overline{\\overline{Y}}\\), sendo portanto os desvios ao quadrado da m√©dia de cada tratamento subtra√≠da da grande m√©dia. \\(SQ_{Trat}\\) tamb√©m √© chamada de soma dos quadrados entre grupos ou entre tratamentos\n\n\\[SQ_{Trat} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(\\overline{Y}_{j} - \\overline{\\overline{Y}})^2\\]\n\nSoma dos Quadrados dos Res√≠duos \\(SQ_{Res}\\): mede as diferen√ßas entre cada observa√ß√£o \\(Y_{ij}\\) e a m√©dia de seu pr√≥prio grupo \\(\\overline{Y}_{j}\\). \\(SQ_{Res}\\) tamb√©m √© chamada de soma dos quadrados dentro dos grupos ou dentro dos tratamentos\n\n\\[SQ_{Res} = \\sum_{j = 1}^{k}\\sum_{i = 1}^{n_{j}}(Y_{ij} - \\overline{Y}_{j})^2\\]\n\n\n\n\n\n\nA caracter√≠stica aditiva das somas dos quadrados\n\n\n\nA parti√ß√£o da soma dos quadrados consiste em decompor a varia√ß√£o total do experimento em uma parcela atribu√≠da √† varia√ß√£o entre tratamentos e outra parcela da varia√ß√£o dentro dos tratamentos. Isto √© poss√≠vel pois as somas dos quadrados definidas acima podem ser expressas de forma aditiva como:\n\\[SQ_{Total} = SQ_{Trat} + SQ_{Res}\\]\nDeste modo, √© poss√≠vel demostrar que:\n\\(\\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{\\overline{Y}})^2 = \\sum_{j = 1}^{k}n_{j}(Y_{j} - \\overline{\\overline{Y}})^2 + \\sum_{j = 1}^{k}\\sum_{i = 1}^{n}(Y_{ij} - \\overline{Y}_{j})^2\\)"
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#medindo-a-associa√ß√£o-entre-y-e-x",
    "href": "content/medidas-associacao/biquantquali.html#medindo-a-associa√ß√£o-entre-y-e-x",
    "title": "Associa√ß√£o entre vari√°veis quantitativas e qualitativas",
    "section": "3 Medindo a associa√ß√£o entre \\(Y\\) e \\(X\\)",
    "text": "3 Medindo a associa√ß√£o entre \\(Y\\) e \\(X\\)\nA caracter√≠stica aditiva das somas dos quadrados pode ser utilizada para mensurar o grau de depend√™ncia de \\(Y_{ij}\\) com respeito aos diferentes tratamentos. Compare as duas figuras abaixo:\n\n\n\n\n\n\n\n\n\nA soma dos quadrados dentro dos grupos √© a mesma nas duas figuras (\\(SQ_{Res} = 362.6\\)). No entanto, na figura da esquerda, em que as m√©dias dos tratamentos s√£o similares (e consequentemente pr√≥ximas √† grande m√©dia), a soma dos quadrados entre os tratamentos √© muito menor (\\(SQ_{Trat}^{esquerda} = 15.8\\)) que na figura da direita, em que as m√©dias dos tratamentos est√£o distantes entre si (\\(SQ_{Trat}^{direita} = 680.8\\)). √â desta forma que a parti√ß√£o das somas dos quadrados nos permite diferenciar situa√ß√µes em que: i - a m√©dia dos grupos depende dos n√≠veis do tratamento (figura da direita); de situa√ß√µes em que ii - a m√©dia n√£o depende dos n√≠veis do tratamento (figura da esquerda).\n\n3.1 O coeficiente de determina√ß√£o (\\(R^2\\))\nPodemos expressar a rela√ß√£o entre \\(SQ_{Trat}\\) e \\(SQ_{Total}\\) pela express√£o:\n\n\\[R^2 = \\frac{SQ_{Trat}}{SQ_{Trat} + SQ_{Res}} = \\frac{SQ_{Trat}}{SQ_{Total}}\\]\n\n\\(R^2\\) √© chamado de coeficiente de determina√ß√£o e varia entre \\(0\\) e \\(1\\). Se \\(R^2 = 0\\) toda a varia√ß√£o em \\(Y\\) √© causada por \\(SQ_{Res}\\) (\\(\\overline{\\overline{Y}} = \\overline{Y}_1 = \\overline{Y}_2 = \\cdots = \\overline{Y}_k\\)). √Ä medida que as m√©dias dos tratamentos se distanciam umas das outras, \\(R^2\\) se aproxima de \\(1\\) pois a maior parte da varia√ß√£o em \\(Y\\) √© causada por \\(SQ_{Trat}\\)."
  },
  {
    "objectID": "content/medidas-associacao/biquantquali.html#parti√ß√£o-das-soma-dos-quadrados-no-ambiente-r",
    "href": "content/medidas-associacao/biquantquali.html#parti√ß√£o-das-soma-dos-quadrados-no-ambiente-r",
    "title": "Associa√ß√£o entre vari√°veis quantitativas e qualitativas",
    "section": "4 Parti√ß√£o das Soma dos Quadrados no ambiente R",
    "text": "4 Parti√ß√£o das Soma dos Quadrados no ambiente R\nVoltando ao conjundo de dados medley.csv, uma forma de obter os somat√≥rios dos quadrados no R √© utilizando a fun√ß√£o aov (mas veja tamb√©m a fun√ß√£o lm).\n\naov(DIVERSITY ~ ZINC, data = medley)\n\nCall:\n   aov(formula = DIVERSITY ~ ZINC, data = medley)\n\nTerms:\n                    ZINC Residuals\nSum of Squares  2.566612  6.516411\nDeg. of Freedom        3        30\n\nResidual standard error: 0.4660619\nEstimated effects may be unbalanced\n\n\nO resultado retorna a soma dos quadrados dos tratamentos (neste caso a coluna ZINC) e dos res√≠duos (coluna Residuals). Como o \\(SQ_{Total}\\) √© simplesmente a soma dos dois anteriores, podemos obt√™-lo facilmente:\n\nsq = aov(DIVERSITY ~ ZINC, data = medley)\nSQTrat = anova(sq)$`Sum Sq`[1]\nSQRes = anova(sq)$`Sum Sq`[2]\nSQTotal = SQTrat + SQRes\n\nSQTotal\n\n[1] 9.083024\n\n\nPor fim, o \\(R^2\\) pode ser calculado por:\n\nR2 = SQTrat / SQTotal\nR2\n\n[1] 0.2825725"
  },
  {
    "objectID": "content/medidas-associacao/series.html",
    "href": "content/medidas-associacao/series.html",
    "title": "1 S√©ries de dados no tempo e no espa√ßo",
    "section": "",
    "text": "1 S√©ries de dados no tempo e no espa√ßo"
  },
  {
    "objectID": "content/fundamentos-probabilidade/combina-probabilidades.html",
    "href": "content/fundamentos-probabilidade/combina-probabilidades.html",
    "title": "Combinando as probabilidades de eventos",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(ggVennDiagram)"
  },
  {
    "objectID": "content/fundamentos-probabilidade/combina-probabilidades.html#eventos-complexos",
    "href": "content/fundamentos-probabilidade/combina-probabilidades.html#eventos-complexos",
    "title": "Combinando as probabilidades de eventos",
    "section": "1 Eventos complexos",
    "text": "1 Eventos complexos\nConsideremos a seguinte situa√ß√£o: h√° dois tipos principais de estruturas nas quais um animal aqu√°tico pode procurar suas presas: folhas e galhos. As folhas podem conter entre 0 e 6 itens, enquanto os galhos podem conter entre 0 e 4 itens. Ao virar qualquer uma dessas estruturas, o predador consome todos os itens encontrados. Embora seja um exemplo altamente hipot√©tico, ele serve para ilustrar nossa discuss√£o. A pergunta que nos interessa √©: ao virar uma dessas estruturas, de quantos itens o predador poder√° se alimentar?\nVejamos as possibilidades. Denotemos por \\(F\\) ou \\(G\\) o evento de encontrar, respectivamente, uma folha ou um galho, e por \\(0\\) a \\(n\\) o n√∫mero de itens presentes. O espa√ßo amostral do experimento ‚Äî virar uma estrutura e contar quantos itens h√° ‚Äî √© dado por:\n\\[\\Omega = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6), (G0), (G1), (G2), (G3), (G4)}\\}.\\]\nNote que h√° \\(\\text{12}\\) eventos simples e mutuamente exclusivos.\nConsidere agora o evento \\(A\\): ‚Äúvirar uma folha‚Äù, que ocorre quando observamos F0 ou F1 ou F2 ou F3 ou F4 ou F5 ou F6. Em nota√ß√£o de conjunto:\n\\[A = \\{\\text{(F0), (F1), (F2), (F3), (F4), (F5), (F6)}\\}.\\]\nO evento \\(A\\) √© um evento complexo, pois consiste na uni√£o de v√°rios eventos simples. Ou seja, podemos dizer que \\(A\\) acontece se a estrutura virada for uma folha com \\(0\\) OU \\(1\\) OU \\(2\\) OU \\(3\\) OU \\(4\\) OU \\(5\\) OU \\(6\\) itens. A palavra OU indica que basta qualquer uma dessas possibilidades para o evento ser considerado realizado, o que significa que \\(A\\) pode ocorrer de 7 maneiras diferentes.\nAssim, podemos representar \\(A\\) pela express√£o:\n\\[A = F0 \\cup F1 \\cup F2 \\cup F3 \\cup F4 \\cup F5 \\cup F6,\\]\nonde, o s√≠mbolo \\(\\cap\\) √© sendo lido como OU.\n\n1.1 Representa√ß√£o de eventos: diagrama de Venn\nUma forma de visualizar o espa√ßo amostral e seus eventos √© por meio de diagramas de Venn. Para isso, vamos considerar tamb√©m o evento \\(B\\): ‚Äúencontrar mais de 3 itens‚Äù, que consiste em:\n\\[B = \\{\\text{(F3), (F4), (F5), (F6), (G3), (G4)}\\}.\\]\nObservando \\(A\\) e \\(B\\) em um Diagrama de Venn, temos:\n\n\n\n\n\n\n\n\n\nO evento \\(B\\) tamb√©m √© um evento complexo que ocorre quando se encontra uma folha OU um galho que tenham 3 ou mais itens.\nObserve que as ocorr√™ncias \\((G0)\\), \\((G1)\\) e \\((G2)\\) n√£o pertencem a \\(A\\) nem a \\(B\\), embora fa√ßam parte do espa√ßo amostral \\(\\Omega\\).\nConsidere agora o evento \\(C\\): ‚Äúvirar uma folha com mais de 3 itens‚Äù. Ele pode ocorrer ao observar F3 ou F4 ou F5 ou F6. No diagrama de Venn, vemos que essas possibilidades constituem a intersec√ß√£o de \\(A\\) e \\(B\\) representada por \\(\\cap\\). Portanto, podemos escrever \\(C\\) como:\n\\[C = A \\cap B.\\]\n\n\n1.2 Probabilidade de eventos complexos\nConsiderando o experimento virar uma estrutura e contar o n√∫mero de itens, qual seria a probabilidade de cada observa√ß√£o? Para isso, lembremos que:\n\nO espa√ßo amostral consiste em \\(N = \\text{12}\\) observa√ß√µes.\nDefiniremos um modelo de probabilidade para cada uma dessas observa√ß√µes.\n\nNeste t√≥pico, vamos assumir um modelo de probabilidade uniforme, ou seja, cada observa√ß√£o tem a mesma probabilidade \\(\\frac{1}{N}\\).\nDessa forma, a probabilidade do evento \\(A\\) ocorrer √© dada pelo n√∫mero de resultados favor√°veis a \\(A\\) dividido pelo n√∫mero total de resultados no espa√ßo amostral. Como \\(A\\) consiste de 7 observa√ß√µes:\n\\[P(A) = \\frac{7}{12} = 0.58\\]\nNaturalmente, a probabilidade de \\(A\\) n√£o ocorrer √©:\n\\[P(\\overline{A}) = 1 - \\frac{7}{12} = 1 - 0.58 = 0.42\\]\nO s√≠mbolo \\(\\overline{A}\\) representa todas as observa√ß√µes que n√£o pertencem a \\(A\\).\nConsidere tamb√©m a probabilidade de \\(B\\) que consiste de 6 observa√ß√µes:\n\\[P(B) = \\frac{6}{12} = 0.5\\]\nVemos tamb√©m que o evento \\(C = A \\cap B\\), consiste de 4 observa√ß√µes e portanto:\n\\[P(C) = P(A \\cap B) = \\frac{4}{12} = 0.33\\]\n\n\n1.3 Probabilidade da uni√£o de eventos\nO evento \\(A \\cup B\\) consiste em todas as observa√ß√µes que estejam em \\(A\\) ou \\(B\\):\n\\(A \\cup B = \\{(F0),(F1),(F2),(F3),(F4),(F5),(F6),(G3),(G4) \\}\\)\nH√° 9 ocorr√™ncias em \\(A \\cup B\\), de modo que:\n\\[P(A \\cup B) = \\frac{9}{12} = 0.75\\]\nDo diagrama de Venn, fica f√°cil verificar que o n√∫mero de eventos em \\(A \\cup B\\) pode ser obtido pelo n√∫mero de eventos em \\(A\\) somados ao n√∫mero de eventos em \\(B\\) e subtra√≠do pelo n√∫mero de evendos que ocorrem em ambos (\\(A \\cap B\\)).\nAssim:\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\\[P(A \\cup B) = 0.58 + 0.5 - 0.33 = 0.75\\]"
  },
  {
    "objectID": "content/fundamentos-probabilidade/espaco-amostral.html",
    "href": "content/fundamentos-probabilidade/espaco-amostral.html",
    "title": "Espa√ßo de possibilidades de um experimento",
    "section": "",
    "text": "Pacotes e fun√ß√µes utilizadas\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(gt)\nConsidere uma pesquisa para determinar os locais de ocorr√™ncia de uma esp√©cie de peixe end√™mica de riachos costeiros de Mata Atl√¢ntica no sudeste do Brasil. A pesquisa envolve amostrar trechos de riachos em diferentes bacias hidrogr√°ficas da regi√£o. Ao amostrar um determinado riacho, o pesquisador n√£o sabe antecipadamente se ir√° ou n√£o encontrar a esp√©cie. Em probabilidade, chamamos esse ato de experimento aleat√≥rio, pois o resultado s√≥ √© conhecido ap√≥s a realiza√ß√£o.\nEmbora n√£o saibamos o resultado de um experimento espec√≠fico, sabemos quais s√£o os resultados poss√≠veis. Neste exemplo, vamos assumir que existem apenas dois resultados para o ato de amostrar um riacho: ou a esp√©cie ocorre, ou n√£o ocorre.\nNo caso em quest√£o:\n\\(\\Omega = {(ocorre), (n√£o-ocorre)}\\)"
  },
  {
    "objectID": "content/fundamentos-probabilidade/espaco-amostral.html#probabilidades-de-um-evento",
    "href": "content/fundamentos-probabilidade/espaco-amostral.html#probabilidades-de-um-evento",
    "title": "Espa√ßo de possibilidades de um experimento",
    "section": "1 Probabilidades de um evento",
    "text": "1 Probabilidades de um evento\nMesmo sem saber o resultado de um experimento particular, podemos perguntar sobre a chance de cada evento ocorrer. Em termos probabil√≠sticos, estamos interessados em \\(P(ocorre)\\). Quando \\(P(ocorre) = 0\\), significa que a esp√©cie jamais ocorre nos riachos; quando \\(P(ocorre) = 1\\), significa que a esp√©cie ocorre em todos os riachos. Na pr√°tica, a probabilidade ficar√° entre esses extremos: \\(0 \\le P(ocorre) \\le 1\\).\nPodemos estimar essa probabilidade empiricamente. Suponha que planejamos amostrar um determinado n√∫mero de riachos, observando quantas vezes a esp√©cie √© capturada.\nDigamos que em certo dia foram amostrados 10 riachos e a esp√©cie foi registrada em 4 deles. Nossa estimativa da probabilidade de ocorr√™ncia ser√°:\n\\[P(ocorre) = \\frac{\\#ocorres}{\\#riachos} = \\frac{4}{10} = 0.4\\]\nNaturalmente, como os dois eventos no espa√ßo amostral s√£o \\((ocorre)\\) e \\((n√£o-ocorre)\\), a probabilidade de n√£o-ocorr√™ncia √©:\n\\[P(n√£o-ocorre) = 1 - \\frac{\\#n√£o-ocorre}{\\#riachos} = 1 - \\frac{4}{10} = 0.6\\]\ne, sendo eventos mutuamente exclusivos e exaustivos (n√£o podem ocorrer juntos e s√£o as √∫nicas possibilidades), temos:\n\\[P(ocorre) + P(n√£o-ocorre) = 1 = P(\\Omega)\\]\nA probabilidade de n√£o-ocorr√™ncia tamb√©m √© conhecida como complemento de \\(P(ocorre)\\), frequentemente denotado por \\(P(\\overline{ocorre})\\):\n\\[P(n√£o-ocorre) = P(\\overline{ocorre})\\]\n\n1.1 Estimando probabilidades\nA estimativa acima descreve o resultado para um conjunto fixo de 10 riachos. No entanto, se continuarmos a amostrar novos riachos, essa estimativa pode variar, pois eventualmente encontraremos mais (ou menos) riachos com a esp√©cie presente. Assim, com um n√∫mero finito de observa√ß√µes, nossa estimativa n√£o ser√° exatamente igual √† probabilidade real.\nSuponha que repetimos o experimento em 30 riachos. A cada nova amostra coletada, calculamos a fra√ß√£o acumulada de ocorr√™ncias:\n\n\n\n\n\n\n\n\nObserva√ß√µes\nOcorr√™ncia acumulada\nP(ocorre)\n\n\n\n\n1\n0\n0.0000000\n\n\n2\n0\n0.0000000\n\n\n3\n1\n0.3333333\n\n\n4\n1\n0.2500000\n\n\n5\n1\n0.2000000\n\n\n6\n2\n0.3333333\n\n\n7\n2\n0.2857143\n\n\n8\n3\n0.3750000\n\n\n9\n4\n0.4444444\n\n\n10\n4\n0.4000000\n\n\n11\n4\n0.3636364\n\n\n12\n4\n0.3333333\n\n\n13\n4\n0.3076923\n\n\n14\n4\n0.2857143\n\n\n15\n4\n0.2666667\n\n\n16\n5\n0.3125000\n\n\n17\n5\n0.2941176\n\n\n18\n5\n0.2777778\n\n\n19\n5\n0.2631579\n\n\n20\n5\n0.2500000\n\n\n21\n5\n0.2380952\n\n\n22\n5\n0.2272727\n\n\n23\n5\n0.2173913\n\n\n24\n5\n0.2083333\n\n\n25\n5\n0.2000000\n\n\n26\n6\n0.2307692\n\n\n27\n6\n0.2222222\n\n\n28\n6\n0.2142857\n\n\n29\n6\n0.2068966\n\n\n30\n7\n0.2333333\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote como a estimativa de \\(P(ocorre)\\) oscila. Espera-se que este valor gradualmente aproxime-se para probabilidade real √† medida que o n√∫mero de observa√ß√µes cresce.\n\n\n\n\n\n\nLei dos Grandes N√∫meros\n\n\n\nA Lei dos Grandes N√∫meros afirma que, √† medida que o n√∫mero de repeti√ß√µes de um experimento aleat√≥rio cresce, a frequ√™ncia relativa de um evento tende a se aproximar da probabilidade real desse evento. Portanto, se continuarmos amostrando mais riachos, a propor√ß√£o de vezes em que a esp√©cie ocorre deve convergir para a probabilidade verdadeira de ocorr√™ncia."
  }
]