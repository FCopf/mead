---
title: "Probabilidade condicional e independência"
description: "Exploração da probabilidade condicional e independência, com aplicações do Teorema de Bayes."
categories: [
          "Probabilidade condicional",
          "Eventos dependentes",
          "Teorema de Bayes",
          "Diagrama de árvore"
        ]
image: "images/probabilidade-condicional.png"
execute:
  echo: true
  warning: false
  include: true
  message: false

format:
  html:
    self-contained: false
---
:::{.callout-tip collapse="true"}
## Pacotes e funções utilizadas

```{r}
#| output: false
library(tidyverse)
library(gt)
library(ggVennDiagram)
source("scripts/conditional-tree.r")
```
:::

```{r}
#| echo: false
nfolha = 0:6
ngalho = 0:4
```

```{r}
#| echo: false
omega <- paste("(", c(paste("F", nfolha, sep=''), paste("G", ngalho, sep='')), ")", sep = '')
omega_text <- paste(omega, collapse = ", ")
eventos <- list(
  A = paste("(F", nfolha,")", sep = ''),
  B = c("(F3)","(F4)","(F5)","(F6)","(G3)","(G4)")
)
PA = length(eventos[[1]])/length(omega)
PB = length(eventos[[2]])/length(omega)
AsumB = c(eventos$A,eventos$B)
C = AsumB[duplicated(AsumB)]
PC = round(length(C)/length(omega),2)
PB_dado_A = PC / PA
```


## Probabilidade Condicional

Consideremos o experimento *“virar uma estrutura (folha ou galho) e contar o número de itens”*:

$\Omega = \{`r omega_text`\}$

Sejam definidos os eventos:

- $A$: “virar uma folha”:  
  $$A = \{\text{`r paste(eventos[[1]], collapse = ", ")`}\}.$$

- $B$: “obter 3 ou mais itens”:  
  $$B = \{\text{`r paste(eventos[[2]], collapse = ", ")`}\}.$$

Que podem ser representados no diagrama de Venn:

```{r}
#| echo: false
#| fig-align: "center"
#| width: 8
#| height: 5
ggVennDiagram(eventos, fill = NA, label = NULL) + 
  annotate(
    geom="text", 
    x = c(+0.0, -2.5, +2.5, -2.2, +0.0, +2.2, +0.0, -4.0, +3.5, -4.3, -2.2, +2.2), 
    y = c(-3.1, -1.0, -1.0, +2.0, +0.8, +2.0, +3.3, +8.0, +8.0, +6.5, +5.0, +5.0), 
    label = omega,
    color = "red", size = 5
  ) +
  theme(legend.position = "none")
```

Podemos perguntar:

> Considerando que tenha sido virada uma folha, qual a probabilidade de que tenham sido obtidos **mais de 3 itens**?

Ao informar que a estrutura era uma folha, sabemos que nem todos os eventos de $\Omega$ podem ter ocorrido. Neste exemplo, *somente* as `r length(eventos[[1]])` observações do evento e $A$ consistem de uma folha.

Destas, apenas `r length(C)` possuem mais de 3 itens, de modo a resposta à pergunta seria $\frac{`r length(C)`}{`r length(eventos[[1]])`}$. Este resultado é conhecido como **probabilidade condicional**, denotada pelo símbolo ($|$). Neste exemplo específico estamos perguntando:

> **Dado** que $A$ OCORREU, qual a probabilidade de que $B$ ocorra? Simbolicamente, esta questão é escrita como $P(B|A)$ e lida como **probabilidade de $B$ dado $A$**.

$$P(B|A) = \frac{`r length(C)`}{`r length(eventos[[1]])`} = `r round(length(C)/length(eventos[[1]]),2)`$$

Esta probabilidade condicional foi calculada pelo número de observações favoráveis à intersecção de $A$ e $B$ ($A \cap B$) **relativa** ao número de observações do evento $A$. Isto significa que ao sabermos parte dos resultados, o espaço amostral inicial foi **reduzido**, neste caso, ao espaço coincidente com $A$.

Deste modo, a **probabilidade condicional** pode ser expressacomo:

$$P(B \mid A) = \frac{P(A \cap B)}{P(A)}$$

que neste exemplo será:

$$P(B \mid A) = \frac{P(A \cap B)}{P(A)} = \frac{`r length(C)`}{`r length(eventos[[1]])`} = `r round(PB_dado_A,2)`$$

## Representação de eventos: diagrama de árvore

Quando lidamos com experimentos em etapas ou eventos sequenciais, um **diagrama de árvore** ajuda a visualizar cada estágio, indicando as probabilidades e as condicionais:


```{r}
#| echo: false
#| fig-align: "center"
#| width: 8
#| height: 5
conditional_tree()
```

Nesse diagrama, cada ramo representa um cenário: por exemplo, ao ocorrer $A$, $B$ pode acontecer com $P(B \mid A)$, resultando na intersecção $A \cap B$. Assim, o diagrama possibilita mapear todos os cenários possíveis de maneira organizada.

## Eventos independentes

Dois eventos $A$ e $B$ são **independentes** quando conhecer a ocorrência de um deles **não altera** a probabilidade do outro, ou seja, conhecer $A$ não nos diz nada sobre a probabilidade de ocorrência de $B$, de modo que $P(B) = P(B \mid A)$.

No experimento “virar uma estrutura e contar o número de itens”, temos por exemplo.

$P(B) = `r round(PB,2)`$

e que

$P(B \mid A) = `r round(PB_dado_A,2)`$

Portanto, ao sabermos que a estrutura virada foi uma folha, a probalidade de que tenham sido observados 3 ou mais items foi alterada.

Os eventos $A$ e $B$ são portanto **eventos dependentes** em que $P(B) \neq P(B \mid A)$.

### Exemplo de eventos independentes

```{r}
#| echo: false
visita_df <- tibble(
  idade = c("Até 20", "Mais de 20"),
  `Da cidade` = c(30, 60),
  `De fora da cidade` = c(170, 340)
)
visita = as.matrix(visita_df[,-1])
N = sum(visita)
idade <- apply(visita,1,sum)
regi <- apply(visita,2,sum)
```

Suponha que foram investigadas `r N` pessoas, classificadas por idade e local de origem. Nesse contexto temos os eventos:

- $A$: ter até 20 anos; $\overline{A}$: ter mais de 20 anos.  
- $B$: ser da cidade; $\overline{B}$: ser de fora da cidade.

Considere a matriz:

```{r}
#| echo: false
visita_df |> 
  gt()
```



As probabilidades são:

$P(A) = \frac{`r visita[1,1] + visita[1,2]`}{`r N`} = `r round((visita[1,1] + visita[1,2])/N,2)`$

$P(\overline{A}) \;=\; \frac{`r visita[2,1] + visita[2,2]`}{`r N`} = `r round((visita[2,1] + visita[2,2])/N,2)`$

$P(B) = \frac{`r visita[1,1] + visita[2,1]`}{`r N`} = `r round((visita[1,1] + visita[2,1])/N,2)`$

$P(\overline{B}) \;=\; \frac{`r visita[1,2] + visita[2,2]`}{`r N`} = `r round((visita[1,2] + visita[2,2])/N,2)`$

Sabendo, por exemplo, que a pessoa tem mais de 20 anos, a probabilidade de ela ser da cidade é:

$$P(B \mid A) = \frac{`r visita[2,1]`}{`r sum(visita[2,])`} = `r round(visita[2,1]/sum(visita[2,]),2)`.$$

Uma vez que $P(B) = P(B \mid A)$, então $A$ e $B$ são eventos independentes.


## Eventos independentes *vs* mutuamente exclusivos

- Dois eventos são **mutuamente exclusivos** quando $P(A \cap B) = 0$. Se ambos ocorrerem, excluem-se mutuamente. Logo, se $A$ ocorre, $B$ não pode ocorrer. Nesse caso, $P(B \mid A) = 0$, caracterizando dependência, pois a informação de $A$ **determina** que $B$ não ocorrerá.

- Dois eventos são **independentes** se $P(A \cap B) = P(A)\times P(B)$. Isso significa que conhecer $A$ não altera a probabilidade de $B$. Se $P(A)$ e $P(B)$ forem não nulos, então não podem ser ao mesmo tempo mutuamente exclusivos **e** independentes.

A representação de eventos mutuamente exclusivos no diagrama de árvore é ilustrada por $P(B \mid A)=0$, pois, ao ocorrer $A$, já se sabe que $B$ não ocorrerá. Assim, eventos *mutuamente exclusivos* implica serem eventos dependentes. Se não há exclusividade, os eventos podem ou não ser independentes, dependendo de $P(B)$ em relação a $P(B \mid A)$.

```{r}
#| echo: false
conditional_tree(prob_text = expression(
  P(A),
  P(bar(A)),
  P(B~"|"~A) == 0,
  P(bar(B)~"|"~A) == 1,
  P(B~"|"~bar(A)),
  P(bar(B)~"|"~bar(A))
),
final_text = rep(" ",4))
```
